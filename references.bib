
@article{van_den_dries_fluorescence_2022,
	title = {Fluorescence {CLEM} in biology: historic developments and current super‐resolution applications},
	volume = {596},
	issn = {0014-5793, 1873-3468},
	shorttitle = {Fluorescence {CLEM}},
	url = {https://febs.onlinelibrary.wiley.com/doi/10.1002/1873-3468.14421},
	doi = {10.1002/1873-3468.14421},
	abstract = {Correlative light and electron microscopy (CLEM) is a powerful imaging approach that allows the direct correlation of information obtained on a light and an electron microscope. There is a growing interest in the application of CLEM in biology, mainly attributable to technical advances in field of fluorescence microscopy in the past two decades. In this review, we summarize the important developments in CLEM for biological applications, focusing on the combination of fluorescence microscopy and electron microscopy. We first provide a brief overview of the early days of fluorescence CLEM usage starting with the initial rise in the late 1970s and the subsequent optimization of CLEM workflows during the following two decades. Next, we describe how the engineering of fluorescent proteins and the development of super‐resolution fluorescence microscopy have significantly renewed the interest in CLEM resulting in the present application of fluorescence CLEM in many different areas of cellular and molecular biology. Lastly, we present the promises and challenges for the future of fluorescence CLEM discussing novel workflows, probe development and quantification possibilities.},
	language = {en},
	number = {19},
	urldate = {2024-03-20},
	journal = {FEBS Letters},
	author = {Van Den Dries, Koen and Fransen, Jack and Cambi, Alessandra},
	month = oct,
	year = {2022},
	pages = {2486--2496},
}

@article{shen_single_2017,
	title = {Single {Particle} {Tracking}: {From} {Theory} to {Biophysical} {Applications}},
	volume = {117},
	issn = {0009-2665, 1520-6890},
	shorttitle = {Single {Particle} {Tracking}},
	url = {https://pubs.acs.org/doi/10.1021/acs.chemrev.6b00815},
	doi = {10.1021/acs.chemrev.6b00815},
	language = {en},
	number = {11},
	urldate = {2024-03-19},
	journal = {Chemical Reviews},
	author = {Shen, Hao and Tauzin, Lawrence J. and Baiyasi, Rashad and Wang, Wenxiao and Moringo, Nicholas and Shuang, Bo and Landes, Christy F.},
	month = jun,
	year = {2017},
	pages = {7331--7376},
}

@article{liu_combination_2011,
	title = {Combination of sources of evidence with different discounting factors based on a new dissimilarity measure},
	volume = {52},
	issn = {01679236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167923611001187},
	doi = {10.1016/j.dss.2011.06.002},
	language = {en},
	number = {1},
	urldate = {2024-03-19},
	journal = {Decision Support Systems},
	author = {Liu, Zhun-ga and Dezert, Jean and Pan, Quan and Mercier, Grégoire},
	month = dec,
	year = {2011},
	pages = {133--141},
}

@article{nomura_tyrosine-phosphorylated_1999,
	title = {Tyrosine-phosphorylated {Caveolin}-1: {Immunolocalization} and {Molecular} {Characterization}},
	volume = {10},
	issn = {1059-1524, 1939-4586},
	shorttitle = {Tyrosine-phosphorylated {Caveolin}-1},
	url = {https://www.molbiolcell.org/doi/10.1091/mbc.10.4.975},
	doi = {10.1091/mbc.10.4.975},
	abstract = {Caveolin-1 was discovered as a major substrate for v-Src, but the effect of its tyrosine phosphorylation has not been known. We generated a specific antibody (PY14) to caveolin-1 phosphorylated at tyrosine 14 and studied the significance of the modification. By Western blotting of lysates of v-Src–expressing cells, PY14 recognized not only a 22-kDa band (the position of nonphosphorylated caveolin-1) but bands at 23–24 and 25 kDa. Bands of slower mobility were diminished by dephosphorylation and were also observed for mutant caveolin-1 lacking tyrosine 14. By immunofluorescence microscopy, PY14 did not label normal cells but detected large dots in v-Src–expressing cells. Immunoelectron microscopy revealed that the dots corresponded to aggregated caveolae and/or vesicles of various sizes; besides, the label was observed in intramembrane particle-free areas in the plasma membrane, which appeared to have been formed by fusion of flattened caveolae. A positive reaction with PY14 was found in normal cells after vanadate or pervanadate treatment; it occurred mainly at 22 kDa by Western blotting and was not seen as large dots by immunofluorescence microscopy. Detergent solubility, oligomerization, and association with caveolin-2 were observed similarly for caveolin-1 in normal and v-Src–expressing cells. The results indicate that phosphorylation of caveolin-1 in v-Src–expressing cells occurs at multiple residues and induces flattening, aggregation, and fusion of caveolae and/or caveolae-derived vesicles.},
	language = {en},
	number = {4},
	urldate = {2024-03-19},
	journal = {Molecular Biology of the Cell},
	author = {Nomura, Ryuji and Fujimoto, Toyoshi},
	editor = {Bonifacino, Juan},
	month = apr,
	year = {1999},
	pages = {975--986},
}

@article{snoek_practical_nodate,
	title = {{PRACTICAL} {BAYESIAN} {OPTIMIZATION} {OF} {MACHINE} {LEARNING} {ALGORITHMS}},
	abstract = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization pa-rameters. Unfortunately, this tuning is often a " black art " that re-quires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian opti-mization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference pro-cedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning al-gorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can lever-age the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks. 1. Introduction. Machine learning algorithms are rarely parameter-free; whether via the properties of a regularizer, the hyperprior of a generative model, or the step size of a gradient-based optimization, learning procedures almost always require a set of high-level choices that significantly impact generalization performance. As a practitioner, one is usually able to specify the general framework of an inductive bias much more easily than the particular weighting that it should have relative to training data. As a result, these high-level parameters are often considered a nuisance, making it desirable to develop algorithms with as few of these " knobs " as possible. Another, more flexible take on this issue is to view the optimization of high-level parameters as a procedure to be automated. Specifically, we could view such tuning as the optimization of an unknown black-box function that reflects generalization performance and invoke algo-rithms developed for such problems. These optimization problems have a somewhat different flavor than the low-level objectives one often encounters as part of a training procedure: here function evaluations are very expensive, as they involve running the primary machine learn-ing algorithm to completion. In this setting where function evaluations are expensive, it is desirable to spend computational time making better choices about where to seek the best parameters. Bayesian optimization (Mockus et al., 1978) provides an elegant approach and has been shown to outperform other state of the art global optimization algorithms on a num-ber of challenging optimization benchmark functions (Jones, 2001). For continuous functions, Bayesian optimization typically works by assuming the unknown function was sampled from a},
	urldate = {2017-10-13},
	author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
}

@article{pontes_design_2016,
	title = {Design of experiments and focused grid search for neural network parameter optimization},
	volume = {186},
	issn = {09252312},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231215020184},
	doi = {10.1016/j.neucom.2015.12.061},
	number = {C},
	urldate = {2017-10-13},
	journal = {Neurocomputing},
	author = {Pontes, F.J. and Amorim, G.F. and Balestrassi, P.P. and Paiva, A.P. and Ferreira, J.R.},
	month = apr,
	year = {2016},
	note = {Publisher: Elsevier Science Publishers B. V.},
	keywords = {Artificial Neural Network, Design of Experiment, Focused Grid Search, Machining, Tuning},
	pages = {22--34},
}

@book{yang_twenty-fourth_2015,
	title = {Twenty-{Fourth} {International} {Joint} {Conference} on {Artificial} {Intelligence}, {IJCAI} 2015, {Buenos} {Aires}, {Argentina}, 25-31 {July} 2015},
	isbn = {978-1-57735-738-4},
	url = {https://dl.acm.org/citation.cfm?id=2832731},
	abstract = {El. zbornik. Konferenca IJCAI 2015 vsebuje 43 podkonferenc. Nasl. z nasl. zaslona. Opis vira z dne 7. 8. 2015.},
	urldate = {2017-11-15},
	publisher = {AAAI Press = The Association for the Advancement of Artificial Intelligence Press},
	author = {Yang, Qiang. and Wooldridge, Michael J. and Hutter, Frank},
	year = {2015},
	note = {Publication Title: Proceedings of the 24th International Conference on Artificial Intelligence},
}

@article{ozbey_unsupervised_2023,
	title = {Unsupervised {Medical} {Image} {Translation} {With} {Adversarial} {Diffusion} {Models}},
	volume = {42},
	issn = {1558-254X},
	url = {https://ieeexplore.ieee.org/document/10167641},
	doi = {10.1109/TMI.2023.3290149},
	abstract = {Imputation of missing images via source-to-target modality translation can improve diversity in medical imaging protocols. A pervasive approach for synthesizing target images involves one-shot mapping through generative adversarial networks (GAN). Yet, GAN models that implicitly characterize the image distribution can suffer from limited sample fidelity. Here, we propose a novel method based on adversarial diffusion modeling, SynDiff, for improved performance in medical image translation. To capture a direct correlate of the image distribution, SynDiff leverages a conditional diffusion process that progressively maps noise and source images onto the target image. For fast and accurate image sampling during inference, large diffusion steps are taken with adversarial projections in the reverse diffusion direction. To enable training on unpaired datasets, a cycle-consistent architecture is devised with coupled diffusive and non-diffusive modules that bilaterally translate between two modalities. Extensive assessments are reported on the utility of SynDiff against competing GAN and diffusion models in multi-contrast MRI and MRI-CT translation. Our demonstrations indicate that SynDiff offers quantitatively and qualitatively superior performance against competing baselines.},
	number = {12},
	urldate = {2024-01-15},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Özbey, Muzaffer and Dalmaz, Onat and Dar, Salman U. H. and Bedel, Hasan A. and Özturk, Şaban and Güngör, Alper and Çukur, Tolga},
	month = dec,
	year = {2023},
	pages = {3524--3539},
}

@article{Rajani,
	title = {Parallel k {Nearest} {Neighbor} {Graph} {Construction} {Using} {Tree}-{Based} {Data} {Structures}},
	abstract = {Construction of a nearest neighbor graph is often a neces-sary step in many machine learning applications. However, constructing such a graph is computationally expensive, es-pecially when the data is high dimensional. Python's open source machine learning library Scikit-learn uses k-d trees and ball trees to implement nearest neighbor graph construc-tion. However, this implementation is inefficient for large datasets. In this work, we focus on exploiting these under-lying tree-based data structures to optimize parallel execu-tion of the nearest neighbor algorithm. We present parallel implementations of nearest neighbor graph construction us-ing such tree structures, with parallelism provided by the OpenMP and the Galois framework. We empirically show that our parallel and exact approach is efficient as well as scalable, compared to the Scikit-learn implementation. We present the first implementation of k-d trees and ball trees using Galois. Our results show that k-d trees are faster when the number of dimensions is small (2 d N); ball trees on the other hand scale well with the number of dimensions. Our implementation of ball trees in Galois has almost linear speedup on a number of datasets irrespective of the size and dimensionality of the data.},
	urldate = {2018-02-19},
	author = {Rajani, Nazneen and Mcardle, Kate and Dhillon, Inderjit S},
}

@inproceedings{xuejuan_multi-resolution_2008,
	title = {Multi-resolution analysis of grid point clouds based on wavelet transform},
	doi = {10.1109/CHICC.2008.4605516},
	abstract = {An application of classical wavelet in the realization of the multi-resolution analysis of point cloud is presented in this paper. Firstly, a proper wavelet function and the expending method are determined by analyzing the character of grid point cloud. With the theory of discrete wavelet transform (DWT), the multi-level wavelet decomposition is realized. Based on the band-pass filter property of the wavelet function, the high frequency information in the point cloud is removed, and the low frequency part is reserved. And then the multi-level of detail and multi-resolution models are generated, which are the simplifications of the original point cloud. Finally, the feasibility and the efficiency are proved by a study case.},
	booktitle = {2008 27th {Chinese} {Control} {Conference}},
	author = {Xuejuan, Niu and Jingtai, Liu and Lei, Sun},
	month = jul,
	year = {2008},
	note = {ISSN: 2161-2927},
	keywords = {Discrete wavelet transforms, Geometry, Grid point clouds, Meteorology, Multi-resolution analysis (MRA), Multiresolution analysis, Transforms, Wavelet analysis, Wavelet transform, Wavelet transforms},
	pages = {341--345},
}

@article{Weigert2017,
	title = {Isotropic reconstruction of {3D} fluorescence microscopy images using convolutional neural networks},
	url = {http://arxiv.org/abs/1704.01510},
	abstract = {Fluorescence microscopy images usually show severe anisotropy in axial versus lateral resolution. This hampers downstream processing, i.e. the automatic extraction of quantitative biological data. While deconvolution methods and other techniques to address this problem exist, they are either time consuming to apply or limited in their ability to remove anisotropy. We propose a method to recover isotropic resolution from readily acquired anisotropic data. We achieve this using a convolutional neural network that is trained end-to-end from the same anisotropic body of data we later apply the network to. The network effectively learns to restore the full isotropic resolution by restoring the image under a trained, sample specific image prior. We apply our method to \$3\$ synthetic and \$3\$ real datasets and show that our results improve on results from deconvolution and state-of-the-art super-resolution techniques. Finally, we demonstrate that a standard 3D segmentation pipeline performs on the output of our network with comparable accuracy as on the full isotropic data.},
	urldate = {2017-09-25},
	author = {Weigert, Martin and Royer, Loic and Jug, Florian and Myers, Gene},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.01510},
}

@article{Wang2015,
	title = {Self-{Tuned} {Deep} {Super} {Resolution}},
	url = {http://arxiv.org/abs/1504.05632},
	abstract = {Deep learning has been successfully applied to image super resolution (SR). In this paper, we propose a deep joint super resolution (DJSR) model to exploit both external and self similarities for SR. A Stacked Denoising Convolutional Auto Encoder (SDCAE) is first pre-trained on external examples with proper data augmentations. It is then fine-tuned with multi-scale self examples from each input, where the reliability of self examples is explicitly taken into account. We also enhance the model performance by sub-model training and selection. The DJSR model is extensively evaluated and compared with state-of-the-arts, and show noticeable performance improvements both quantitatively and perceptually on a wide range of images.},
	urldate = {2017-09-28},
	author = {Wang, Zhangyang and Yang, Yingzhen and Wang, Zhaowen and Chang, Shiyu and Han, Wei and Yang, Jianchao and Huang, Thomas S.},
	month = apr,
	year = {2015},
	note = {arXiv: 1504.05632},
}

@inproceedings{gamage_multi-motifgan_2020,
	title = {Multi-{MotifGAN} ({MMGAN}): {Motif}-{Targeted} {Graph} {Generation} {And} {Prediction}},
	shorttitle = {Multi-{MotifGAN} ({MMGAN})},
	url = {https://ieeexplore.ieee.org/abstract/document/9053451?casa_token=z6ElleTkjVYAAAAA:o19plbGFQDzc-1AJTW0ZtPWZbW0Gc-1_ylbCW-K16Va9KDyqaIYla7FlGxUXFJi9q7iCc3liCg},
	doi = {10.1109/ICASSP40776.2020.9053451},
	abstract = {Generative graph models create instances of graphs that mimic the properties of real-world networks. Generative models are successful at retaining pairwise associations in the underlying networks but often fail to capture higher-order connectivity patterns known as network motifs. Different types of graphs contain different network motifs, an example of which are triangles that often arise in social and biological networks. It is hence vital to capture these higher-order structures to simulate real-world networks accurately. We propose Multi-MotifGAN (MMGAN), a motif-targeted Generative Adversarial Network (GAN) that generalizes the benchmark NetGAN approach. The generalization consists of combining multiple biased random walks, each of which captures a different motif structure. MMGAN outperforms NetGAN at creating new graphs that accurately reflect the network motif statistics of input graphs such as Citeseer, Cora and Facebook.},
	urldate = {2023-10-31},
	booktitle = {{ICASSP} 2020 - 2020 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Gamage, Anuththari and Chien, Eli and Peng, Jianhao and Milenkovic, Olgica},
	month = may,
	year = {2020},
	note = {ISSN: 2379-190X},
	pages = {4182--4186},
}

@article{proietti_does_2013,
	title = {Does the {Box}–{Cox} transformation help in forecasting macroeconomic time series?},
	volume = {29},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207012000830},
	doi = {10.1016/j.ijforecast.2012.06.001},
	abstract = {The paper investigates whether transforming a time series leads to an improvement in forecasting accuracy. The class of transformations that is considered is the Box–Cox power transformation, which applies to series measured on a ratio scale. We propose a nonparametric approach for estimating the optimal transformation parameter based on the frequency domain estimation of the prediction error variance, and also conduct an extensive recursive forecast experiment on a large set of seasonal monthly macroeconomic time series related to industrial production and retail turnover. In about a fifth of the series considered, the Box–Cox transformation produces forecasts which are significantly better than the untransformed data at the one-step-ahead horizon; in most cases, the logarithmic transformation is the relevant one. As the forecast horizon increases, the evidence in favour of a transformation becomes less strong. Typically, the naïve predictor that just reverses the transformation leads to a lower mean square error than the optimal predictor at short forecast lead times. We also discuss whether the preliminary in-sample frequency domain assessment conducted here provides reliable guidance as to which series should be transformed in order to improve the predictive performance significantly.},
	language = {en},
	number = {1},
	urldate = {2022-05-17},
	journal = {International Journal of Forecasting},
	author = {Proietti, Tommaso and Lütkepohl, Helmut},
	month = jan,
	year = {2013},
	keywords = {Forecast comparisons, Multi-step forecasting, Nonparametric estimation of prediction error variance, Rolling forecasts},
	pages = {88--99},
}

@article{Zhao2017,
	title = {Loss {Functions} for {Image} {Restoration} {With} {Neural} {Networks}},
	volume = {3},
	issn = {2333-9403},
	url = {http://ieeexplore.ieee.org/document/7797130/},
	doi = {10.1109/TCI.2016.2644865},
	number = {1},
	urldate = {2018-04-23},
	journal = {IEEE Transactions on Computational Imaging},
	author = {Zhao, Hang and Gallo, Orazio and Frosio, Iuri and Kautz, Jan},
	month = mar,
	year = {2017},
	keywords = {Image processing, Image quality, Image restoration, Measurement, Neural networks, image restoration, loss functions, neural networks},
	pages = {47--57},
}

@article{Zhou2014,
	title = {Alpha shape and {Delaunay} triangulation in studies of protein-related interactions},
	volume = {15},
	issn = {1467-5463},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23193202},
	doi = {10.1093/bib/bbs077},
	abstract = {In recent years, more 3D protein structures have become available, which has made the analysis of large molecular structures much easier. There is a strong demand for geometric models for the study of protein-related interactions. Alpha shape and Delaunay triangulation are powerful tools to represent protein structures and have advantages in characterizing the surface curvature and atom contacts. This review presents state-of-the-art applications of alpha shape and Delaunay triangulation in the studies on protein-DNA, protein-protein, protein-ligand interactions and protein structure analysis.},
	number = {1},
	urldate = {2018-04-24},
	journal = {Briefings in Bioinformatics},
	author = {Zhou, W. and Yan, H.},
	month = jan,
	year = {2014},
	pmid = {23193202},
	keywords = {Delaunay triangulation, alpha shape, protein structure analysis, protein–DNA interactions, protein–ligand interactions, protein–protein interactions},
	pages = {54--64},
}

@article{zheng_iaspp_2022,
	title = {{iASPP} suppresses {Gp78}-mediated {TMCO1} degradation to maintain {Ca2}+ homeostasis and control tumor growth and drug resistance},
	volume = {119},
	doi = {10.1073/pnas.2111380119},
	abstract = {Ca2+ release from the endoplasmic reticulum (ER) is an essential event in the modulation of Ca2+ homeostasis, which is coordinated by multiple biological processes, ranging from cell proliferation to apoptosis. Deregulated Ca2+ homeostasis is linked with various cancer hallmarks; thus, uncovering the mechanisms underlying Ca2+ homeostasis dynamics may lead to new anticancer treatment strategies. Here, we demonstrate that a reported Ca2+-channel protein TMCO1 (transmembrane and coiled-coil domains 1) is overexpressed in colon cancer tissues at protein levels but not at messenger RNA levels in colon cancer. Further study revealed that TMCO1 is a substrate of ER-associated degradation E3 ligase Gp78. Intriguingly, Gp78-mediated TMCO1 degradation at K186 is under the control of the iASPP (inhibitor of apoptosis-stimulating protein of p53) oncogene. Mechanistically, iASPP robustly reduces ER Ca2+ stores, mainly by competitively binding with Gp78 and interfering with Gp78-mediated TMCO1 degradation. A positive correlation between iASPP and TMCO1 proteins is further validated in human colon tissues. Inhibition of iASPP-TMCO1 axis promotes cytosolic Ca2+ overload-induced apoptotic cell death, reducing tumor growth both in vitro and in vivo. Thus, iASPP-TMCO1 represents a promising anticancer treatment target by modulating Ca2+ homeostasis.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Zheng, Shanliang and Zhao, Dong and Hou, Guixue and Zhao, Song and Zhang, Wenxin and Wang, Xingwen and Li, Li and Lin, Liang and Tang, Tie-Shan and Hu, Ying},
	month = feb,
	year = {2022},
}

@article{wasserstein_asa_2016,
	title = {The {ASA} {Statement} on p-{Values}: {Context}, {Process}, and {Purpose}},
	volume = {70},
	issn = {0003-1305},
	shorttitle = {The {ASA} {Statement} on p-{Values}},
	url = {https://doi.org/10.1080/00031305.2016.1154108},
	doi = {10.1080/00031305.2016.1154108},
	number = {2},
	urldate = {2021-04-03},
	journal = {The American Statistician},
	author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
	month = apr,
	year = {2016},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2016.1154108},
	keywords = {epxeriment design, significance, statistics},
	pages = {129--133},
}

@inproceedings{wang_gunrock_2016,
	address = {New York, New York, USA},
	title = {Gunrock},
	volume = {51},
	isbn = {978-1-4503-4092-2},
	url = {http://dl.acm.org/citation.cfm?doid=2851141.2851145},
	doi = {10.1145/2851141.2851145},
	urldate = {2018-01-04},
	booktitle = {Proceedings of the 21st {ACM} {SIGPLAN} {Symposium} on {Principles} and {Practice} of {Parallel} {Programming} - {PPoPP} '16},
	publisher = {ACM Press},
	author = {Wang, Yangzihao and Davidson, Andrew and Pan, Yuechao and Wu, Yuduo and Riffel, Andy and Owens, John D. and Wang, Yangzihao and Davidson, Andrew and Pan, Yuechao and Wu, Yuduo and Riffel, Andy and Owens, John D.},
	year = {2016},
	note = {Issue: 8
ISSN: 0362-1340},
	pages = {1--12},
}

@misc{noauthor_generalized_nodate,
	title = {Generalized {Statistical} {Object} {Distance} {Analysis} ({GSODA}) {For} {Object} {Based} {Colocalization} {In} {Quantitative} {Microscopy}},
	url = {https://www.elmi2021.org/abstract/generalized-statistical-object-distance-analysis-gsoda-for-object-based-colocalization-in-quantitative-microscopy.html},
	urldate = {2022-05-11},
}

@misc{noauthor_researchgate_nodate,
	title = {{ResearchGate}},
	url = {https://www.researchgate.net/requests/r87515778},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2021-04-27},
	journal = {ResearchGate},
}

@misc{noauthor_home_nodate,
	title = {Home {Feed}},
	url = {https://www.researchgate.net/},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2022-05-26},
	journal = {ResearchGate},
}

@incollection{Xie2017,
	title = {Deep {Voting} and {Structured} {Regression} for {Microscopy} {Image} {Analysis}},
	isbn = {978-0-12-810409-5},
	abstract = {Robust and accurate nuclei localization in microscopy images can provide crucial clues for accurate computer-aided diagnosis. In this chapter, we present two methods that rely on convolutional neural networks (CNNs) to solve this problem. The first one is named as deep voting, which is a CNN based hough voting method used to localize nucleus centroids that exhibit heavy cluttering and morphological variations. It mainly consists of the following two parts: (i) Given an input image, this model maps every local testing image patch to the proposed target information, which consists of several pairs of voting offset vectors and voting confidence. Voting offset vectors are used to specify the pixel coordinates each local testing image patch votes to, and the corresponding voting confidence is used as weight assigned to each vote. (ii) We collect the weighted votes from all the testing image patches and compute the final voting density map for the entire testing image in a way similar to Parzen-window estimation. The final nucleus positions are then identified by searching the local maxima of the density map.The second one is a novel CNN based structured regression model, which is shown to be able to handle touching cells, inhomogeneous background noises, and large variations in sizes and shapes. Given an input image patch, instead of providing a single class label like many traditional methods, it will generate the structured outputs (referred to as proximity patches). These proximity patches, which exhibit higher values for pixels near cell centers, will then be gathered from all testing image patches and fused to obtain the final proximity map, where the maximum positions indicate the cell centroids.Both methods only require a few training images with weak annotations (just one click near the center of the object). Experimental results demonstrate that the proposed method achieves significantly improved performance compared to the state-of-the-art methods and shows strong robustness when dealing with the complex touching cells, weak staining, and fuzzy boundaries.},
	booktitle = {Deep {Learning} for {Medical} {Image} {Analysis}},
	author = {Xie, Yuanpu and Xing, Fuyong and Yang, Lin},
	year = {2017},
	doi = {10.1016/B978-0-12-810408-8.00009-2},
}

@article{VonDiezmann2017c,
	title = {Three-{Dimensional} {Localization} of {Single} {Molecules} for {Super}-{Resolution} {Imaging} and {Single}-{Particle} {Tracking}},
	volume = {117},
	issn = {0009-2665},
	url = {http://pubs.acs.org/doi/abs/10.1021/acs.chemrev.6b00629},
	doi = {10.1021/acs.chemrev.6b00629},
	abstract = {Single-molecule super-resolution fluorescence microscopy and single-particle tracking are two imaging modalities that illuminate the properties of cells and materials on spatial scales down to tens of nanometers or with dynamical information about nanoscale particle motion in the millisecond range, respectively. These methods generally use wide-field microscopes and two-dimensional camera detectors to localize molecules to much higher precision than the diffraction limit. Given the limited total photons available from each single-molecule label, both modalities require careful mathematical analysis and image processing. Much more information can be obtained about the system under study by extending to three-dimensional (3D) single-molecule localization: without this capability, visualization of structures or motions extending in the axial direction can easily be missed or confused, compromising scientific understanding. A variety of methods for obtaining both 3D super-resolution images and 3D tracking inf...},
	number = {11},
	urldate = {2017-09-19},
	journal = {Chemical Reviews},
	author = {von Diezmann, Alex and Shechtman, Yoav and Moerner, W. E.},
	month = jun,
	year = {2017},
	note = {Publisher: American Chemical Society},
	pages = {7244--7275},
}

@article{viana_tutorial_2016,
	title = {A {Tutorial} on {Latin} {Hypercube} {Design} of {Experiments}},
	volume = {32},
	issn = {07488017},
	url = {http://doi.wiley.com/10.1002/qre.1924},
	doi = {10.1002/qre.1924},
	number = {5},
	urldate = {2017-05-29},
	journal = {Quality and Reliability Engineering International},
	author = {Viana, Felipe A. C.},
	month = jul,
	year = {2016},
	keywords = {Latin hypercube sampling, design and analysis of computer experiments, sequential sampling, space‐filling designs},
	pages = {1975--1985},
}

@article{Verdier2017,
	title = {Single particle maximum likelihood reconstruction from superresolution microscopy images},
	volume = {12},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0172943},
	doi = {10.1371/journal.pone.0172943},
	number = {3},
	urldate = {2017-11-30},
	journal = {PLOS ONE},
	author = {Verdier, Timothée and Gunzenhauser, Julia and Manley, Suliana and Castelnovo, Martin},
	editor = {Brody, James P},
	month = mar,
	year = {2017},
	note = {Publisher: Public Library of Science},
	pages = {e0172943},
}

@article{valle_data_2017,
	title = {Data, {Depth}, and {Design}: {Learning} {Reliable} {Models} for {Melanoma} {Screening}},
	abstract = {—Art on melanoma screening evolved steeply in the last two years, with the adoption of deep learning, but those models pose challenges of their own, as they are expensive to train, and complex to parameterize. We shed light at those difficulties, with an exhaustive evaluation of nine commonly found open choices faced when picking or designing deep networks for melanoma screening: model architecture, training dataset, image resolution, data augmentation, input normalization, use of segmentation, duration of training, additional use of SVM, and test data augmentation. We perform a full 2-level factorial, for five different test datasets, resulting in 2560 experiments, which we analyze with a multi-way ANOVA. The main finding is that the size of training data has a disproportional influence, explaining almost half the variation in performance. Of the other factors, test data augmentation and input resolution are the most helpful. The use of deeper models if combined with extra data, also helps. We show that the expensive full-factorial design, or the unreliable sequential optimization are not the only options: ensembling models allow obtaining reliable results with limited resources. We also warn against the very common practice of hyperoptimizing and testing on the same dataset, showing the clear (and unfair) increases this practice brings to performance metrics, leading to overoptimistic results.},
	number = {X},
	urldate = {2017-11-07},
	journal = {IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS},
	author = {Valle, Eduardo and Fornaciali, Michel and Menegola, Afonso and Tavares, Julia and Vasques Bittencourt, Flávia and Tzy Li, Lin and Avila, Sandra},
	year = {2017},
	keywords = {Index Terms—Deep learning, cross dataset, experimen-tal design, melanoma screening, model parametrization},
}

@article{Teutschb,
	title = {A parallel point cloud clustering algorithm for subset segmentation and outlier detection},
	abstract = {We present a fast point cloud clustering technique which is suitable for outlier detection, object segmentation and region labeling for large multi-dimensional data sets. The basis is a minimal data structure similar to a kd-tree which enables us to detect connected subsets very fast. The proposed algorithms utilizing this tree structure are parallelizable which further increases the computation speed for very large data sets. The procedures given are a vital part of the data pre-processing. They improve the input data properties for a more reliable computation of surface measures, polygonal meshes and other visualization techniques. In order to show the effectiveness of our techniques we evaluate sets of point clouds from different 3D scanning devices.},
	urldate = {2017-09-28},
	author = {Teutsch, Christian and Trostmann, Erik and Berndt, Dirk},
	keywords = {laser scanning, outlier removal, point cloud, segmentation},
}

@article{supowit_relative_1983,
	title = {The {Relative} {Neighborhood} {Graph}, with an {Application} to {Minimum} {Spanning} {Trees}},
	volume = {30},
	issn = {00045411},
	url = {http://portal.acm.org/citation.cfm?doid=2402.322386},
	doi = {10.1145/2402.322386},
	number = {3},
	urldate = {2018-03-26},
	journal = {Journal of the ACM},
	author = {Supowit, Kenneth J.},
	month = jul,
	year = {1983},
	pages = {428--448},
}

@article{su_splatnet_2018,
	title = {{SPLATNet}: {Sparse} {Lattice} {Networks} for {Point} {Cloud} {Processing}},
	url = {http://arxiv.org/abs/1802.08275},
	abstract = {We present a network architecture for processing point clouds that directly operates on a collection of points represented as a sparse set of samples in a high-dimensional lattice. Naively applying convolutions on this lattice scales poorly, both in terms of memory and computational cost, as the size of the lattice increases. Instead, our network uses sparse bilateral convolutional layers as building blocks. These layers maintain efficiency by using indexing structures to apply convolutions only on occupied parts of the lattice, and allow flexible specifications of the lattice structure enabling hierarchical and spatially-aware feature learning, as well as joint 2D-3D reasoning. Both point-based and image-based representations can be easily incorporated in a network with such layers and the resulting model can be trained in an end-to-end manner. We present results on 3D segmentation tasks where our approach outperforms existing state-of-the-art techniques.},
	urldate = {2018-07-09},
	author = {Su, Hang and Jampani, Varun and Sun, Deqing and Maji, Subhransu and Kalogerakis, Evangelos and Yang, Ming-Hsuan and Kautz, Jan},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.08275},
}

@article{stehbens_analysis_2014,
	title = {Analysis of focal adhesion turnover: {A} quantitative live-cell imaging example},
	volume = {123},
	issn = {0091-679X},
	url = {https://www.sciencedirect.com/science/article/pii/B9780124201385000185#bb0005},
	doi = {10.1016/B978-0-12-420138-5.00018-5},
	abstract = {Recent advances in optical and fluorescent protein technology have rapidly raised expectations in cell biology, allowing quantitative insights into dynamic intracellular processes like never before. However, quantitative live-cell imaging comes with many challenges including how best to translate dynamic microscopy data into numerical outputs that can be used to make meaningful comparisons rather than relying on representative data sets. Here, we use analysis of focal adhesion turnover dynamics as a straightforward specific example on how to image, measure, and analyze intracellular protein dynamics, but we believe this outlines a thought process and can provide guidance on how to understand dynamic microcopy data of other intracellular structures.},
	urldate = {2018-04-29},
	journal = {Methods in Cell Biology},
	author = {Stehbens, Samantha J. and Wittmann, Torsten},
	month = jan,
	year = {2014},
	note = {Publisher: Academic Press
ISBN: 9780124201385},
	pages = {335--346},
}

@article{stadler_diffusion_2018,
	title = {Diffusion of {Exit} {Sites} on the {Endoplasmic} {Reticulum}: {A} {Random} {Walk} on a {Shivering} {Backbone}},
	volume = {115},
	issn = {1542-0086},
	shorttitle = {Diffusion of {Exit} {Sites} on the {Endoplasmic} {Reticulum}},
	doi = {10.1016/j.bpj.2018.09.007},
	abstract = {Major parts of the endoplasmic reticulum (ER) in eukaryotic cells are organized as a dynamic network of membrane tubules connected by three-way junctions. On this network, self-assembled membrane domains, called ER exit sites (ERES), provide platforms at which nascent cargo proteins are packaged into vesicular carriers for subsequent transport along the secretory pathway. Although ERES appear stationary and spatially confined on long timescales, we show here via single-particle tracking that they exhibit a microtubule-dependent and heterogeneous anomalous diffusion behavior on short and intermediate timescales. By quantifying key parameters of their random walk, we show that the subdiffusive motion of ERES is distinct from that of ER junctions, i.e., ERES are not tied to junctions but rather are mobile on ER tubules. We complement and corroborate our experimental findings with model simulations that also indicate that ERES are not actively moved by microtubules. Altogether, our study shows that ERES perform a random walk on the shivering ER backbone, indirectly powered by microtubular activity. Similar phenomena can be expected for other domains on subcellular structures, setting a caveat for the interpretation of domain-tracking data.},
	language = {eng},
	number = {8},
	journal = {Biophysical Journal},
	author = {Stadler, Lorenz and Speckner, Konstantin and Weiss, Matthias},
	month = oct,
	year = {2018},
	pmid = {30274831},
	pmcid = {PMC6260206},
	keywords = {Cell Membrane, Cell Tracking, Computer Simulation, Diffusion, Endoplasmic Reticulum, Green Fluorescent Proteins, HeLa Cells, Humans, Membrane Proteins, Microtubules, Protein Transport, Saccharomyces cerevisiae Proteins, Signal Transduction},
	pages = {1552--1560},
}

@article{shuman_emerging_2013,
	title = {The emerging field of signal processing on graphs: {Extending} high-dimensional data analysis to networks and other irregular domains},
	volume = {30},
	issn = {1053-5888},
	url = {http://ieeexplore.ieee.org/document/6494675/},
	doi = {10.1109/MSP.2012.2235192},
	number = {3},
	urldate = {2018-03-22},
	journal = {IEEE Signal Processing Magazine},
	author = {Shuman, D. I. and Narang, S. K. and Frossard, P. and Ortega, A. and Vandergheynst, P.},
	month = may,
	year = {2013},
	pages = {83--98},
}

@article{Shankar2015,
	title = {Caveolin-1, galectin-3 and lipid raft domains in cancer cell signalling.},
	volume = {57},
	issn = {1744-1358},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25658354},
	doi = {10.1042/bse0570189},
	abstract = {Spatial organization of the plasma membrane is an essential feature of the cellular response to external stimuli. Receptor organization at the cell surface mediates transmission of extracellular stimuli to intracellular signalling molecules and effectors that impact various cellular processes including cell differentiation, metabolism, growth, migration and apoptosis. Membrane domains include morphologically distinct plasma membrane invaginations such as clathrin-coated pits and caveolae, but also less well-defined domains such as lipid rafts and the galectin lattice. In the present chapter, we will discuss interaction between caveolae, lipid rafts and the galectin lattice in the control of cancer cell signalling.},
	urldate = {2018-04-20},
	journal = {Essays in biochemistry},
	author = {Shankar, Jay and Boscher, Cecile and Nabi, Ivan R},
	month = feb,
	year = {2015},
	pmid = {25658354},
	note = {Publisher: Portland Press Limited},
	pages = {189--201},
}

@article{Sedlazeck2018a,
	title = {Accurate detection of complex structural variations using single-molecule sequencing},
	volume = {15},
	issn = {15487105},
	url = {http://dx.doi.org/10.1038/s41592-018-0001-7},
	doi = {10.1038/s41592-018-0001-7},
	abstract = {Structural variations are the greatest source of genetic variation, but they remain poorly understood because of technological limitations. Single-molecule long-read sequencing has the potential to dramatically advance the field, although high error rates are a challenge with existing methods. Addressing this need, we introduce open-source methods for long-read alignment (NGMLR; 
                https://github.com/philres/ngmlr
                
              ) and structural variant identification (Sniffles; 
                https://github.com/fritzsedlazeck/Sniffles
                
              ) that provide unprecedented sensitivity and precision for variant detection, even in repeat-rich regions and for complex nested events that can have substantial effects on human health. In several long-read datasets, including healthy and cancerous human genomes, we discovered thousands of novel variants and categorized systematic errors in short-read approaches. NGMLR and Sniffles can automatically filter false events and operate on low-coverage data, thereby reducing the high costs that have hindered the application of long reads in clinical and research settings.},
	number = {6},
	journal = {Nature Methods},
	author = {Sedlazeck, Fritz J. and Rescheneder, Philipp and Smolka, Moritz and Fang, Han and Nattestad, Maria and Von Haeseler, Arndt and Schatz, Michael C.},
	year = {2018},
	pmid = {29713083},
	note = {Publisher: Springer US
ISBN: 1471-0064 (Electronic) 1471-0056 (Linking)},
	keywords = {Genome informatics, Software, Structural variation},
	pages = {461--468},
}

@incollection{schmidt_symbolic_2010,
	title = {Symbolic {Regression} of {Implicit} {Equations}},
	url = {http://link.springer.com/10.1007/978-1-4419-1626-6_5},
	urldate = {2017-05-22},
	publisher = {Springer US},
	author = {Schmidt, Michael and Lipson, Hod},
	year = {2010},
	doi = {10.1007/978-1-4419-1626-6_5},
	pages = {73--85},
}

@article{schmidt_distilling_2009,
	title = {Distilling {Free}-{Form} {Natural} {Laws} from {Experimental} {Data}},
	volume = {324},
	issn = {0036-8075},
	url = {http://www.sciencemag.org/lookup/doi/10.1126/science.1165893},
	doi = {10.1126/science.1165893},
	number = {5923},
	urldate = {2017-10-17},
	journal = {Science},
	author = {Schmidt, Michael and Lipson, Hod},
	month = apr,
	year = {2009},
	pages = {81--85},
}

@article{Sage2015a,
	title = {Quantitative evaluation of software packages for single-molecule localization microscopy},
	issn = {15487105},
	doi = {10.1038/nmeth.3442},
	abstract = {The quality of super-resolution images obtained by single-molecule localization microscopy (SMLM) depends largely on the software used to detect and accurately localize point sources. In this work, we focus on the computational aspects of super-resolution microscopy and present a comprehensive evaluation of localization software packages. Our philosophy is to evaluate each package as a whole, thus maintaining the integrity of the software. We prepared synthetic data that represent three-dimensional structures modeled after biological components, taking excitation parameters, noise sources, point-spread functions and pixelation into account. We then asked developers to run their software on our data; most responded favorably, allowing us to present a broad picture of the methods available. We evaluated their results using quantitative and user-interpretable criteria: detection rate, accuracy, quality of image reconstruction, resolution, software usability and computational resources. These metrics reflect the various tradeoffs of SMLM software packages and help users to choose the software that fits their needs.},
	journal = {Nature Methods},
	author = {Sage, Daniel and Kirshner, Hagai and Pengo, Thomas and Stuurman, Nico and Min, Junhong and Manley, Suliana and Unser, Michael},
	year = {2015},
	pmid = {26076424},
	note = {ISBN: doi:10.1038/nmeth.3442},
	keywords = {Computational platforms and environments, Image processing, Software},
}

@inproceedings{roy_x-stream_2013,
	address = {New York, New York, USA},
	title = {X-{Stream}},
	isbn = {978-1-4503-2388-8},
	url = {http://dl.acm.org/citation.cfm?doid=2517349.2522740},
	doi = {10.1145/2517349.2522740},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the {Twenty}-{Fourth} {ACM} {Symposium} on {Operating} {Systems} {Principles} - {SOSP} '13},
	publisher = {ACM Press},
	author = {Roy, Amitabha and Mihailovic, Ivo and Zwaenepoel, Willy},
	year = {2013},
	pages = {472--488},
}

@inproceedings{roy_chaos_2015,
	address = {New York, New York, USA},
	title = {Chaos},
	isbn = {978-1-4503-3834-9},
	url = {http://dl.acm.org/citation.cfm?doid=2815400.2815408},
	doi = {10.1145/2815400.2815408},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 25th {Symposium} on {Operating} {Systems} {Principles} - {SOSP} '15},
	publisher = {ACM Press},
	author = {Roy, Amitabha and Bindschaedler, Laurent and Malicevic, Jasmina and Zwaenepoel, Willy},
	year = {2015},
	pages = {410--424},
}

@article{Rivenson2017b,
	title = {Deep learning microscopy},
	volume = {4},
	issn = {2334-2536},
	url = {https://www.osapublishing.org/abstract.cfm?URI=optica-4-11-1437},
	doi = {10.1364/OPTICA.4.001437},
	abstract = {We demonstrate that a deep neural network can significantly improve optical microscopy, enhancing its spatial resolution over a large field of view and depth of field. After its training, the only input to this network is an image acquired using a regular optical microscope, without any changes to its design. We blindly tested this deep learning approach using various tissue samples that are imaged with low-resolution and wide-field systems, where the network rapidly outputs an image with better resolution, matching the performance of higher numerical aperture lenses and also significantly surpassing their limited field of view and depth of field. These results are significant for various fields that use microscopy tools, including, e.g., life sciences, where optical microscopy is considered as one of the most widely used and deployed techniques. Beyond such applications, the presented approach might be applicable to other imaging modalities, also spanning different parts of the electromagnetic spectrum, and can be used to design computational imagers that get better as they continue to image specimens and establish new transformations among different modes of imaging.},
	number = {11},
	urldate = {2018-01-08},
	journal = {Optica},
	author = {Rivenson, Yair and Göröcs, Zoltán and Günaydin, Harun and Zhang, Yibo and Wang, Hongda and Ozcan, Aydogan},
	month = nov,
	year = {2017},
	note = {Publisher: Optical Society of America},
	keywords = {Computational imaging, Image reconstruction techniques, Inverse problems, Microscopy, Pattern recognition, neural networks},
	pages = {1437},
}

@article{perkins_intertwined_2021,
	title = {Intertwined and {Finely} {Balanced}: {Endoplasmic} {Reticulum} {Morphology}, {Dynamics}, {Function}, and {Diseases}},
	volume = {10},
	issn = {2073-4409},
	shorttitle = {Intertwined and {Finely} {Balanced}},
	doi = {10.3390/cells10092341},
	abstract = {The endoplasmic reticulum (ER) is an organelle that is responsible for many essential subcellular processes. Interconnected narrow tubules at the periphery and thicker sheet-like regions in the perinuclear region are linked to the nuclear envelope. It is becoming apparent that the complex morphology and dynamics of the ER are linked to its function. Mutations in the proteins involved in regulating ER structure and movement are implicated in many diseases including neurodegenerative diseases such as Alzheimer's, Parkinson's, and amyotrophic lateral sclerosis (ALS). The ER is also hijacked by pathogens to promote their replication. Bacteria such as Legionella pneumophila and Chlamydia trachomatis, as well as the Zika virus, bind to ER morphology and dynamics-regulating proteins to exploit the functions of the ER to their advantage. This review covers our understanding of ER morphology, including the functional subdomains and membrane contact sites that the organelle forms. We also focus on ER dynamics and the current efforts to quantify ER motion and discuss the diseases related to ER morphology and dynamics.},
	language = {eng},
	number = {9},
	journal = {Cells},
	author = {Perkins, Hannah T. and Allan, Viki},
	month = sep,
	year = {2021},
	pmid = {34571990},
	pmcid = {PMC8472773},
	keywords = {Animals, Cytoskeleton, Endoplasmic Reticulum, Humans, Lipids, Membrane Proteins, Microtubules, Mitochondria, Mitochondrial Membranes, Nuclear Envelope, Structure-Activity Relationship, anomalous diffusion, dynamics, dynein, endoplasmic reticulum (ER), kinesin, membrane contact site (MCS), microtubule, morphology},
	pages = {2341},
}

@article{pearson_introduction_2013,
	title = {An introduction to sequence similarity (\&quot;homology\&quot;) searching.},
	volume = {Chapter 3},
	issn = {1934-340X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23749753},
	doi = {10.1002/0471250953.bi0301s42},
	abstract = {Sequence similarity searching, typically with BLAST, is the most widely used and most reliable strategy for characterizing newly determined sequences. Sequence similarity searches can identify "homologous" proteins or genes by detecting excess similarity- statistically significant similarity that reflects common ancestry. This unit provides an overview of the inference of homology from significant similarity, and introduces other units in this chapter that provide more details on effective strategies for identifying homologs.},
	urldate = {2018-09-12},
	journal = {Current protocols in bioinformatics},
	author = {Pearson, William R},
	month = jun,
	year = {2013},
	pmid = {23749753},
	note = {Publisher: NIH Public Access},
	pages = {Unit3.1},
}

@article{Gomez-Romero2018a,
	title = {Precise detection of de novo single nucleotide variants in human genomes},
	volume = {115},
	issn = {0027-8424},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1802244115},
	doi = {10.1073/pnas.1802244115},
	abstract = {The precise determination of de novo genetic variants has enormous implications across different fields of biology and medicine, particularly personalized medicine. Currently, de novo variations are identified by mapping sample reads from a parent-offspring trio to a reference genome, allowing for a certain degree of differences. While widely used, this approach often introduces false-positive (FP) results due to misaligned reads and mischaracterized sequencing errors. In a previous study, we developed an alternative approach to accurately identify single nucleotide variants (SNVs) using only perfect matches. However, this approach could be applied only to haploid regions of the genome and was computationally intensive. In this study, we present a unique approach, coverage-based single nucleotide variant identification (COBASI), which allows the exploration of the entire genome using second-generation short sequence reads without extensive computing requirements. COBASI identifies SNVs using changes in coverage of exactly matching unique substrings, and is particularly suited for pinpointing de novo SNVs. Unlike other approaches that require population frequencies across hundreds of samples to filter out any methodological biases, COBASI can be applied to detect de novo SNVs within isolated families. We demonstrate this capability through extensive simulation studies and by studying a parent-offspring trio we sequenced using short reads. Experimental validation of all 58 candidate de novo SNVs and a selection of non-de novo SNVs found in the trio confirmed zero FP calls. COBASI is available as open source at https://github.com/Laura-Gomez/COBASI for any researcher to use.},
	number = {21},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Gómez-Romero, Laura and Palacios-Flores, Kim and Reyes, José and García, Delfino and Boege, Margareta and Dávila, Guillermo and Flores, Margarita and Schatz, Michael C. and Palacios, Rafael},
	year = {2018},
	pmid = {29735690},
	note = {ISBN: 1802244115},
	keywords = {coverage map, de novo mutations, genomic algorithms, genomic landscape, human genome variation},
	pages = {5516--5521},
}

@article{greenland_valid_2019,
	title = {Valid \textit{{P}} -{Values} {Behave} {Exactly} as {They} {Should}: {Some} {Misleading} {Criticisms} of \textit{{P}} -{Values} and {Their} {Resolution} {With} \textit{{S}} -{Values}},
	volume = {73},
	issn = {0003-1305, 1537-2731},
	shorttitle = {Valid \textit{{P}} -{Values} {Behave} {Exactly} as {They} {Should}},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1529625},
	doi = {10.1080/00031305.2018.1529625},
	language = {en},
	number = {sup1},
	urldate = {2023-09-25},
	journal = {The American Statistician},
	author = {Greenland, Sander},
	month = mar,
	year = {2019},
	pages = {106--114},
}

@article{haas_single-molecule_2018,
	title = {Single-molecule localization microscopy reveals molecular transactions during {RAD51} filament assembly at cellular {DNA} damage sites},
	volume = {46},
	issn = {0305-1048},
	url = {https://academic.oup.com/nar/article/46/5/2398/4788348},
	doi = {10.1093/nar/gkx1303},
	number = {5},
	urldate = {2018-11-09},
	journal = {Nucleic Acids Research},
	author = {Haas, Kalina T and Lee, MiYoung and Esposito, Alessandro and Venkitaraman, Ashok R},
	month = mar,
	year = {2018},
	note = {Publisher: Oxford University Press},
	keywords = {brca2 protein, dna, dna damage, molecule},
	pages = {2398--2416},
}

@article{Havaei2015,
	title = {Brain {Tumor} {Segmentation} with {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1505.03540},
	doi = {10.1016/j.media.2016.05.004},
	abstract = {In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that we've found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data. We present a novel CNN architecture which differs from those traditionally used in computer vision. Our CNN exploits both local features as well as more global contextual features simultaneously. Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up. We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels. Finally, we explore a cascade architecture in which the output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test dataset reveal that our architecture improves over the currently published state-of-the-art while being over 30 times faster.},
	urldate = {2017-09-14},
	author = {Havaei, Mohammad and Davy, Axel and Warde-Farley, David and Biard, Antoine and Courville, Aaron and Bengio, Yoshua and Pal, Chris and Jodoin, Pierre-Marc and Larochelle, Hugo},
	month = may,
	year = {2015},
	note = {arXiv: 1505.03540},
}

@article{hazan_bindsnet_2018,
	title = {{BindsNET}: {A} {Machine} {Learning}-{Oriented} {Spiking} {Neural} {Networks} {Library} in {Python}},
	volume = {12},
	shorttitle = {{BindsNET}},
	doi = {10.3389/fninf.2018.00089},
	abstract = {The development of spiking neural network simulation software is a critical component enabling the modeling of neural systems and the development of biologically inspired algorithms. Existing software frameworks support a wide range of neural functionality, software abstraction levels, and hardware devices, yet are typically not suitable for rapid prototyping or application to problems in the domain of machine learning. In this paper, we describe a new Python package for the simulation of spiking neural networks, specifically geared toward machine learning and reinforcement learning. Our software, called BindsNET1, enables rapid building and simulation of spiking networks and features user-friendly, concise syntax. BindsNET is built on the PyTorch deep neural networks library, facilitating the implementation of spiking neural networks on fast CPU and GPU computational platforms. Moreover, the BindsNET framework can be adjusted to utilize other existing computing and hardware backends; e.g., TensorFlow and SpiNNaker. We provide an interface with the OpenAI gym library, allowing for training and evaluation of spiking networks on reinforcement learning environments. We argue that this package facilitates the use of spiking networks for large-scale machine learning problems and show some simple examples by using BindsNET in practice.},
	journal = {Frontiers in Neuroinformatics},
	author = {Hazan, Hananel and Saunders, Daniel and Khan, Hassaan and Patel, Devdhar and Sanghavi, Darpan and Siegelmann, Hava and Kozma, Robert},
	month = dec,
	year = {2018},
	pages = {89},
}

@article{Kanchanawong2010,
	title = {Nanoscale architecture of integrin-based cell adhesions.},
	volume = {468},
	issn = {1476-4687},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21107430},
	doi = {10.1038/nature09621},
	abstract = {Cell adhesions to the extracellular matrix (ECM) are necessary for morphogenesis, immunity and wound healing. Focal adhesions are multifunctional organelles that mediate cell-ECM adhesion, force transmission, cytoskeletal regulation and signalling. Focal adhesions consist of a complex network of trans-plasma-membrane integrins and cytoplasmic proteins that form a {\textless}200-nm plaque linking the ECM to the actin cytoskeleton. The complexity of focal adhesion composition and dynamics implicate an intricate molecular machine. However, focal adhesion molecular architecture remains unknown. Here we used three-dimensional super-resolution fluorescence microscopy (interferometric photoactivated localization microscopy) to map nanoscale protein organization in focal adhesions. Our results reveal that integrins and actin are vertically separated by a ∼40-nm focal adhesion core region consisting of multiple protein-specific strata: a membrane-apposed integrin signalling layer containing integrin cytoplasmic tails, focal adhesion kinase and paxillin; an intermediate force-transduction layer containing talin and vinculin; and an uppermost actin-regulatory layer containing zyxin, vasodilator-stimulated phosphoprotein and α-actinin. By localizing amino- and carboxy-terminally tagged talins, we reveal talin's polarized orientation, indicative of a role in organizing the focal adhesion strata. The composite multilaminar protein architecture provides a molecular blueprint for understanding focal adhesion functions.},
	number = {7323},
	urldate = {2018-04-16},
	journal = {Nature},
	author = {Kanchanawong, Pakorn and Shtengel, Gleb and Pasapera, Ana M and Ramko, Ericka B and Davidson, Michael W and Hess, Harald F and Waterman, Clare M},
	month = nov,
	year = {2010},
	pmid = {21107430},
	note = {Publisher: NIH Public Access},
	pages = {580--4},
}

@article{keene_log_1995,
	title = {The log transformation is special},
	volume = {14},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4780140810},
	doi = {10.1002/sim.4780140810},
	abstract = {The logarithmic (log) transformation is a simple yet controversial step in the analysis of positive continuous data measured on an interval scale. Situations where a log transformation is indicated will be reviewed. This paper contends that the log transformation should not be classed with other transformations as it has particular advantages. Problems with using the data themselves to decide whether or not to transform will be discussed. It is recommended that log transformed analyses should frequently be preferred to untransformed analyses and that careful consideration should be given to use of a log transformation at the protocol design stage.},
	language = {en},
	number = {8},
	urldate = {2022-05-16},
	journal = {Statistics in Medicine},
	author = {Keene, Oliver N.},
	year = {1995},
	pages = {811--819},
}

@article{kim_snp_2007,
	title = {{SNP} {Genotyping}: {Technologies} and {Biomedical} {Applications}},
	volume = {9},
	issn = {1523-9829},
	url = {http://www.annualreviews.org/doi/10.1146/annurev.bioeng.9.060906.152037},
	doi = {10.1146/annurev.bioeng.9.060906.152037},
	abstract = {AbstractSingle nucleotide polymorphisms (SNPs) are the most frequently occurring genetic variation in the human genome, with the total number of SNPs reported in public SNP databases currently exceeding 9 million. SNPs are important markers in many studies that link sequence variations to phenotypic changes; such studies are expected to advance the understanding of human physiology and elucidate the molecular bases of diseases. For this reason, over the past several years a great deal of effort has been devoted to developing accurate, rapid, and cost-effective technologies for SNP analysis, yielding a large number of distinct approaches. This article presents a review of SNP genotyping techniques and examines their principles of genotype determination in terms of allele differentiation strategies and detection methods. Further, several current biomedical applications of SNP genotyping are discussed.},
	number = {1},
	urldate = {2018-11-16},
	journal = {Annual Review of Biomedical Engineering},
	author = {Kim, Sobin and Misra, Ashish},
	month = aug,
	year = {2007},
	note = {Publisher: Annual Reviews},
	keywords = {association study, high-throughput, mutation, pharmacogenomics, sequence variation, single nucleotide polymorphism},
	pages = {289--320},
}

@article{Klementieva2017a,
	title = {Intrinsic blinking of red fluorescent proteins for super-resolution microscopy},
	volume = {53},
	issn = {1359-7345},
	doi = {10.1039/C6CC09200D},
	abstract = {{\textless}p{\textgreater}Blinking of some RFPs in live untreated cells can be used to reconstruct super-resolved images.{\textless}/p{\textgreater}},
	number = {5},
	journal = {Chem. Commun.},
	author = {Klementieva, Natalia V. and Pavlikov, Anton I. and Moiseev, Alexander A. and Bozhanova, Nina G. and Mishina, Natalie M. and Lukyanov, Sergey A. and Zagaynova, Elena V. and Lukyanov, Konstantin A. and Mishin, Alexander S.},
	year = {2017},
	pmid = {28044165},
	note = {ISBN: 1364-548X (Electronic){\textbackslash}r1359-7345 (Linking)},
}

@article{kraska_case_2017,
	title = {The {Case} for {Learned} {Index} {Structures}},
	url = {http://arxiv.org/abs/1712.01208},
	abstract = {Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70\% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.},
	urldate = {2018-01-08},
	author = {Kraska, Tim and Beutel, Alex and Chi, Ed H. and Dean, Jeffrey and Polyzotis, Neoklis},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.01208},
}

@article{leisten_super-resolution_2023,
	title = {Super-resolution microscopy: {Insights} into mitochondria–lysosome crosstalk in health and disease},
	volume = {222},
	issn = {0021-9525},
	shorttitle = {Super-resolution microscopy},
	url = {https://doi.org/10.1083/jcb.202305032},
	doi = {10.1083/jcb.202305032},
	abstract = {Live super-resolution microscopy has allowed for new insights into recently identified mitochondria–lysosome contact sites, which mediate crosstalk between mitochondria and lysosomes, including co-regulation of Rab7 GTP hydrolysis and Drp1 GTP hydrolysis. Here, we highlight recent findings and future perspectives on this dynamic pathway and its roles in health and disease.},
	number = {12},
	urldate = {2023-11-08},
	journal = {Journal of Cell Biology},
	author = {Leisten, Eric D. and Woods, Abby C. and Wong, Yvette C.},
	month = nov,
	year = {2023},
	pages = {e202305032},
}

@article{Lehmann2016,
	title = {Novel organic dyes for multicolor localization-based super-resolution microscopy},
	volume = {9},
	issn = {1864063X},
	url = {http://doi.wiley.com/10.1002/jbio.201500119},
	doi = {10.1002/jbio.201500119},
	number = {1-2},
	urldate = {2018-02-14},
	journal = {Journal of Biophotonics},
	author = {Lehmann, Martin and Lichtner, Gregor and Klenz, Haider and Schmoranzer, Jan},
	month = jan,
	year = {2016},
	note = {Publisher: WILEY‐VCH Verlag},
	keywords = {STORM, dSTORM, direct stochastic optical reconstruction microscop, fluorescent probes, multicolor, organic dyes, single molecule localization, super‐resolution microscopy},
	pages = {161--170},
}

@article{Lagache2018,
	title = {Mapping molecular assemblies with fluorescence microscopy and object-based spatial statistics},
	volume = {9},
	issn = {2041-1723},
	url = {http://www.nature.com/articles/s41467-018-03053-x},
	doi = {10.1038/s41467-018-03053-x},
	abstract = {Elucidating protein functions and molecular organisation requires to localise precisely single or aggregated molecules and analyse their spatial distributions. We develop a statistical method SODA (Statistical Object Distance Analysis) that uses either micro- or nanoscopy to significantly improve on standard co-localisation techniques. Our method considers cellular geometry and densities of molecules to provide statistical maps of isolated and associated (coupled) molecules. We use SODA with three-colour structured-illumination microscopy (SIM) images of hippocampal neurons, and statistically characterise spatial organisation of thousands of synapses. We show that presynaptic synapsin is arranged in asymmetric triangle with the 2 postsynaptic markers homer and PSD95, indicating a deeper localisation of homer. We then determine stoichiometry and distance between localisations of two synaptic vesicle proteins with 3D-STORM. These findings give insights into the protein organisation at the synapse, and prove the efficiency of SODA to quantitatively assess the geometry of molecular assemblies.},
	number = {1},
	urldate = {2018-02-21},
	journal = {Nature Communications},
	author = {Lagache, Thibault and Grassart, Alexandre and Dallongeville, Stéphane and Faklaris, Orestis and Sauvonnet, Nathalie and Dufour, Alexandre and Danglot, Lydia and Olivo-Marin, Jean-Christophe},
	month = dec,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Fluorescence imaging, Humanities and Social Sciences, Image processing, Science, Statistical methods, Super, multidisciplinary, resolution microscopy},
	pages = {698},
}

@article{karathanasis_molecule_2017,
	title = {Molecule {Counts} in {Localization} {Microscopy} with {Organic} {Fluorophores}},
	volume = {18},
	issn = {14394235},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/28196307},
	doi = {10.1002/cphc.201601425},
	abstract = {Single-molecule localization microscopy (SMLM) can be used to count fluorescently labeled molecules even when they are not individually resolved. We demonstrate SMLM molecule counting for nucleic acids labeled with the organic fluorophore Alexa Fluor 647 and imaged under photoswitching conditions. From the observed distributions of the number of fluorophore blinking events, we extract the number of fluorophores per spot using a statistical model. We validate the molecule counting method for single Alexa Fluor 647 fluorophores, and for trimers of Alexa Fluor 647 constructed on a DNA origami structure. This simple counting strategy enables quantitative super-resolution imaging with organic fluorophores.},
	number = {8},
	urldate = {2018-11-28},
	journal = {ChemPhysChem},
	author = {Karathanasis, Christos and Fricke, Franziska and Hummer, Gerhard and Heilemann, Mike},
	month = apr,
	year = {2017},
	pmid = {28196307},
	keywords = {molecular counting, molecule imaging, organic fluorophores, photokinetic analysis, resolution microscopy, single, single-molecule imaging, super, super-resolution microscopy},
	pages = {942--948},
}

@article{Lanctot2017,
	title = {A {Unified} {Game}-{Theoretic} {Approach} to {Multiagent} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1711.00832},
	abstract = {To achieve general intelligence, agents must learn how to interact with others in a shared environment: this is the challenge of multiagent reinforcement learning (MARL). The simplest form is independent reinforcement learning (InRL), where each agent treats its experience as part of its (non-stationary) environment. In this paper, we first observe that policies learned using InRL can overfit to the other agents' policies during training, failing to sufficiently generalize during execution. We introduce a new metric, joint-policy correlation, to quantify this effect. We describe an algorithm for general MARL, based on approximate best responses to mixtures of policies generated using deep reinforcement learning, and empirical game-theoretic analysis to compute meta-strategies for policy selection. The algorithm generalizes previous ones such as InRL, iterated best response, double oracle, and fictitious play. Then, we present a scalable implementation which reduces the memory requirement using decoupled meta-solvers. Finally, we demonstrate the generality of the resulting policies in two partially observable settings: gridworld coordination games and poker.},
	urldate = {2017-11-11},
	author = {Lanctot, Marc and Zambaldi, Vinicius and Gruslys, Audrunas and Lazaridou, Angeliki and Tuyls, Karl and Perolat, Julien and Silver, David and Graepel, Thore},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.00832},
}

@article{perkins_network_2021,
	title = {Network organisation and the dynamics of tubules in the endoplasmic reticulum},
	volume = {11},
	issn = {2045-2322},
	doi = {10.1038/s41598-021-94901-2},
	abstract = {The endoplasmic reticulum (ER) is a eukaryotic subcellular organelle composed of tubules and sheet-like areas of membrane connected at junctions. The tubule network is highly dynamic and undergoes rapid and continual rearrangement. There are currently few tools to evaluate network organisation and dynamics. We quantified ER network organisation in Vero and MRC5 cells, and developed an analysis workflow for dynamics of established tubules in live cells. The persistence length, tubule length, junction coordination number and angles of the network were quantified. Hallmarks of imbalances in ER tension, indications of interactions with microtubules and other subcellular organelles, and active dynamics were observed. Clear differences in dynamic behaviour were observed for established tubules at different positions within the cell using itemset mining. We found that tubules with activity-driven fluctuations were more likely to be located away from the cell periphery and a population of peripheral tubules with no signs of active motion was found.},
	language = {eng},
	number = {1},
	journal = {Scientific Reports},
	author = {Perkins, Hannah T. and Allan, Victoria J. and Waigh, Thomas A.},
	month = aug,
	year = {2021},
	pmid = {34376706},
	pmcid = {PMC8355327},
	keywords = {Animals, Chlorocebus aethiops, Endoplasmic Reticulum, Fibroblasts, Humans, Lung, Microtubules, Vero Cells},
	pages = {16230},
}

@book{parlett_symmetric_1998,
	title = {The {Symmetric} {Eigenvalue} {Problem}},
	isbn = {978-0-89871-402-9},
	url = {http://epubs.siam.org/doi/book/10.1137/1.9781611971163},
	urldate = {2018-05-23},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Parlett, Beresford N.},
	month = jan,
	year = {1998},
	doi = {10.1137/1.9781611971163},
}

@article{ohi_emerging_2022,
	title = {Emerging {Insights} into the {Molecular} {Architecture} of {Caveolin}-1},
	volume = {255},
	doi = {10.1007/s00232-022-00259-5},
	abstract = {Caveolins are an unusual family of membrane proteins whose primary biological function is to build small invaginated membrane structures at the surface of cells known as caveolae. Caveolins and caveolae regulate numerous signaling pathways, lipid homeostasis, intracellular transport, cell adhesion, and cell migration. They also serve as sensors and protect the plasma membrane from mechanical stress. Despite their many important functions, the molecular basis for how these 50–100 nm “little caves” are assembled and regulate cell physiology has perplexed researchers for 70 years. One major impediment to progress has been the lack of information about the structure of caveolin complexes that serve as building blocks for the assembly of caveolae. Excitingly, recent advances have finally begun to shed light on this long-standing question. In this review, we highlight new developments in our understanding of the structure of caveolin oligomers, including the landmark discovery of the molecular architecture of caveolin-1 complexes using cryo-electron microscopy.

Graphical Abstract},
	journal = {The Journal of Membrane Biology},
	author = {Ohi, Melanie and Kenworthy, Anne},
	month = aug,
	year = {2022},
	keywords = {Caveolae, Caveolin, Caveolin 1, Cell Membrane, Cryo-electron microscopy, Cryoelectron Microscopy, Lipids, Membrane Proteins, Membrane nanodomains, Membrane protein structure},
}

@article{Nehmeb,
	title = {Deep-{STORM}: {Super} {Resolution} {Single} {Molecule} {Microscopy} by {Deep} {Learning}},
	abstract = {We present an ultra-fast, precise, parameter-free method, which we term Deep-STORM, for obtaining super-resolution im-ages from stochastically-blinking emitters, such as fluorescent molecules used for localization microscopy. Deep-STORM uses a deep convolutional neural network that can be trained on sim-ulated data or experimental measurements, both of which are demonstrated. The method achieves state-of-the-art resolution under challenging signal-to-noise conditions and high emitter densities, and is significantly faster than existing approaches. Additionally, no prior information on the shape of the underly-ing structure is required, making the method applicable to any blinking data-set. We validate our approach by super-resolution image reconstruction of simulated and experimentally obtained data.},
	urldate = {2018-01-30},
	author = {Nehme, Elias and Weiss, Lucien E and Michaeli, Tomer and Shechtman, Yoav},
	keywords = {Deep Learning, Diffraction limit, Fluorescence Microscopy, High numerical aperture optics, Image enhancement, Image processing, Image reconstruction, Spatial resolution, Superresolution},
}

@article{meng_phosphocaveolin-1_2017,
	title = {The phospho–caveolin-1 scaffolding domain dampens force fluctuations in focal adhesions and promotes cancer cell migration},
	volume = {28},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.e17-05-0278},
	doi = {10.1091/mbc.e17-05-0278},
	number = {16},
	urldate = {2018-11-28},
	journal = {Molecular Biology of the Cell},
	author = {Meng, Fanrui and Saxena, Sandeep and Liu, Youtao and Joshi, Bharat and Wong, Timothy H. and Shankar, Jay and Foster, Leonard J. and Bernatchez, Pascal and Nabi, Ivan R.},
	editor = {Nusrat, Asma},
	month = aug,
	year = {2017},
	pages = {2190--2201},
}

@article{matula_properties_2010,
	title = {Properties of {Gabriel} {Graphs} {Relevant} to {Geographic} {Variation} {Research} and the {Clustering} of {Points} in the {Plane}},
	volume = {12},
	issn = {00167363},
	url = {http://doi.wiley.com/10.1111/j.1538-4632.1980.tb00031.x},
	doi = {10.1111/j.1538-4632.1980.tb00031.x},
	number = {3},
	urldate = {2018-03-26},
	journal = {Geographical Analysis},
	author = {Matula, David W. and Sokal, Robert R.},
	month = sep,
	year = {2010},
	note = {Publisher: Wiley/Blackwell (10.1111)},
	pages = {205--222},
}

@article{marenda_parameter-free_2021,
	title = {Parameter-free molecular super-structures quantification in single-molecule localization microscopy},
	volume = {220},
	issn = {0021-9525, 1540-8140},
	url = {https://rupress.org/jcb/article/220/5/e202010003/211893/Parameter-free-molecular-super-structures},
	doi = {10.1083/jcb.202010003},
	abstract = {Understanding biological function requires the identification and characterization of complex patterns of molecules. Single-molecule localization microscopy (SMLM) can quantitatively measure molecular components and interactions at resolutions far beyond the diffraction limit, but this information is only useful if these patterns can be quantified and interpreted. We provide a new approach for the analysis of SMLM data that develops the concept of structures and super-structures formed by interconnected elements, such as smaller protein clusters. Using a formal framework and a parameter-free algorithm, (super-)structures formed from smaller components are found to be abundant in classes of nuclear proteins, such as heterogeneous nuclear ribonucleoprotein particles (hnRNPs), but are absent from ceramides located in the plasma membrane. We suggest that mesoscopic structures formed by interconnected protein clusters are common within the nucleus and have an important role in the organization and function of the genome. Our algorithm, SuperStructure, can be used to analyze and explore complex SMLM data and extract functionally relevant information.},
	language = {en},
	number = {5},
	urldate = {2023-09-27},
	journal = {Journal of Cell Biology},
	author = {Marenda, Mattia and Lazarova, Elena and Van De Linde, Sebastian and Gilbert, Nick and Michieletto, Davide},
	month = may,
	year = {2021},
	pages = {e202010003},
}

@article{Manzo2015,
	title = {A review of progress in single particle tracking: from methods to biophysical insights},
	volume = {78},
	issn = {13616633},
	doi = {10.1088/0034-4885/78/12/124601},
	abstract = {Optical microscopy has for centuries been a key tool to study living cells with minimum invasiveness. The advent of single molecule techniques over the past two decades has revolutionized the field of cell biology by providing a more quantitative picture of the complex and highly dynamic organization of living systems. Amongst these techniques, single particle tracking (SPT) has emerged as a powerful approach to study a variety of dynamic processes in life sciences. SPT provides access to single molecule behavior in the natural context of living cells, thereby allowing a complete statistical characterization of the system under study. In this review we describe the foundations of SPT together with novel optical implementations that nowadays allow the investigation of single molecule dynamic events with increasingly high spatiotemporal resolution using molecular densities closer to physiological expression levels. We outline some of the algorithms for the faithful reconstruction of SPT trajectories as well as data analysis, and highlight biological examples where the technique has provided novel insights into the role of diffusion regulating cellular function. The last part of the review concentrates on different theoretical models that describe anomalous transport behavior and ergodicity breaking observed from SPT studies in living cells.},
	number = {12},
	journal = {Reports on progress in physics. Physical Society (Great Britain)},
	author = {Manzo, Carlo and Garcia-Parajo, Maria F.},
	year = {2015},
	pmid = {26511974},
	note = {ISBN: 1361-6633 (Electronic){\textbackslash}r0034-4885 (Linking)},
	pages = {124601},
}

@article{Ludwig2016,
	title = {Architecture of the caveolar coat complex.},
	volume = {129},
	issn = {1477-9137},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27369768},
	doi = {10.1242/jcs.191262},
	abstract = {Caveolae are specialized membrane domains that are crucial for the correct function of endothelial cells, adipocytes and muscle cells. Caveolins and cavins are both required for caveolae formation, and assemble into a large (80S) caveolar coat complex (80S-CCC). The architecture of the 80S-CCC, however, has not been analyzed. Here, we study the 80S-CCC isolated from mammalian cells using negative stain electron microscopy and 3D cryo-electron tomography. We show that the 80S-CCC is a hollow sphere with a diameter of 50-80 nm, and so has the same size and shape as individual caveolar bulbs. This provides strong evidence that the distinctive membrane shape of caveolae is generated by the shape of the 80S-CCC itself. The particle appears to be made up of two layers, an inner coat composed of polygonal units of caveolins that form a polyhedral cage, and an outer filamentous coat composed of cavins. The data suggest that the peripheral cavin coat is aligned along the edges of the inner polyhedral cage, thereby providing a mechanism for the generation of a morphologically stable caveolar coat.},
	number = {16},
	urldate = {2018-11-26},
	journal = {Journal of cell science},
	author = {Ludwig, Alexander and Nichols, Benjamin James and Sandin, Sara},
	month = jul,
	year = {2016},
	pmid = {27369768},
	note = {Publisher: The Company of Biologists Ltd},
	keywords = {Caveolae, Caveolar coat, Caveolin, Cavin, Cryo-electron tomography},
	pages = {3077--83},
}

@article{li_real-time_2018,
	title = {Real-time {3D} single-molecule localization using experimental point spread functions},
	volume = {15},
	issn = {1548-7091},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/29630062},
	doi = {10.1038/nmeth.4661},
	abstract = {We present a real-time fitter for 3D single-molecule localization microscopy using experimental point spread functions (PSFs) that achieves minimal uncertainty in 3D on any microscope and is compatible with any PSF engineering approach. We used this method to image cellular structures and attained unprecedented image quality for astigmatic PSFs. The fitter compensates for most optical aberrations and makes accurate 3D super-resolution microscopy broadly accessible, even on standard microscopes without dedicated 3D optics.},
	number = {5},
	urldate = {2018-09-12},
	journal = {Nature Methods},
	author = {Li, Yiming and Mund, Markus and Hoess, Philipp and Deschamps, Joran and Matti, Ulf and Nijmeijer, Bianca and Sabinina, Vilma Jimenez and Ellenberg, Jan and Schoen, Ingmar and Ries, Jonas},
	month = apr,
	year = {2018},
	pmid = {29630062},
	keywords = {Software, Super, resolution microscopy},
	pages = {367--369},
}

@book{li_towards_2016,
	title = {Towards {Direct} {Medical} {Image} {Analysis} without {Segmentation}},
	abstract = {Invited presentation by VALSE},
	author = {Li, Shuo},
	month = jan,
	year = {2016},
	doi = {10.13140/RG.2.1.2125.1600},
}

@incollection{Li2017,
	title = {Fast {Background} {Removal} {Method} for {3D} {Multi}-channel {Deep} {Tissue} {Fluorescence} {Imaging}},
	url = {http://link.springer.com/10.1007/978-3-319-66185-8_11},
	urldate = {2017-09-25},
	publisher = {Springer, Cham},
	author = {Li, Chenchen and Li, Xiaowei and Cao, Hongji and Jiang, He and Deng, Xiaotie and Chen, Danny Z. and Yang, Lin and Shao, Zhifeng},
	month = sep,
	year = {2017},
	doi = {10.1007/978-3-319-66185-8_11},
	pages = {92--99},
}

@article{finn_model-agnostic_2017,
	title = {Model-{Agnostic} {Meta}-{Learning} for {Fast} {Adaptation} of {Deep} {Networks}},
	url = {http://arxiv.org/abs/1703.03400},
	abstract = {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.},
	urldate = {2018-11-21},
	author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.03400},
}

@article{Fricke2015a,
	title = {One, two or three? {Probing} the stoichiometry of membrane proteins by single-molecule localization microscopy},
	volume = {5},
	issn = {20452322},
	doi = {10.1038/srep14072},
	abstract = {Probing the oligomeric state of abundant molecules, such as membrane proteins in intact cells, is essential, but has not been straightforward. We address this challenge with a simple counting strategy that is capable of reporting the oligomeric state of dense, membrane-bound protein complexes. It is based on single-molecule localization microscopy to super-resolve protein structures in intact cells and basic quantitative evaluation. We validate our method with membrane-bound monomeric CD86 and dimeric cytotoxic T-lymphocyte-associated protein as model proteins and confirm their oligomeric states. We further detect oligomerization of CD80 and vesicular stomatitis virus glycoprotein and propose coexistence of monomers and dimers for CD80 and trimeric assembly of the viral protein at the cell membrane. This approach should prove valuable for researchers striving for reliable molecular counting in cells.},
	journal = {Scientific Reports},
	author = {Fricke, Franziska and Beaudouin, Joel and Eils, Roland and Heilemann, Mike},
	year = {2015},
	pmid = {26358640},
	note = {ISBN: 1548-7091},
	keywords = {Single, Super, molecule biophysics, resolution microscopy},
}

@article{Gahlmann2014,
	title = {Exploring bacterial cell biology with single-molecule tracking and super-resolution imaging},
	volume = {12},
	issn = {17401526},
	doi = {10.1038/nrmicro3154},
	abstract = {The ability to detect single molecules in live bacterial cells enables us to probe biological events one molecule at a time and thereby gain knowledge of the activities of intracellular molecules that remain obscure in conventional ensemble-averaged measurements. Single-molecule fluorescence tracking and super-resolution imaging are thus providing a new window into bacterial cells and facilitating the elucidation of cellular processes at an unprecedented level of sensitivity, specificity and spatial resolution. In this Review, we consider what these technologies have taught us about the bacterial cytoskeleton, nucleoid organization and the dynamic processes of transcription and translation, and we also highlight the methodological improvements that are needed to address a number of experimental challenges in the field.},
	number = {1},
	journal = {Nature Reviews Microbiology},
	author = {Gahlmann, Andreas and Moerner, W. E.},
	year = {2014},
	pmid = {24336182},
	note = {arXiv: NIHMS150003
ISBN: 1740-1534 (Electronic){\textbackslash}r1740-1526 (Linking)},
	pages = {9--22},
}

@incollection{Jog2016,
	title = {Self {Super}-{Resolution} for {Magnetic} {Resonance} {Images}},
	url = {http://link.springer.com/10.1007/978-3-319-46726-9_64},
	urldate = {2017-10-03},
	publisher = {Springer, Cham},
	author = {Jog, Amod and Carass, Aaron and Prince, Jerry L.},
	month = oct,
	year = {2016},
	doi = {10.1007/978-3-319-46726-9_64},
	pages = {553--560},
}

@article{jakovljevic_recognition_2015,
	title = {Recognition of {Planar} {Segments} in {Point} {Cloud} {Based} on {Wavelet} {Transform}},
	volume = {11},
	issn = {1941-0050},
	doi = {10.1109/TII.2015.2389195},
	abstract = {Within industrial automation systems, three-dimensional (3-D) vision provides very useful feedback information in autonomous operation of various manufacturing equipment (e.g., industrial robots, material handling devices, assembly systems, and machine tools). The hardware performance in contemporary 3-D scanning devices is suitable for online utilization. However, the bottleneck is the lack of real-time algorithms for recognition of geometric primitives (e.g., planes and natural quadrics) from a scanned point cloud. One of the most important and the most frequent geometric primitive in various engineering tasks is plane. In this paper, we propose a new fast one-pass algorithm for recognition (segmentation and fitting) of planar segments from a point cloud. To effectively segment planar regions, we exploit the orthonormality of certain wavelets to polynomial function, as well as their sensitivity to abrupt changes. After segmentation of planar regions, we estimate the parameters of corresponding planes using standard fitting procedures. For point cloud structuring, a z-buffer algorithm with mesh triangles representation in barycentric coordinates is employed. The proposed recognition method is tested and experimentally validated in several real-world case studies.},
	number = {2},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Jakovljevic, Zivana and Puzovic, Radovan and Pajic, Miroslav},
	month = apr,
	year = {2015},
	keywords = {3D vision, Approximation methods, Discrete wavelet transforms, Image segmentation, Industrial automation systems, Intelligent manufacturing systems, Manufacturing automation, Multiresolution analysis, Object recognition, Object segmentation, Reverse engineering, Three-dimensional displays, intelligent manufacturing systems, manufacturing automation, object recognition, object segmentation, reverse engineering (RE), three-dimensional (3-D) vision},
	pages = {342--352},
}

@article{husslage_space-filling_2011,
	title = {Space-filling {Latin} hypercube designs for computer experiments},
	volume = {12},
	issn = {1389-4420},
	url = {http://link.springer.com/10.1007/s11081-010-9129-8},
	doi = {10.1007/s11081-010-9129-8},
	number = {4},
	urldate = {2017-05-29},
	journal = {Optimization and Engineering},
	author = {Husslage, Bart G. M. and Rennen, Gijs and van Dam, Edwin R. and den Hertog, Dick},
	month = dec,
	year = {2011},
	note = {Publisher: Springer US},
	pages = {611--630},
}

@article{hummer_model-independent_2016,
	title = {Model-independent counting of molecules in single-molecule localization microscopy.},
	volume = {27},
	issn = {1939-4586},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27466316},
	doi = {10.1091/mbc.E16-07-0525},
	abstract = {Most biomolecular processes rely on tightly controlled stoichiometries, from the formation of molecular assemblies to cellular signaling. Single-molecule localization micro-scopy studies of fluorophore blinking offer a promising route to probe oligomeric states. Here we show that the distribution of the number of blinking events assumes a universal functional form, independent of photophysics, under relatively mild assumptions. The number of photophysical states, the kinetics of interconversion, and the fraction of active fluorophores enter as two or three constants. This essentially model-independent formulation allows us to determine molecule counts from fluorophore blinking statistics. The formulas hold even if the fluorophores have many different yet unresolved dark states, as long as there is only a single fluorescent state, or if there are different yet unresolvable fluorescent states, as long as there is only a single dark state. We demonstrate the practical applicability of this approach by quantifying the oligomerization states of membrane proteins tagged with the mEos2 fluorescent protein. We find that the model parameters, obtained by likelihood maximization, are transferable. With the counting statistics being independent of the detailed photophysics and its parameters being transferable, the method should be robust and broadly applicable to counting colocalized molecules in vivo and in vitro.},
	number = {22},
	urldate = {2018-02-14},
	journal = {Molecular biology of the cell},
	author = {Hummer, Gerhard and Fricke, Franziska and Heilemann, Mike},
	month = nov,
	year = {2016},
	pmid = {27466316},
	note = {Publisher: American Society for Cell Biology},
	pages = {3637--3644},
}

@article{Huang2011b,
	title = {Simultaneous multiple-emitter fitting for single molecule super-resolution imaging},
	volume = {2},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-2-5-1377},
	doi = {10.1364/BOE.2.001377},
	abstract = {Single molecule localization based super-resolution imaging techniques require repeated localization of many single emitters. We describe a method that uses the maximum likelihood estimator to localize multiple emitters simultaneously within a single, two-dimensional fitting sub-region, yielding an order of magnitude improvement in the tolerance of the analysis routine with regards to the single-frame active emitter density. Multiple-emitter fitting enables the overall performance of single-molecule super-resolution to be improved in one or more of several metrics that result in higher single-frame density of localized active emitters. For speed, the algorithm is implemented on Graphics Processing Unit (GPU) architecture, resulting in analysis times on the order of minutes. We show the performance of multiple emitter fitting as a function of the single-frame active emitter density. We describe the details of the algorithm that allow robust fitting, the details of the GPU implementation, and the other imaging processing steps required for the analysis of data sets.},
	number = {5},
	urldate = {2018-01-30},
	journal = {Biomedical Optics Express},
	author = {Huang, Fang and Schwartz, Samantha L. and Byars, Jason M. and Lidke, Keith A.},
	month = may,
	year = {2011},
	note = {Publisher: Optical Society of America},
	keywords = {Fluorescence microscopy, Image reconstruction techniques, Superresolution},
	pages = {1377},
}

@inproceedings{hu_open_2020,
	title = {Open {Graph} {Benchmark}: {Datasets} for {Machine} {Learning} on {Graphs}},
	volume = {33},
	shorttitle = {Open {Graph} {Benchmark}},
	url = {https://proceedings.neurips.cc/paper/2020/hash/fb60d411a5c5b72b2e7d3527cfc84fd0-Abstract.html},
	abstract = {We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale, encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at https://ogb.stanford.edu .},
	urldate = {2023-10-31},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
	year = {2020},
	pages = {22118--22133},
}

@article{Emmert-Streib2016,
	title = {Fifty years of graph matching, network alignment and network comparison},
	volume = {346-347},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S002002551630010X},
	doi = {10.1016/J.INS.2016.01.074},
	abstract = {In this paper we survey methods for performing a comparative graph analysis and explain the history, foundations and differences of such techniques of the last 50 years. While surveying these methods, we introduce a novel classification scheme by distinguishing between methods for deterministic and random graphs. We believe that this scheme is useful for a better understanding of the methods, their challenges and, finally, for applying the methods efficiently in an interdisciplinary setting of data science to solve a particular problem involving comparative network analysis.},
	urldate = {2018-04-24},
	journal = {Information Sciences},
	author = {Emmert-Streib, Frank and Dehmer, Matthias and Shi, Yongtang},
	month = jun,
	year = {2016},
	note = {Publisher: Elsevier},
	pages = {180--197},
}

@article{ellingson_protein_2012,
	title = {Protein {Surface} {Matching} by {Combining} {Local} and {Global} {Geometric} {Information}},
	volume = {7},
	issn = {1932-6203},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22815760},
	doi = {10.1371/journal.pone.0040540},
	abstract = {Comparison of the binding sites of proteins is an effective means for predicting protein functions based on their structure information. Despite the importance of this problem and much research in the past, it is still very challenging to predict the binding ligands from the atomic structures of protein binding sites. Here, we designed a new algorithm, TIPSA (Triangulation-based Iterative-closest-point for Protein Surface Alignment), based on the iterative closest point (ICP) algorithm. TIPSA aims to find the maximum number of atoms that can be superposed between two protein binding sites, where any pair of superposed atoms has a distance smaller than a given threshold. The search starts from similar tetrahedra between two binding sites obtained from 3D Delaunay triangulation and uses the Hungarian algorithm to find additional matched atoms. We found that, due to the plasticity of protein binding sites, matching the rigid body of point clouds of protein binding sites is not adequate for satisfactory binding ligand prediction. We further incorporated global geometric information, the radius of gyration of binding site atoms, and used nearest neighbor classification for binding site prediction. Tested on benchmark data, our method achieved a performance comparable to the best methods in the literature, while simultaneously providing the common atom set and atom correspondences.},
	number = {7},
	urldate = {2018-08-15},
	journal = {PLoS ONE},
	author = {Ellingson, Leif and Zhang, Jinfeng},
	editor = {Fraternali, Franca},
	month = jul,
	year = {2012},
	pmid = {22815760},
	pages = {e40540},
}

@article{Du2016a,
	title = {Measurement uncertainty on the circular features in coordinate measurement system based on the error ellipse and {Monte} {Carlo} methods},
	volume = {27},
	issn = {0957-0233},
	url = {http://stacks.iop.org/0957-0233/27/i=12/a=125016?key=crossref.0c262760c72501985475e19209de2ace},
	doi = {10.1088/0957-0233/27/12/125016},
	number = {12},
	urldate = {2018-03-15},
	journal = {Measurement Science and Technology},
	author = {Du, Zhengchun and Zhu, Mengrui and Wu, Zhaoyong and Yang, Jianguo},
	month = dec,
	year = {2016},
	note = {Publisher: IOP Publishing},
	pages = {125016},
}

@article{Dolatshah,
	title = {Ball*-tree: {Efficient} spatial indexing for constrained nearest-neighbor search in metric spaces},
	abstract = {Emerging location-based systems and data analysis frame-works requires efficient management of spatial data for approximate and exact search. Exact similarity search can be done using space partitioning data structures, such as KD-tree, R*-tree, and ball-tree. In this paper, we focus on ball-tree, an efficient search tree that is specific for spatial queries which use euclidean distance. Each node of a ball-tree defines a ball, i.e. a hypersphere that contains a subset of the points to be searched. In this paper, we propose ball*-tree, an improved ball-tree that is more efficient for spatial queries. Ball*-tree enjoys a modified space partition-ing algorithm that considers the distribution of the data points in order to find an efficient splitting hyperplane. Also, we propose a new algorithm for KNN queries with restricted range using ball*-tree, which performs better than both KNN and range search for such queries. Results show that ball*-tree performs 39\%-57\% faster than the original ball-tree algo-rithm.},
	urldate = {2018-02-19},
	author = {Dolatshah, Mohamad and Hadian, Ali and Minaei-Bidgoli, Behrouz},
	keywords = {Ball-tree, Constrained NN, Eigenvector analysis, Range search, Spatial indexing},
}

@article{Diederich2018,
	title = {{cellSTORM} - {Cost}-effective {Super}-{Resolution} on a {Cellphone} using {dSTORM}},
	url = {http://arxiv.org/abs/1804.06244},
	abstract = {Expensive scientific camera hardware is amongst the main cost factors in modern, high-performance microscopes. On the other hand, cheap, consumer-grade camera devices can provide surprisingly good performance. Widely available smartphones include cameras, providing a good opportunity for "imaging on a budget". Yet, Single-Molecule-Localization-Microscopy (SMLM) techniques like Photoactivated Localization Microscopy (PALM) or (direct) Stochastic Optical Reconstruction Microscopy dSTORM, are demanding in terms of photon sensitivity and readout noise, seemingly requiring a scientific-grade camera. Here we show that super-resolution imaging by dSTORM is possible using a consumer grade cellphone camera. Trained image-to-image generative adversarial network (GAN), successfully improves the signal-to-noise ratio (SNR) by compensating noise and compression artifacts in the acquired video-stream at poor imaging conditions. We believe that "cellSTORM" paves the way for affordable super-resolution microscopy suitable for research and education. Our low-cost setup achieves optical resolution below 80{\textbackslash},nm yielding wide access to cutting edge research to a big community.},
	urldate = {2018-04-27},
	author = {Diederich, Benedict and Then, Patrick and Jügler, Alexander and Förster, Ronny and Heintzmann, Rainer},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.06244},
}

@article{Dempsey2011,
	title = {Evaluation of fluorophores for optimal performance in localization-based super-resolution imaging.},
	volume = {8},
	issn = {1548-7105},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22056676},
	doi = {10.1038/nmeth.1768},
	abstract = {One approach to super-resolution fluorescence imaging uses sequential activation and localization of individual fluorophores to achieve high spatial resolution. Essential to this technique is the choice of fluorescent probes; the properties of the probes, including photons per switching event, on-off duty cycle, photostability and number of switching cycles, largely dictate the quality of super-resolution images. Although many probes have been reported, a systematic characterization of the properties of these probes and their impact on super-resolution image quality has been described in only a few cases. Here we quantitatively characterized the switching properties of 26 organic dyes and directly related these properties to the quality of super-resolution images. This analysis provides guidelines for characterization of super-resolution probes and a resource for selecting probes based on performance. Our evaluation identified several photoswitchable dyes with good to excellent performance in four independent spectral ranges, with which we demonstrated low-cross-talk, four-color super-resolution imaging.},
	number = {12},
	urldate = {2017-09-27},
	journal = {Nature methods},
	author = {Dempsey, Graham T and Vaughan, Joshua C and Chen, Kok Hao and Bates, Mark and Zhuang, Xiaowei},
	month = nov,
	year = {2011},
	pmid = {22056676},
	note = {Publisher: NIH Public Access},
	keywords = {Fluorescence imaging, Fluorescent dyes, Single, Super, molecule fluorescence, resolution microscopy},
	pages = {1027--36},
}

@article{Dedecker2012b,
	title = {and {Modular} {Software} {Package} for {Superresolution} {Microscopy}},
	issn = {1560-2281},
	doi = {10.1117/1.JBO.17.12},
	abstract = {We present Localizer, a freely available and open source software package that implements the computational data processing inherent to several types of superresolution fluorescence imaging, such as localization (PALM/STORM/GSDIM) and fluctuation imaging (SOFI/pcSOFI). Localizer delivers high accuracy and performance and comes with a fully featured and easy-to-use graphical user interface but is also designed to be integrated in higher-level analysis environments. Due to its modular design, Localizer can be readily extended with new algorithms as they become available, while maintaining the same interface and performance. We provide front-ends for running Localizer from Igor Pro, Matlab, or as a stand-alone program. We show that Localizer performs favorably when compared with two existing superresolution packages, and to our knowledge is the only freely available implementation of SOFI/pcSOFI microscopy. By dramatically improving the analysis performance and ensuring the easy addition of current and future enhancements, Localizer strongly improves the usability of superresolution imaging in a variety of biomedical studies.},
	journal = {Journal of Biomedical Optics},
	author = {Dedecker, Peter and Neely, Robert K},
	year = {2012},
	pmid = {23208219},
	note = {ISBN: 1560-2281 (Electronic){\textbackslash}r1083-3668 (Linking)},
	keywords = {2012, 31, 5, accepted for publication oct, image processing, paper 12427l received jul, published online, revised manuscript received oct, subdiffraction limit},
}

@inproceedings{de_schepper_pi_2016,
	address = {New York, New York, USA},
	title = {{PI} $^{\textrm{2}}$},
	isbn = {978-1-4503-4292-6},
	url = {http://dl.acm.org/citation.cfm?doid=2999572.2999578},
	doi = {10.1145/2999572.2999578},
	urldate = {2017-05-25},
	booktitle = {Proceedings of the 12th {International} on {Conference} on emerging {Networking} {EXperiments} and {Technologies}  - {CoNEXT} '16},
	publisher = {ACM Press},
	author = {De Schepper, Koen and Bondarenko, Olga and Tsang, Ing-Jyh and Briscoe, Bob},
	year = {2016},
	keywords = {algorithms, aqm, congestion control, fairness, latency, qos, scalability, scheduling, starvation, tcp, testbed evaluation},
	pages = {105--119},
}

@techreport{de_bie_stochastic_2018,
	title = {Stochastic {Deep} {Networks}},
	abstract = {Machine learning is increasingly targeting areas where input data cannot be accurately described by a single vector, but can be modeled instead using the more flexible concept of random vectors, namely probability measures or more simply point clouds of varying cardinality. Using deep architectures on measures poses, however, many challenging issues. Indeed, deep architectures are originally designed to handle fixed-length vectors, or, using recursive mechanisms, ordered sequences thereof. In sharp constrast, measures describe a varying number of weighted observations with no particular order. We propose in this work a deep framework designed to handle crucial aspects of measures, namely permutation invariances, variations in weights and cardinality. Architectures derived from this pipeline can (i) map measures to measures-using the concept of push-forward operators; (ii) bridge the gap between measures and Euclidean spaces-through integration steps. This allows to design dis-criminative networks (to classify or reduce the dimen-sionality of input measures), generative architectures (to synthesize measures) and recurrent pipelines (to predict measure dynamics). We provide a theoretical analysis of these building blocks, review our archi-tectures' approximation abilities and robustness w.r.t. perturbation, and try them on various discriminative and generative tasks.},
	author = {De Bie, Gwendoline and Peyré, Gabriel and Cuturi, Marco and Brain, Google},
	year = {2018},
	note = {arXiv: 1811.07429v1},
}

@inproceedings{dai_deformable_2017,
	title = {Deformable {Convolutional} {Networks}},
	isbn = {978-1-5386-1032-9},
	doi = {10.1109/ICCV.2017.89},
	abstract = {Convolutional neural networks (CNNs) are inherently limited to model geometric transformations due to the fixed geometric structures in its building modules. In this work, we introduce two new modules to enhance the transformation modeling capacity of CNNs, namely, deformable convolution and deformable RoI pooling. Both are based on the idea of augmenting the spatial sampling locations in the modules with additional offsets and learning the offsets from target tasks, without additional supervision. The new modules can readily replace their plain counterparts in existing CNNs and can be easily trained end-to-end by standard back-propagation, giving rise to deformable convolutional networks. Extensive experiments validate the effectiveness of our approach on sophisticated vision tasks of object detection and semantic segmentation. The code would be released.},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},
	year = {2017},
	pmid = {23459267},
	note = {arXiv: 1703.06211
ISSN: 15505499},
}

@article{Colabrese2018a,
	title = {Machine learning approach for single molecule localisation microscopy},
	volume = {9},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/abstract.cfm?URI=boe-9-4-1680},
	doi = {10.1364/BOE.9.001680},
	abstract = {Single molecule localisation (SML) microscopy is a fundamental tool for biological discoveries; it provides sub-diffraction spatial resolution images by detecting and localizing \&\#x0201C;all\&\#x0201D; the fluorescent molecules labeling the structure of interest. For this reason, the effective resolution of SML microscopy strictly depends on the algorithm used to detect and localize the single molecules from the series of microscopy frames. To adapt to the different imaging conditions that can occur in a SML experiment, all current localisation algorithms request, from the microscopy users, the choice of different parameters. This choice is not always easy and their wrong selection can lead to poor performance. Here we overcome this weakness with the use of machine learning. We propose a parameter-free pipeline for SML learning based on support vector machine (SVM). This strategy requires a short supervised training that consists in selecting by the user few fluorescent molecules (\&\#x0223C; 10\&\#x02013;20) from the frames under analysis. The algorithm has been extensively tested on both synthetic and real acquisitions. Results are qualitatively and quantitatively consistent with the state of the art in SML microscopy and demonstrate that the introduction of machine learning can lead to a new class of algorithms competitive and conceived from the user point of view.},
	number = {4},
	urldate = {2018-03-21},
	journal = {Biomedical Optics Express},
	author = {Colabrese, Silvia and Castello, Marco and Vicidomini, Giuseppe and Del Bue, Alessio},
	month = apr,
	year = {2018},
	note = {Publisher: Optical Society of America},
	keywords = {(100.0100) Image processing, (100.5010) Pattern recognition, (180.2520) Fluorescence microscopy, Fluorescence microscopy, Image processing, Pattern recognition},
	pages = {1680},
}

@article{choi_stargan_2017,
	title = {{StarGAN}: {Unified} {Generative} {Adversarial} {Networks} for {Multi}-{Domain} {Image}-to-{Image} {Translation}},
	url = {http://arxiv.org/abs/1711.09020},
	abstract = {Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks.},
	urldate = {2017-11-28},
	author = {Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.09020},
}

@article{Chen2014,
	title = {Extending particle tracking capability with delaunay triangulation},
	issn = {15205827},
	doi = {10.1021/la500323r},
	abstract = {Particle tracking, the analysis of individual moving elements in time series of microscopic images, enables burgeoning new applications, but there is need to better resolve conformation and dynamics. Here we describe the advantages of Delaunay triangulation to extend the capabilities of particle tracking in three areas: (1) discriminating irregularly shaped objects, which allows one to track items other than point features; (2) combining time and space to better connect missing frames in trajectories; and (3) identifying shape backbone. To demonstrate the method, specific examples are given, involving analyzing the time-dependent molecular conformations of actin filaments and λ-DNA. The main limitation of this method, shared by all other clustering techniques, is the difficulty to separate objects when they are very close. This can be mitigated by inspecting locally to remove edges that are longer than their neighbors and also edges that link two objects, using methods described here, so that the combination of Delaunay triangulation with edge removal can be robustly applied to processing large data sets. As common software packages, both commercial and open source, can construct Delaunay triangulation on command, the methods described in this paper are both computationally efficient and easy to implement.},
	journal = {Langmuir},
	author = {Chen, Kejia and Anthony, Stephen M. and Granick, Steve},
	year = {2014},
	pmid = {24734998},
	note = {ISBN: 0743-7463},
}

@article{calderon_inferring_2017,
	title = {Inferring {Relevant} {Cell} {Types} for {Complex} {Traits} by {Using} {Single}-{Cell} {Gene} {Expression}},
	volume = {101},
	issn = {0002-9297},
	url = {https://www.sciencedirect.com/science/article/pii/S0002929717303786},
	doi = {10.1016/J.AJHG.2017.09.009},
	abstract = {Previous studies have prioritized trait-relevant cell types by looking for an enrichment of genome-wide association study (GWAS) signal within functional regions. However, these studies are limited in cell resolution by the lack of functional annotations from difficult-to-characterize or rare cell populations. Measurement of single-cell gene expression has become a popular method for characterizing novel cell types, and yet limited work has linked single-cell RNA sequencing (RNA-seq) to phenotypes of interest. To address this deficiency, we present RolyPoly, a regression-based polygenic model that can prioritize trait-relevant cell types and genes from GWAS summary statistics and gene expression data. RolyPoly is designed to use expression data from either bulk tissue or single-cell RNA-seq. In this study, we demonstrated RolyPoly’s accuracy through simulation and validated previously known tissue-trait associations. We discovered a significant association between microglia and late-onset Alzheimer disease and an association between schizophrenia and oligodendrocytes and replicating fetal cortical cells. Additionally, RolyPoly computes a trait-relevance score for each gene to reflect the importance of expression specific to a cell type. We found that differentially expressed genes in the prefrontal cortex of individuals with Alzheimer disease were significantly enriched with genes ranked highly by RolyPoly gene scores. Overall, our method represents a powerful framework for understanding the effect of common variants on cell types contributing to complex traits.},
	number = {5},
	urldate = {2018-10-03},
	journal = {The American Journal of Human Genetics},
	author = {Calderon, Diego and Bhaskar, Anand and Knowles, David A. and Golan, David and Raj, Towfique and Fu, Audrey Q. and Pritchard, Jonathan K.},
	month = nov,
	year = {2017},
	note = {Publisher: Cell Press},
	pages = {686--699},
}

@article{calaim_geometry_2022,
	title = {The geometry of robustness in spiking neural networks},
	volume = {11},
	doi = {10.7554/eLife.73276},
	abstract = {Neural systems are remarkably robust against various perturbations, a phenomenon that still requires a clear explanation. Here, we graphically illustrate howneural networks can become robust. We study spiking networks that generate low-dimensional representations, and we show that the neurons; subthreshold voltages are confined to a convex region in a lower-dimensional voltage subspace, which we call a 'bounding box'. Any changes in network parameters (such as number of neurons, dimensionality of inputs, firing thresholds, synapticweights, or transmission delays) can all be understood as deformations of this bounding box. Using these insights, we showthat functionality is preserved as long as perturbations do not destroy the integrity of the bounding box. We suggest that the principles underlying robustness in these networks-low-dimensional representations, heterogeneity of tuning, and precise negative feedback-may be key to understanding the robustness of neural systems at the circuit level.},
	journal = {eLife},
	author = {Calaim, Nuno and Dehmelt, Florian and Goncalves, Pedro and Machens, Christian},
	month = may,
	year = {2022},
}

@article{bui_neural_2017,
	title = {Neural {Graph} {Machines}: {Learning} {Neural} {Networks} {Using} {Graphs}},
	url = {http://arxiv.org/abs/1703.04818},
	abstract = {Label propagation is a powerful and flexible semi-supervised learning technique on graphs. Neural networks, on the other hand, have proven track records in many supervised learning tasks. In this work, we propose a training framework with a graph-regularised objective, namely "Neural Graph Machines", that can combine the power of neural networks and label propagation. This work generalises previous literature on graph-augmented training of neural networks, enabling it to be applied to multiple neural architectures (Feed-forward NNs, CNNs and LSTM RNNs) and a wide range of graphs. The new objective allows the neural networks to harness both labeled and unlabeled data by: (a) allowing the network to train using labeled data as in the supervised setting, (b) biasing the network to learn similar hidden representations for neighboring nodes on a graph, in the same vein as label propagation. Such architectures with the proposed objective can be trained efficiently using stochastic gradient descent and scaled to large graphs, with a runtime that is linear in the number of edges. The proposed joint training approach convincingly outperforms many existing methods on a wide range of tasks (multi-label classification on social graphs, news categorization, document classification and semantic intent classification), with multiple forms of graph inputs (including graphs with and without node-level features) and using different types of neural networks.},
	urldate = {2018-01-09},
	author = {Bui, Thang D. and Ravi, Sujith and Ramavajjala, Vivek},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.04818},
}

@article{Boyd2018,
	title = {{DeepLoco}: {Fast} {3D} {Localization} {Microscopy} {Using} {Neural} {Networks}},
	doi = {10.1101/267096},
	abstract = {Single-molecule localization super-resolution microscopy (SMLM) techniques like STORM and PALM have transformed cellular microscopy by substantially increasing spatial resolution. In this paper we introduce a new algorithm for a critical part of the SMLM process: estimating the number and locations of the fluorophores in a single frame. Our algorithm can analyze a 20000-frame experimental 3D SMLM dataset in about one second — substantially faster than real-time and existing algorithms. Our approach is straightforward but very different from existing algorithms: we train a neural network to minimize the Bayes' risk under a generative model for single SMLM frames. The neural network maps a frame directly to a collection of fluorophore locations, which we compare to the ground truth using a novel loss function. While training the neural network takes several hours, it only has to be done once for a given experimental setup. After training, localizing fluorophores in new images is extremely fast — orders of magnitude faster than existing algorithms. Faster recovery opens the door to real-time calibration and accelerated acquisition, and future work could tackle more complicated optical systems and more realistic simulators.},
	urldate = {2018-03-22},
	author = {Boyd, Nicholas and Jonas, Eric and Babcock, Hazen and Recht, Benjamin},
	year = {2018},
}

@article{Bodlaender2011,
	title = {Treewidth computations {II}. {Lower} bounds},
	issn = {08905401},
	doi = {10.1016/j.ic.2011.04.003},
	abstract = {For several applications, it is important to be able to compute the treewidth of a given graph and to find tree decompositions of small width reasonably fast. Good lower bounds on the treewidth of a graph can, amongst others, help to speed up branch and bound algorithms that compute the treewidth of a graph exactly. A high lower bound for a specific graph instance can tell that a dynamic programming approach for solving a problem is infeasible for this instance. This paper gives an overview of several recent methods that give lower bounds on the treewidth of graphs. © 2011 Elsevier Inc. All rights reserved.},
	journal = {Information and Computation},
	author = {Bodlaender, Hans L. and Koster, Arie M.C.A.},
	year = {2011},
	keywords = {Graph algorithms, Heuristics, Lower bounds, Treewidth},
}

@incollection{Bodlaender1988,
	title = {Dynamic programming on graphs with bounded treewidth},
	url = {http://link.springer.com/10.1007/3-540-19488-6_110},
	urldate = {2017-10-06},
	publisher = {Springer-Verlag},
	author = {Bodlaender, Hans L.},
	year = {1988},
	doi = {10.1007/3-540-19488-6_110},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {105--118},
}

@article{Biteen2017,
	title = {Introduction: {Super}-{Resolution} and {Single}-{Molecule} {Imaging}},
	volume = {117},
	issn = {0009-2665},
	url = {http://pubs.acs.org/doi/abs/10.1021/acs.chemrev.7b00242},
	doi = {10.1021/acs.chemrev.7b00242},
	number = {11},
	urldate = {2017-09-19},
	journal = {Chemical Reviews},
	author = {Biteen, Julie and Willets, Katherine A.},
	month = jun,
	year = {2017},
	note = {Publisher: American Chemical Society},
	pages = {7241--7243},
}

@article{bengio_practical_2012,
	title = {Practical {Recommendations} for {Gradient}-{Based} {Training} of {Deep} {Architectures}},
	abstract = {Learning algorithms related to artificial neural net-works and in particular for Deep Learning may seem to involve many bells and whistles, called hyper-parameters. This chapter is meant as a practical guide with recommendations for some of the most commonly used hyper-parameters, in particular in the context of learning algorithms based on back-propagated gradient and gradient-based optimiza-tion. It also discusses how to deal with the fact that more interesting results can be obtained when allow-ing one to adjust many hyper-parameters. Overall, it describes elements of the practice used to successfully and efficiently train and debug large-scale and often deep multi-layer neural networks. It closes with open questions about the training difficulties observed with deeper architectures.},
	urldate = {2017-10-13},
	author = {Bengio, Yoshua},
	year = {2012},
	note = {arXiv: 1206.5533v2},
	keywords = {()},
}

@article{jusuf_towards_2022,
	title = {Towards optimal point spread function design for resolving closely spaced emitters in three dimensions},
	volume = {30},
	issn = {1094-4087},
	url = {https://opg.optica.org/abstract.cfm?URI=oe-30-20-37154},
	doi = {10.1364/OE.472067},
	abstract = {The past decade has brought many innovations in optical design for 3D super-resolution imaging of point-like emitters, but these methods often focus on single-emitter localization precision as a performance metric. Here, we propose a simple heuristic for designing a point spread function (PSF) that allows for precise measurement of the distance between two emitters. We discover that there are two types of PSFs that achieve high performance for resolving emitters in 3D, as quantified by the Cramér-Rao bounds for estimating the separation between two closely spaced emitters. One PSF is very similar to the existing Tetrapod PSFs; the other is a rotating single-spot PSF, which we call the crescent PSF. The latter exhibits excellent performance for localizing single emitters throughout a 1-µm focal volume (localization precisions of 7.3 nm in 
              x 
              , 7.7 nm in 
              y 
              , and 18.3 nm in 
              z 
              using 1000 detected photons), and it distinguishes between one and two closely spaced emitters with superior accuracy (25-53\% lower error rates than the best-performing Tetrapod PSF, averaged throughout a 1-µm focal volume). Our study provides additional insights into optimal strategies for encoding 3D spatial information into optical PSFs.},
	language = {en},
	number = {20},
	urldate = {2024-03-19},
	journal = {Optics Express},
	author = {Jusuf, James M. and Lew, Matthew D.},
	month = sep,
	year = {2022},
	pages = {37154},
}

@article{sarkans_rembi_2021,
	title = {{REMBI}: {Recommended} {Metadata} for {Biological} {Images}—enabling reuse of microscopy data in biology},
	volume = {18},
	copyright = {2021 Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{REMBI}},
	url = {https://www.nature.com/articles/s41592-021-01166-8},
	doi = {10.1038/s41592-021-01166-8},
	abstract = {Bioimaging data have significant potential for reuse, but unlocking this potential requires systematic archiving of data and metadata in public databases. We propose draft metadata guidelines to begin addressing the needs of diverse communities within light and electron microscopy. We hope this publication and the proposed Recommended Metadata for Biological Images (REMBI) will stimulate discussions about their implementation and future extension.},
	language = {en},
	number = {12},
	urldate = {2024-03-19},
	journal = {Nature Methods},
	author = {Sarkans, Ugis and Chiu, Wah and Collinson, Lucy and Darrow, Michele C. and Ellenberg, Jan and Grunwald, David and Hériché, Jean-Karim and Iudin, Andrii and Martins, Gabriel G. and Meehan, Terry and Narayan, Kedar and Patwardhan, Ardan and Russell, Matthew Robert Geoffrey and Saibil, Helen R. and Strambio-De-Castillia, Caterina and Swedlow, Jason R. and Tischer, Christian and Uhlmann, Virginie and Verkade, Paul and Barlow, Mary and Bayraktar, Omer and Birney, Ewan and Catavitello, Cesare and Cawthorne, Christopher and Wagner-Conrad, Stephan and Duke, Elizabeth and Paul-Gilloteaux, Perrine and Gustin, Emmanuel and Harkiolaki, Maria and Kankaanpää, Pasi and Lemberger, Thomas and McEntyre, Jo and Moore, Josh and Nicholls, Andrew W. and Onami, Shuichi and Parkinson, Helen and Parsons, Maddy and Romanchikova, Marina and Sofroniew, Nicholas and Swoger, Jim and Utz, Nadine and Voortman, Lenard M. and Wong, Frances and Zhang, Peijun and Kleywegt, Gerard J. and Brazma, Alvis},
	month = dec,
	year = {2021},
	keywords = {Data integration, Molecular imaging, Optical imaging},
	pages = {1418--1422},
}

@article{schmied_community-developed_2024,
	title = {Community-developed checklists for publishing images and image analyses},
	volume = {21},
	copyright = {2023 Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-023-01987-9},
	doi = {10.1038/s41592-023-01987-9},
	abstract = {Images document scientific discoveries and are prevalent in modern biomedical research. Microscopy imaging in particular is currently undergoing rapid technological advancements. However, for scientists wishing to publish obtained images and image-analysis results, there are currently no unified guidelines for best practices. Consequently, microscopy images and image data in publications may be unclear or difficult to interpret. Here, we present community-developed checklists for preparing light microscopy images and describing image analyses for publications. These checklists offer authors, readers and publishers key recommendations for image formatting and annotation, color selection, data availability and reporting image-analysis workflows. The goal of our guidelines is to increase the clarity and reproducibility of image figures and thereby to heighten the quality and explanatory power of microscopy data.},
	language = {en},
	number = {2},
	urldate = {2024-03-19},
	journal = {Nature Methods},
	author = {Schmied, Christopher and Nelson, Michael S. and Avilov, Sergiy and Bakker, Gert-Jan and Bertocchi, Cristina and Bischof, Johanna and Boehm, Ulrike and Brocher, Jan and Carvalho, Mariana T. and Chiritescu, Catalin and Christopher, Jana and Cimini, Beth A. and Conde-Sousa, Eduardo and Ebner, Michael and Ecker, Rupert and Eliceiri, Kevin and Fernandez-Rodriguez, Julia and Gaudreault, Nathalie and Gelman, Laurent and Grunwald, David and Gu, Tingting and Halidi, Nadia and Hammer, Mathias and Hartley, Matthew and Held, Marie and Jug, Florian and Kapoor, Varun and Koksoy, Ayse Aslihan and Lacoste, Judith and Le Dévédec, Sylvia and Le Guyader, Sylvie and Liu, Penghuan and Martins, Gabriel G. and Mathur, Aastha and Miura, Kota and Montero Llopis, Paula and Nitschke, Roland and North, Alison and Parslow, Adam C. and Payne-Dwyer, Alex and Plantard, Laure and Ali, Rizwan and Schroth-Diez, Britta and Schütz, Lucas and Scott, Ryan T. and Seitz, Arne and Selchow, Olaf and Sharma, Ved P. and Spitaler, Martin and Srinivasan, Sathya and Strambio-De-Castillia, Caterina and Taatjes, Douglas and Tischer, Christian and Jambor, Helena Klara},
	month = feb,
	year = {2024},
	keywords = {Microscopy, Publishing},
	pages = {170--181},
}

@article{moore_ome-zarr_2023,
	title = {{OME}-{Zarr}: a cloud-optimized bioimaging file format with international community support},
	volume = {160},
	issn = {1432-119X},
	shorttitle = {{OME}-{Zarr}},
	url = {https://doi.org/10.1007/s00418-023-02209-1},
	doi = {10.1007/s00418-023-02209-1},
	abstract = {A growing community is constructing a next-generation file format (NGFF) for bioimaging to overcome problems of scalability and heterogeneity. Organized by the Open Microscopy Environment (OME), individuals and institutes across diverse modalities facing these problems have designed a format specification process (OME-NGFF) to address these needs. This paper brings together a wide range of those community members to describe the cloud-optimized format itself—OME-Zarr—along with tools and data resources available today to increase FAIR access and remove barriers in the scientific process. The current momentum offers an opportunity to unify a key component of the bioimaging domain—the file format that underlies so many personal, institutional, and global data management and analysis tasks.},
	language = {en},
	number = {3},
	urldate = {2024-03-19},
	journal = {Histochemistry and Cell Biology},
	author = {Moore, Josh and Basurto-Lozada, Daniela and Besson, Sébastien and Bogovic, John and Bragantini, Jordão and Brown, Eva M. and Burel, Jean-Marie and Casas Moreno, Xavier and de Medeiros, Gustavo and Diel, Erin E. and Gault, David and Ghosh, Satrajit S. and Gold, Ilan and Halchenko, Yaroslav O. and Hartley, Matthew and Horsfall, Dave and Keller, Mark S. and Kittisopikul, Mark and Kovacs, Gabor and Küpcü Yoldaş, Aybüke and Kyoda, Koji and le Tournoulx de la Villegeorges, Albane and Li, Tong and Liberali, Prisca and Lindner, Dominik and Linkert, Melissa and Lüthi, Joel and Maitin-Shepard, Jeremy and Manz, Trevor and Marconato, Luca and McCormick, Matthew and Lange, Merlin and Mohamed, Khaled and Moore, William and Norlin, Nils and Ouyang, Wei and Özdemir, Bugra and Palla, Giovanni and Pape, Constantin and Pelkmans, Lucas and Pietzsch, Tobias and Preibisch, Stephan and Prete, Martin and Rzepka, Norman and Samee, Sameeul and Schaub, Nicholas and Sidky, Hythem and Solak, Ahmet Can and Stirling, David R. and Striebel, Jonathan and Tischer, Christian and Toloudis, Daniel and Virshup, Isaac and Walczysko, Petr and Watson, Alan M. and Weisbart, Erin and Wong, Frances and Yamauchi, Kevin A. and Bayraktar, Omer and Cimini, Beth A. and Gehlenborg, Nils and Haniffa, Muzlifah and Hotaling, Nathan and Onami, Shuichi and Royer, Loic A. and Saalfeld, Stephan and Stegle, Oliver and Theis, Fabian J. and Swedlow, Jason R.},
	month = sep,
	year = {2023},
	keywords = {Bioimaging, Cloud, Community, Data, FAIR, Format},
	pages = {223--251},
}

@misc{gemin_hibernating_2023,
	title = {Hibernating ribosomes tether to mitochondria as an adaptive response to cellular stress during glucose depletion},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2023.10.08.561365v1},
	doi = {10.1101/2023.10.08.561365},
	abstract = {Cell survival under nutrient-deprived conditions relies on cells’ ability to adapt their organelles and to rewire their metabolic pathways. In the fission yeast Schizosaccharomyces pombe, nutrient depletion is an unfavorable condition for protein synthesis and triggers a response characterized by mitochondrial fragmentation and the sequestration of cytosolic ribosomes on mitochondria. The molecular mechanism underlying ribosomal sequestration remains elusive. In this study, we performed time-lapse in situ cryo-electron tomography and cryo-electron microscopy complemented by biochemical experiments to elucidate the molecular details of this adaptive response. Our analysis indicate that upon glucose depletion protein synthesis is halted, causing ribosomes to enter an inactive state characterized by a conformational change that obstructs the peptidyl transferase center. Our in situ experiments reveal the presence of oligomeric arrays of hibernating ribosomes tethered to the mitochondrial surface. Surprisingly, ribosomes bind to the outer mitochondrial membrane via the small ribosomal subunit, an interaction facilitated by the ribosomal protein RACK1-orthologue Cpc2. Our experiments show that ribosome tethering is important for cell survival under glucose depletion conditions. This study broadens our understanding of the cellular adaptations triggered by nutrient scarcity and the underlying molecular mechanisms that regulate cell quiescence.},
	language = {en},
	urldate = {2024-03-18},
	publisher = {bioRxiv},
	author = {Gemin, Olivier and Gluc, Maciej and Purdy, Michael and Rosa, Higor and Niemann, Moritz and Peskova, Yelena and Mattei, Simone and Jomaa, Ahmad},
	month = oct,
	year = {2023},
}

@article{pelet_adapting_2024,
	title = {Adapting to ever-changing conditions},
	volume = {13},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.91717},
	doi = {10.7554/eLife.91717},
	abstract = {Experiments involving periodic stimuli shed light on the interplay between hyper-osmotic stress and glucose starvation in yeast cells.},
	urldate = {2024-03-12},
	journal = {eLife},
	author = {Pelet, Serge},
	month = feb,
	year = {2024},
	keywords = {glucose starvation, microfluidics, stress adaptation, systems biology},
	pages = {e91717},
}

@misc{zhong_benchmarking_2024,
	title = {Benchmarking {Large} {Language} {Models} for {Molecule} {Prediction} {Tasks}},
	url = {http://arxiv.org/abs/2403.05075},
	abstract = {Large Language Models (LLMs) stand at the forefront of a number of Natural Language Processing (NLP) tasks. Despite the widespread adoption of LLMs in NLP, much of their potential in broader fields remains largely unexplored, and significant limitations persist in their design and implementation. Notably, LLMs struggle with structured data, such as graphs, and often falter when tasked with answering domain-specific questions requiring deep expertise, such as those in biology and chemistry. In this paper, we explore a fundamental question: Can LLMs effectively handle molecule prediction tasks? Rather than pursuing top-tier performance, our goal is to assess how LLMs can contribute to diverse molecule tasks. We identify several classification and regression prediction tasks across six standard molecule datasets. Subsequently, we carefully design a set of prompts to query LLMs on these tasks and compare their performance with existing Machine Learning (ML) models, which include text-based models and those specifically designed for analysing the geometric structure of molecules. Our investigation reveals several key insights: Firstly, LLMs generally lag behind ML models in achieving competitive performance on molecule tasks, particularly when compared to models adept at capturing the geometric structure of molecules, highlighting the constrained ability of LLMs to comprehend graph data. Secondly, LLMs show promise in enhancing the performance of ML models when used collaboratively. Lastly, we engage in a discourse regarding the challenges and promising avenues to harness LLMs for molecule prediction tasks. The code and models are available at https://github.com/zhiqiangzhongddu/LLMaMol.},
	urldate = {2024-03-12},
	publisher = {arXiv},
	author = {Zhong, Zhiqiang and Zhou, Kuangyu and Mottin, Davide},
	month = mar,
	year = {2024},
	note = {arXiv:2403.05075 [cs, q-bio]},
	keywords = {Computer Science - Machine Learning, Quantitative Biology - Biomolecules},
}

@misc{hossain_not_2024,
	title = {Not all tickets are equal and we know it: {Guiding} pruning with domain-specific knowledge},
	shorttitle = {Not all tickets are equal and we know it},
	url = {http://arxiv.org/abs/2403.04805},
	doi = {10.48550/arXiv.2403.04805},
	abstract = {Neural structure learning is of paramount importance for scientific discovery and interpretability. Yet, contemporary pruning algorithms that focus on computational resource efficiency face algorithmic barriers to select a meaningful model that aligns with domain expertise. To mitigate this challenge, we propose DASH, which guides pruning by available domain-specific structural information. In the context of learning dynamic gene regulatory network models, we show that DASH combined with existing general knowledge on interaction partners provides data-specific insights aligned with biology. For this task, we show on synthetic data with ground truth information and two real world applications the effectiveness of DASH, which outperforms competing methods by a large margin and provides more meaningful biological insights. Our work shows that domain specific structural information bears the potential to improve model-derived scientific insights.},
	urldate = {2024-03-12},
	publisher = {arXiv},
	author = {Hossain, Intekhab and Fischer, Jonas and Burkholz, Rebekka and Quackenbush, John},
	month = mar,
	year = {2024},
	note = {arXiv:2403.04805 [cs, q-bio, stat]},
	keywords = {Computer Science - Machine Learning, Quantitative Biology - Quantitative Methods, Statistics - Applications, Statistics - Machine Learning},
}

@article{skinner_building_2024,
	title = {Building a mathematical model of the brain},
	volume = {13},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.96231},
	doi = {10.7554/eLife.96231},
	abstract = {Automatic leveraging of information in a hippocampal neuron database to generate mathematical models should help foster interactions between experimental and computational neuroscientists.},
	urldate = {2024-03-12},
	journal = {eLife},
	author = {Skinner, Frances},
	month = feb,
	year = {2024},
	keywords = {hippocampus, neuron, neuroscience, simulation},
	pages = {e96231},
}

@inproceedings{mansouri_heidegger_2020,
	address = {New York, NY, USA},
	series = {{KDD} '20},
	title = {Heidegger: {Interpretable} {Temporal} {Causal} {Discovery}},
	isbn = {9781450379984},
	shorttitle = {Heidegger},
	url = {https://dl.acm.org/doi/10.1145/3394486.3403220},
	doi = {10.1145/3394486.3403220},
	abstract = {Temporal causal discovery aims to find cause-effect relationships between time-series. However, none of the existing techniques is able to identify the causal profile, the temporal pattern that the causal variable needs to follow in order to trigger the most significant change in the outcome. Toward a new horizon, this study introduces the novel problem of Causal Profile Discovery, which is crucial for many applications such as adverse drug reaction and cyber-attack detection. This work correspondingly proposes Heidegger to discover causal profiles, comprised of a flexible randomized block design for hypothesis evaluation and an efficient profile search via on-the-fly graph construction and entropy-based pruning. Heidegger's performance is demonstrated/evaluated extensively on both synthetic and real-world data. The experimental results show the proposed method is robust to noise and flexible at detecting complex patterns.},
	urldate = {2024-03-11},
	booktitle = {Proceedings of the 26th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Mansouri, Mehrdad and Arab, Ali and Zohrevand, Zahra and Ester, Martin},
	month = aug,
	year = {2020},
	keywords = {graph search, pattern recognition, randomized-block design, temporal causal discovery},
	pages = {1688--1696},
}

@article{hadsell_embracing_2020,
	title = {Embracing {Change}: {Continual} {Learning} in {Deep} {Neural} {Networks}},
	volume = {24},
	issn = {13646613},
	shorttitle = {Embracing {Change}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661320302199},
	doi = {10.1016/j.tics.2020.09.004},
	language = {en},
	number = {12},
	urldate = {2024-03-11},
	journal = {Trends in Cognitive Sciences},
	author = {Hadsell, Raia and Rao, Dushyant and Rusu, Andrei A. and Pascanu, Razvan},
	month = dec,
	year = {2020},
	pages = {1028--1040},
}

@misc{donahue_when_2024,
	title = {When {Are} {Two} {Lists} {Better} than {One}?: {Benefits} and {Harms} in {Joint} {Decision}-making},
	shorttitle = {When {Are} {Two} {Lists} {Better} than {One}?},
	url = {http://arxiv.org/abs/2308.11721},
	doi = {10.48550/arXiv.2308.11721},
	abstract = {Historically, much of machine learning research has focused on the performance of the algorithm alone, but recently more attention has been focused on optimizing joint human-algorithm performance. Here, we analyze a specific type of human-algorithm collaboration where the algorithm has access to a set of \$n\$ items, and presents a subset of size \$k\$ to the human, who selects a final item from among those \$k\$. This scenario could model content recommendation, route planning, or any type of labeling task. Because both the human and algorithm have imperfect, noisy information about the true ordering of items, the key question is: which value of \$k\$ maximizes the probability that the best item will be ultimately selected? For \$k=1\$, performance is optimized by the algorithm acting alone, and for \$k=n\$ it is optimized by the human acting alone. Surprisingly, we show that for multiple of noise models, it is optimal to set \$k {\textbackslash}in [2, n-1]\$ - that is, there are strict benefits to collaborating, even when the human and algorithm have equal accuracy separately. We demonstrate this theoretically for the Mallows model and experimentally for the Random Utilities models of noisy permutations. However, we show this pattern is reversed when the human is anchored on the algorithm's presented ordering - the joint system always has strictly worse performance. We extend these results to the case where the human and algorithm differ in their accuracy levels, showing that there always exist regimes where a more accurate agent would strictly benefit from collaborating with a less accurate one, but these regimes are asymmetric between the human and the algorithm's accuracy.},
	urldate = {2024-03-11},
	publisher = {arXiv},
	author = {Donahue, Kate and Gollapudi, Sreenivas and Kollias, Kostas},
	month = feb,
	year = {2024},
	note = {arXiv:2308.11721 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
}

@article{frechet_sur_1943,
	title = {Sur l'extension de certaines evaluations statistiques au cas de petits echantillons},
	volume = {11},
	issn = {03731138},
	url = {https://www.jstor.org/stable/1401114?origin=crossref},
	doi = {10.2307/1401114},
	number = {3/4},
	urldate = {2024-03-11},
	journal = {Revue de l'Institut International de Statistique / Review of the International Statistical Institute},
	author = {Fréchet, Maurice},
	year = {1943},
	pages = {182},
}

@misc{teranishi_epithelial_2024,
	title = {Epithelial {Folding} {Irreversibility} is {Controlled} by {Elastoplastic} {Transition} via {Mechanosensitive} {Actin} {Bracket} {Formation}},
	copyright = {© 2024, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2023.12.19.572470v2},
	doi = {10.1101/2023.12.19.572470},
	abstract = {During morphogenesis, epithelial sheets undergo sequential folding to form three-dimensional organ structures. The resulting folds are irreversible, ensuring that morphogenesis progresses in one direction. However, the mechanism establishing the irreversibility of folding remains unclear. Here, we report a novel mechanical property of epithelia that is responsible for folding irreversibility. Using a newly developed mechanical indentation assay, we demonstrate that short-term or low-curvature folding induces an elastic, shape-restoring response. In contrast, combined long-term, high-curvature folding results in plastic, irreversible deformation. This elastic-to-plastic transition occurs in a switch-like manner, with critical thresholds for the folding curvature and duration. Specific cells at the fold initiate this transition, sensing the curvature and duration of folding on their apical side via mechanosensitive signaling pathways, including transient receptor potential canonical (TRPC) 3/6-mediated calcium influx and ligand-independent epidermal growth factor receptor activation. These pathways induce F-actin accumulation into a bracket-like structure across the fold, establishing the transition. The duration threshold is determined and tunable by the actin polymerization rate. These results demonstrate that cells control the irreversibility of epithelial folding by detecting folding characteristics and adaptively switching between elastic and plastic responses. This finding resolves a long-standing question about the directionality of morphogenesis.},
	language = {en},
	urldate = {2024-03-11},
	publisher = {bioRxiv},
	author = {Teranishi, Aki and Mori, Misato and Ichiki, Rihoko and Toda, Satoshi and Shioi, Go and Okuda, Satoru},
	month = feb,
	year = {2024},
}

@misc{ben_cardoen_smlmvis_2023,
	title = {{SMLMVis}: {Python} {API} to load {SMLM} data from diverse microscopes and visualize using {VTK}/{VTU} (https://zenodo.org/record/8006954)},
	copyright = {Open Access},
	shorttitle = {{SMLMVis} (https://zenodo.org/record/8006954)},
	url = {https://zenodo.org/record/8006954},
	abstract = {Adds support for thunderstorm data Cleanup problematic dependencies},
	urldate = {2023-07-07},
	publisher = {Zenodo},
	author = {{Ben Cardoen}},
	month = jun,
	year = {2023},
	doi = {10.5281/ZENODO.8006954},
}

@misc{cardoen_slurmmonitorjl_2022,
	title = {{SlurmMonitor}.jl: {A} {Slurm} monitoring tool that notifies slack on adverse {SLURM} {HPC} state changes and records temporal statistics on utilization. https://zenodo.org/record/7106106},
	copyright = {GNU Affero General Public License v3.0, Open Access},
	shorttitle = {{SlurmMonitor}.jl},
	url = {https://zenodo.org/record/7106106},
	abstract = {A monitoring tool, in Julia, to watch for unexpected state changes in SLURM HPC workload managers, that collects usage / utilization statistics and can notify Slack if intervention is needed.{\textless}br{\textgreater} https://github.com/bencardoen/SlurmMonitor.jl},
	urldate = {2023-07-24},
	publisher = {Zenodo},
	author = {Cardoen, Ben},
	month = sep,
	year = {2022},
	doi = {10.5281/ZENODO.7106106},
	keywords = {HPC, SLURM},
}

@misc{cardoen_colocalizationjl_2023,
	title = {Colocalization.jl {A} {Julia} reference implementation of image colocalization metrics (https://zenodo.org/record/7552357)},
	copyright = {GNU Affero General Public License v3.0 or later, Open Access},
	shorttitle = {Colocalization.jl (https://zenodo.org/record/7552357)},
	url = {https://zenodo.org/record/7552357},
	abstract = {A set of reference colocalization metrics for images.},
	urldate = {2023-07-07},
	publisher = {Zenodo},
	author = {Cardoen, Ben},
	month = jan,
	year = {2023},
	doi = {10.5281/ZENODO.7552357},
}

@misc{cardoen_ben_smlmtools_2023,
	title = {{SmlmTools}: {A} {Julia} package for computational methods for single molecule localization / superresolution microscopy https://zenodo.org/record/7632321},
	copyright = {GNU Affero General Public License v3.0 or later, Open Access},
	shorttitle = {{SmlmTools}},
	url = {https://zenodo.org/record/7632321},
	abstract = {A set of Julia tools to process point cloud data from SMLM experiments. Including but not limited to fiducial detection, tracking, alignment between channels, point cloud to image conversion, ... . https://github.com/bencardoen/SmlmTools.jl},
	urldate = {2023-07-07},
	publisher = {Zenodo},
	author = {{Cardoen, Ben}},
	month = feb,
	year = {2023},
	doi = {10.5281/ZENODO.7632321},
	keywords = {Julia, fiducial tracking, registration, single molecule localization microscopy, superresolution},
}

@article{laine_nanoj_2019,
	title = {{NanoJ}: a high-performance open-source super-resolution microscopy toolbox},
	volume = {52},
	issn = {0022-3727, 1361-6463},
	shorttitle = {{NanoJ}},
	url = {https://iopscience.iop.org/article/10.1088/1361-6463/ab0261},
	doi = {10.1088/1361-6463/ab0261},
	number = {16},
	urldate = {2024-03-06},
	journal = {Journal of Physics D: Applied Physics},
	author = {Laine, Romain F and Tosheva, Kalina L and Gustafsson, Nils and Gray, Robert D M and Almada, Pedro and Albrecht, David and Risa, Gabriel T and Hurtig, Fredrik and Lindås, Ann-Christin and Baum, Buzz and Mercer, Jason and Leterrier, Christophe and Pereira, Pedro M and Culley, Siân and Henriques, Ricardo},
	month = apr,
	year = {2019},
	pages = {163001},
}

@article{schodt_smite_2023,
	title = {{SMITE}: {Single} {Molecule} {Imaging} {Toolbox} {Extraordinaire} ({MATLAB})},
	volume = {8},
	issn = {2475-9066},
	shorttitle = {{SMITE}},
	url = {https://joss.theoj.org/papers/10.21105/joss.05563},
	doi = {10.21105/joss.05563},
	number = {90},
	urldate = {2024-03-06},
	journal = {Journal of Open Source Software},
	author = {Schodt, David J. and Wester, Michael J. and Fazel, Mohamadreza and Khan, Sajjad and Mazloom-Farsibaf, Hanieh and Pallikkuth, Sandeep and Meddens, Marjolein B. M. and Farzam, Farzin and Burns, Eric A. and Kanagy, William K. and Rinaldi, Derek A. and Jhamba, Elton and Liu, Sheng and Relich, Peter K. and Olah, Mark J. and Steinberg, Stanly L. and Lidke, Keith A.},
	month = oct,
	year = {2023},
	pages = {5563},
}

@article{betzig_imaging_2006,
	title = {Imaging intracellular fluorescent proteins at nanometer resolution},
	volume = {313},
	issn = {1095-9203},
	doi = {10.1126/science.1127344},
	abstract = {We introduce a method for optically imaging intracellular proteins at nanometer spatial resolution. Numerous sparse subsets of photoactivatable fluorescent protein molecules were activated, localized (to approximately 2 to 25 nanometers), and then bleached. The aggregate position information from all subsets was then assembled into a superresolution image. We used this method--termed photoactivated localization microscopy--to image specific target proteins in thin sections of lysosomes and mitochondria; in fixed whole cells, we imaged vinculin at focal adhesions, actin within a lamellipodium, and the distribution of the retroviral protein Gag at the plasma membrane.},
	language = {eng},
	number = {5793},
	journal = {Science (New York, N.Y.)},
	author = {Betzig, Eric and Patterson, George H. and Sougrat, Rachid and Lindwasser, O. Wolf and Olenych, Scott and Bonifacino, Juan S. and Davidson, Michael W. and Lippincott-Schwartz, Jennifer and Hess, Harald F.},
	month = sep,
	year = {2006},
	pmid = {16902090},
	keywords = {Actins, Algorithms, Animals, COS Cells, Cell Line, Cell Membrane, Chlorocebus aethiops, Fluorescence, Focal Adhesions, Gene Products, gag, HIV-1, Light, Luminescent Proteins, Lysosomes, Microscopy, Mitochondria, Nanotechnology, Organelles, Photobleaching, Proteins, Pseudopodia, Recombinant Fusion Proteins, Vinculin},
	pages = {1642--1645},
}

@article{long_super_2020,
	title = {Super resolution microscopy and deep learning identify {Zika} virus reorganization of the endoplasmic reticulum},
	volume = {10},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-77170-3},
	doi = {10.1038/s41598-020-77170-3},
	abstract = {Abstract 
            The endoplasmic reticulum (ER) is a complex subcellular organelle composed of diverse structures such as tubules, sheets and tubular matrices. Flaviviruses such as Zika virus (ZIKV) induce reorganization of ER membranes to facilitate viral replication. Here, using 3D super resolution microscopy, ZIKV infection is shown to induce the formation of dense tubular matrices associated with viral replication in the central ER. Viral non-structural proteins NS4B and NS2B associate with replication complexes within the ZIKV-induced tubular matrix and exhibit distinct ER distributions outside this central ER region. Deep neural networks trained to distinguish ZIKV-infected versus mock-infected cells successfully identified ZIKV-induced central ER tubular matrices as a determinant of viral infection. Super resolution microscopy and deep learning are therefore able to identify and localize morphological features of the ER and allow for better understanding of how ER morphology changes due to viral infection.},
	language = {en},
	number = {1},
	urldate = {2024-03-03},
	journal = {Scientific Reports},
	author = {Long, Rory K. M. and Moriarty, Kathleen P. and Cardoen, Ben and Gao, Guang and Vogl, A. Wayne and Jean, François and Hamarneh, Ghassan and Nabi, Ivan R.},
	month = dec,
	year = {2020},
	pages = {20937},
}

@article{izadi_image_2023,
	title = {Image denoising in the deep learning era},
	volume = {56},
	issn = {0269-2821, 1573-7462},
	url = {https://link.springer.com/10.1007/s10462-022-10305-2},
	doi = {10.1007/s10462-022-10305-2},
	language = {en},
	number = {7},
	urldate = {2024-03-03},
	journal = {Artificial Intelligence Review},
	author = {Izadi, Saeed and Sutton, Darren and Hamarneh, Ghassan},
	month = jul,
	year = {2023},
	pages = {5929--5974},
}

@article{myers_foundation_2024,
	title = {Foundation and large language models: fundamentals, challenges, opportunities, and social impacts},
	volume = {27},
	issn = {1573-7543},
	shorttitle = {Foundation and large language models},
	url = {https://doi.org/10.1007/s10586-023-04203-7},
	doi = {10.1007/s10586-023-04203-7},
	abstract = {Foundation and Large Language Models (FLLMs) are models that are trained using a massive amount of data with the intent to perform a variety of downstream tasks. FLLMs are very promising drivers for different domains, such as Natural Language Processing (NLP) and other AI-related applications. These models emerged as a result of the AI paradigm shift, involving the use of pre-trained language models (PLMs) and extensive data to train transformer models. FLLMs have also demonstrated impressive proficiency in addressing a wide range of NLP applications, including language generation, summarization, comprehension, complex reasoning, and question answering, among others. In recent years, there has been unprecedented interest in FLLMs-related research, driven by contributions from both academic institutions and industry players. Notably, the development of ChatGPT, a highly capable AI chatbot built around FLLMs concepts, has garnered considerable interest from various segments of society. The technological advancement of large language models (LLMs) has had a significant influence on the broader artificial intelligence (AI) community, potentially transforming the processes involved in the development and use of AI systems. Our study provides a comprehensive survey of existing resources related to the development of FLLMs and addresses current concerns, challenges and social impacts. Moreover, we emphasize on the current research gaps and potential future directions in this emerging and promising field.},
	language = {en},
	number = {1},
	urldate = {2024-03-03},
	journal = {Cluster Computing},
	author = {Myers, Devon and Mohawesh, Rami and Chellaboina, Venkata Ishwarya and Sathvik, Anantha Lakshmi and Venkatesh, Praveen and Ho, Yi-Hui and Henshaw, Hanna and Alhawawreh, Muna and Berdik, David and Jararweh, Yaser},
	month = feb,
	year = {2024},
	keywords = {Advanced pre-trained models, Artificial intelligence, Foundation models, Large language models, Machine learning, Natural language processing},
	pages = {1--26},
}

@article{li_chatgpt-like_2024,
	title = {{ChatGPT}-like large-scale foundation models for prognostics and health management: {A} survey and roadmaps},
	volume = {243},
	issn = {0951-8320},
	shorttitle = {{ChatGPT}-like large-scale foundation models for prognostics and health management},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832023007640},
	doi = {10.1016/j.ress.2023.109850},
	abstract = {PHM technology is vital in industrial production and maintenance, identifying and predicting potential equipment failures and damages. This enables proactive maintenance measures to be implemented, improving equipment reliability and reducing production costs. Recently, artificial intelligence (AI)-based PHM methods have made remarkable achievements, and it is widely used in various industries, such as railway, energy, and aviation, for condition monitoring, fault prediction, and health management. The emergence of large-scale foundation models (LSF-Models) such as ChatGPT and DALLE-E marks the entry of AI into a new era of AI-2.0 from AI-1.0, where deep models have rapidly evolved from a research paradigm of single-modal, single-task, and limited-data to a multi-modal, multi-task, massive data, and super-large model paradigm. ChatGPT represents a landmark achievement in this research paradigm, offering hope for general AI due to its brilliant natural language understanding ability. However, the PHM field lacks a consensus on responding to this significant change, and systematic reviews and roadmaps are required to elucidate future development directions. Therefore, this paper expounds on the key components and latest developments of LSF-Models. Then, we systematically answered how to build LSF-Models applicable to PHM tasks and outlined the challenges and future development roadmaps for this research paradigm.},
	urldate = {2024-03-03},
	journal = {Reliability Engineering \& System Safety},
	author = {Li, Yan-Fu and Wang, Huan and Sun, Muxia},
	month = mar,
	year = {2024},
	keywords = {Fault diagnosis, Large-scale foundation model, Prognostics and health management, Representation learning},
	pages = {109850},
}

@article{chater_probabilistic_2006,
	title = {Probabilistic models of cognition: {Conceptual} foundations},
	volume = {10},
	issn = {1364-6613, 1879-307X},
	shorttitle = {Probabilistic models of cognition},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(06)00132-X},
	doi = {10.1016/j.tics.2006.05.007},
	language = {English},
	number = {7},
	urldate = {2024-03-03},
	journal = {Trends in Cognitive Sciences},
	author = {Chater, Nick and Tenenbaum, Joshua B. and Yuille, Alan},
	month = jul,
	year = {2006},
	pmid = {16807064},
	pages = {287--291},
}

@article{wornow_shaky_2023,
	title = {The shaky foundations of large language models and foundation models for electronic health records},
	volume = {6},
	copyright = {2023 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-023-00879-8},
	doi = {10.1038/s41746-023-00879-8},
	abstract = {The success of foundation models such as ChatGPT and AlphaFold has spurred significant interest in building similar models for electronic medical records (EMRs) to improve patient care and hospital operations. However, recent hype has obscured critical gaps in our understanding of these models’ capabilities. In this narrative review, we examine 84 foundation models trained on non-imaging EMR data (i.e., clinical text and/or structured data) and create a taxonomy delineating their architectures, training data, and potential use cases. We find that most models are trained on small, narrowly-scoped clinical datasets (e.g., MIMIC-III) or broad, public biomedical corpora (e.g., PubMed) and are evaluated on tasks that do not provide meaningful insights on their usefulness to health systems. Considering these findings, we propose an improved evaluation framework for measuring the benefits of clinical foundation models that is more closely grounded to metrics that matter in healthcare.},
	language = {en},
	number = {1},
	urldate = {2024-03-03},
	journal = {npj Digital Medicine},
	author = {Wornow, Michael and Xu, Yizhe and Thapa, Rahul and Patel, Birju and Steinberg, Ethan and Fleming, Scott and Pfeffer, Michael A. and Fries, Jason and Shah, Nigam H.},
	month = jul,
	year = {2023},
	keywords = {Computational platforms and environments, Data mining, Machine learning, Predictive medicine, Statistical methods},
	pages = {1--10},
}

@article{bulow_new_2023,
	title = {New discoveries in {ER}-mitochondria communication},
	volume = {51},
	issn = {1470-8752},
	doi = {10.1042/BST20221305},
	abstract = {The study of endoplasmic reticulum (ER)-mitochondria communication is a vast and expanding field with many novel developments in the past few years. In this mini-review, we focus on several recent publications that identify novel functions of tether complexes, in particular autophagy regulation and lipid droplet biogenesis. We review novel findings that shed light on the role of triple contacts between ER and mitochondria with peroxisomes or lipid droplets as the third player. We also summarize recent findings on the role of ER-mitochondria contacts in human neurodegenerative diseases, which implicate either enhanced or reduced ER-mitochondria contacts in neurodegeneration. Taken together, the discussed studies highlight the need for further research into the role of triple organelle contacts, as well as into the exact mechanisms of increased and decreased ER-mitochondria contacts in neurodegeneration.},
	language = {eng},
	number = {2},
	journal = {Biochemical Society Transactions},
	author = {Bülow, Margret Helene and Sellin, Julia},
	month = apr,
	year = {2023},
	pmid = {36892405},
	keywords = {Autophagy, Endoplasmic Reticulum, Humans, Mitochondria, Neurodegenerative Diseases, Peroxisomes, endoplasmic reticulum, mitochondria, neurodegeneration, organelles},
	pages = {571--577},
}

@article{sassano_er-mitochondria_2022,
	title = {{ER}-mitochondria contact sites; a multifaceted factory for {Ca2}+ signaling and lipid transport},
	volume = {10},
	issn = {2296-634X},
	doi = {10.3389/fcell.2022.988014},
	abstract = {Membrane contact sites (MCS) between organelles of eukaryotic cells provide structural integrity and promote organelle homeostasis by facilitating intracellular signaling, exchange of ions, metabolites and lipids and membrane dynamics. Cataloguing MCS revolutionized our understanding of the structural organization of a eukaryotic cell, but the functional role of MSCs and their role in complex diseases, such as cancer, are only gradually emerging. In particular, the endoplasmic reticulum (ER)-mitochondria contacts (EMCS) are key effectors of non-vesicular lipid trafficking, thereby regulating the lipid composition of cellular membranes and organelles, their physiological functions and lipid-mediated signaling pathways both in physiological and diseased conditions. In this short review, we discuss key aspects of the functional complexity of EMCS in mammalian cells, with particular emphasis on their role as central hubs for lipid transport between these organelles and how perturbations of these pathways may favor key traits of cancer cells.},
	language = {eng},
	journal = {Frontiers in Cell and Developmental Biology},
	author = {Sassano, Maria Livia and Felipe-Abrio, Blanca and Agostinis, Patrizia},
	year = {2022},
	pmid = {36158205},
	pmcid = {PMC9494157},
	keywords = {Ca2+ signaling, ER-mitochondria contact sites, cancer, lipid transfer protein, lipids},
	pages = {988014},
}

@article{ruhmkorf_role_2023,
	title = {Role of {Mitochondria}-{ER} {Contact} {Sites} in {Mitophagy}},
	volume = {13},
	issn = {2218-273X},
	doi = {10.3390/biom13081198},
	abstract = {Mitochondria are often referred to as the "powerhouse" of the cell. However, this organelle has many more functions than simply satisfying the cells' metabolic needs. Mitochondria are involved in calcium homeostasis and lipid metabolism, and they also regulate apoptotic processes. Many of these functions require contact with the ER, which is mediated by several tether proteins located on the respective organellar surfaces, enabling the formation of mitochondria-ER contact sites (MERCS). Upon damage, mitochondria produce reactive oxygen species (ROS) that can harm the surrounding cell. To circumvent toxicity and to maintain a functional pool of healthy organelles, damaged and excess mitochondria can be targeted for degradation via mitophagy, a form of selective autophagy. Defects in mitochondria-ER tethers and the accumulation of damaged mitochondria are found in several neurodegenerative diseases, including Parkinson's disease and amyotrophic lateral sclerosis, which argues that the interplay between the two organelles is vital for neuronal health. This review provides an overview of the different mechanisms of mitochondrial quality control that are implicated with the different mitochondria-ER tether proteins, and also provides a novel perspective on how MERCS are involved in mediating mitophagy upon mitochondrial damage.},
	language = {eng},
	number = {8},
	journal = {Biomolecules},
	author = {Rühmkorf, Alina and Harbauer, Angelika Bettina},
	month = jul,
	year = {2023},
	pmid = {37627263},
	pmcid = {PMC10452924},
	keywords = {Amyotrophic Lateral Sclerosis, Apoptosis, Humans, Mitochondria, Mitochondrial Membranes, Mitochondrial Proteins, Mitophagy, Receptors, Estrogen, mitochondria, mitophagy, organellar contact sites},
	pages = {1198},
}

@article{cardoen_datacuratorjl_2023,
	title = {{DataCurator}.jl: efficient, portable and reproducible validation, curation and transformation of large heterogeneous datasets using human-readable recipes compiled into machine-verifiable templates},
	volume = {3},
	issn = {2635-0041},
	shorttitle = {{DataCurator}.jl},
	url = {https://academic.oup.com/bioinformaticsadvances/article/doi/10.1093/bioadv/vbad068/7188122},
	doi = {10.1093/bioadv/vbad068},
	abstract = {Summary 
            Large-scale processing of heterogeneous datasets in interdisciplinary research often requires time-consuming manual data curation. Ambiguity in the data layout and preprocessing conventions can easily compromise reproducibility and scientific discovery, and even when detected, it requires time and effort to be corrected by domain experts. Poor data curation can also interrupt processing jobs on large computing clusters, causing frustration and delays. We introduce DataCurator, a portable software package that verifies arbitrarily complex datasets of mixed formats, working equally well on clusters as on local systems. Human-readable TOML recipes are converted into executable, machine-verifiable templates, enabling users to easily verify datasets using custom rules without writing code. Recipes can be used to transform and validate data, for pre- or post-processing, selection of data subsets, sampling and aggregation, such as summary statistics. Processing pipelines no longer need to be burdened by laborious data validation, with data curation and validation replaced by human and machine-verifiable recipes specifying rules and actions. Multithreaded execution ensures scalability on clusters, and existing Julia, R and Python libraries can be reused. DataCurator enables efficient remote workflows, offering integration with Slack and the ability to transfer curated data to clusters using OwnCloud and SCP. Code available at: https://github.com/bencardoen/DataCurator.jl.},
	language = {en},
	number = {1},
	urldate = {2024-02-29},
	journal = {Bioinformatics Advances},
	author = {Cardoen, Ben and Ben Yedder, Hanene and Lee, Sieun and Nabi, Ivan Robert and Hamarneh, Ghassan},
	month = jan,
	year = {2023},
	pages = {vbad068},
}

@misc{noauthor_mitograph_nodate,
	title = {{MitoGraph} {V} 2.0 software},
	url = {http://rafelski.com/susanne/MitoGraph},
	urldate = {2024-02-28},
}

@article{kichuk_using_2024,
	title = {Using {MitER} for {3D} analysis of mitochondrial morphology and {ER} contacts},
	volume = {4},
	issn = {2667-2375},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10832265/},
	doi = {10.1016/j.crmeth.2023.100692},
	abstract = {We have developed an open-source workflow that allows for quantitative single-cell analysis of organelle morphology, distribution, and inter-organelle contacts with an emphasis on the analysis of mitochondria and mitochondria-endoplasmic reticulum (mito-ER) contact sites. As the importance of inter-organelle contacts becomes more widely recognized, there is a concomitant increase in demand for tools to analyze subcellular architecture. Here, we describe a workflow we call MitER (pronounced “mightier”), which allows for automated calculation of organelle morphology, distribution, and inter-organelle contacts from 3D renderings by employing the animation software Blender. We then use MitER to quantify the variations in the mito-ER networks of Saccharomyces cerevisiae, revealing significantly more mito-ER contacts within respiring cells compared to fermenting cells. We then demonstrate how this workflow can be applied to mammalian systems and used to monitor mitochondrial dynamics and inter-organelle contact in time-lapse studies., •MitER is an open-source analysis workflow for three-dimensional organelle renderings•MitER provides automated volume, surface area, and inter-organelle contact measurements•MitER can be used to capture dynamic changes in organelle morphologies, Mitochondrial morphology and contact with proximal organelles are important in both healthy and diseased cell states. Quantification of mitochondrial contact with the endoplasmic reticulum (ER) is particularly valuable as these contacts influence numerous cellular processes, such as mitochondrial fission and fusion, mitophagy, and calcium signaling. However, there are limited tools for such quantitative analyses. Current open-source methods solely allow for colocalization measurements, which are sufficient to estimate inter-organelle contact but lack the ability to provide more substantial metrics, such as the surface area and number of discrete contacts., Kichuk et al. introduce MitER, an open-source workflow that allows for quantitative single-cell analysis of organelle morphology, distribution, and inter-organelle contacts. The workflow is used to quantify the variations in the mitochondria-endoplasmic reticulum (mito-ER) networks of Saccharomyces cerevisiae, revealing a significant increase in mito-ER contacts within respiring cells compared to fermenting cells.},
	number = {1},
	urldate = {2024-02-28},
	journal = {Cell Reports Methods},
	author = {Kichuk, Therese and Dhamankar, Satyen and Malani, Saurabh and Hofstadter, William A. and Wegner, Scott A. and Cristea, Ileana M. and Avalos, José L.},
	month = jan,
	year = {2024},
	pmid = {38232737},
	pmcid = {PMC10832265},
	pages = {100692},
}

@article{athreya_bootstrap_1987,
	title = {Bootstrap of the {Mean} in the {Infinite} {Variance} {Case}},
	volume = {15},
	issn = {0090-5364},
	url = {https://www.jstor.org/stable/2241336},
	abstract = {Let X1, X2, ..., Xn be independent identically distributed random variables with EX2 1 = ∞ but X1 belonging to the domain of attraction of a stable law. It is known that the sample mean X̄n appropriately normalized converges to a stable law. It is shown here that the bootstrap version of the normalized mean has a random distribution (given the sample) whose limit is also a random distribution implying that the naive bootstrap could fail in the heavy tailed case.},
	number = {2},
	urldate = {2024-02-28},
	journal = {The Annals of Statistics},
	author = {Athreya, K. B.},
	year = {1987},
	pages = {724--731},
}

@article{russo_causal_2022,
	title = {Causal {Discovery} and {Knowledge} {Injection} for {Contestable} {Neural} {Networks} (with {Appendices})},
	copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
	url = {https://arxiv.org/abs/2205.09787},
	doi = {10.48550/ARXIV.2205.09787},
	abstract = {Neural networks have proven to be effective at solving machine learning tasks but it is unclear whether they learn any relevant causal relationships, while their black-box nature makes it difficult for modellers to understand and debug them. We propose a novel method overcoming these issues by allowing a two-way interaction whereby neural-network-empowered machines can expose the underpinning learnt causal graphs and humans can contest the machines by modifying the causal graphs before re-injecting them into the machines. The learnt models are guaranteed to conform to the graphs and adhere to expert knowledge, some of which can also be given up-front. By building a window into the model behaviour and enabling knowledge injection, our method allows practitioners to debug networks based on the causal structure discovered from the data and underpinning the predictions. Experiments with real and synthetic tabular data show that our method improves predictive performance up to 2.4x while producing parsimonious networks, up to 7x smaller in the input layer, compared to SOTA regularised networks.},
	urldate = {2024-02-27},
	journal = {Arxiv},
	author = {Russo, Fabrizio and Toni, Francesca},
	year = {2022},
	keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, Human-Computer Interaction (cs.HC), Machine Learning (cs.LG), Machine Learning (stat.ML)},
}

@inproceedings{yang_neural_2023,
	title = {Neural {Vector} {Fields}: {Implicit} {Representation} by {Explicit} {Learning}},
	shorttitle = {Neural {Vector} {Fields}},
	url = {https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Neural_Vector_Fields_Implicit_Representation_by_Explicit_Learning_CVPR_2023_paper.html},
	language = {en},
	urldate = {2024-02-26},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Yang, Xianghui and Lin, Guosheng and Chen, Zhenghao and Zhou, Luping},
	year = {2023},
	pages = {16727--16738},
}

@inproceedings{thierry_validation_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Validation of {Smets}’ {Hypothesis} in the {Crowdsourcing} {Environment}},
	isbn = {9783030886011},
	doi = {10.1007/978-3-030-88601-1_26},
	abstract = {In the late 1990s, Philippe Smets hypothesizes that the more imprecise humans are, the more certain they are. The modeling of human responses by belief functions has been little discussed. In this context, it is essential to validate the hypothesis of Ph. Smets. This paper focuses on the experimental validation of this hypothesis in the context of crowdsourcing. Crowdsourcing is the outsourcing of tasks to users of dedicated platforms. Two crowdsourcing campaigns have been carried out. For the first one, the user could be imprecise in his answer, for the second one he had to be precise. For both experiments, the user had to indicate his certainty in his answer. The results show that by being imprecise, users are more certain of their answers.},
	language = {en},
	booktitle = {Belief {Functions}: {Theory} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Thierry, Constance and Martin, Arnaud and Dubois, Jean-Christophe and Gall, Yolande Le},
	editor = {Denœux, Thierry and Lefèvre, Eric and Liu, Zhunga and Pichon, Frédéric},
	year = {2021},
	keywords = {Belief functions, Crowdsourcing, Imprecision, Uncertainty},
	pages = {259--268},
}

@inproceedings{lowe_amortized_2022,
	title = {Amortized {Causal} {Discovery}: {Learning} to {Infer} {Causal} {Graphs} from {Time}-{Series} {Data}},
	shorttitle = {Amortized {Causal} {Discovery}},
	url = {https://proceedings.mlr.press/v177/lowe22a.html},
	abstract = {On time-series data, most causal discovery methods fit a new model whenever they encounter samples from a new underlying causal graph. However, these samples often share relevant information which is lost when following this approach. Specifically, different samples may share the dynamics which describe the effects of their causal relations. We propose Amortized Causal Discovery, a novel framework that leverages such shared dynamics to learn to infer causal relations from time-series data. This enables us to train a single, amortized model that infers causal relations across samples with different underlying causal graphs, and thus leverages the shared dynamics information. We demonstrate experimentally that this approach, implemented as a variational model, leads to significant improvements in causal discovery performance, and show how it can be extended to perform well under added noise and hidden confounding.},
	language = {en},
	urldate = {2024-02-27},
	booktitle = {Proceedings of the {First} {Conference} on {Causal} {Learning} and {Reasoning}},
	publisher = {PMLR},
	author = {Löwe, Sindy and Madras, David and Zemel, Richard and Welling, Max},
	month = jun,
	year = {2022},
	pages = {509--525},
}

@article{salas-callo_trichoteiromania_2019,
	title = {Trichoteiromania: {Good} {Response} to {Treatment} with {N}-{Acetylcysteine}},
	volume = {5},
	issn = {2296-9195},
	shorttitle = {Trichoteiromania},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6615340/},
	doi = {10.1159/000497167},
	abstract = {Lichen simplex chronicus on the scalp, also known as trichoteiromania, can be difficult to manage, as the therapeutic options are limited to topical or intralesional glucocorticoids. We describe a patient with trichoteiromania, presenting three lichenified pruriginous plaques on different regions of the scalp, associated with fracture and loss of hair shafts. Prior treatment with potent topical glucocorticoids was ineffective. However, treatment with oral N-acetylcysteine (NAC) 1,200 mg/day resulted in complete hair regrowth within 16 weeks. NAC is a safe drug with a good tolerance profile that could be a therapeutic option for patients with trichoteiromania. The potential of NAC has not been completely elucidated, thus more studies will be necessary to confirm its efficacy in the long term for some psychodermatological conditions.},
	number = {4},
	urldate = {2024-02-27},
	journal = {Skin Appendage Disorders},
	author = {Salas-Callo, Corina Isabel and Pirmez, Rodrigo},
	month = jun,
	year = {2019},
	pmid = {31367603},
	pmcid = {PMC6615340},
	pages = {242--245},
}

@article{petersen_causal_2023,
	title = {Causal {Discovery} for {Observational} {Sciences} {Using} {Supervised} {Machine} {Learning}},
	issn = {1680-743X, 1683-8602},
	url = {https://jds-online.org/doi/10.6339/23-JDS1088},
	doi = {10.6339/23-JDS1088},
	abstract = {Causal inference can estimate causal effects, but unless data are collected experimentally, statistical analyses must rely on pre-specified causal models. Causal discovery algorithms are empirical methods for constructing such causal models from data. Several asymptotically correct discovery methods already exist, but they generally struggle on smaller samples. Moreover, most methods focus on very sparse causal models, which may not always be a realistic representation of real-life data generating mechanisms. Finally, while causal relationships suggested by the methods often hold true, their claims about causal non-relatedness have high error rates. This non-conservative error trade off is not ideal for observational sciences, where the resulting model is directly used to inform causal inference: A causal model with many missing causal relations entails too strong assumptions and may lead to biased effect estimates. We propose a new causal discovery method that addresses these three shortcomings: Supervised learning discovery (SLdisco). SLdisco uses supervised machine learning to obtain a mapping from observational data to equivalence classes of causal models. We evaluate SLdisco in a large simulation study based on Gaussian data and we consider several choices of model size and sample size. We find that SLdisco is more conservative, only moderately less informative and less sensitive towards sample size than existing procedures. We furthermore provide a real epidemiological data application. We use random subsampling to investigate real data performance on small samples and again find that SLdisco is less sensitive towards sample size and hence seems to better utilize the information available in small datasets.},
	language = {en},
	urldate = {2024-02-26},
	journal = {Journal of Data Science},
	author = {Petersen, Anne Helby and Ramsey, Joseph and Ekstrøm, Claus Thorn and Spirtes, Peter},
	year = {2023},
	pages = {255--280},
}

@article{koptev_neural_2023,
	title = {Neural {Joint} {Space} {Implicit} {Signed} {Distance} {Functions} for {Reactive} {Robot} {Manipulator} {Control}},
	volume = {8},
	issn = {2377-3766, 2377-3774},
	url = {https://ieeexplore.ieee.org/document/9976191/},
	doi = {10.1109/LRA.2022.3227860},
	number = {2},
	urldate = {2024-02-26},
	journal = {IEEE Robotics and Automation Letters},
	author = {Koptev, Mikhail and Figueroa, Nadia and Billard, Aude},
	month = feb,
	year = {2023},
	pages = {480--487},
}

@inproceedings{dhaou_causal_2021,
	address = {Virtual Event Singapore},
	title = {Causal and {Interpretable} {Rules} for {Time} {Series} {Analysis}},
	isbn = {9781450383325},
	url = {https://dl.acm.org/doi/10.1145/3447548.3467161},
	doi = {10.1145/3447548.3467161},
	language = {en},
	urldate = {2024-02-26},
	booktitle = {Proceedings of the 27th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Dhaou, Amin and Bertoncello, Antoine and Gourvénec, Sébastien and Garnier, Josselin and Le Pennec, Erwan},
	month = aug,
	year = {2021},
	pages = {2764--2772},
}

@article{cui_scgpt_2024,
	title = {{scGPT}: toward building a foundation model for single-cell multi-omics using generative {AI}},
	copyright = {2024 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{scGPT}},
	url = {https://www.nature.com/articles/s41592-024-02201-0},
	doi = {10.1038/s41592-024-02201-0},
	abstract = {Generative pretrained models have achieved remarkable success in various domains such as language and computer vision. Specifically, the combination of large-scale diverse datasets and pretrained transformers has emerged as a promising approach for developing foundation models. Drawing parallels between language and cellular biology (in which texts comprise words; similarly, cells are defined by genes), our study probes the applicability of foundation models to advance cellular biology and genetic research. Using burgeoning single-cell sequencing data, we have constructed a foundation model for single-cell biology, scGPT, based on a generative pretrained transformer across a repository of over 33 million cells. Our findings illustrate that scGPT effectively distills critical biological insights concerning genes and cells. Through further adaptation of transfer learning, scGPT can be optimized to achieve superior performance across diverse downstream applications. This includes tasks such as cell type annotation, multi-batch integration, multi-omic integration, perturbation response prediction and gene network inference.},
	language = {en},
	urldate = {2024-02-26},
	journal = {Nature Methods},
	author = {Cui, Haotian and Wang, Chloe and Maan, Hassaan and Pang, Kuan and Luo, Fengning and Duan, Nan and Wang, Bo},
	month = feb,
	year = {2024},
	keywords = {Computational models, Machine learning, Software, Transcriptomics},
	pages = {1--11},
}

@article{liu_discriminative_2011,
	series = {Semi-{Supervised} {Learning} for {Visual} {Content} {Analysis} and {Understanding}},
	title = {Discriminative deep belief networks for visual data classification},
	volume = {44},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320310005789},
	doi = {10.1016/j.patcog.2010.12.012},
	abstract = {Visual data classification using insufficient labeled data is a well-known hard problem. Semi-supervise learning, which attempts to exploit the unlabeled data in additional to the labeled ones, has attracted much attention in recent years. This paper proposes a novel semi-supervised classifier called discriminative deep belief networks (DDBN). DDBN utilizes a new deep architecture to integrate the abstraction ability of deep belief nets (DBN) and discriminative ability of backpropagation strategy. For unsupervised learning, DDBN inherits the advantage of DBN, which preserves the information well from high-dimensional features space to low-dimensional embedding. For supervised learning, through a well designed objective function, the backpropagation strategy directly optimizes the classification results in training dataset by refining the parameter space. Moreover, we apply DDBN to visual data classification task and observe an important fact that the learning ability of deep architecture is seriously underrated in real-world applications, especially in visual data analysis. The comparative experiments on standard datasets of different types and different scales demonstrate that the proposed algorithm outperforms both representative semi-supervised classifiers and existing deep learning techniques. For visual dataset, we can further improve the DDBN performance with much larger and deeper architecture.},
	number = {10},
	urldate = {2024-02-26},
	journal = {Pattern Recognition},
	author = {Liu, Yan and Zhou, Shusen and Chen, Qingcai},
	month = oct,
	year = {2011},
	keywords = {Deep learning, Discriminative deep belief networks, Semi-supervised learning, Visual data classification},
	pages = {2287--2296},
}

@misc{noauthor_digital_nodate,
	title = {Digital {Imaging} {Group} of {London}},
	url = {http://digitalimaginggroup.ca/direct.php},
	urldate = {2024-02-26},
}

@inproceedings{zhen_direct_2015,
	title = {Direct volume estimation without segmentation},
	volume = {9413},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/9413/94132G/Direct-volume-estimation-without-segmentation/10.1117/12.2081377.full},
	doi = {10.1117/12.2081377},
	abstract = {Volume estimation plays an important role in clinical diagnosis. For example, cardiac ventricular volumes including left ventricle (LV) and right ventricle (RV) are important clinical indicators of cardiac functions. Accurate and automatic estimation of the ventricular volumes is essential to the assessment of cardiac functions and diagnosis of heart diseases. Conventional methods are dependent on an intermediate segmentation step which is obtained either manually or automatically. However, manual segmentation is extremely time-consuming, subjective and highly non-reproducible; automatic segmentation is still challenging, computationally expensive, and completely unsolved for the RV. Towards accurate and efficient direct volume estimation, our group has been researching on learning based methods without segmentation by leveraging state-of-the-art machine learning techniques. Our direct estimation methods remove the accessional step of segmentation and can naturally deal with various volume estimation tasks. Moreover, they are extremely flexible to be used for volume estimation of either joint bi-ventricles (LV and RV) or individual LV/RV. We comparatively study the performance of direct methods on cardiac ventricular volume estimation by comparing with segmentation based methods. Experimental results show that direct estimation methods provide more accurate estimation of cardiac ventricular volumes than segmentation based methods. This indicates that direct estimation methods not only provide a convenient and mature clinical tool for cardiac volume estimation but also enables diagnosis of cardiac diseases to be conducted in a more efficient and reliable way.},
	urldate = {2024-02-26},
	booktitle = {Medical {Imaging} 2015: {Image} {Processing}},
	publisher = {SPIE},
	author = {Zhen, X. and Wang, Z. and Islam, A. and Bhaduri, M. and Chan, I. and Li, S.},
	month = mar,
	year = {2015},
	pages = {671--676},
}

@inproceedings{mohamed_understanding_2012,
	title = {Understanding how {Deep} {Belief} {Networks} perform acoustic modelling},
	url = {https://ieeexplore.ieee.org/abstract/document/6288863},
	doi = {10.1109/ICASSP.2012.6288863},
	abstract = {Deep Belief Networks (DBNs) are a very competitive alternative to Gaussian mixture models for relating states of a hidden Markov model to frames of coefficients derived from the acoustic input. They are competitive for three reasons: DBNs can be fine-tuned as neural networks; DBNs have many non-linear hidden layers; and DBNs are generatively pre-trained. This paper illustrates how each of these three aspects contributes to the DBN's good recognition performance using both phone recognition performance on the TIMIT corpus and a dimensionally reduced visualization of the relationships between the feature vectors learned by the DBNs that preserves the similarity structure of the feature vectors at multiple scales. The same two methods are also used to investigate the most suitable type of input representation for a DBN.},
	urldate = {2024-02-26},
	booktitle = {2012 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Mohamed, Abdel-rahman and Hinton, Geoffrey and Penn, Gerald},
	month = mar,
	year = {2012},
	note = {ISSN: 2379-190X},
	keywords = {Biological neural networks, Deep belief networks, Hidden Markov models, Mel frequency cepstral coefficient, Speech, Training, Vectors, acoustic modeling, neural networks},
	pages = {4273--4276},
}

@article{tran_deep_2018,
	title = {Deep {Logic} {Networks}: {Inserting} and {Extracting} {Knowledge} {From} {Deep} {Belief} {Networks}},
	volume = {29},
	issn = {2162-237X, 2162-2388},
	shorttitle = {Deep {Logic} {Networks}},
	url = {http://ieeexplore.ieee.org/document/7738566/},
	doi = {10.1109/TNNLS.2016.2603784},
	number = {2},
	urldate = {2024-02-26},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Tran, Son N. and d'Avila Garcez, Artur S.},
	month = feb,
	year = {2018},
	pages = {246--258},
}

@article{smets_decision_2005,
	title = {Decision making in the {TBM}: the necessity of the pignistic transformation},
	volume = {38},
	issn = {0888613X},
	shorttitle = {Decision making in the {TBM}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0888613X04000593},
	doi = {10.1016/j.ijar.2004.05.003},
	language = {en},
	number = {2},
	urldate = {2024-02-26},
	journal = {International Journal of Approximate Reasoning},
	author = {Smets, Philippe},
	month = feb,
	year = {2005},
	pages = {133--147},
}

@inproceedings{gao_complex_2023,
	address = {Hefei, China},
	title = {A {Complex} {Belief} {Jensen}-{Shannon} {Divergence} in {Complex} {Evidence} {Theory} for {Decision}-{Making}},
	isbn = {9798350316308},
	url = {https://ieeexplore.ieee.org/document/10318369/},
	doi = {10.1109/ICUS58632.2023.10318369},
	urldate = {2024-02-26},
	booktitle = {2023 {IEEE} {International} {Conference} on {Unmanned} {Systems} ({ICUS})},
	publisher = {IEEE},
	author = {Gao, Linlu and Yin, Mingrui and Xiao, Fuyuan and Cao, Zehong},
	month = oct,
	year = {2023},
	pages = {299--304},
}

@article{zhang_enhanced_2023,
	title = {An {Enhanced} {Pignistic} {Transformation}-{Based} {Fusion} {Scheme} {With} {Applications} in {Image} {Segmentation}},
	volume = {11},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/abstract/document/10054034},
	doi = {10.1109/ACCESS.2023.3249294},
	abstract = {The traditional Pignistic transformation is limited in the context of “betting”, which faces information loss and is inconvenient for multi-source information fusion. To tackle this challenge, an Enhanced Pignistic transformation is proposed for the first time. New divergence and information volume measures are tailor-made for the enhanced Pignistic probability, and a novel information fusion algorithm is developed. To further prove the fusion algorithm’s advantages in conflict management, it is applied in a new semi-automatic image segmentation scheme. Two uncertain decision-support techniques named adaptive belief assignment and scalable information extraction are raised, and a fuzzy heuristic refinement algorithm is conducted, fulfilling the gap between evidential decision-making and segmentation refinement. Experimental analysis shows the proposed segmentation algorithm is superior on four metrics each and can enhance the robustness of foreground segmentation, indicating the effectiveness of the proposal in solving the decision inaccuracy of evidential segmentation schemes.},
	urldate = {2024-02-26},
	journal = {IEEE Access},
	author = {Zhang, Jiaxu and Ma, Xiaojian and Song, Tingting and Wang, Ao and Lin, Yuhua},
	year = {2023},
	keywords = {Decision making, Enhanced Pignistic transformation, Entropy, Evidence theory, Heuristic algorithms, Image segmentation, Information retrieval, Volume measurement, belief hellinger distance, heuristic refinement, multi-source information fusion, semi-automatic image segmentation, uncertain decision-support},
	pages = {19892--19913},
}

@article{guo_survey_2024,
	title = {A survey on uncertainty reasoning and quantification in belief theory and its application to deep learning},
	volume = {101},
	issn = {1566-2535},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253523003032},
	doi = {10.1016/j.inffus.2023.101987},
	abstract = {An in-depth understanding of uncertainty is the first step to making effective decisions under uncertainty. Machine/deep learning (ML/DL) has been hugely leveraged to solve complex problems involved with processing high-dimensional data. However, reasoning and quantifying different uncertainties to achieve effective decision-making have been much less explored in ML/DL than in other Artificial Intelligence (AI) domains. In particular, belief/evidence theories have been studied in Knowledge representation and reasoning (KRR) since the 1960s to reason and measure uncertainties to enhance decision-making effectiveness. Based on our in-depth literature review, only a few studies have leveraged mature uncertainty research in belief/evidence theories in ML/DL to tackle complex problems under different types of uncertainty. Our present survey paper discusses major belief theories and their core ideas dealing with uncertainty causes and types and quantifying them, along with the discussions of their applicability in ML/DL. Particularly, we discuss three main approaches leveraging belief theories in Deep Neural Networks (DNNs), including Evidential DNNs, Fuzzy DNNs, and Rough DNNs, in terms of their uncertainty causes, types, and quantification methods along with their applicability in diverse problem domains. Through an in-depth understanding of the extensive survey on this topic, we discuss insights, lessons learned, limitations of the current state-of-the-art bridging belief theories and ML/DL, and future research directions. This paper conducts an extensive survey by bridging belief theories and deep learning in reasoning and quantifying uncertainty to help researchers initiate uncertainty and decision-making research.},
	urldate = {2024-02-26},
	journal = {Information Fusion},
	author = {Guo, Zhen and Wan, Zelin and Zhang, Qisheng and Zhao, Xujiang and Zhang, Qi and Kaplan, Lance M. and Jøsang, Audun and Jeong, Dong H. and Chen, Feng and Cho, Jin-Hee},
	month = jan,
	year = {2024},
	keywords = {Belief theory, Decision making, Machine/deep learning, Uncertainty quantification, Uncertainty reasoning},
	pages = {101987},
}

@article{cai_pignistic_2020,
	title = {Pignistic {Belief} {Transform}: {A} {New} {Method} of {Conflict} {Measurement}},
	volume = {8},
	issn = {2169-3536},
	shorttitle = {Pignistic {Belief} {Transform}},
	url = {https://ieeexplore.ieee.org/abstract/document/8960550},
	doi = {10.1109/ACCESS.2020.2966821},
	abstract = {To measure conflict between two basic probability assignment functions plays the key role of conflict management in Dempster-shafer evidence theory. In this paper, a new conflict measure is proposed. First, the classical pignistic probability transform (PPT) is generalized as pignistic belief transform (PBT). One of the advantages of PBT is that it can assign belief to multiple sets. When the belief is assigned to single element, the proposed PBT is degenerated as classical PPT. Then, the betting distance of two pignistic belief transforms is proposed, which can be used as a new conflict degree of BPAs. Finally, a numerical example is illustrated to show the use of the proposed method to combine conflicting evidence.},
	urldate = {2024-02-26},
	journal = {IEEE Access},
	author = {Cai, Qixuan and Gao, Xiaozhuan and Deng, Yong},
	year = {2020},
	keywords = {Data integration, Dempster-Shafer evidence theory, Fuzzy sets, Q measurement, Transforms, Volume measurement, belief function, conflict, pignistic belief transform},
	pages = {15265--15272},
}

@article{tewari_advances_2022,
	title = {Advances in {Neural} {Rendering}},
	volume = {41},
	copyright = {© 2022 The author(s) Computer Graphics Forum © 2022 The Eurographics Association and John Wiley \& Sons Ltd. Published by John Wiley \& Sons Ltd.},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14507},
	doi = {10.1111/cgf.14507},
	abstract = {Synthesizing photo-realistic images and videos is at the heart of computer graphics and has been the focus of decades of research. Traditionally, synthetic images of a scene are generated using rendering algorithms such as rasterization or ray tracing, which take specifically defined representations of geometry and material properties as input. Collectively, these inputs define the actual scene and what is rendered, and are referred to as the scene representation (where a scene consists of one or more objects). Example scene representations are triangle meshes with accompanied textures (e.g., created by an artist), point clouds (e.g., from a depth sensor), volumetric grids (e.g., from a CT scan), or implicit surface functions (e.g., truncated signed distance fields). The reconstruction of such a scene representation from observations using differentiable rendering losses is known as inverse graphics or inverse rendering. Neural rendering is closely related, and combines ideas from classical computer graphics and machine learning to create algorithms for synthesizing images from real-world observations. Neural rendering is a leap forward towards the goal of synthesizing photo-realistic image and video content. In recent years, we have seen immense progress in this field through hundreds of publications that show different ways to inject learnable components into the rendering pipeline. This state-of-the-art report on advances in neural rendering focuses on methods that combine classical rendering principles with learned 3D scene representations, often now referred to as neural scene representations. A key advantage of these methods is that they are 3D-consistent by design, enabling applications such as novel viewpoint synthesis of a captured scene. In addition to methods that handle static scenes, we cover neural scene representations for modeling non-rigidly deforming objects and scene editing and composition. While most of these approaches are scene-specific, we also discuss techniques that generalize across object classes and can be used for generative tasks. In addition to reviewing these state-of-the-art methods, we provide an overview of fundamental concepts and definitions used in the current literature. We conclude with a discussion on open challenges and social implications.},
	language = {en},
	number = {2},
	urldate = {2024-02-26},
	journal = {Computer Graphics Forum},
	author = {Tewari, A. and Thies, J. and Mildenhall, B. and Srinivasan, P. and Tretschk, E. and Yifan, W. and Lassner, C. and Sitzmann, V. and Martin-Brualla, R. and Lombardi, S. and Simon, T. and Theobalt, C. and Nießner, M. and Barron, J. T. and Wetzstein, G. and Zollhöfer, M. and Golyanik, V.},
	year = {2022},
	pages = {703--735},
}

@article{von_bertalanffy_theory_1950,
	title = {The theory of open systems in physics and biology},
	volume = {111},
	issn = {0036-8075},
	doi = {10.1126/science.111.2872.23},
	language = {eng},
	number = {2872},
	journal = {Science (New York, N.Y.)},
	author = {Von Bertalanffy, L.},
	month = jan,
	year = {1950},
	pmid = {15398815},
	keywords = {BIOLOGY, Biology, PHYSICS, Physical Phenomena, Physics},
	pages = {23--29},
}

@article{esfarjani_equilibrium_2022,
	title = {Equilibrium and {Non}-{Equilibrium} {Lattice} {Dynamics} of {Anharmonic} {Systems}},
	volume = {24},
	issn = {1099-4300},
	doi = {10.3390/e24111585},
	abstract = {In this review, motivated by the recent interest in high-temperature materials, we review our recent progress in theories of lattice dynamics in and out of equilibrium. To investigate thermodynamic properties of anharmonic crystals, the self-consistent phonon theory was developed, mainly in the 1960s, for rare gas atoms and quantum crystals. We have extended this theory to investigate the properties of the equilibrium state of a crystal, including its unit cell shape and size, atomic positions and lattice dynamical properties. Using the equation-of-motion method combined with the fluctuation-dissipation theorem and the Donsker-Furutsu-Novikov (DFN) theorem, this approach was also extended to investigate the non-equilibrium case where there is heat flow across a junction or an interface. The formalism is a classical one and therefore valid at high temperatures.},
	language = {eng},
	number = {11},
	journal = {Entropy (Basel, Switzerland)},
	author = {Esfarjani, Keivan and Liang, Yuan},
	month = nov,
	year = {2022},
	pmid = {36359675},
	pmcid = {PMC9689135},
	keywords = {anharmonicity, heat current, nanoscale thermal transport, phonons, thermal conductance, transmission},
	pages = {1585},
}

@article{rodriguez_de_san_miguel_conditional_2023,
	title = {Conditional {Equilibrium} {Constants} {Reviewed}},
	volume = {53},
	issn = {1547-6510},
	doi = {10.1080/10408347.2021.1977609},
	abstract = {A free energy-based conceptual theoretical framework from which the conditional equilibrium constant can be comprehensibly understood is presented. This constant is found to be a weighted geometric mean of the equilibrium constants of the reactions of all forms of the conditioned species under buffering conditions, where the weight is given by a function of their predominance in terms of their mole fractions. Once it is shown that this type of equilibrium constant can be easily deduced form free energy functions, it is shown how corrections for activity coefficient can be incorporated as well. The framework additionally permits to interpret side-reactions coefficients as free energy terms related to the chemical speciation of the system, allowing the use of the generalization of Hess' law to obtain conditional constants and a straightforward deduction of multiconditional equilibrium constants. Furthermore, different uses of the conditional constants along the actual literature are reviewed as well allowing to have a complete and updated panorama of the employment of this important concept in chemical and speciation analysis in many areas of research.},
	language = {eng},
	number = {4},
	journal = {Critical Reviews in Analytical Chemistry},
	author = {Rodríguez de San Miguel, Eduardo and González-Albarrán, René and Rojas-Challa, Yahsé},
	year = {2023},
	pmid = {34601994},
	keywords = {Solution chemistry, conditional equilibrium constant, free-energy, side-reaction coefficient, thermodynamics},
	pages = {775--797},
}

@article{petersen_equilibrium_2022,
	title = {Equilibrium distribution functions: connection with microscopic dynamics},
	volume = {24},
	issn = {1463-9084},
	shorttitle = {Equilibrium distribution functions},
	doi = {10.1039/d1cp05316g},
	abstract = {Standard textbook derivations of the equilibrium distribution function rely on assumptions that may not satisfy all readers. Here, we present a straightforward approach to derive the equilibrium distribution function from the microscopic dynamics, and review how it can be used to obtain the expected expressions. In molecular dynamics simulations the equations of motion are often modified to simulate different ensembles or phenomena. We show that in some cases these equations will sample an equilibrium ensemble whereas in other cases they will not. For example, we find that for charged particles driven by a field, an equilibrium distribution is only possible when the system is confined. Furthermore, the approach correctly predicts that neither SLLOD shear flow dynamics nor constant temperature dynamics with a Berendsen thermostat sample any time-independent phase space distributions.},
	language = {eng},
	number = {11},
	journal = {Physical chemistry chemical physics: PCCP},
	author = {Petersen, Charlotte F. and Searles, Debra J.},
	month = mar,
	year = {2022},
	pmid = {35262116},
	keywords = {Molecular Dynamics Simulation, Motion, Temperature},
	pages = {6383--6392},
}

@article{hummel_where_2019,
	title = {Where to find equilibrium constants?},
	volume = {692},
	issn = {1879-1026},
	doi = {10.1016/j.scitotenv.2019.07.161},
	abstract = {A crucial part of any equilibrium modelling calculation is the selection of equilibrium constants that quantify the strength of interactions between metals and ligands. For researchers new to the field of solution chemistry, locating suitable equilibrium constants that lead to reliable model results can be problematic. Numerous large compilations of equilibrium constant values have been published each having their own limitations, coverage and availability. This work surveys eleven major compilations of equilibrium constants including those from authoritative groups such as IUPAC, NIST, and NEA. For each compilation surveyed, details are given related to the historical background and underlying project, scope of the database with respect to range of included metals and ligands, and the present-day availability of publications or computer databases resulting from the project. The various methods employed by different data compilers in their critical assessment for each compilation are also discussed.},
	language = {eng},
	journal = {The Science of the Total Environment},
	author = {Hummel, Wolfgang and Filella, Montserrat and Rowland, Darren},
	month = nov,
	year = {2019},
	pmid = {31336301},
	keywords = {Chemical equilibria, Constant compilations, Equilibrium constants, Speciation calculations, Speciation modelling},
	pages = {49--59},
}

@article{yip_atomic-resolution_2020,
	title = {Atomic-resolution protein structure determination by cryo-{EM}},
	volume = {587},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-020-2833-4},
	doi = {10.1038/s41586-020-2833-4},
	abstract = {Single-particle electron cryo-microscopy (cryo-EM) is a powerful method for solving the three-dimensional structures of biological macromolecules. The technological development of transmission electron microscopes, detectors and automated procedures in combination with user-friendly image processing software and ever-increasing computational power have made cryo-EM a successful and expanding technology over the past decade1. At resolutions better than 4 Å, atomic model building starts to become possible, but the direct visualization of true atomic positions in protein structure determination requires much higher (better than 1.5 Å) resolution, which so far has not been attained by cryo-EM. The direct visualization of atom positions is essential for understanding the mechanisms of protein-catalysed chemical reactions, and for studying how drugs bind to and interfere with the function of proteins2. Here we report a 1.25 Å-resolution structure of apoferritin obtained by cryo-EM with a newly developed electron microscope that provides, to our knowledge, unprecedented structural detail. Our apoferritin structure has almost twice the 3D information content of the current world record reconstruction (at 1.54 Å resolution3). We can visualize individual atoms in a protein, see density for hydrogen atoms and image single-atom chemical modifications. Beyond the nominal improvement in resolution, we also achieve a substantial improvement in the quality of the cryo-EM density map, which is highly relevant for using cryo-EM in structure-based drug design.},
	language = {en},
	number = {7832},
	urldate = {2024-02-26},
	journal = {Nature},
	author = {Yip, Ka Man and Fischer, Niels and Paknia, Elham and Chari, Ashwin and Stark, Holger},
	month = nov,
	year = {2020},
	keywords = {Cryoelectron microscopy},
	pages = {157--161},
}

@article{si_deep_2020,
	title = {Deep {Learning} to {Predict} {Protein} {Backbone} {Structure} from {High}-{Resolution} {Cryo}-{EM} {Density} {Maps}},
	volume = {10},
	copyright = {2020 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-60598-y},
	doi = {10.1038/s41598-020-60598-y},
	abstract = {Cryo-electron microscopy (cryo-EM) has become a leading technology for determining protein structures. Recent advances in this field have allowed for atomic resolution. However, predicting the backbone trace of a protein has remained a challenge on all but the most pristine density maps ({\textless}2.5 Å resolution). Here we introduce a deep learning model that uses a set of cascaded convolutional neural networks (CNNs) to predict Cα atoms along a protein’s backbone structure. The cascaded-CNN (C-CNN) is a novel deep learning architecture comprised of multiple CNNs, each predicting a specific aspect of a protein’s structure. This model predicts secondary structure elements (SSEs), backbone structure, and Cα atoms, combining the results of each to produce a complete prediction map. The cascaded-CNN is a semantic segmentation image classifier and was trained using thousands of simulated density maps. This method is largely automatic and only requires a recommended threshold value for each protein density map. A specialized tabu-search path walking algorithm was used to produce an initial backbone trace with Cα placements. A helix-refinement algorithm made further improvements to the α-helix SSEs of the backbone trace. Finally, a novel quality assessment-based combinatorial algorithm was used to effectively map protein sequences onto Cα traces to obtain full-atom protein structures. This method was tested on 50 experimental maps between 2.6 Å and 4.4 Å resolution. It outperformed several state-of-the-art prediction methods including Rosetta de-novo, MAINMAST, and a Phenix based method by producing the most complete predicted protein structures, as measured by percentage of found Cα atoms. This method accurately predicted 88.9\% (mean) of the Cα atoms within 3 Å of a protein’s backbone structure surpassing the 66.8\% mark achieved by the leading alternate method (Phenix based fully automatic method) on the same set of density maps. The C-CNN also achieved an average root-mean-square deviation (RMSD) of 1.24 Å on a set of 50 experimental density maps which was tested by the Phenix based fully automatic method. The source code and demo of this research has been published at https://github.com/DrDongSi/Ca-Backbone-Prediction.},
	language = {en},
	number = {1},
	urldate = {2024-02-26},
	journal = {Scientific Reports},
	author = {Si, Dong and Moritz, Spencer A. and Pfab, Jonas and Hou, Jie and Cao, Renzhi and Wang, Liguo and Wu, Tianqi and Cheng, Jianlin},
	month = mar,
	year = {2020},
	keywords = {Computational science, Cryoelectron microscopy, Protein structure predictions},
	pages = {4282},
}

@article{terashi_deepmainmast_2024,
	title = {{DeepMainmast}: integrated protocol of protein structure modeling for cryo-{EM} with deep learning and structure prediction},
	volume = {21},
	copyright = {2023 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{DeepMainmast}},
	url = {https://www.nature.com/articles/s41592-023-02099-0},
	doi = {10.1038/s41592-023-02099-0},
	abstract = {Three-dimensional structure modeling from maps is an indispensable step for studying proteins and their complexes with cryogenic electron microscopy. Although the resolution of determined cryogenic electron microscopy maps has generally improved, there are still many cases where tracing protein main chains is difficult, even in maps determined at a near-atomic resolution. Here we developed a protein structure modeling method, DeepMainmast, which employs deep learning to capture the local map features of amino acids and atoms to assist main-chain tracing. Moreover, we integrated AlphaFold2 with the de novo density tracing protocol to combine their complementary strengths and achieved even higher accuracy than each method alone. Additionally, the protocol is able to accurately assign the chain identity to the structure models of homo-multimers, which is not a trivial task for existing methods.},
	language = {en},
	number = {1},
	urldate = {2024-02-26},
	journal = {Nature Methods},
	author = {Terashi, Genki and Wang, Xiao and Prasad, Devashish and Nakamura, Tsukasa and Kihara, Daisuke},
	month = jan,
	year = {2024},
	keywords = {Cryoelectron microscopy, Protein structure predictions, Software},
	pages = {122--131},
}

@article{shyam_attentive_2017,
	title = {Attentive {Recurrent} {Comparators}},
	url = {http://arxiv.org/abs/1703.00767},
	abstract = {Rapid learning requires flexible representations to quickly adopt to new evidence. We develop a novel class of models called Attentive Recurrent Comparators (ARCs) that form representations of objects by cycling through them and making observations. Using the representations extracted by ARCs, we develop a way of approximating a {\textbackslash}textit\{dynamic representation space\} and use it for one-shot learning. In the task of one-shot classification on the Omniglot dataset, we achieve the state of the art performance with an error rate of 1.5{\textbackslash}\%. This represents the first super-human result achieved for this task with a generic model that uses only pixel information.},
	urldate = {2017-09-15},
	journal = {Arxiv},
	author = {Shyam, Pranav and Gupta, Shubham and Dukkipati, Ambedkar},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.00767},
}

@article{han_retinex-based_2023,
	title = {A {Retinex}-based variational model for noise suppression and nonuniform illumination correction in corneal confocal microscopy images},
	volume = {68},
	issn = {1361-6560},
	doi = {10.1088/1361-6560/acaeef},
	abstract = {Objective.Corneal confocal microscopy (CCM) image analysis is a non-invasivein vivoclinical technique that can quantify corneal nerve fiber damage. However, the acquired CCM images are often accompanied by speckle noise and nonuniform illumination, which seriously affects the analysis and diagnosis of the diseases.Approach.In this paper, first we propose a variational Retinex model for the inhomogeneity correction and noise removal of CCM images. In this model, the Beppo Levi space is introduced to constrain the smoothness of the illumination layer for the first time, and the fractional order differential is adopted as the regularization term to constrain reflectance layer. Then, a denoising regularization term is also constructed with Block Matching 3D (BM3D) to suppress noise. Finally, by adjusting the uneven illumination layer, we obtain the final results. Second, an image quality evaluation metric is proposed to evaluate the illumination uniformity of images objectively.Main results.To demonstrate the effectiveness of our method, the proposed method is tested on 628 low-quality CCM images from the CORN-2 dataset. Extensive experiments show the proposed method outperforms the other four related methods in terms of noise removal and uneven illumination suppression.SignificanceThis demonstrates that the proposed method may be helpful for the diagnostics and analysis of eye diseases.},
	language = {eng},
	number = {2},
	journal = {Physics in Medicine and Biology},
	author = {Han, Rui and Tang, Chen and Xu, Min and Lei, Zhenkun},
	month = jan,
	year = {2023},
	pmid = {36577141},
	keywords = {Image Processing, Computer-Assisted, Lighting, Microscopy, Confocal, Nerve Fibers, Noise, corneal confocal microscopy images, noise suppressing, nonuniform illumination correction, variational retinex model},
}

@article{goceri_evaluation_2023,
	title = {Evaluation of denoising techniques to remove speckle and {Gaussian} noise from dermoscopy images},
	volume = {152},
	issn = {1879-0534},
	doi = {10.1016/j.compbiomed.2022.106474},
	abstract = {Computerized methods provide analyses of skin lesions from dermoscopy images automatically. However, the images acquired from dermoscopy devices are noisy and cause low accuracy in automated methods. Therefore, various methods have been applied for denoising in the literature. There are some review-type papers about these methods. However, their authors have focused on either denoising with a specific approach or denoising from other images rather than dermoscopy images, which have a different characteristic. It is not possible to determine which method is the most suitable for denoising from dermoscopy images according to the results presented in them. Therefore, a review on the denoising approaches applied with dermoscopy images is required and, according to our knowledge, there is no such a review-type paper. To fill this gap in the literature, the required review has been performed in this work. Also, in this work, the methods in the literature have been implemented using the same data sets containing images with speckle or Gaussian types of noise. The results have been analyzed not only visually but also quantitatively to compare capabilities of the techniques. Our experiments indicated that each denoising technique has its own disadvantages and advantages. The main contributions of this paper are three-fold: (i) A comprehensive review on the denoising approaches applied with dermoscopy images has been presented. (ii) The denoising techniques have been implemented with the same images for meaningful comparisons. (iii) Both visual and quantitative analyses with different metrics have been performed and comparative performance evaluations have been presented.},
	language = {eng},
	journal = {Computers in Biology and Medicine},
	author = {Goceri, Evgin},
	month = jan,
	year = {2023},
	pmid = {36563540},
	keywords = {Algorithms, Denoising, Dermoscopy, Dermoscopy images, Filtering, Noise, Noise reduction, Normal Distribution, Signal-To-Noise Ratio, Skin lesions},
	pages = {106474},
}

@article{benfenati_upu-net_2022,
	title = {{upU}-{Net} {Approaches} for {Background} {Emission} {Removal} in {Fluorescence} {Microscopy}},
	volume = {8},
	issn = {2313-433X},
	doi = {10.3390/jimaging8050142},
	abstract = {The physical process underlying microscopy imaging suffers from several issues: some of them include the blurring effect due to the Point Spread Function, the presence of Gaussian or Poisson noise, or even a mixture of these two types of perturbation. Among them, auto-fluorescence presents other artifacts in the registered image, and such fluorescence may be an important obstacle in correctly recognizing objects and organisms in the image. For example, particle tracking may suffer from the presence of this kind of perturbation. The objective of this work is to employ Deep Learning techniques, in the form of U-Nets like architectures, for background emission removal. Such fluorescence is modeled by Perlin noise, which reveals to be a suitable candidate for simulating such a phenomenon. The proposed architecture succeeds in removing the fluorescence, and at the same time, it acts as a denoiser for both Gaussian and Poisson noise. The performance of this approach is furthermore assessed on actual microscopy images and by employing the restored images for particle recognition.},
	language = {eng},
	number = {5},
	journal = {Journal of Imaging},
	author = {Benfenati, Alessandro},
	month = may,
	year = {2022},
	pmid = {35621906},
	pmcid = {PMC9146274},
	keywords = {Perlin noise, U-Nets, deep learning, microscopy imaging, neural network, particle estimation},
	pages = {142},
}

@article{yang_poisson-gaussian_2015,
	title = {Poisson-{Gaussian} {Noise} {Reduction} {Using} the {Hidden} {Markov} {Model} in {Contourlet} {Domain} for {Fluorescence} {Microscopy} {Images}},
	volume = {10},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0136964},
	abstract = {In certain image acquisitions processes, like in fluorescence microscopy or astronomy, only a limited number of photons can be collected due to various physical constraints. The resulting images suffer from signal dependent noise, which can be modeled as a Poisson distribution, and a low signal-to-noise ratio. However, the majority of research on noise reduction algorithms focuses on signal independent Gaussian noise. In this paper, we model noise as a combination of Poisson and Gaussian probability distributions to construct a more accurate model and adopt the contourlet transform which provides a sparse representation of the directional components in images. We also apply hidden Markov models with a framework that neatly describes the spatial and interscale dependencies which are the properties of transformation coefficients of natural images. In this paper, an effective denoising algorithm for Poisson-Gaussian noise is proposed using the contourlet transform, hidden Markov models and noise estimation in the transform domain. We supplement the algorithm by cycle spinning and Wiener filtering for further improvements. We finally show experimental results with simulations and fluorescence microscopy images which demonstrate the improved performance of the proposed approach.},
	language = {eng},
	number = {9},
	journal = {PloS One},
	author = {Yang, Sejung and Lee, Byung-Uk},
	year = {2015},
	pmid = {26352138},
	pmcid = {PMC4564212},
	keywords = {Algorithms, Image Processing, Computer-Assisted, Markov Chains, Microscopy, Fluorescence, Normal Distribution, Signal-To-Noise Ratio},
	pages = {e0136964},
}

@article{khademi_self-supervised_2021,
	title = {Self-{Supervised} {Poisson}-{Gaussian} {Denoising}},
	volume = {2021},
	issn = {2472-6737},
	doi = {10.1109/wacv48630.2021.00218},
	abstract = {We extend the blindspot model for self-supervised denoising to handle Poisson-Gaussian noise and introduce an improved training scheme that avoids hyperparameters and adapts the denoiser to the test data. Self-supervised models for denoising learn to denoise from only noisy data and do not require corresponding clean images, which are difficult or impossible to acquire in some application areas of interest such as low-light microscopy. We introduce a new training strategy to handle Poisson-Gaussian noise which is the standard noise model for microscope images. Our new strategy eliminates hyperparameters from the loss function, which is important in a self-supervised regime where no ground truth data is available to guide hyperparameter tuning. We show how our denoiser can be adapted to the test data to improve performance. Our evaluations on microscope image denoising benchmarks validate our approach.},
	language = {eng},
	journal = {IEEE Winter Conference on Applications of Computer Vision. IEEE Winter Conference on Applications of Computer Vision},
	author = {Khademi, Wesley and Rao, Sonia and Minnerath, Clare and Hagen, Guy and Ventura, Jonathan},
	month = jan,
	year = {2021},
	pmid = {34296053},
	pmcid = {PMC8294668},
	pages = {2130--2138},
}

@article{ma_fight_2019,
	title = {Fight against background noise in stimulated emission depletion nanoscopy},
	volume = {16},
	issn = {1478-3975},
	doi = {10.1088/1478-3975/ab255c},
	abstract = {STimulated emission depletion (STED) nanoscopy has been proposed to extend greatly our capability of using light to study a variety of biological problems with nanometer-scale resolution. However, in practice the unwanted background noise degrades the STED image quality and precludes quantitative analysis. Here, we discuss the underlying sources of the background noise in STED images, and review current approaches to alleviate this problem, such as time-gating, anti-Stokes excitation removal, and off-focus incomplete depletion suppression. Progress in correcting uncorrelated background photons in fluorescence correlation spectroscopy combined with STED (STED-FCS) will also be discussed.},
	language = {eng},
	number = {5},
	journal = {Physical Biology},
	author = {Ma, Ye and Ha, Taekjip},
	month = jul,
	year = {2019},
	pmid = {31141791},
	keywords = {Image Processing, Computer-Assisted, Microscopy, Fluorescence, Time Factors},
	pages = {051002},
}

@article{kar_theory_2020,
	title = {Theory building with big data-driven research – {Moving} away from the “{What}” towards the “{Why}”},
	volume = {54},
	issn = {0268-4012},
	url = {https://www.sciencedirect.com/science/article/pii/S0268401220311257},
	doi = {10.1016/j.ijinfomgt.2020.102205},
	abstract = {Data availability and access to various platforms, is changing the nature of Information Systems (IS) studies. Such studies often use large datasets, which may incorporate structured and unstructured data, from various platforms. The questions that such papers address, in turn, may attempt to use methods from computational science like sentiment mining, text mining, network science and image analytics to derive insights. However, there is often a weak theoretical contribution in many of these studies. We point out the need for such studies to contribute back to the IS discipline, whereby findings can explain more about the phenomenon surrounding the interaction of people with technology artefacts and the ecosystem within which these contextual usage is situated. Our opinion paper attempts to address this gap and provide insights on the methodological adaptations required in “big data studies” to be converted into “IS research” and contribute to theory building in information systems.},
	urldate = {2024-02-25},
	journal = {International Journal of Information Management},
	author = {Kar, Arpan Kumar and Dwivedi, Yogesh K.},
	month = oct,
	year = {2020},
	keywords = {Big data analytics, Data science, Image mining, Inductive theory building, Information management, Machine learning, Network mining, Review, Sentiment analysis, Text mining},
	pages = {102205},
}

@article{ciga_overcoming_2021,
	title = {Overcoming the limitations of patch-based learning to detect cancer in whole slide images},
	volume = {11},
	issn = {2045-2322},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8076327/},
	doi = {10.1038/s41598-021-88494-z},
	abstract = {Whole slide images (WSIs) pose unique challenges when training deep learning models. They are very large which makes it necessary to break each image down into smaller patches for analysis, image features have to be extracted at multiple scales in order to capture both detail and context, and extreme class imbalances may exist. Significant progress has been made in the analysis of these images, thanks largely due to the availability of public annotated datasets. We postulate, however, that even if a method scores well on a challenge task, this success may not translate to good performance in a more clinically relevant workflow. Many datasets consist of image patches which may suffer from data curation bias; other datasets are only labelled at the whole slide level and the lack of annotations across an image may mask erroneous local predictions so long as the final decision is correct. In this paper, we outline the differences between patch or slide-level classification versus methods that need to localize or segment cancer accurately across the whole slide, and we experimentally verify that best practices differ in both cases. We apply a binary cancer detection network on post neoadjuvant therapy breast cancer WSIs to find the tumor bed outlining the extent of cancer, a task which requires sensitivity and precision across the whole slide. We extensively study multiple design choices and their effects on the outcome, including architectures and augmentations. We propose a negative data sampling strategy, which drastically reduces the false positive rate (25\% of false positives versus 62.5\%) and improves each metric pertinent to our problem, with a 53\% reduction in the error of tumor extent. Our results indicate classification performances of image patches versus WSIs are inversely related when the same negative data sampling strategy is used. Specifically, injection of negatives into training data for image patch classification degrades the performance, whereas the performance is improved for slide and pixel-level WSI classification tasks. Furthermore, we find applying extensive augmentations helps more in WSI-based tasks compared to patch-level image classification.},
	urldate = {2024-02-25},
	journal = {Scientific Reports},
	author = {Ciga, Ozan and Xu, Tony and Nofech-Mozes, Sharon and Noy, Shawna and Lu, Fang-I and Martel, Anne L.},
	month = apr,
	year = {2021},
	pmid = {33903725},
	pmcid = {PMC8076327},
	pages = {8894},
}

@misc{noauthor_clip_nodate,
	title = {{CLIP}: {Connecting} text and images},
	shorttitle = {{CLIP}},
	url = {https://openai.com/research/clip},
	abstract = {We’re introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the “zero-shot” capabilities of GPT-2 and GPT-3.},
	language = {en-US},
	urldate = {2024-02-23},
}

@misc{noauthor_si-eun_2023,
	title = {Si-eun},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Si-eun&oldid=1180172001},
	abstract = {Si-eun, also spelled Shi-eun, is a Korean feminine given name. The meaning differs based on the hanja used to write each syllable of the name. There are 56 hanja with the reading  "shi" and 33 hanja with the reading "eun" on the South Korean government's official list of hanja which may be used in given names.},
	language = {en},
	urldate = {2024-02-21},
	journal = {Wikipedia},
	month = oct,
	year = {2023},
	note = {Page Version ID: 1180172001},
}

@inproceedings{ghorbani_towards_2019,
	title = {Towards {Automatic} {Concept}-based {Explanations}},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper/2019/hash/77d2afcb31f6493e350fca61764efb9a-Abstract.html},
	abstract = {Interpretability has become an important topic of research as more machine learning (ML) models are deployed and widely used to make important decisions. 
    Most of the current explanation methods provide explanations through feature importance scores, which identify features that are important for each individual input. However, how to systematically summarize and interpret such per sample feature importance scores itself is challenging. In this work, we propose principles and desiderata for {\textbackslash}emph\{concept\} based explanation, which goes beyond per-sample features to identify higher level human-understandable concepts that apply across the entire dataset. We develop a new algorithm, ACE, to automatically extract visual concepts. Our systematic experiments demonstrate that {\textbackslash}alg discovers concepts that are human-meaningful, coherent and important for the neural network's predictions.},
	urldate = {2024-02-21},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been},
	year = {2019},
}

@article{luecken_benchmarking_2022,
	title = {Benchmarking atlas-level data integration in single-cell genomics},
	volume = {19},
	copyright = {2021 The Author(s)},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-021-01336-8},
	doi = {10.1038/s41592-021-01336-8},
	abstract = {Single-cell atlases often include samples that span locations, laboratories and conditions, leading to complex, nested batch effects in data. Thus, joint analysis of atlas datasets requires reliable data integration. To guide integration method choice, we benchmarked 68 method and preprocessing combinations on 85 batches of gene expression, chromatin accessibility and simulation data from 23 publications, altogether representing {\textgreater}1.2 million cells distributed in 13 atlas-level integration tasks. We evaluated methods according to scalability, usability and their ability to remove batch effects while retaining biological variation using 14 evaluation metrics. We show that highly variable gene selection improves the performance of data integration methods, whereas scaling pushes methods to prioritize batch removal over conservation of biological variation. Overall, scANVI, Scanorama, scVI and scGen perform well, particularly on complex integration tasks, while single-cell ATAC-sequencing integration performance is strongly affected by choice of feature space. Our freely available Python module and benchmarking pipeline can identify optimal data integration methods for new data, benchmark new methods and improve method development.},
	language = {en},
	number = {1},
	urldate = {2024-02-20},
	journal = {Nature Methods},
	author = {Luecken, Malte D. and Büttner, M. and Chaichoompu, K. and Danese, A. and Interlandi, M. and Mueller, M. F. and Strobl, D. C. and Zappia, L. and Dugas, M. and Colomé-Tatché, M. and Theis, Fabian J.},
	month = jan,
	year = {2022},
	keywords = {Data integration, Machine learning, Software, Transcriptomics},
	pages = {41--50},
}

@article{cole_surprise_2021,
	title = {Surprise!},
	volume = {190},
	issn = {1476-6256},
	doi = {10.1093/aje/kwaa136},
	abstract = {Measures of information and surprise, such as the Shannon information value (S value), quantify the signal present in a stream of noisy data. We illustrate the use of such information measures in the context of interpreting P values as compatibility indices. S values help communicate the limited information supplied by conventional statistics and cast a critical light on cutoffs used to judge and construct those statistics. Misinterpretations of statistics may be reduced by interpreting P values and interval estimates using compatibility concepts and S values instead of "significance" and "confidence."},
	language = {eng},
	number = {2},
	journal = {American Journal of Epidemiology},
	author = {Cole, Stephen R. and Edwards, Jessie K. and Greenland, Sander},
	month = feb,
	year = {2021},
	pmid = {32648906},
	pmcid = {PMC7850156},
	keywords = {Confidence Intervals, Data Interpretation, Statistical, Epidemiologic Methods, Humans, P value, S value, Uncertainty, compatibility, confidence intervals, information, random error, significance tests, statistical inference},
	pages = {191--193},
}

@article{mansournia_p-value_2022,
	title = {P-value, compatibility, and {S}-value},
	volume = {4},
	issn = {2590-1133},
	doi = {10.1016/j.gloepi.2022.100085},
	abstract = {Misinterpretations of P-values and 95\% confidence intervals are ubiquitous in medical research. Specifically, the terms significance or confidence, extensively used in medical papers, ignore biases and violations of statistical assumptions and hence should be called overconfidence terms. In this paper, we present the compatibility view of P-values and confidence intervals; the P-value is interpreted as an index of compatibility between data and the model, including the test hypothesis and background assumptions, whereas a confidence interval is interpreted as the range of parameter values that are compatible with the data under background assumptions. We also suggest the use of a surprisal measure, often referred to as the S-value, a novel metric that transforms the P-value, for gauging compatibility in terms of an intuitive experiment of coin tossing.},
	language = {eng},
	journal = {Global Epidemiology},
	author = {Mansournia, Mohammad Ali and Nazemipour, Maryam and Etminan, Mahyar},
	month = dec,
	year = {2022},
	pmid = {37637018},
	pmcid = {PMC10446114},
	keywords = {Compatibility interval, Confidence interval, P-value, S-value, Significance},
	pages = {100085},
}

@article{ma_mitophagy_2020,
	title = {Mitophagy, {Mitochondrial} {Homeostasis}, and {Cell} {Fate}},
	volume = {8},
	issn = {2296-634X},
	url = {https://www.frontiersin.org/articles/10.3389/fcell.2020.00467},
	abstract = {Mitochondria are highly plastic and dynamic organelles that have graded responses to the changing cellular, environmental, and developmental cues. Mitochondria undergo constant mitochondrial fission and fusion, mitochondrial biogenesis, and mitophagy, which coordinately control mitochondrial morphology, quantity, quality, turnover, and inheritance. Mitophagy is a cellular process that selectively removes the aged and damaged mitochondria via the specific sequestration and engulfment of mitochondria for subsequent lysosomal degradation. It plays a pivotal role in reinstating cellular homeostasis in normal physiology and conditions of stress. Damaged mitochondria may either instigate innate immunity through the overproduction of ROS or the release of mtDNA, or trigger cell death through the release of cytochrome c and other apoptogenic factors when mitochondria damage is beyond repair. Distinct molecular machineries and signaling pathways are found to regulate these mitochondrial dynamics and behaviors. It is less clear how mitochondrial behaviors are coordinated at molecular levels. BCL2 family proteins interact within family members to regulate mitochondrial outer membrane permeabilization and apoptosis. They were also described as global regulators of mitochondrial homeostasis and mitochondrial fate through their interaction with distinct partners including Drp1, mitofusins, PGAM5, and even LC3 that involved mitochondrial dynamics and behaviors. In this review, we summarize recent findings on molecular pathways governing mitophagy and its coordination with other mitochondrial behaviors, which together determine cellular fate.},
	urldate = {2024-02-06},
	journal = {Frontiers in Cell and Developmental Biology},
	author = {Ma, Kaili and Chen, Guo and Li, Wenhui and Kepp, Oliver and Zhu, Yushan and Chen, Quan},
	year = {2020},
}

@misc{piefke_computational_2024,
	title = {Computational characterization of the role of an attention schema in controlling visuospatial attention},
	url = {http://arxiv.org/abs/2402.01056},
	doi = {10.48550/arXiv.2402.01056},
	abstract = {How does the brain control attention? The Attention Schema Theory suggests that the brain constructs an internal model of attention for its control. However, it remains unclear under which circumstances an attention schema is computationally useful, and whether it can emerge in a learning system without hard-wiring it. To address these questions, we trained a reinforcement learning agent with attention to track and catch a ball in a noisy environment. Crucially, the agent had additional neural resources that it could freely use. We asked under which conditions these additional resources develop an attention schema to track attention. We found that the more uncertain the agent was about the location of its attentional state, the more it benefited from these additional resources, which developed an attention schema. Together, these results indicate that an attention schema emerges in simple learning systems where attention is both important and difficult to track.},
	urldate = {2024-02-06},
	publisher = {arXiv},
	author = {Piefke, Lotta and Doerig, Adrien and Kietzmann, Tim and Thorat, Sushrut},
	month = feb,
	year = {2024},
	note = {arXiv:2402.01056 [q-bio]},
	keywords = {Quantitative Biology - Neurons and Cognition},
}

@misc{alemi_lyapunov_2024,
	title = {A {Lyapunov} theory demonstrating a fundamental limit on the speed of systems consolidation},
	url = {http://arxiv.org/abs/2402.01605},
	doi = {10.48550/arXiv.2402.01605},
	abstract = {The nervous system reorganizes memories from an early site to a late site, a commonly observed feature of learning and memory systems known as systems consolidation. Previous work has suggested learning rules by which consolidation may occur. Here, we provide conditions under which such rules are guaranteed to lead to stable convergence of learning and consolidation. We use the theory of Lyapunov functions, which enforces stability by requiring learning rules to decrease an energy-like (Lyapunov) function. We present the theory in the context of a simple circuit architecture motivated by classic models of learning in systems consolidation mediated by the cerebellum. Stability is only guaranteed if the learning rate in the late stage is not faster than the learning rate in the early stage. Further, the slower the learning rate at the late stage, the larger the perturbation the system can tolerate with a guarantee of stability. We provide intuition for this result by mapping the consolidation model to a damped driven oscillator system, and showing that the ratio of early- to late-stage learning rates in the consolidation model can be directly identified with the (square of the) oscillator's damping ratio. This work suggests the power of the Lyapunov approach to provide constraints on nervous system function.},
	urldate = {2024-02-06},
	publisher = {arXiv},
	author = {Alemi, Alireza and Aksay, Emre R. F. and Goldman, Mark S.},
	month = feb,
	year = {2024},
	note = {arXiv:2402.01605 [physics, q-bio]},
	keywords = {Electrical Engineering and Systems Science - Systems and Control, Physics - Biological Physics, Quantitative Biology - Neurons and Cognition},
}

@article{musielak_combination_2021,
	title = {The {Combination} of {Liposomes} and {Metallic} {Nanoparticles} as {Multifunctional} {Nanostructures} in the {Therapy} and {Medical} {Imaging}—{A} {Review}},
	volume = {22},
	issn = {1422-0067},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8229649/},
	doi = {10.3390/ijms22126229},
	abstract = {Nanotechnology has introduced a new quality and has definitely developed the possibilities of treating and diagnosing various diseases. One of the scientists’ interests is liposomes and metallic nanoparticles (LipoMNPs)—the combination of which has introduced new properties and applications. However, the field of creating hybrid nanostructures consisting of liposomes and metallic nanoparticles is relatively little understood. The purpose of this review was to compile the latest reports in the field of treatment and medical imaging using of LipoMNPs. The authors focused on presenting this issue in the direction of improving the used conventional treatment and imaging methods. Most of all, the nature of bio-interactions between nanostructures and cells is not sufficiently taken into account. As a result, overcoming the existing limitations in the implementation of such solutions in the clinic is difficult. We concluded that hybrid nanostructures are used in a very wide range, especially in the treatment of cancer and magnetic resonance imaging. There were also solutions that combine treatments with simultaneous imaging, creating a theragnostic approach. In the future, researchers should focus on the description of the biological interactions and the long-term effects of the nanostructures to use LipoMNPs in the treatment of patients.},
	number = {12},
	urldate = {2024-02-04},
	journal = {International Journal of Molecular Sciences},
	author = {Musielak, Marika and Potoczny, Jakub and Boś-Liedke, Agnieszka and Kozak, Maciej},
	month = jun,
	year = {2021},
	pmid = {34207682},
	pmcid = {PMC8229649},
	pages = {6229},
}

@article{harrison_evaluating_2023,
	title = {Evaluating the utility of brightfield image data for mechanism of action prediction},
	volume = {19},
	issn = {1553-7358},
	doi = {10.1371/journal.pcbi.1011323},
	abstract = {Fluorescence staining techniques, such as Cell Painting, together with fluorescence microscopy have proven invaluable for visualizing and quantifying the effects that drugs and other perturbations have on cultured cells. However, fluorescence microscopy is expensive, time-consuming, labor-intensive, and the stains applied can be cytotoxic, interfering with the activity under study. The simplest form of microscopy, brightfield microscopy, lacks these downsides, but the images produced have low contrast and the cellular compartments are difficult to discern. Nevertheless, by harnessing deep learning, these brightfield images may still be sufficient for various predictive purposes. In this study, we compared the predictive performance of models trained on fluorescence images to those trained on brightfield images for predicting the mechanism of action (MoA) of different drugs. We also extracted CellProfiler features from the fluorescence images and used them to benchmark the performance. Overall, we found comparable and largely correlated predictive performance for the two imaging modalities. This is promising for future studies of MoAs in time-lapse experiments for which using fluorescence images is problematic. Explorations based on explainable AI techniques also provided valuable insights regarding compounds that were better predicted by one modality over the other.},
	language = {eng},
	number = {7},
	journal = {PLoS computational biology},
	author = {Harrison, Philip John and Gupta, Ankit and Rietdijk, Jonne and Wieslander, Håkan and Carreras-Puigvert, Jordi and Georgiev, Polina and Wählby, Carolina and Spjuth, Ola and Sintorn, Ida-Maria},
	month = jul,
	year = {2023},
	pmid = {37490493},
	pmcid = {PMC10403126},
	keywords = {Cells, Cultured, Image Processing, Computer-Assisted, Microscopy, Fluorescence},
	pages = {e1011323},
}

@article{behanova_visualization_2023,
	title = {Visualization and quality control tools for large-scale multiplex tissue analysis in {TissUUmaps3}},
	volume = {3},
	issn = {2633-903X},
	url = {https://www.cambridge.org/core/journals/biological-imaging/article/visualization-and-quality-control-tools-for-largescale-multiplex-tissue-analysis-in-tissuumaps3/FCACFA343351C72F94F1DBF5B25591FC#},
	doi = {10.1017/S2633903X23000053},
	abstract = {Large-scale multiplex tissue analysis aims to understand processes such as development and tumor formation by studying the occurrence and interaction of cells in local environments in, for example, tissue samples from patient cohorts. A typical procedure in the analysis is to delineate individual cells, classify them into cell types, and analyze their spatial relationships. All steps come with a number of challenges, and to address them and identify the bottlenecks of the analysis, it is necessary to include quality control tools in the analysis workflow. This makes it possible to optimize the steps and adjust settings in order to get better and more precise results. Additionally, the development of automated approaches for tissue analysis requires visual verification to reduce skepticism with regard to the accuracy of the results. Quality control tools could be used to build users’ trust in automated approaches. In this paper, we present three plugins for visualization and quality control in large-scale multiplex tissue analysis of microscopy images. The first plugin focuses on the quality of cell staining, the second one was made for interactive evaluation and comparison of different cell classification results, and the third one serves for reviewing interactions of different cell types.},
	language = {en},
	urldate = {2024-02-04},
	journal = {Biological Imaging},
	author = {Behanova, Andrea and Avenel, Christophe and Andersson, Axel and Chelebian, Eduard and Klemm, Anna and Wik, Lina and Östman, Arne and Wählby, Carolina},
	month = jan,
	year = {2023},
	keywords = {Cell classification, quality control, spatial omics, visualization},
	pages = {e6},
}

@misc{noauthor_generative_nodate,
	title = {A generative model to simulate spatiotemporal dynamics of biomolecules in cells {\textbar} {Biological} {Imaging} {\textbar} {Cambridge} {Core}},
	url = {https://www.cambridge.org/core/journals/biological-imaging/article/generative-model-to-simulate-spatiotemporal-dynamics-of-biomolecules-in-cells/5B5906774B53D75BC08A6BD16B6DEDCD},
	urldate = {2024-02-04},
}

@misc{noauthor_cf-loss_nodate,
	title = {{CF}-{Loss}: {Clinically}-relevant feature optimised loss function for retinal multi-class vessel segmentation and vascular feature measurement - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841524000239},
	urldate = {2024-02-03},
}

@article{heyn_mitochondrial-derived_2023,
	title = {Mitochondrial-{Derived} {Vesicles}—{Link} to {Extracellular} {Vesicles} and {Implications} in {Cardiovascular} {Disease}},
	volume = {24},
	issn = {1422-0067},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9917113/},
	doi = {10.3390/ijms24032637},
	abstract = {Mitochondria are dynamic organelles regulating metabolism, cell death, and energy production. Therefore, maintaining mitochondrial health is critical for cellular homeostasis. Mitophagy and mitochondrial reorganization via fission and fusion are established mechanisms for ensuring mitochondrial quality. In recent years, mitochondrial-derived vesicles (MDVs) have emerged as a novel cellular response. MDVs are shed from the mitochondrial surface and can be directed to lysosomes or peroxisomes for intracellular degradation. MDVs may contribute to cardiovascular disease (CVD) which is characterized by mitochondrial dysfunction. In addition, evidence suggests that mitochondrial content is present in extracellular vesicles (EVs). Herein, we provide an overview of the current knowledge on MDV formation and trafficking. Moreover, we review recent findings linking MDV and EV biogenesis and discuss their role in CVD. Finally, we discuss the role of vesicle-mediated mitochondrial transfer and its potential cardioprotective effects.},
	number = {3},
	urldate = {2024-02-02},
	journal = {International Journal of Molecular Sciences},
	author = {Heyn, Jonas and Heuschkel, Marina Augusto and Goettsch, Claudia},
	month = jan,
	year = {2023},
	pmid = {36768960},
	pmcid = {PMC9917113},
	pages = {2637},
}

@article{hell_ground-state-depletion_1995,
	title = {Ground-state-depletion fluorscence microscopy: {A} concept for breaking the diffraction resolution limit},
	volume = {60},
	issn = {1432-0649},
	shorttitle = {Ground-state-depletion fluorscence microscopy},
	url = {https://doi.org/10.1007/BF01081333},
	doi = {10.1007/BF01081333},
	abstract = {We introduce and study a novel concept in farfield fluorescence microscopy fundamentally overcoming the classical diffraction resolution limit. This is accomlished by reducing the spatial extent of the effective focus of a scanning fluorescence microscope. The reduction is achieved by depleting the ground-state energy of the molecules located in the outer region of the focus. Our theoretical study shows that ground-state-depletion fluorescence microscopy has the potential of increasing the resolution of far-field fluorescence microscopy by an order of magnitude which is equivalent to a lateral resolution of 15 NM.},
	language = {en},
	number = {5},
	urldate = {2024-02-01},
	journal = {Applied Physics B},
	author = {Hell, S. W. and Kroug, M.},
	month = may,
	year = {1995},
	keywords = {07.60, 87.64},
	pages = {495--497},
}

@article{rasheed_characterization_1974,
	title = {Characterization of a newly derived human sarcoma cell line ({HT}-1080)},
	volume = {33},
	issn = {0008-543X, 1097-0142},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/1097-0142(197404)33:4<1027::AID-CNCR2820330419>3.0.CO;2-Z},
	doi = {10.1002/1097-0142(197404)33:4<1027::AID-CNCR2820330419>3.0.CO;2-Z},
	language = {en},
	number = {4},
	urldate = {2024-02-01},
	journal = {Cancer},
	author = {Rasheed, Suraiya and Nelson-Rees, Walter A. and Toth, Eva M. and Arnstein, Paul and Gardner, Murray B.},
	month = apr,
	year = {1974},
	pages = {1027--1033},
}

@inproceedings{yoo_slurm_2003,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{SLURM}: {Simple} {Linux} {Utility} for {Resource} {Management}},
	isbn = {9783540397274},
	shorttitle = {{SLURM}},
	doi = {10.1007/10968987_3},
	abstract = {A new cluster resource management system called Simple Linux Utility Resource Management (SLURM) is described in this paper. SLURM, initially developed for large Linux clusters at the Lawrence Livermore National Laboratory (LLNL), is a simple cluster manager that can scale to thousands of processors. SLURM is designed to be flexible and fault-tolerant and can be ported to other clusters of different size and architecture with minimal effort. We are certain that SLURM will benefit both users and system architects by providing them with a simple, robust, and highly scalable parallel job execution environment for their cluster system.},
	language = {en},
	booktitle = {Job {Scheduling} {Strategies} for {Parallel} {Processing}},
	publisher = {Springer},
	author = {Yoo, Andy B. and Jette, Morris A. and Grondona, Mark},
	editor = {Feitelson, Dror and Rudolph, Larry and Schwiegelshohn, Uwe},
	year = {2003},
	keywords = {Exit Status, Lawrence Livermore National Laboratory, Message Authentication Code, Remote Execution, Resource Management System},
	pages = {44--60},
}

@article{xu_crispr-cas_2020,
	title = {{CRISPR}-{Cas} systems: {Overview}, innovations and applications in human disease research and gene therapy},
	volume = {18},
	issn = {2001-0370},
	shorttitle = {{CRISPR}-{Cas} systems},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7508700/},
	doi = {10.1016/j.csbj.2020.08.031},
	abstract = {Genome editing is the modification of genomic DNA at a specific target site in a wide variety of cell types and organisms, including insertion, deletion and replacement of DNA, resulting in inactivation of target genes, acquisition of novel genetic traits and correction of pathogenic gene mutations. Due to the advantages of simple design, low cost, high efficiency, good repeatability and short-cycle, CRISPR-Cas systems have become the most widely used genome editing technology in molecular biology laboratories all around the world. In this review, an overview of the CRISPR-Cas systems will be introduced, including the innovations, the applications in human disease research and gene therapy, as well as the challenges and opportunities that will be faced in the practical application of CRISPR-Cas systems.},
	urldate = {2024-01-31},
	journal = {Computational and Structural Biotechnology Journal},
	author = {Xu, Yuanyuan and Li, Zhanjun},
	month = sep,
	year = {2020},
	pmid = {33005303},
	pmcid = {PMC7508700},
	pages = {2401--2415},
}

@article{scheltens_alzheimers_2021,
	title = {Alzheimer's disease},
	volume = {397},
	issn = {1474-547X},
	doi = {10.1016/S0140-6736(20)32205-4},
	abstract = {In this Seminar, we highlight the main developments in the field of Alzheimer's disease. The most recent data indicate that, by 2050, the prevalence of dementia will double in Europe and triple worldwide, and that estimate is 3 times higher when based on a biological (rather than clinical) definition of Alzheimer's disease. The earliest phase of Alzheimer's disease (cellular phase) happens in parallel with accumulating amyloid β, inducing the spread of tau pathology. The risk of Alzheimer's disease is 60-80\% dependent on heritable factors, with more than 40 Alzheimer's disease-associated genetic risk loci already identified, of which the APOE alleles have the strongest association with the disease. Novel biomarkers include PET scans and plasma assays for amyloid β and phosphorylated tau, which show great promise for clinical and research use. Multidomain lifestyle-based prevention trials suggest cognitive benefits in participants with increased risk of dementia. Lifestyle factors do not directly affect Alzheimer's disease pathology, but can still contribute to a positive outcome in individuals with Alzheimer's disease. Promising pharmacological treatments are poised at advanced stages of clinical trials and include anti-amyloid β, anti-tau, and anti-inflammatory strategies.},
	language = {eng},
	number = {10284},
	journal = {Lancet (London, England)},
	author = {Scheltens, Philip and De Strooper, Bart and Kivipelto, Miia and Holstege, Henne and Chételat, Gael and Teunissen, Charlotte E. and Cummings, Jeffrey and van der Flier, Wiesje M.},
	month = apr,
	year = {2021},
	pmid = {33667416},
	pmcid = {PMC8354300},
	keywords = {Alzheimer Disease, Humans},
	pages = {1577--1590},
}

@article{kuntz_stationary_2021,
	title = {Stationary {Distributions} of {Continuous}-{Time} {Markov} {Chains}: {A} {Review} of {Theory} and {Truncation}-{Based} {Approximations}},
	copyright = {© 2021, Society for Industrial and Applied Mathematics},
	shorttitle = {Stationary {Distributions} of {Continuous}-{Time} {Markov} {Chains}},
	url = {https://epubs.siam.org/doi/10.1137/19M1289625},
	doi = {10.1137/19M1289625},
	abstract = {Computing the stationary distributions of a continuous-time Markov chain (CTMC) involves solving a set of linear equations. In most cases of interest, the number of equations is infinite or too large, and the equations cannot be solved analytically or numerically. Several approximation schemes overcome this issue by truncating the state space to a manageable size. In this review, we first give a comprehensive theoretical account of the stationary distributions and their relation to the long-term behaviour of CTMCs that is readily accessible to non-experts and free of irreducibility assumptions made in standard texts. We then review truncation-based approximation schemes for CTMCs with infinite state spaces paying particular attention to the schemes' convergence and the errors they introduce, and we illustrate their performance with an example of a stochastic reaction network of relevance in biology and chemistry. We conclude by elaborating on computational trade-offs associated with error control and several open questions.},
	language = {en},
	urldate = {2024-01-30},
	journal = {SIAM Review},
	author = {Kuntz, Juan and Thomas, Philipp and Stan, Guy-Bart and Barahona, Mauricio},
	month = feb,
	year = {2021},
}

@article{chiapino_multivariate_2020,
	title = {A multivariate extreme value theory approach to anomaly clustering and visualization},
	volume = {35},
	issn = {1613-9658},
	url = {https://doi.org/10.1007/s00180-019-00913-y},
	doi = {10.1007/s00180-019-00913-y},
	abstract = {In a wide variety of situations, anomalies in the behaviour of a complex system, whose health is monitored through the observation of a random vector \$\${\textbackslash}mathbf\{X \}=(X\_1,{\textbackslash}; {\textbackslash}ldots ,{\textbackslash}; X\_d)\$\$ valued in \$\${\textbackslash}mathbb \{R\}{\textasciicircum}d\$\$, correspond to the simultaneous occurrence of extreme values for certain subgroups \$\${\textbackslash}alpha {\textbackslash}subset {\textbackslash}\{1,{\textbackslash}; {\textbackslash}ldots ,{\textbackslash}; d {\textbackslash}\}\$\$ of variables \$\$X\_j\$\$. Under the heavy-tail assumption, which is precisely appropriate for modeling these phenomena, statistical methods relying on multivariate extreme value theory have been developed in the past few years for identifying such events/subgroups. This paper exploits this approach much further by means of a novel mixture model that permits to describe the distribution of extremal observations and where the anomaly type \$\${\textbackslash}alpha \$\$ is viewed as a latent variable. One may then take advantage of the model by assigning to any extreme point a posterior probability for each anomaly type \$\${\textbackslash}alpha \$\$, defining implicitly a similarity measure between anomalies. It is explained at length how the latter permits to cluster extreme observations and obtain an informative planar representation of anomalies using standard graph-mining tools. The relevance and usefulness of the clustering and 2-d visual display thus designed is illustrated on simulated datasets and on real observations as well, in the aeronautics application domain.},
	language = {en},
	number = {2},
	urldate = {2024-01-25},
	journal = {Computational Statistics},
	author = {Chiapino, Maël and Clémençon, Stephan and Feuillard, Vincent and Sabourin, Anne},
	month = jun,
	year = {2020},
	keywords = {Anomaly detection, Clustering, Graph-mining, Latent variable analysis, Mixture modelling, Multivariate extreme value theory, Visualization},
	pages = {607--628},
}

@article{diebold_pitfalls_2000,
	title = {Pitfalls and {Opportunities} in the {Use} of {Extreme} {Value} {Theory} in {Risk} {Management}},
	volume = {1},
	issn = {1526-5943},
	url = {https://doi.org/10.1108/eb043443},
	doi = {10.1108/eb043443},
	abstract = {Extreme value theory (EVT) holds promise for advancing the assessment and management of extreme financial risks. Recent literature suggests that the application of EVT generally results in more precise estimates of extreme quantiles and tail probabilities of financial asset returns. This article assesses EVT from the perspective of financial risk management. The authors believe that the recent optimism regarding EVT may be appropriate but exaggerated, and that much of its potential remains latent. They support their claim by describing various pitfalls associated with the current use of EVT techniques, and illustrate how these can be avoided. In conclusion, the article defines several specific research directions that may further the practical and effective application of EVT to risk management.},
	number = {2},
	urldate = {2024-01-25},
	journal = {The Journal of Risk Finance},
	author = {Diebold, Francis X. and Schuermann, Til and Stroughair, John D.},
	month = jan,
	year = {2000},
	pages = {30--35},
}

@article{gomes_extreme_2015,
	title = {Extreme {Value} {Theory} and {Statistics} of {Univariate} {Extremes}: {A} {Review}},
	volume = {83},
	issn = {0306-7734, 1751-5823},
	shorttitle = {Extreme {Value} {Theory} and {Statistics} of {Univariate} {Extremes}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/insr.12058},
	doi = {10.1111/insr.12058},
	abstract = {Summary 
            Statistical issues arising in modelling univariate extremes of a random sample have been successfully used in the most diverse fields, such as biometrics, finance, insurance and risk theory. Statistics of univariate extremes (SUE), the subject to be dealt with in this review paper, has recently faced a huge development, partially because rare events can have catastrophic consequences for human activities, through their impact on the natural and constructed environments. In the last decades, there has been a shift from the area of parametric SUE, based on probabilistic asymptotic results in extreme value theory, towards semi‐parametric approaches. After a brief reference to Gumbel's block methodology and more recent improvements in the parametric framework, we present an overview of the developments on the estimation of parameters of extreme events and on the testing of extreme value conditions under a semi‐parametric framework. We further discuss a few challenging topics in the area of SUE. © 2014 The Authors. International Statistical Review © 2014 International Statistical Institute},
	language = {en},
	number = {2},
	urldate = {2024-01-25},
	journal = {International Statistical Review},
	author = {Gomes, M. Ivette and Guillou, Armelle},
	month = aug,
	year = {2015},
	pages = {263--292},
}

@article{gwosch_minflux_2020,
	title = {{MINFLUX} nanoscopy delivers {3D} multicolor nanometer resolution in cells},
	volume = {17},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-019-0688-0},
	doi = {10.1038/s41592-019-0688-0},
	abstract = {The ultimate goal of biological super-resolution fluorescence microscopy is to provide three-dimensional resolution at the size scale of a fluorescent marker. Here we show that by localizing individual switchable fluorophores with a probing donut-shaped excitation beam, MINFLUX nanoscopy can provide resolutions in the range of 1 to 3 nm for structures in fixed and living cells. This progress has been facilitated by approaching each fluorophore iteratively with the probing-donut minimum, making the resolution essentially uniform and isotropic over scalable fields of view. MINFLUX imaging of nuclear pore complexes of a mammalian cell shows that this true nanometer-scale resolution is obtained in three dimensions and in two color channels. Relying on fewer detected photons than standard camera-based localization, MINFLUX nanoscopy is poised to open a new chapter in the imaging of protein complexes and distributions in fixed and living cells.},
	language = {en},
	number = {2},
	urldate = {2024-01-24},
	journal = {Nature Methods},
	author = {Gwosch, Klaus C. and Pape, Jasmin K. and Balzarotti, Francisco and Hoess, Philipp and Ellenberg, Jan and Ries, Jonas and Hell, Stefan W.},
	month = feb,
	year = {2020},
	keywords = {Microscopy, Super-resolution microscopy},
	pages = {217--224},
}

@article{ramsey_six_2010,
	title = {Six problems for causal inference from {fMRI}},
	volume = {49},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S105381190900977X},
	doi = {10.1016/j.neuroimage.2009.08.065},
	abstract = {Neuroimaging (e.g. fMRI) data are increasingly used to attempt to identify not only brain regions of interest (ROIs) that are especially active during…},
	language = {en},
	number = {2},
	urldate = {2022-05-18},
	journal = {NeuroImage},
	author = {Ramsey, J.D.},
	month = jan,
	year = {2010},
	pages = {1545--1558},
}

@misc{bommasani_opportunities_2022,
	title = {On the {Opportunities} and {Risks} of {Foundation} {Models}},
	url = {http://arxiv.org/abs/2108.07258},
	doi = {10.48550/arXiv.2108.07258},
	abstract = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
	urldate = {2024-01-24},
	publisher = {arXiv},
	author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
	month = jul,
	year = {2022},
	note = {arXiv:2108.07258 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
}

@article{krawczyk_learning_2016,
	title = {Learning from imbalanced data: open challenges and future directions},
	volume = {5},
	issn = {2192-6360},
	shorttitle = {Learning from imbalanced data},
	url = {https://doi.org/10.1007/s13748-016-0094-0},
	doi = {10.1007/s13748-016-0094-0},
	abstract = {Despite more than two decades of continuous development learning from imbalanced data is still a focus of intense research. Starting as a problem of skewed distributions of binary tasks, this topic evolved way beyond this conception. With the expansion of machine learning and data mining, combined with the arrival of big data era, we have gained a deeper insight into the nature of imbalanced learning, while at the same time facing new emerging challenges. Data-level and algorithm-level methods are constantly being improved and hybrid approaches gain increasing popularity. Recent trends focus on analyzing not only the disproportion between classes, but also other difficulties embedded in the nature of data. New real-life problems motivate researchers to focus on computationally efficient, adaptive and real-time methods. This paper aims at discussing open issues and challenges that need to be addressed to further develop the field of imbalanced learning. Seven vital areas of research in this topic are identified, covering the full spectrum of learning from imbalanced data: classification, regression, clustering, data streams, big data analytics and applications, e.g., in social media and computer vision. This paper provides a discussion and suggestions concerning lines of future research for each of them.},
	language = {en},
	number = {4},
	urldate = {2024-01-24},
	journal = {Progress in Artificial Intelligence},
	author = {Krawczyk, Bartosz},
	month = nov,
	year = {2016},
	keywords = {Big data, Data streams, Imbalanced clustering, Imbalanced data, Imbalanced regression, Machine learning, Multi-class imbalance},
	pages = {221--232},
}

@misc{rissanen_critical_2022,
	title = {A {Critical} {Look} at the {Consistency} of {Causal} {Estimation} {With} {Deep} {Latent} {Variable} {Models}},
	url = {http://arxiv.org/abs/2102.06648},
	doi = {10.48550/arXiv.2102.06648},
	abstract = {Using deep latent variable models in causal inference has attracted considerable interest recently, but an essential open question is their ability to yield consistent causal estimates. While they have demonstrated promising results and theory exists on some simple model formulations, we also know that causal effects are not even identifiable in general with latent variables. We investigate this gap between theory and empirical results with analytical considerations and extensive experiments under multiple synthetic and real-world data sets, using the causal effect variational autoencoder (CEVAE) as a case study. While CEVAE seems to work reliably under some simple scenarios, it does not estimate the causal effect correctly with a misspecified latent variable or a complex data distribution, as opposed to its original motivation. Hence, our results show that more attention should be paid to ensuring the correctness of causal estimates with deep latent variable models.},
	urldate = {2024-01-24},
	publisher = {arXiv},
	author = {Rissanen, Severi and Marttinen, Pekka},
	month = jan,
	year = {2022},
	note = {arXiv:2102.06648 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{steel_retinotopic_2024,
	title = {A retinotopic code structures the interaction between perception and memory systems},
	copyright = {2024 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-023-01512-3},
	doi = {10.1038/s41593-023-01512-3},
	abstract = {Conventional views of brain organization suggest that regions at the top of the cortical hierarchy processes internally oriented information using an abstract amodal neural code. Despite this, recent reports have described the presence of retinotopic coding at the cortical apex, including the default mode network. What is the functional role of retinotopic coding atop the cortical hierarchy? Here we report that retinotopic coding structures interactions between internally oriented (mnemonic) and externally oriented (perceptual) brain areas. Using functional magnetic resonance imaging, we observed robust inverted (negative) retinotopic coding in category-selective memory areas at the cortical apex, which is functionally linked to the classic (positive) retinotopic coding in category-selective perceptual areas in high-level visual cortex. These functionally linked retinotopic populations in mnemonic and perceptual areas exhibit spatially specific opponent responses during both bottom-up perception and top-down recall, suggesting that these areas are interlocked in a mutually inhibitory dynamic. These results show that retinotopic coding structures interactions between perceptual and mnemonic neural systems, providing a scaffold for their dynamic interaction.},
	language = {en},
	urldate = {2024-01-02},
	journal = {Nature Neuroscience},
	author = {Steel, Adam and Silson, Edward H. and Garcia, Brenda D. and Robertson, Caroline E.},
	month = jan,
	year = {2024},
	keywords = {Cognitive neuroscience, Learning and memory, Neuroscience, Visual system},
	pages = {1--9},
}

@misc{rahaman_spectral_2019,
	title = {On the {Spectral} {Bias} of {Neural} {Networks}},
	url = {http://arxiv.org/abs/1806.08734},
	doi = {10.48550/arXiv.1806.08734},
	abstract = {Neural networks are known to be a class of highly expressive functions able to fit even random input-output mappings with \$100{\textbackslash}\%\$ accuracy. In this work, we present properties of neural networks that complement this aspect of expressivity. By using tools from Fourier analysis, we show that deep ReLU networks are biased towards low frequency functions, meaning that they cannot have local fluctuations without affecting their global behavior. Intuitively, this property is in line with the observation that over-parameterized networks find simple patterns that generalize across data samples. We also investigate how the shape of the data manifold affects expressivity by showing evidence that learning high frequencies gets {\textbackslash}emph\{easier\} with increasing manifold complexity, and present a theoretical understanding of this behavior. Finally, we study the robustness of the frequency components with respect to parameter perturbation, to develop the intuition that the parameters must be finely tuned to express high frequency functions.},
	urldate = {2023-12-12},
	publisher = {arXiv},
	author = {Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred A. and Bengio, Yoshua and Courville, Aaron},
	month = may,
	year = {2019},
	note = {arXiv:1806.08734 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{cecon_melatonin_2022,
	title = {Melatonin drugs inhibit {SARS}-{CoV}-2 entry into the brain and virus-induced damage of cerebral small vessels},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.12.30.474561v1},
	doi = {10.1101/2021.12.30.474561},
	abstract = {COVID-19 is a complex disease with short- and long-term respiratory, inflammatory and neurological symptoms that are triggered by the infection with SARS-CoV-2. Invasion of the brain by SARS-CoV-2 has been observed in humans and is postulated to be involved in post COVID condition. Brain infection is particularly pronounced in the K18-hACE2 mouse model of COVID-19. Here, we show that treatment of K18-hACE2 mice with melatonin and two melatonin-derived marketed drugs, agomelatine and ramelteon, prevent SARS-CoV-2 entry in the brain thereby reducing virus-induced damage of small cerebral vessels, immune cell infiltration and brain inflammation. Brain entry of SARS-CoV-2 through endothelial cells is prevented by melatonin through allosteric binding to human angiotensin-converting enzyme 2 (ACE2), which interferes with the cell entry receptor function of ACE2 for SARS-CoV-2. Our findings open new perspectives for the repurposing of melatonergic drugs in the prevention of brain infection by SARS-CoV-2 and COVID-19-related long-term neurological symptoms.},
	language = {en},
	urldate = {2023-12-12},
	publisher = {bioRxiv},
	author = {Cecon, Erika and Fernandois, Daniela and Renault, Nicolas and Coelho, Caio Fernando Ferreira and Wenzel, Jan and Bedart, Corentin and Izabelle, Charlotte and Wimez, Sarah Gallet and Poder, Sophie Le and Klonjkowski, Bernard and Schwaninger, Markus and Prevot, Vincent and Dam, Julie and Jockers, Ralf},
	month = jan,
	year = {2022},
}

@article{collinson_volume_2023,
	title = {Volume {EM}: a quiet revolution takes shape},
	volume = {20},
	copyright = {2023 Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {Volume {EM}},
	url = {https://www.nature.com/articles/s41592-023-01861-8},
	doi = {10.1038/s41592-023-01861-8},
	abstract = {Volume electron microscopy (vEM) is a group of techniques that reveal the 3D ultrastructure of cells and tissues through continuous depths of at least 1 micrometer. A burgeoning grassroots community effort is fast building the profile and revealing the impact of vEM technology in the life sciences and clinical research.},
	language = {en},
	number = {6},
	urldate = {2023-12-06},
	journal = {Nature Methods},
	author = {Collinson, Lucy M. and Bosch, Carles and Bullen, Anwen and Burden, Jemima J. and Carzaniga, Raffaella and Cheng, Cheng and Darrow, Michele C. and Fletcher, Georgina and Johnson, Errin and Narayan, Kedar and Peddie, Christopher J. and Winn, Martyn and Wood, Charles and Patwardhan, Ardan and Kleywegt, Gerard J. and Verkade, Paul},
	month = jun,
	year = {2023},
	keywords = {Imaging, Scanning electron microscopy, Scientific community, Software, Transmission electron microscopy},
	pages = {777--782},
}

@misc{schneider_universal_2023,
	title = {Universal {Backdoor} {Attacks}},
	url = {http://arxiv.org/abs/2312.00157},
	doi = {10.48550/arXiv.2312.00157},
	abstract = {Web-scraped datasets are vulnerable to data poisoning, which can be used for backdooring deep image classifiers during training. Since training on large datasets is expensive, a model is trained once and re-used many times. Unlike adversarial examples, backdoor attacks often target specific classes rather than any class learned by the model. One might expect that targeting many classes through a naive composition of attacks vastly increases the number of poison samples. We show this is not necessarily true and more efficient, universal data poisoning attacks exist that allow controlling misclassifications from any source class into any target class with a small increase in poison samples. Our idea is to generate triggers with salient characteristics that the model can learn. The triggers we craft exploit a phenomenon we call inter-class poison transferability, where learning a trigger from one class makes the model more vulnerable to learning triggers for other classes. We demonstrate the effectiveness and robustness of our universal backdoor attacks by controlling models with up to 6,000 classes while poisoning only 0.15\% of the training dataset.},
	urldate = {2023-12-06},
	publisher = {arXiv},
	author = {Schneider, Benjamin and Lukas, Nils and Kerschbaum, Florian},
	month = nov,
	year = {2023},
	note = {arXiv:2312.00157 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@misc{li_fluorogenic_2023,
	title = {A fluorogenic complementation tool kit for interrogating lipid droplet-organelle interaction},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2023.11.29.569289v1},
	doi = {10.1101/2023.11.29.569289},
	abstract = {Contact sites between lipid droplets and other organelles are essential for cellular lipid and energy homeostasis. Detection of these contact sites at nanometer scale over time in living cells is challenging. Here, we developed a tool kit for detecting contact sites based on Fluorogen- Activated Bimolecular complementation at CONtact sites, FABCON, using a reversible, low affinity split fluorescent protein, splitFAST. FABCON labels contact sites with minimal perturbation to organelle interaction. Via FABCON, we quantitatively demonstrated that endoplasmic reticulum (ER)- and mitochondria (mito)-lipid droplet contact sites are dynamic foci in distinct metabolic conditions, such as during lipid droplet biogenesis and consumption. An automated analysis pipeline further classified individual contact sites into distinct subgroups based on size, likely reflecting differential regulation and function. Moreover, FABCON is generalizable to visualize a repertoire of organelle contact sites including ER-mito. Altogether, FABCON reveals insights into the dynamic regulation of lipid droplet-organelle contact sites and generates new hypotheses for further mechanistical interrogation during metabolic switch.},
	language = {en},
	urldate = {2023-12-06},
	publisher = {bioRxiv},
	author = {Li, Xiao and Gamuyao, Rico and Wu, Ming-Lun and Cho, Woo Jung and Kurtz, Nathan B. and King, Sharon V. and Petersen, R. A. and Stabley, Daniel R. and Lindow, Caleb and Climer, Leslie and Shirinifard, Abbas and Ferrara, Francesca and Throm, Robert E. and Robinson, Camenzind G. and Carisey, Alex and Tebo, Alison G. and Chang, Chi-Lun},
	month = nov,
	year = {2023},
}

@article{stoffel_iron_2020,
	title = {Iron absorption from supplements is greater with alternate day than with consecutive day dosing in iron-deficient anemic women},
	volume = {105},
	issn = {1592-8721},
	doi = {10.3324/haematol.2019.220830},
	abstract = {In iron-depleted women without anemia, oral iron supplements induce an increase in serum hepcidin (SHep) that persists for 24 hours, decreasing iron absorption from supplements given later on the same or next day. Consequently, iron absorption from supplements is highest if iron is given on alternate days. Whether this dosing schedule is also beneficial in women with iron-deficiency anemia (IDA) given high-dose iron supplements is uncertain. The primary objective of this study was to assess whether, in women with IDA, alternate-day administration of 100 and 200 mg iron increases iron absorption compared to consecutive-day iron administration. Secondary objectives were to correlate iron absorption with SHep and iron status parameters. We performed a cross-over iron absorption study in women with IDA (n=19; median hemoglobin 11.5 mg/dL; mean serum ferritin 10 mg/L) who received either 100 or 200 mg iron as ferrous sulfate given at 8 AM on days 2, 3 and 5 labeled with stable iron isotopes 57Fe, 58Fe and 54Fe; after a 16-day incorporation period, the other labeled dose was given at 8 AM on days 23, 24 and 26 (days 2, 3 and 5 of the second period). Iron absorption on days 2 and 3 (consecutive) and day 5 (alternate) was assessed by measuring erythrocyte isotope incorporation. For both doses, SHep was higher on day 3 than on day 2 (P{\textless}0.001) or day 5 (P{\textless}0.01) with no significant difference between days 2 and 5. Similarly, for both doses, fractional iron absorption (FIA) on days 2 and 5 was 40-50\% higher than on day 3 (P{\textless}0.001), while absorption on day 2 did not differ significantly from day 5. There was no significant difference in the incidence of gastrointestinal side effects comparing the two iron doses (P=0.105). Alternate day dosing of oral iron supplements in anemic women may be preferable because it sharply increases FIA. If needed, to provide the same total amount of iron with alternate day dosing, twice the daily target dose should be given on alternate days, as total iron absorption from a single dose of 200 mg given on alternate days was approximately twice that from 100 mg given on consecutive days (P{\textless}0.001). In IDA, even if hepatic hepcidin expression is strongly suppressed by iron deficiency and erythropoietic drive, the intake of oral iron supplements leads to an acute hepcidin increase for 24 hours. The study was funded by ETH Zürich, Switzerland. This study has been registered at www.clinicaltrials.gov as \#NCT03623997.},
	language = {eng},
	number = {5},
	journal = {Haematologica},
	author = {Stoffel, Nicole U. and Zeder, Christophe and Brittenham, Gary M. and Moretti, Diego and Zimmermann, Michael B.},
	month = may,
	year = {2020},
	pmid = {31413088},
	pmcid = {PMC7193469},
	keywords = {Anemia, Iron-Deficiency, Cross-Over Studies, Dietary Supplements, Female, Hepcidins, Humans, Iron, Switzerland},
	pages = {1232--1239},
}

@article{richards_enzymic_1958,
	title = {{ON} {THE} {ENZYMIC} {ACTIVITY} {OF} {SUBTILISIN}-{MODIFIED} {RIBONUCLEASE}},
	volume = {44},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.44.2.162},
	doi = {10.1073/pnas.44.2.162},
	language = {en},
	number = {2},
	urldate = {2023-11-30},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Richards, Frederic M.},
	month = feb,
	year = {1958},
	pages = {162--166},
}

@article{lucas_phasik_2023,
	title = {Phasik: a {Python} package to identify system states in partially temporal networks},
	volume = {8},
	issn = {2475-9066},
	shorttitle = {Phasik},
	url = {https://joss.theoj.org/papers/10.21105/joss.05872},
	doi = {10.21105/joss.05872},
	abstract = {Lucas et al., (2023). Phasik: a Python package to identify system states in partially temporal networks. Journal of Open Source Software, 8(91), 5872, https://doi.org/10.21105/joss.05872},
	language = {en},
	number = {91},
	urldate = {2023-11-26},
	journal = {Journal of Open Source Software},
	author = {Lucas, Maxime and Townsend-Teague, Alex and Neri, Matteo and Poetto, Simone and Morris, Arthur and Habermann, Bianca and Tichit, Laurent},
	month = nov,
	year = {2023},
	pages = {5872},
}

@misc{israel_foundation_2023,
	title = {A {Foundation} {Model} for {Cell} {Segmentation}},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2023.11.17.567630v2},
	doi = {10.1101/2023.11.17.567630},
	abstract = {Cells are the fundamental unit of biological organization, and identifying them in imaging data - cell segmentation - is a critical task for various cellular imaging experiments. While deep learning methods have led to substantial progress on this problem, models that have seen wide use are specialist models that work well for specific domains. Methods that have learned the general notion of "what is a cell" and can identify them across different domains of cellular imaging data have proven elusive. In this work, we present CellSAM, a foundation model for cell segmentation that generalizes across diverse cellular imaging data. CellSAM builds on top of the Segment Anything Model (SAM) by developing a prompt engineering approach to mask generation. We train an object detector, CellFinder, to automatically detect cells and prompt SAM to generate segmentations. We show that this approach allows a single model to achieve state-of-the-art performance for segmenting images of mammalian cells (in tissues and cell culture), yeast, and bacteria collected with various imaging modalities. To enable accessibility, we integrate CellSAM into DeepCell Label to further accelerate human-in-the-loop labeling strategies for cellular imaging data. A deployed version of CellSAM is available at https://label-dev.deepcell.org.},
	language = {en},
	urldate = {2023-11-22},
	publisher = {bioRxiv},
	author = {Israel, Uriah and Marks, Markus and Dilip, Rohit and Li, Qilin and Schwartz, Morgan Sarah and Pradhan, Elora and Pao, Edward and Li, Shenyi and Pearson-Goulart, Alexander and Perona, Pietro and Gkioxari, Georgia and Barnowski, Ross and Yue, Yisong and Valen, David Ashley Van},
	month = nov,
	year = {2023},
}

@article{tiwari_sirtuin3_2023,
	title = {Sirtuin3 ensures the metabolic plasticity of neurotransmission during glucose deprivation},
	volume = {223},
	issn = {0021-9525},
	url = {https://doi.org/10.1083/jcb.202305048},
	doi = {10.1083/jcb.202305048},
	abstract = {Neurotransmission is an energetically expensive process that underlies cognition. During intense electrical activity or dietary restrictions, the glucose level in the brain plummets, forcing neurons to utilize alternative fuels. However, the molecular mechanisms of neuronal metabolic plasticity remain poorly understood. Here, we demonstrate that glucose-deprived neurons activate the CREB and PGC1α transcriptional program, which induces expression of the mitochondrial deacetylase Sirtuin 3 (Sirt3) both in vitro and in vivo. We show that Sirt3 localizes to axonal mitochondria and stimulates mitochondrial oxidative capacity in hippocampal nerve terminals. Sirt3 plays an essential role in sustaining synaptic transmission in the absence of glucose by providing metabolic support for the retrieval of synaptic vesicles after release. These results demonstrate that the transcriptional induction of Sirt3 facilitates the metabolic plasticity of synaptic transmission.},
	number = {1},
	urldate = {2023-11-21},
	journal = {Journal of Cell Biology},
	author = {Tiwari, Anupama and Hashemiaghdam, Arsalan and Laramie, Marissa A. and Maschi, Dario and Haddad, Tristaan and Stunault, Marion I. and Bergom, Carmen and Javaheri, Ali and Klyachko, Vitaly and Ashrafi, Ghazaleh},
	month = nov,
	year = {2023},
	pages = {e202305048},
}

@article{zhao_training_2020,
	title = {Training confounder-free deep learning models for medical applications},
	volume = {11},
	issn = {2041-1723},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7691500/},
	doi = {10.1038/s41467-020-19784-9},
	abstract = {The presence of confounding effects (or biases) is one of the most critical challenges in using deep learning to advance discovery in medical imaging studies. Confounders affect the relationship between input data (e.g., brain MRIs) and output variables (e.g., diagnosis). Improper modeling of those relationships often results in spurious and biased associations. Traditional machine learning and statistical models minimize the impact of confounders by, for example, matching data sets, stratifying data, or residualizing imaging measurements. Alternative strategies are needed for state-of-the-art deep learning models that use end-to-end training to automatically extract informative features from large set of images. In this article, we introduce an end-to-end approach for deriving features invariant to confounding factors while accounting for intrinsic correlations between the confounder(s) and prediction outcome. The method does so by exploiting concepts from traditional statistical methods and recent fair machine learning schemes. We evaluate the method on predicting the diagnosis of HIV solely from Magnetic Resonance Images (MRIs), identifying morphological sex differences in adolescence from those of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA), and determining the bone age from X-ray images of children. The results show that our method can accurately predict while reducing biases associated with confounders. The code is available at https://github.com/qingyuzhao/br-net., The presence of confounding effects is one of the most critical challenges in using deep learning to advance discovery in medical imaging studies. Here, the authors introduce an end-to-end approach for deriving features invariant to confounding factors as inputs to prediction models.},
	urldate = {2023-11-21},
	journal = {Nature Communications},
	author = {Zhao, Qingyu and Adeli, Ehsan and Pohl, Kilian M.},
	month = nov,
	year = {2020},
	pmid = {33243992},
	pmcid = {PMC7691500},
	pages = {6010},
}

@article{lang_ermitochondria_2015,
	series = {Cell organelles},
	title = {{ER}–mitochondria contact sites in yeast: beyond the myths of {ERMES}},
	volume = {35},
	issn = {0955-0674},
	shorttitle = {{ER}–mitochondria contact sites in yeast},
	url = {https://www.sciencedirect.com/science/article/pii/S0955067415000241},
	doi = {10.1016/j.ceb.2015.03.002},
	abstract = {A standout feature of eukaryotic cells is the presence of organelles with distinct chemical compositions and physical properties, which aid in the accomplishment of specialized metabolic tasks. This complex topology, however, makes a permanent crosstalk between the organelles a necessity for the coordination of cellular function. While molecule exchange between organelles via the vesicular transport system has been extensively studied, communication via direct connections has only recently become a new matter of interest. These direct connections termed membrane contact sites (MCSs) represent zones of close proximity (10–30nm) between two organelles. Research in the past years has revealed a number of MCSs especially between the ER and almost every other organelle [1•]. In particular, the MCSs between the ER and the mitochondria have undergone intense investigation. While the quest for ER–mitochondria MCS components in human cells has led to the revelation of an ever growing number of potential factors, studies in the simpler eukaryote Saccharomyces cerevisiae revealed the actual existence of a molecular tether between the two organelles [2••].},
	urldate = {2023-11-21},
	journal = {Current Opinion in Cell Biology},
	author = {Lang, Alexander and John Peter, Arun T and Kornmann, Benoît},
	month = aug,
	year = {2015},
	pages = {7--12},
}

@article{hsu_myths_2021,
	title = {Myths and facts about getting an academic faculty position in neuroscience},
	volume = {7},
	issn = {2375-2548},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8397261/},
	doi = {10.1126/sciadv.abj2604},
	abstract = {Prior funding and/or papers in high-profile journals are not necessary to obtain a tenure-track faculty position., We at the National Institute of Neurological Disorders and Stroke routinely receive questions and statements from trainees and faculty that suggest widespread beliefs about the necessity of a National Institutes of Health K99/R00 award, other prior funding, and/or specific types of publications for obtaining one’s first tenure-track position in neuroscience. To address these beliefs, we examined the funding and publication history of a cohort of investigators who began their first academic faculty position between 2009 and 2019, and we interviewed several senior academic leaders with extensive experience in hiring new faculty. Our data show that {\textless}11\% of newly hired faculty had a K99/R00 award and that neither prior funding nor papers in prestigious journals were necessary to obtain a tenure-track faculty position. Interviews with academic leaders almost uniformly referred to critically important factors that were considered to be more important in the hiring process than funding or publishing in high-profile journals.},
	number = {35},
	urldate = {2023-11-20},
	journal = {Science Advances},
	author = {Hsu, Nina S. and Rezai-zadeh, K. Paul and Tennekoon, Michael S. and Korn, Stephen J.},
	month = aug,
	year = {2021},
	pmid = {34452920},
	pmcid = {PMC8397261},
	pages = {eabj2604},
}

@article{hu_ocif_2023,
	title = {{OCIF}: automatically learning the optimized clinical information fusion method for computer-aided diagnosis tasks},
	volume = {18},
	issn = {1861-6429},
	shorttitle = {{OCIF}},
	doi = {10.1007/s11548-023-02985-0},
	abstract = {PURPOSE: In computer-aided diagnosis, the fusion of image features extracted from neural networks and clinical information is crucial to improve diagnostic accuracy. How to integrate low-dimensional clinical information (LDCF) with high-dimensional network features (HDNF) is an urgent problem to be solved. We offer a new network search framework to address this problem, which can provide optimized LDCF fusion and efficient dimensionality reduction in HDNF.
METHODS: OCIF innovatively uses Gaussian process optimization to explore the search space for the number of fully connected (FC) layers, the number of neurons in each FC layer, the activation function, the dropout factor, and whether to add clinical information to each FC layer. Moreover, OCIF employs transfer learning to reduce the training parameter space and improve search efficiency. To evaluate the effectiveness of the proposed OCIF, we utilized three popular end-to-end overall survival (OS) time prediction models to predict the three classes.
RESULTS: Our experimental results show that applying OCIF to a classical computer-aided diagnosis neural network can improve classification accuracy. Experiments on the 2020 BRATS dataset prove that OCIF achieves satisfactory performance, with an accuracy of 0.684, precision of 0.735, recall of 0.684, and F1-score of 0.675 on the OS time prediction task.
CONCLUSION: OCIF effectively and creatively combines clinical information and network features, leveraging both clinical information and image features to enhance the accuracy of the final diagnosis. Our experiments demonstrate that the use of OCIF can significantly improve computer-aided diagnosis accuracy, and the approach has the potential to be extended to other medical classification tasks as well.},
	language = {eng},
	number = {12},
	journal = {International Journal of Computer Assisted Radiology and Surgery},
	author = {Hu, Zhaoyu and Li, Leyin and Sui, An and Wu, Guoqing and Wang, Yuanyuan and Shi, Zhifeng and Yu, Jinhua and Chen, Liang and Yang, Guiguan and Sun, Yuhao},
	month = dec,
	year = {2023},
	pmid = {37603163},
	keywords = {Clinical information fusion, Computers, Diagnosis, Computer-Assisted, Gaussian process optimization algorithm, Humans, Neural Networks, Computer, Neural architecture search},
	pages = {2273--2286},
}

@article{bai_computer-aided_2023,
	title = {Computer-aided diagnosis in predicting the invasion depth of early colorectal cancer: a systematic review and meta-analysis of diagnostic test accuracy},
	volume = {37},
	issn = {1432-2218},
	shorttitle = {Computer-aided diagnosis in predicting the invasion depth of early colorectal cancer},
	url = {https://doi.org/10.1007/s00464-023-10223-6},
	doi = {10.1007/s00464-023-10223-6},
	abstract = {Endoscopic resection (ER) is widely applied to treat early colorectal cancer (CRC). Predicting the invasion depth of early CRC is critical in determining treatment strategies. The use of computer-aided diagnosis (CAD) algorithms could theoretically make accurate and objective predictions regarding the suitability of lesions for ER indication based on invasion depth. This study aimed to assess diagnostic test accuracy of CAD algorithms in predicting the invasion depth of early CRC and to compare the performance between the CAD algorithms and endoscopists.},
	language = {en},
	number = {9},
	urldate = {2023-11-18},
	journal = {Surgical Endoscopy},
	author = {Bai, Jiawei and Liu, Kai and Gao, Li and Zhao, Xin and Zhu, Shaohua and Han, Ying and Liu, Zhiguo},
	month = sep,
	year = {2023},
	keywords = {Artificial intelligence, Colonoscopy, Colorectal cancer, Computer-aided diagnosis, Invasion depth},
	pages = {6627--6639},
}

@article{nemoto_machine_2016,
	title = {[{Machine} {Learning} for {Computer}-aided {Diagnosis}]},
	volume = {36},
	issn = {1345-5354},
	doi = {10.11323/jjmp.36.1_29},
	abstract = {Machine learning algorithms are to analyze any dataset to extract data-driven model, prediction rule, or decision rule from the dataset. Various machine learning algorithms are now used to develop high-performance medical image processing systems such as computer-aided detection (CADe) system which detects clinically significant objects from medical images and computer-aided diagnosis (CADx) system which quantifies malignancy of manually or automatically detected clinical objects. In this paper, we introduce some applications of machine learning algorithms to the development of medical image processing system.},
	language = {jpn},
	number = {1},
	journal = {Igaku Butsuri: Nihon Igaku Butsuri Gakkai Kikanshi = Japanese Journal of Medical Physics: An Official Journal of Japan Society of Medical Physics},
	author = {Nemoto, Mitsutaka and Masutani, Yoshitaka and Nomura, Yukihiro and Hanaoka, Shohei and Miki, Soichiro and Yoshikawa, Takeharu and Hayashi, Naoto and Ootomo, Kuni},
	year = {2016},
	pmid = {28428494},
	keywords = {Diagnosis, Computer-Assisted, Humans, Image Processing, Computer-Assisted, Intracranial Aneurysm, Machine Learning, Software Design, computer-aided detection (CADe), computer-aided diagnosis (CADx), machine learning, medical image processing, pattern recognition},
	pages = {29--34},
}

@article{van_ginneken_fifty_2017,
	title = {Fifty years of computer analysis in chest imaging: rule-based, machine learning, deep learning},
	volume = {10},
	issn = {1865-0341},
	shorttitle = {Fifty years of computer analysis in chest imaging},
	doi = {10.1007/s12194-017-0394-5},
	abstract = {Half a century ago, the term "computer-aided diagnosis" (CAD) was introduced in the scientific literature. Pulmonary imaging, with chest radiography and computed tomography, has always been one of the focus areas in this field. In this study, I describe how machine learning became the dominant technology for tackling CAD in the lungs, generally producing better results than do classical rule-based approaches, and how the field is now rapidly changing: in the last few years, we have seen how even better results can be obtained with deep learning. The key differences among rule-based processing, machine learning, and deep learning are summarized and illustrated for various applications of CAD in the chest.},
	language = {eng},
	number = {1},
	journal = {Radiological Physics and Technology},
	author = {van Ginneken, Bram},
	month = mar,
	year = {2017},
	pmid = {28211015},
	pmcid = {PMC5337239},
	keywords = {Computer-aided detection, Computer-aided diagnosis, Deep learning, Humans, Image Processing, Computer-Assisted, Image processing, Lung Neoplasms, Machine Learning, Machine learning, Pulmonary image analysis, Radiography, Thoracic},
	pages = {23--32},
}

@incollection{balogh_diagnostic_2015,
	title = {The {Diagnostic} {Process}},
	url = {https://www.ncbi.nlm.nih.gov/books/NBK338593/},
	abstract = {This chapter provides an overview of diagnosis in health care, including the committee's conceptual model of the diagnostic process and a review of clinical reasoning. Diagnosis has important implications for patient care, research, and policy. Diagnosis has been described as both a process and a classification scheme, or a “pre-existing set of categories agreed upon by the medical profession to designate a specific condition” (Jutel, 2009).1 When a diagnosis is accurate and made in a timely manner, a patient has the best opportunity for a positive health outcome because clinical decision making will be tailored to a correct understanding of the patient's health problem (Holmboe and Durning, 2014). In addition, public policy decisions are often influenced by diagnostic information, such as setting payment policies, resource allocation decisions, and research priorities (Jutel, 2009; Rosenberg, 2002; WHO, 2012).},
	language = {en},
	urldate = {2023-11-18},
	booktitle = {Improving {Diagnosis} in {Health} {Care}},
	publisher = {National Academies Press (US)},
	author = {Balogh, Erin P. and Miller, Bryan T. and Ball, John R. and Care, Committee on Diagnostic Error in Health and Services, Board on Health Care and Medicine, Institute of and The National Academies of Sciences, Engineering},
	month = dec,
	year = {2015},
}

@article{xu_chatbot_2021,
	title = {Chatbot for {Health} {Care} and {Oncology} {Applications} {Using} {Artificial} {Intelligence} and {Machine} {Learning}: {Systematic} {Review}},
	volume = {7},
	issn = {2369-1999},
	shorttitle = {Chatbot for {Health} {Care} and {Oncology} {Applications} {Using} {Artificial} {Intelligence} and {Machine} {Learning}},
	doi = {10.2196/27850},
	abstract = {BACKGROUND: Chatbot is a timely topic applied in various fields, including medicine and health care, for human-like knowledge transfer and communication. Machine learning, a subset of artificial intelligence, has been proven particularly applicable in health care, with the ability for complex dialog management and conversational flexibility.
OBJECTIVE: This review article aims to report on the recent advances and current trends in chatbot technology in medicine. A brief historical overview, along with the developmental progress and design characteristics, is first introduced. The focus will be on cancer therapy, with in-depth discussions and examples of diagnosis, treatment, monitoring, patient support, workflow efficiency, and health promotion. In addition, this paper will explore the limitations and areas of concern, highlighting ethical, moral, security, technical, and regulatory standards and evaluation issues to explain the hesitancy in implementation.
METHODS: A search of the literature published in the past 20 years was conducted using the IEEE Xplore, PubMed, Web of Science, Scopus, and OVID databases. The screening of chatbots was guided by the open-access Botlist directory for health care components and further divided according to the following criteria: diagnosis, treatment, monitoring, support, workflow, and health promotion.
RESULTS: Even after addressing these issues and establishing the safety or efficacy of chatbots, human elements in health care will not be replaceable. Therefore, chatbots have the potential to be integrated into clinical practice by working alongside health practitioners to reduce costs, refine workflow efficiencies, and improve patient outcomes. Other applications in pandemic support, global health, and education are yet to be fully explored.
CONCLUSIONS: Further research and interdisciplinary collaboration could advance this technology to dramatically improve the quality of care for patients, rebalance the workload for clinicians, and revolutionize the practice of medicine.},
	language = {eng},
	number = {4},
	journal = {JMIR cancer},
	author = {Xu, Lu and Sanders, Leslie and Li, Kay and Chow, James C. L.},
	month = nov,
	year = {2021},
	pmid = {34847056},
	pmcid = {PMC8669585},
	keywords = {artificial intelligence, cancer therapy, chatbot, communication, diagnosis, ethics, health, machine learning, medical biophysics, medicine, mobile phone},
	pages = {e27850},
}

@article{tillu_cavin1_2021,
	title = {Cavin1 intrinsically disordered domains are essential for fuzzy electrostatic interactions and caveola formation},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-21035-4},
	doi = {10.1038/s41467-021-21035-4},
	abstract = {Caveolae are spherically shaped nanodomains of the plasma membrane, generated by cooperative assembly of caveolin and cavin proteins. Cavins are cytosolic peripheral membrane proteins with negatively charged intrinsically disordered regions that flank positively charged α-helical regions. Here, we show that the three disordered domains of Cavin1 are essential for caveola formation and dynamic trafficking of caveolae. Electrostatic interactions between disordered regions and α-helical regions promote liquid-liquid phase separation behaviour of Cavin1 in vitro, assembly of Cavin1 oligomers in solution, generation of membrane curvature, association with caveolin-1, and Cavin1 recruitment to caveolae in cells. Removal of the first disordered region causes irreversible gel formation in vitro and results in aberrant caveola trafficking through the endosomal system. We propose a model for caveola assembly whereby fuzzy electrostatic interactions between Cavin1 and caveolin-1 proteins, combined with membrane lipid interactions, are required to generate membrane curvature and a metastable caveola coat.},
	language = {en},
	number = {1},
	urldate = {2023-11-15},
	journal = {Nature Communications},
	author = {Tillu, Vikas A. and Rae, James and Gao, Ya and Ariotti, Nicholas and Floetenmeyer, Matthias and Kovtun, Oleksiy and McMahon, Kerrie-Ann and Chaudhary, Natasha and Parton, Robert G. and Collins, Brett M.},
	month = feb,
	year = {2021},
	keywords = {Caveolae, Membrane proteins},
	pages = {931},
}

@article{han_structure_2020,
	title = {Structure and assembly of {CAV1} {8S} complexes revealed by single particle electron microscopy},
	volume = {6},
	issn = {2375-2548},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7821874/},
	doi = {10.1126/sciadv.abc6185},
	abstract = {Single particle analysis reveals how the membrane sculpting protein caveolin 1 is packaged within disc-shaped complexes., Highly stable oligomeric complexes of the monotopic membrane protein caveolin serve as fundamental building blocks of caveolae. Current evidence suggests these complexes are disc shaped, but the details of their structural organization and how they assemble are poorly understood. Here, we address these questions using single particle electron microscopy of negatively stained recombinant 8S complexes of human caveolin 1. We show that 8S complexes are toroidal structures {\textasciitilde}15 nm in diameter that consist of an outer ring, an inner ring, and central protruding stalk. Moreover, we map the position of the N and C termini and determine their role in complex assembly, and visualize the 8S complexes in heterologous caveolae. Our findings provide critical insights into the structural features of 8S complexes and allow us to propose a model for how these highly stable membrane-embedded complexes are generated.},
	number = {49},
	urldate = {2023-11-15},
	journal = {Science Advances},
	author = {Han, Bing and Porta, Jason C. and Hanks, Jessica L. and Peskova, Yelena and Binshtein, Elad and Dryden, Kelly and Claxton, Derek P. and Mchaourab, Hassane S. and Karakas, Erkan and Ohi, Melanie D. and Kenworthy, Anne K.},
	month = dec,
	year = {2020},
	pmid = {33268374},
	pmcid = {PMC7821874},
	pages = {eabc6185},
}

@article{porta_molecular_2022,
	title = {Molecular architecture of the human caveolin-1 complex},
	volume = {8},
	issn = {2375-2548},
	doi = {10.1126/sciadv.abn7232},
	abstract = {Membrane-sculpting proteins shape the morphology of cell membranes and facilitate remodeling in response to physiological and environmental cues. Complexes of the monotopic membrane protein caveolin function as essential curvature-generating components of caveolae, flask-shaped invaginations that sense and respond to plasma membrane tension. However, the structural basis for caveolin's membrane remodeling activity is currently unknown. Here, we show that, using cryo-electron microscopy, the human caveolin-1 complex is composed of 11 protomers organized into a tightly packed disc with a flat membrane-embedded surface. The structural insights suggest a previously unrecognized mechanism for how membrane-sculpting proteins interact with membranes and reveal how key regions of caveolin-1, including its scaffolding, oligomerization, and intramembrane domains, contribute to its function.},
	language = {eng},
	number = {19},
	journal = {Science Advances},
	author = {Porta, Jason C. and Han, Bing and Gulsevin, Alican and Chung, Jeong Min and Peskova, Yelena and Connolly, Sarah and Mchaourab, Hassane S. and Meiler, Jens and Karakas, Erkan and Kenworthy, Anne K. and Ohi, Melanie D.},
	month = may,
	year = {2022},
	pmid = {35544577},
	pmcid = {PMC9094659},
	pages = {eabn7232},
}

@article{durand_machine_2018,
	title = {A machine learning approach for online automated optimization of super-resolution optical microscopy},
	volume = {9},
	issn = {2041-1723},
	url = {http://www.nature.com/articles/s41467-018-07668-y},
	doi = {10.1038/s41467-018-07668-y},
	abstract = {Traditional approaches for finding well-performing parameterizations of complex imaging systems, such as super-resolution microscopes rely on an extensive exploration phase over the illumination and acquisition settings, prior to the imaging task. This strategy suffers from several issues: it requires a large amount of parameter configurations to be evaluated, it leads to discrepancies between well-performing parameters in the exploration phase and imaging task, and it results in a waste of time and resources given that optimization and final imaging tasks are conducted separately. Here we show that a fully automated, machine learning-based system can conduct imaging parameter optimization toward a trade-off between several objectives, simultaneously to the imaging task. Its potential is highlighted on various imaging tasks, such as live-cell and multicolor imaging and multimodal optimization. This online optimization routine can be integrated to various imaging systems to increase accessibility, optimize performance and improve overall imaging quality.},
	number = {1},
	urldate = {2018-12-08},
	journal = {Nature Communications},
	author = {Durand, Audrey and Wiesner, Theresa and Gardner, Marc-Andre and Robitaille, Louis-Emile and Bilodeau, Anthony and Gagne, Christian and De Koninck, Paul and Lavoie-Cardinal, Flavie},
	month = dec,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Machine learning, Super, resolution microscopy},
	pages = {5247},
}

@article{burns_machine_2023,
	title = {Machine {Learning} {Validation} via {Rational} {Dataset} {Sampling} with astartes},
	volume = {8},
	issn = {2475-9066},
	url = {https://joss.theoj.org/papers/10.21105/joss.05996},
	doi = {10.21105/joss.05996},
	abstract = {Burns et al., (2023). Machine Learning Validation via Rational Dataset Sampling with astartes. Journal of Open Source Software, 8(91), 5996, https://doi.org/10.21105/joss.05996},
	language = {en},
	number = {91},
	urldate = {2023-11-12},
	journal = {Journal of Open Source Software},
	author = {Burns, Jackson W. and Spiekermann, Kevin A. and Bhattacharjee, Himaghna and Vlachos, Dionisios G. and Green, William H.},
	month = nov,
	year = {2023},
	pages = {5996},
}

@article{cardoen_membrane_2023,
	title = {Membrane contact site detection ({MCS}-{DETECT}) reveals dual control of rough mitochondria–{ER} contacts},
	volume = {223},
	issn = {0021-9525},
	url = {https://doi.org/10.1083/jcb.202206109},
	doi = {10.1083/jcb.202206109},
	abstract = {Identification and morphological analysis of mitochondria–ER contacts (MERCs) by fluorescent microscopy is limited by subpixel resolution interorganelle distances. Here, the membrane contact site (MCS) detection algorithm, MCS-DETECT, reconstructs subpixel resolution MERCs from 3D super-resolution image volumes. MCS-DETECT shows that elongated ribosome-studded riboMERCs, present in HT-1080 but not COS-7 cells, are morphologically distinct from smaller smooth contacts and larger contacts induced by mitochondria–ER linker expression in COS-7 cells. RiboMERC formation is associated with increased mitochondrial potential, reduced in Gp78 knockout HT-1080 cells and induced by Gp78 ubiquitin ligase activity in COS-7 and HeLa cells. Knockdown of riboMERC tether RRBP1 eliminates riboMERCs in both wild-type and Gp78 knockout HT-1080 cells. By MCS-DETECT, Gp78-dependent riboMERCs present complex tubular shapes that intercalate between and contact multiple mitochondria. MCS-DETECT of 3D whole-cell super-resolution image volumes, therefore, identifies novel dual control of tubular riboMERCs, whose formation is dependent on RRBP1 and size modulated by Gp78 E3 ubiquitin ligase activity.},
	number = {1},
	urldate = {2023-11-11},
	journal = {Journal of Cell Biology},
	author = {Cardoen, Ben and Vandevoorde, Kurt R. and Gao, Guang and Ortiz-Silva, Milene and Alan, Parsa and Liu, William and Tiliakou, Ellie and Vogl, A. Wayne and Hamarneh, Ghassan and Nabi, Ivan R.},
	month = nov,
	year = {2023},
	pages = {e202206109},
}

@article{macdonald_does_2015,
	title = {Does super-resolution fluorescence microscopy obsolete previous microscopic approaches to protein co-localization},
	volume = {1270},
	issn = {1064-3745},
	url = {https://europepmc.org/article/med/25702123},
	doi = {10.1007/978-1-4939-2309-0_19},
	journal = {Methods in Molecular Biology},
	author = {MacDonald, Laura and Baldini, Giulia and Storrie, Brian},
	year = {2015},
	pmid = {25702123},
	pmcid = {PMC4389218},
	pages = {255--275},
}

@article{ioannidis_correction_2022,
	title = {Correction: {Why} {Most} {Published} {Research} {Findings} {Are} {False}},
	volume = {19},
	issn = {1549-1676},
	shorttitle = {Correction},
	url = {https://dx.plos.org/10.1371/journal.pmed.1004085},
	doi = {10.1371/journal.pmed.1004085},
	language = {en},
	number = {8},
	urldate = {2023-11-07},
	journal = {PLOS Medicine},
	author = {Ioannidis, John P. A.},
	month = aug,
	year = {2022},
	pages = {e1004085},
}

@article{venkatraman_cristae_2023,
	title = {Cristae formation is a mechanical buckling event controlled by the inner mitochondrial membrane lipidome},
	volume = {n/a},
	issn = {0261-4189},
	url = {https://www.embopress.org/doi/full/10.15252/embj.2023114054},
	doi = {10.15252/embj.2023114054},
	abstract = {Abstract Cristae are high-curvature structures in the inner mitochondrial membrane (IMM) that are crucial for ATP production. While cristae-shaping proteins have been defined, analogous lipid-based mechanisms have yet to be elucidated. Here, we combine experimental lipidome dissection with multi-scale modeling to investigate how lipid interactions dictate IMM morphology and ATP generation. When modulating phospholipid (PL) saturation in engineered yeast strains, we observed a surprisingly abrupt breakpoint in IMM topology driven by a continuous loss of ATP synthase organization at cristae ridges. We found that cardiolipin (CL) specifically buffers the inner mitochondrial membrane against curvature loss, an effect that is independent of ATP synthase dimerization. To explain this interaction, we developed a continuum model for cristae tubule formation that integrates both lipid and protein-mediated curvatures. This model highlighted a snapthrough instability, which drives IMM collapse upon small changes in membrane properties. We also showed that cardiolipin is essential in low-oxygen conditions that promote PL saturation. These results demonstrate that the mechanical function of cardiolipin is dependent on the surrounding lipid and protein components of the IMM.},
	number = {n/a},
	urldate = {2023-11-07},
	journal = {The EMBO Journal},
	author = {Venkatraman, Kailash and Lee, Christopher T and Garcia, Guadalupe C and Mahapatra, Arijit and Milshteyn, Daniel and Perkins, Guy and Kim, Keun-Young and Pasolli, H Amalia and Phan, Sebastien and Lippincott-Schwartz, Jennifer and Ellisman, Mark H and Rangamani, Padmini and Budin, Itay},
	month = nov,
	year = {2023},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {cardiolipin, cristae, lipids, mechanics, mitochondria},
	pages = {e114054},
}

@article{harner_mitochondrial_2011,
	title = {The mitochondrial contact site complex, a determinant of mitochondrial architecture},
	volume = {30},
	issn = {1460-2075},
	doi = {10.1038/emboj.2011.379},
	abstract = {Mitochondria are organelles with a complex architecture. They are bounded by an envelope consisting of the outer membrane and the inner boundary membrane (IBM). Narrow crista junctions (CJs) link the IBM to the cristae. OMs and IBMs are firmly connected by contact sites (CS). The molecular nature of the CS remained unknown. Using quantitative high-resolution mass spectrometry we identified a novel complex, the mitochondrial contact site (MICOS) complex, formed by a set of mitochondrial membrane proteins that is essential for the formation of CS. MICOS is preferentially located at the CJs. Upon loss of one of the MICOS subunits, CJs disappear completely or are impaired, showing that CJs require the presence of CS to form a superstructure that links the IBM to the cristae. Loss of MICOS subunits results in loss of respiratory competence and altered inheritance of mitochondrial DNA.},
	language = {eng},
	number = {21},
	journal = {The EMBO journal},
	author = {Harner, Max and Körner, Christian and Walther, Dirk and Mokranjac, Dejana and Kaesmacher, Johannes and Welsch, Ulrich and Griffith, Janice and Mann, Matthias and Reggiori, Fulvio and Neupert, Walter},
	month = oct,
	year = {2011},
	pmid = {22009199},
	pmcid = {PMC3230385},
	keywords = {Binding Sites, DNA, Mitochondrial, Intracellular Membranes, Membrane Proteins, Microscopy, Electron, Mitochondria, Mitochondrial Proteins, Models, Biological, Multiprotein Complexes, Organisms, Genetically Modified, Protein Binding, Protein Transport, Saccharomyces cerevisiae},
	pages = {4356--4370},
}

@misc{cardoen_logparadox_2023,
	title = {{LogParadox}},
	copyright = {GNU General Public License v3.0 or later, Open Access},
	url = {https://zenodo.org/record/7545841},
	abstract = {Companion source for the LogParadox paper. The software induces a paradoxical inversion conditional on the log-transform.},
	urldate = {2023-11-06},
	publisher = {Zenodo},
	author = {Cardoen, Ben and Yedder, Hanene Ben and {Sieun Lee} and Nabi, Ivan Robert and Hamarneh, Ghassan},
	month = jan,
	year = {2023},
	doi = {10.5281/ZENODO.7545841},
	keywords = {biomedical imaging, log-transform, statistics},
}

@misc{saalfeld_saalfeldlabn5_2022,
	title = {saalfeldlab/n5: n5-2.5.1},
	copyright = {Open Access},
	shorttitle = {saalfeldlab/n5},
	url = {https://zenodo.org/record/6578232},
	abstract = {Not HDF5},
	urldate = {2023-11-04},
	publisher = {Zenodo},
	author = {Saalfeld, Stephan and Pisarev, Igor and Hanslovsky, Philipp and Champion, Andrew and Rueden, Curtis and Bogovic, John and Kittisopikul, Mark and {Jakirkham}},
	month = may,
	year = {2022},
	doi = {10.5281/ZENODO.6578232},
}

@article{zhanghao_fast_2021,
	title = {Fast, live-cell imaging of 15 intracellular compartments by deep learning segmentation of super-resolution data},
	volume = {1},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.12.13.472520v1},
	doi = {10.1101/2021.12.13.472520},
	abstract = {The number of colors that can be used in fluorescence microscopy to image the live-cell anatomy and organelles’ interactions is far less than the number of intracellular organelles and compartments. Here, we report that deep convolutional neuronal networks can predict 15 subcellular structures from super-resolution spinning-disk microscopy images using only one dye, one laser excitation, and two detection channels. Comparing to the colocalization images, this method achieves pixel accuracies of over 91.7\%, which not only bypasses the fundamental limitation of multi-color imaging but also accelerates the imaging speed by more than one order of magnitude.},
	language = {en},
	number = {1},
	urldate = {2023-06-02},
	journal = {Biorxiv},
	author = {Zhanghao, Karl and Li, Meiqi and Chen, Xingye and Liu, Wenhui and Wang, Yiming and Wu, Zihan and Shan, Chunyan and Wu, Jiamin and Zhang, Yan and Xi, Peng and Jin, Dayong},
	month = dec,
	year = {2021},
}

@article{shi_semiparametrically_2023,
	title = {Semiparametrically {Efficient} {Tests} of {Multivariate} {Independence} {Using} {Center}-{Outward} {Quadrant}, {Spearman}, and {Kendall} {Statistics}},
	volume = {1},
	url = {http://arxiv.org/abs/2111.15567},
	doi = {10.48550/arXiv.2111.15567},
	abstract = {Defining multivariate generalizations of the classical univariate ranks has been a long-standing open problem in statistics. Optimal transport has been shown to offer a solution in which multivariate ranks are obtained by transporting data points to a grid that approximates a uniform reference measure (Chernozhukov et al., 2017; Hallin, 2017; Hallin et al., 2021). We take up this new perspective to develop and study multivariate analogues of the sign covariance/quadrant statistic, Kendall's tau, and Spearman's rho. The resulting tests of multivariate independence are genuinely distribution-free, hence uniformly valid irrespective of the actual (absolutely continuous) distributions of the observations. Our results provide asymptotic distribution theory for these new test statistics, with asymptotic approximations to critical values to be used for testing independence as well as a power analysis of the resulting tests. This includes a multivariate elliptical Chernoff-Savage property, which guarantees that, under ellipticity, our nonparametric tests of independence enjoy an asymptotic relative efficiency of one or larger with respect to the classical Gaussian procedures.},
	number = {1},
	urldate = {2023-05-15},
	journal = {Arxiv},
	author = {Shi, Hongjian and Drton, Mathias and Hallin, Marc and Han, Fang},
	month = jan,
	year = {2023},
	note = {arXiv:2111.15567 [math, stat]},
	keywords = {Mathematics - Statistics Theory},
}

@article{reinke_common_2022,
	title = {Common {Limitations} of {Image} {Processing} {Metrics}: {A} {Picture} {Story}},
	volume = {1},
	shorttitle = {Common {Limitations} of {Image} {Processing} {Metrics}},
	url = {http://arxiv.org/abs/2104.05642},
	doi = {10.48550/arXiv.2104.05642},
	abstract = {While the importance of automatic image analysis is continuously increasing, recent meta-research revealed major flaws with respect to algorithm validation. Performance metrics are particularly key for meaningful, objective, and transparent performance assessment and validation of the used automatic algorithms, but relatively little attention has been given to the practical pitfalls when using specific metrics for a given image analysis task. These are typically related to (1) the disregard of inherent metric properties, such as the behaviour in the presence of class imbalance or small target structures, (2) the disregard of inherent data set properties, such as the non-independence of the test cases, and (3) the disregard of the actual biomedical domain interest that the metrics should reflect. This living dynamically document has the purpose to illustrate important limitations of performance metrics commonly applied in the field of image analysis. In this context, it focuses on biomedical image analysis problems that can be phrased as image-level classification, semantic segmentation, instance segmentation, or object detection task. The current version is based on a Delphi process on metrics conducted by an international consortium of image analysis experts from more than 60 institutions worldwide.},
	number = {1},
	urldate = {2023-04-17},
	journal = {Arxiv},
	author = {Reinke, Annika and Tizabi, Minu D. and Sudre, Carole H. and Eisenmann, Matthias and Rädsch, Tim and Baumgartner, Michael and Acion, Laura and Antonelli, Michela and Arbel, Tal and Bakas, Spyridon and Bankhead, Peter and Benis, Arriel and Cardoso, M. Jorge and Cheplygina, Veronika and Christodoulou, Evangelia and Cimini, Beth and Collins, Gary S. and Farahani, Keyvan and van Ginneken, Bram and Glocker, Ben and Godau, Patrick and Hamprecht, Fred and Hashimoto, Daniel A. and Heckmann-Nötzel, Doreen and Hoffman, Michael M. and Huisman, Merel and Isensee, Fabian and Jannin, Pierre and Kahn, Charles E. and Karargyris, Alexandros and Karthikesalingam, Alan and Kainz, Bernhard and Kavur, Emre and Kenngott, Hannes and Kleesiek, Jens and Kooi, Thijs and Kozubek, Michal and Kreshuk, Anna and Kurc, Tahsin and Landman, Bennett A. and Litjens, Geert and Madani, Amin and Maier-Hein, Klaus and Martel, Anne L. and Mattson, Peter and Meijering, Erik and Menze, Bjoern and Moher, David and Moons, Karel G. M. and Müller, Henning and Nichyporuk, Brennan and Nickel, Felix and Noyan, M. Alican and Petersen, Jens and Polat, Gorkem and Rajpoot, Nasir and Reyes, Mauricio and Rieke, Nicola and Riegler, Michael and Rivaz, Hassan and Saez-Rodriguez, Julio and Gutierrez, Clarisa Sanchez and Schroeter, Julien and Saha, Anindo and Shetty, Shravya and van Smeden, Maarten and Stieltjes, Bram and Summers, Ronald M. and Taha, Abdel A. and Tsaftaris, Sotirios A. and Van Calster, Ben and Varoquaux, Gaël and Wiesenfarth, Manuel and Yaniv, Ziv R. and Kopp-Schneider, Annette and Jäger, Paul and Maier-Hein, Lena},
	month = jul,
	year = {2022},
	note = {arXiv:2104.05642 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@misc{ieee_ieee_2023,
	type = {Text},
	title = {{IEEE} {DataPort}},
	shorttitle = {{DataPort}},
	url = {https://ieee-dataport.org/},
	abstract = {Easily store and access hundreds of datasets, including big data datasets, through IEEE's dataset storage and dataset search platform, DataPort.},
	language = {en},
	urldate = {2023-05-12},
	journal = {IEEE DataPort},
	author = {IEEE, Data},
	month = nov,
	year = {2023},
}

@article{pun_persistent-homology-based_2018,
	title = {Persistent-{Homology}-based {Machine} {Learning} and its {Applications} -- {A} {Survey}},
	volume = {1},
	url = {http://arxiv.org/abs/1811.00252},
	doi = {10.48550/arXiv.1811.00252},
	abstract = {A suitable feature representation that can both preserve the data intrinsic information and reduce data complexity and dimensionality is key to the performance of machine learning models. Deeply rooted in algebraic topology, persistent homology (PH) provides a delicate balance between data simplification and intrinsic structure characterization, and has been applied to various areas successfully. However, the combination of PH and machine learning has been hindered greatly by three challenges, namely topological representation of data, PH-based distance measurements or metrics, and PH-based feature representation. With the development of topological data analysis, progresses have been made on all these three problems, but widely scattered in different literatures. In this paper, we provide a systematical review of PH and PH-based supervised and unsupervised models from a computational perspective. Our emphasizes are the recent development of mathematical models and tools, including PH softwares and PH-based functions, feature representations, kernels, and similarity models. Essentially, this paper can work as a roadmap for the practical application of PH-based machine learning tools. Further, we consider different topological feature representations in different machine learning models, and investigate their impacts on the protein secondary structure classification.},
	number = {1},
	urldate = {2023-06-12},
	journal = {Arxiv},
	author = {Pun, Chi Seng and Xia, Kelin and Lee, Si Xian},
	month = nov,
	year = {2018},
	note = {arXiv:1811.00252 [math]},
	keywords = {Mathematics - Algebraic Topology},
}

@article{schwartz_importance_2008,
	title = {The importance of stupidity in scientific research},
	volume = {121},
	issn = {0021-9533},
	url = {https://doi.org/10.1242/jcs.033340},
	doi = {10.1242/jcs.033340},
	number = {11},
	urldate = {2023-11-04},
	journal = {Journal of Cell Science},
	author = {Schwartz, Martin A.},
	month = jun,
	year = {2008},
	pages = {1771},
}

@article{tendler_why_2023,
	title = {Why every lab needs a handbook},
	volume = {12},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.88853},
	doi = {10.7554/eLife.88853},
	abstract = {A lab handbook is a flexible document that outlines the ethos of a research lab or group. A good handbook will outline the different roles within the lab, explain what is expected of all lab members, provide an overview of the culture the lab aims to create, and describe how the lab supports its members so that they can develop as researchers. Here we describe how we wrote a lab handbook for a large research group, and provide resources to help other labs write their own handbooks.},
	urldate = {2023-11-01},
	journal = {eLife},
	author = {Tendler, Benjamin C and Welland, Maddie and Miller, Karla L and {The WIN Handbook Team}},
	month = jul,
	year = {2023},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {careers in science, early-career researchers, lab handbooks, onboarding, principal investigators, research culture},
	pages = {e88853},
}

@article{noauthor_application_nodate,
	title = {Application {Note}: {Pushing} {STED} beyond its limits with {TauSTED}},
	copyright = {© 2023 Springer Nature Limited},
	shorttitle = {Application {Note}},
	url = {https://www.nature.com/articles/d42473-021-00241-0},
	abstract = {The new TauSTED technology from Leica Microsystems sets the new standard for straightforward, gentle STED using lifetime-based information},
	language = {en},
	urldate = {2023-10-31},
	note = {Bandiera\_abtest: a
Cg\_type: Advertisement Feature},
}

@article{wherry_new_1931,
	title = {A {New} {Formula} for {Predicting} the {Shrinkage} of the {Coefficient} of {Multiple} {Correlation}},
	volume = {2},
	issn = {0003-4851},
	url = {https://www.jstor.org/stable/2957681},
	number = {4},
	urldate = {2023-10-31},
	journal = {The Annals of Mathematical Statistics},
	author = {Wherry, R. J.},
	year = {1931},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {440--457},
}

@misc{bose_meta-graph_2020,
	title = {Meta-{Graph}: {Few} {Shot} {Link} {Prediction} via {Meta} {Learning}},
	shorttitle = {Meta-{Graph}},
	url = {http://arxiv.org/abs/1912.09867},
	doi = {10.48550/arXiv.1912.09867},
	abstract = {We consider the task of few shot link prediction on graphs. The goal is to learn from a distribution over graphs so that a model is able to quickly infer missing edges in a new graph after a small amount of training. We show that current link prediction methods are generally ill-equipped to handle this task. They cannot effectively transfer learned knowledge from one graph to another and are unable to effectively learn from sparse samples of edges. To address this challenge, we introduce a new gradient-based meta learning framework, Meta-Graph. Our framework leverages higher-order gradients along with a learned graph signature function that conditionally generates a graph neural network initialization. Using a novel set of few shot link prediction benchmarks, we show that Meta-Graph can learn to quickly adapt to a new graph using only a small sample of true edges, enabling not only fast adaptation but also improved results at convergence.},
	urldate = {2023-10-31},
	publisher = {arXiv},
	author = {Bose, Avishek Joey and Jain, Ankit and Molino, Piero and Hamilton, William L.},
	month = mar,
	year = {2020},
	note = {arXiv:1912.09867 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@article{kosasih_machine_2022,
	title = {A machine learning approach for predicting hidden links in supply chain with graph neural networks},
	volume = {60},
	issn = {0020-7543},
	url = {https://doi.org/10.1080/00207543.2021.1956697},
	doi = {10.1080/00207543.2021.1956697},
	abstract = {Supply chain business interruption has been identified as a key risk factor in recent years, with high-impact disruptions due to disease outbreaks, logistic issues such as the recent Suez Canal blockage showing examples of how disruptions could propagate across complex emergent networks. Researchers have highlighted the importance of gaining visibility into procurement interdependencies between suppliers to develop more informed business contingency plans. However, extant methods such as supplier surveys rely on the willingness or ability of suppliers to share data and are not easily verifiable. In this article, we pose the supply chain visibility problem as a link prediction problem from the field of Machine Learning (ML) and propose the use of an automated method to detect potential links that are unknown to the buyer with Graph Neural Networks (GNN). Using a real automotive network as a test case, we show that our method performs better than existing algorithms. Additionally, we use Integrated Gradient to improve the explainability of our approach by highlighting input features that influence GNN’s decisions. We also discuss the advantages and limitations of using GNN for link prediction, outlining future research directions.},
	number = {17},
	urldate = {2023-10-31},
	journal = {International Journal of Production Research},
	author = {Kosasih, Edward Elson and Brintrup, Alexandra},
	month = sep,
	year = {2022},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2021.1956697},
	keywords = {Supply chain, artificial intelligence, explainability, link prediction, machine learning, visibility},
	pages = {5380--5393},
}

@article{zhang_withdrawal_2023,
	title = {Withdrawal: {Mitochondrial} autophagy is an {HIF}-1-dependent adaptive metabolic response to hypoxia},
	volume = {299},
	issn = {1083-351X},
	shorttitle = {Withdrawal},
	doi = {10.1016/j.jbc.2023.105125},
	language = {eng},
	number = {8},
	journal = {The Journal of Biological Chemistry},
	author = {Zhang, Huafeng and Bosch-Marce, Marta and Shimoda, Larissa A. and Tan, Yee Sun and Baek, Jin Hyen and Wesley, Jacob B. and Gonzalez, Frank J. and Semenza, Gregg L.},
	month = aug,
	year = {2023},
	pmid = {37556879},
	pmcid = {PMC10424196},
	pages = {105125},
}

@article{poillet-perez_interplay_2015,
	title = {Interplay between {ROS} and autophagy in cancer cells, from tumor initiation to cancer therapy},
	volume = {4},
	issn = {2213-2317},
	doi = {10.1016/j.redox.2014.12.003},
	abstract = {Cancer formation is a complex and highly regulated multi-step process which is highly dependent of its environment, from the tissue to the patient. This complexity implies the development of specific treatments adapted to each type of tumor. The initial step of cancer formation requires the transformation of a healthy cell to a cancer cell, a process regulated by multiple intracellular and extracellular stimuli. The further steps, from the anarchic proliferation of cancer cells to form a primary tumor to the migration of cancer cells to distant organs to form metastasis, are also highly dependent of the tumor environment but of intracellular molecules and pathways as well. In this review, we will focus on the regulatory role of reactive oxygen species (ROS) and autophagy levels during the course of cancer development, from cellular transformation to the formation of metastasis. These data will allow us to discuss the potential of this molecule or pathway as putative future therapeutic targets.},
	language = {eng},
	journal = {Redox Biology},
	author = {Poillet-Perez, Laura and Despouy, Gilles and Delage-Mourroux, Régis and Boyer-Guittaut, Michaël},
	year = {2015},
	pmid = {25590798},
	pmcid = {PMC4803791},
	keywords = {AMP-Activated Protein Kinases, Antineoplastic Agents, Antioxidant, Apoptosis Regulatory Proteins, Autophagy, Autophagy-Related Protein-1 Homolog, Autophagy-Related Proteins, Beclin-1, Cancer, Cell Transformation, Neoplastic, Cysteine Endopeptidases, Gene Expression Regulation, Neoplastic, Humans, Intracellular Signaling Peptides and Proteins, Kelch-Like ECH-Associated Protein 1, Lymphatic Metastasis, Membrane Proteins, Mitochondria, Mitophagy, Neoplasms, Protein Serine-Threonine Kinases, ROS, Reactive Oxygen Species, Signal Transduction, Tumor Microenvironment},
	pages = {184--192},
}

@article{mathew_autophagy_2011,
	title = {Autophagy, stress, and cancer metabolism: what doesn't kill you makes you stronger},
	volume = {76},
	issn = {1943-4456},
	shorttitle = {Autophagy, stress, and cancer metabolism},
	doi = {10.1101/sqb.2012.76.011015},
	abstract = {Altered metabolism is a hallmark of cancer. Oncogenic events that lead to cancerous states reorganize metabolic pathways to increase nutrient uptake, which promotes biosynthetic capabilities and cell-autonomous behavior. Increased biosynthesis dictates metabolic demand for ATP, building blocks, and reducing equivalents, rendering cancer cells metabolically in a perpetually hungry state. Moreover, most chemotherapy agents induce acute metabolic stress that cancer cells must overcome for their survival. These metabolic stress cues in cancer cells can activate and cause dependence on the self-cannibalization mechanism of macroautophagy (autophagy hereafter) for the lysosomal turnover and recycling of organelles and proteins for energy and stress survival. For example, activating mutations in Ras or Ras-effector pathways induce autophagy, and cancer cell lines with Ras activation show elevated levels of basal autophagy that is essential for starvation survival and tumor growth. The metabolic implications of this are profound and multifaceted. First, autophagy-mediated degradation and recycling of cellular substrates can support metabolism and promote survival and tumor growth. Second, acute autophagy activation in response to cancer therapy can potentially lead to refractory tumors resistant to conventional chemotherapy. For example, a specific form of autophagy that targets mitochondria (mitophagy) may also function to promote cell survival by the clearance of damaged mitochondria that are potential sources of reactive oxygen species (ROS). These point to the possibility that autophagy is a unique metabolic need, important for survival as well as therapy resistance in cancer cells. Targeting autophagy in single-agent therapy to sensitize aggressive cancers that are dependent on autophagy for survival or in combination with therapeutic agents that induce autophagy as a resistance mechanism may be an effective therapeutic strategy to treat cancer.},
	language = {eng},
	journal = {Cold Spring Harbor Symposia on Quantitative Biology},
	author = {Mathew, R. and White, E.},
	year = {2011},
	pmid = {22442109},
	keywords = {Autophagy, Cell Survival, Humans, Metabolic Networks and Pathways, Neoplasms, Oncogenes, Stress, Physiological},
	pages = {389--396},
}

@article{murphy_how_2009,
	title = {How mitochondria produce reactive oxygen species},
	volume = {417},
	issn = {1470-8728},
	doi = {10.1042/BJ20081386},
	abstract = {The production of ROS (reactive oxygen species) by mammalian mitochondria is important because it underlies oxidative damage in many pathologies and contributes to retrograde redox signalling from the organelle to the cytosol and nucleus. Superoxide (O2(*-)) is the proximal mitochondrial ROS, and in the present review I outline the principles that govern O2(*-) production within the matrix of mammalian mitochondria. The flux of O2(*-) is related to the concentration of potential electron donors, the local concentration of O2 and the second-order rate constants for the reactions between them. Two modes of operation by isolated mitochondria result in significant O2(*-) production, predominantly from complex I: (i) when the mitochondria are not making ATP and consequently have a high Deltap (protonmotive force) and a reduced CoQ (coenzyme Q) pool; and (ii) when there is a high NADH/NAD+ ratio in the mitochondrial matrix. For mitochondria that are actively making ATP, and consequently have a lower Deltap and NADH/NAD+ ratio, the extent of O2(*-) production is far lower. The generation of O2(*-) within the mitochondrial matrix depends critically on Deltap, the NADH/NAD+ and CoQH2/CoQ ratios and the local O2 concentration, which are all highly variable and difficult to measure in vivo. Consequently, it is not possible to estimate O2(*-) generation by mitochondria in vivo from O2(*-)-production rates by isolated mitochondria, and such extrapolations in the literature are misleading. Even so, the description outlined here facilitates the understanding of factors that favour mitochondrial ROS production. There is a clear need to develop better methods to measure mitochondrial O2(*-) and H2O2 formation in vivo, as uncertainty about these values hampers studies on the role of mitochondrial ROS in pathological oxidative damage and redox signalling.},
	language = {eng},
	number = {1},
	journal = {The Biochemical Journal},
	author = {Murphy, Michael P.},
	month = jan,
	year = {2009},
	pmid = {19061483},
	pmcid = {PMC2605959},
	keywords = {Animals, Electron Transport Complex I, Humans, Hydrogen Peroxide, Mitochondria, Models, Biological, Reactive Oxygen Species, Superoxides},
	pages = {1--13},
}

@article{gorrini_modulation_2013,
	title = {Modulation of oxidative stress as an anticancer strategy},
	volume = {12},
	issn = {1474-1784},
	doi = {10.1038/nrd4002},
	abstract = {The regulation of oxidative stress is an important factor in both tumour development and responses to anticancer therapies. Many signalling pathways that are linked to tumorigenesis can also regulate the metabolism of reactive oxygen species (ROS) through direct or indirect mechanisms. High ROS levels are generally detrimental to cells, and the redox status of cancer cells usually differs from that of normal cells. Because of metabolic and signalling aberrations, cancer cells exhibit elevated ROS levels. The observation that this is balanced by an increased antioxidant capacity suggests that high ROS levels may constitute a barrier to tumorigenesis. However, ROS can also promote tumour formation by inducing DNA mutations and pro-oncogenic signalling pathways. These contradictory effects have important implications for potential anticancer strategies that aim to modulate levels of ROS. In this Review, we address the controversial role of ROS in tumour development and in responses to anticancer therapies, and elaborate on the idea that targeting the antioxidant capacity of tumour cells can have a positive therapeutic impact.},
	language = {eng},
	number = {12},
	journal = {Nature Reviews. Drug Discovery},
	author = {Gorrini, Chiara and Harris, Isaac S. and Mak, Tak W.},
	month = dec,
	year = {2013},
	pmid = {24287781},
	keywords = {Animals, Antineoplastic Agents, Humans, Neoplasms, Oxidative Stress, Reactive Oxygen Species},
	pages = {931--947},
}

@article{springer_brief_2016,
	title = {In {Brief}: {Mitophagy}: mechanisms and role in human disease},
	volume = {240},
	issn = {1096-9896},
	shorttitle = {In {Brief}},
	doi = {10.1002/path.4774},
	abstract = {Mitophagy is a selective form of macro-autophagy in which mitochondria are specifically targeted for autophagic degradation. Mitophagy plays an important role in cellular homeostasis by eliminating dysfunctional mitochondria and reducing mitochondrial mass as an adaptive response to stress. Cells execute mitophagy through several non-redundant mechanisms, including the PINK1/Parkin partnership, which modulates turnover of depolarized mitochondria, and stress-induced BNIP3, NIX, and FUNDC1 molecular adaptors, which interact directly with LC3 to promote mitophagy. These pathways are deregulated in human diseases, including cancer, neurodegeneration, metabolic disorders, muscle atrophy, ageing, and inflammation, reflecting the importance of mitophagy as a cellular housekeeping function. Copyright © 2016 Pathological Society of Great Britain and Ireland. Published by John Wiley \& Sons, Ltd.},
	language = {eng},
	number = {3},
	journal = {The Journal of Pathology},
	author = {Springer, Maya Z. and Macleod, Kay F.},
	month = nov,
	year = {2016},
	pmid = {27453450},
	pmcid = {PMC5071152},
	keywords = {Adaptation, Physiological, Aging, Autophagy, BNIP3, FUNDC1, Homeostasis, Humans, Inflammation, Membrane Proteins, Metabolic Diseases, Microtubule-Associated Proteins, Mitochondria, Mitochondrial Proteins, Mitophagy, Models, Biological, Muscular Atrophy, NIX, Neoplasms, Neurodegenerative Diseases, PINK1, Parkin, Protein Interaction Maps, Proto-Oncogene Proteins, Signal Transduction, Stress, Physiological, Tumor Suppressor Proteins, Ubiquitin-Protein Ligases, ageing, autophagy, disease, mitochondria},
	pages = {253--255},
}

@article{harper_building_2018,
	title = {Building and decoding ubiquitin chains for mitophagy},
	volume = {19},
	issn = {1471-0080},
	doi = {10.1038/nrm.2017.129},
	abstract = {Mitochondria produce energy in the form of ATP via oxidative phosphorylation. As defects in oxidative phosphorylation can generate harmful reactive oxygen species, it is important that damaged mitochondria are efficiently removed via a selective form of autophagy known as mitophagy. Owing to a combination of cell biological, structural and proteomic approaches, we are beginning to understand the mechanisms by which ubiquitin-dependent signals mark damaged mitochondria for mitophagy. This Review discusses the biochemical steps and regulatory mechanisms that promote the conjugation of ubiquitin to damaged mitochondria via the PTEN-induced putative kinase 1 (PINK1) and the E3 ubiquitin-protein ligase parkin and how ubiquitin chains promote autophagosomal capture. Recently discovered roles for parkin and PINK1 in the suppression of mitochondrial antigen presentation provide alternative models for how this pathway promotes the survival of neurons. A deeper understanding of these processes has major implications for neurodegenerative diseases, including Parkinson disease, where defects in mitophagy and other forms of selective autophagy are prominent.},
	language = {eng},
	number = {2},
	journal = {Nature Reviews. Molecular Cell Biology},
	author = {Harper, J. Wade and Ordureau, Alban and Heo, Jin-Mi},
	month = jan,
	year = {2018},
	pmid = {29358684},
	keywords = {Animals, Autophagy, Humans, Mitochondria, Mitophagy, Neurons, Oxidative Phosphorylation, Parkinson Disease, Protein Kinases, Proteomics, Signal Transduction, Ubiquitin, Ubiquitin-Protein Ligases, Ubiquitination},
	pages = {93--108},
}

@article{drake_expanding_2017,
	title = {Expanding perspectives on the significance of mitophagy in cancer},
	volume = {47},
	issn = {1096-3650},
	doi = {10.1016/j.semcancer.2017.04.008},
	abstract = {Mitophagy is a selective mode of autophagy in which mitochondria are specifically targeted for degradation at the autophagolysosome. Mitophagy is activated by stresses such as hypoxia, nutrient deprivation, DNA damage, inflammation and mitochondrial membrane depolarization and plays a role in maintaining mitochondrial integrity and function. Defects in mitophagy lead to mitochondrial dysfunction that can affect metabolic reprogramming in response to stress, alter cell fate determination and differentiation, which in turn affects disease incidence and etiology, including cancer. Here, we discuss how different mitophagy adaptors and modulators, including Parkin, BNIP3, BNIP3L, p62/SQSTM1 and OPTN, are regulated in response to physiological stresses and deregulated in cancers. Additionally, we explore how these different mitophagy control pathways coordinate with each other. Finally, we review new developments in understanding how mitophagy affects stemness, cell fate determination, inflammation and DNA damage responses that are relevant to understanding the role of mitophagy in cancer.},
	language = {eng},
	journal = {Seminars in Cancer Biology},
	author = {Drake, Lauren E. and Springer, Maya Z. and Poole, Logan P. and Kim, Casey J. and Macleod, Kay F.},
	month = dec,
	year = {2017},
	pmid = {28450176},
	pmcid = {PMC5654704},
	keywords = {Adaptation, Biological, Animals, Autophagy, BNIP3/BNIP3L, Biogenesis, Cardiolipin, Cell fate determination, DNA Damage, DNA damage responses, Energy Metabolism, FUNDC1, Humans, Inflammasome activation, Inflammation, Metabolic reprogramming, Mitochondria, Mitophagy, Neoplasms, Parkin, Signal Transduction, Stress, Physiological},
	pages = {110--124},
}

@article{zimmermann_how_2017,
	title = {How to get rid of mitochondria: crosstalk and regulation of multiple mitophagy pathways},
	volume = {399},
	issn = {1437-4315},
	shorttitle = {How to get rid of mitochondria},
	doi = {10.1515/hsz-2017-0206},
	abstract = {Mitochondria are indispensable cellular organelles providing ATP and numerous other essential metabolites to ensure cell survival. Reactive oxygen species (ROS), which are formed as side reactions during oxidative phosphorylation or by external agents, induce molecular damage in mitochondrial proteins, lipids/membranes and DNA. To cope with this and other sorts of organellar stress, a multi-level quality control system exists to maintain cellular homeostasis. One critical level of mitochondrial quality control is the removal of damaged mitochondria by mitophagy. This process utilizes parts of the general autophagy machinery, e.g. for the formation of autophagosomes but also employs mitophagy-specific factors. Depending on the proteins utilized mitophagy is divided into receptor-mediated and ubiquitin-mediated mitophagy. So far, at least seven receptor proteins are known to be required for mitophagy under different experimental conditions. In contrast to receptor-mediated pathways, the Pink-Parkin-dependent pathway is currently the best characterized ubiquitin-mediated pathway. Recently two additional ubiquitin-mediated pathways with distinctive similarities and differences were unraveled. We will summarize the current state of knowledge about these multiple pathways, explain their mechanism, and describe the regulation and crosstalk between these pathways. Finally, we will review recent evidence for the evolutionary conservation of ubiquitin-mediated mitophagy pathways.},
	language = {eng},
	number = {1},
	journal = {Biological Chemistry},
	author = {Zimmermann, Marcel and Reichert, Andreas S.},
	month = dec,
	year = {2017},
	pmid = {28976890},
	keywords = {Animals, Autophagy, Humans, Mitochondria, Receptors, Cell Surface, Ubiquitin, autophagy, mitochondria, mitochondrial quality control, mitophagy, ubiquitin},
	pages = {29--45},
}

@article{counts_acute_2016,
	title = {The acute and chronic effects of “{NO} {LOAD}” resistance training},
	volume = {164},
	issn = {0031-9384},
	url = {https://www.sciencedirect.com/science/article/pii/S003193841630436X},
	doi = {10.1016/j.physbeh.2016.06.024},
	abstract = {The purpose of the study was to remove the influence of an external load and determine if muscle growth can be elicited by maximally contracting through a full range of motion. In addition, the acute physiologic and perceptual responses to each stimulus were also investigated. Thirteen participants completed 18 sessions of unilateral elbow flexion exercise. Each arm was designated to either NO LOAD or HIGH LOAD condition (70\% one repetition maximum). For the NO LOAD condition, participants repeatedly contracted as hard as they could through a full range of motion without the use of an external load. Our results show that anterior muscle thickness increased similarly from Pre to Post, with no differences between conditions for the 50\% [Pre: 2.7 (0.8) vs. Post: 2.9 (0.7)], 60\% [Pre: 2.9 (0.7) vs. Post: 3.1 (0.7)] or 70\% [Pre: 3.2 (0.7) vs. Post: 3.5 (0.7)] sites. There was a significant condition×time interaction for one repetition maximum (p=0.017), with HIGH LOAD (+2.3kg) increasing more than the NO LOAD condition (+1kg). These results extend previous studies that have observed muscle growth across a range of external loads and muscle actions and suggest that muscle growth can occur independent of an external load provided there are enough muscle fibers undergoing mechanotransduction.},
	urldate = {2023-10-30},
	journal = {Physiology \& Behavior},
	author = {Counts, Brittany R. and Buckner, Samuel L. and Dankel, Scott J. and Jessee, Matthew B. and Mattocks, Kevin T. and Mouser, J. Grant and Laurentino, Gilberto C. and Loenneke, Jeremy P.},
	month = oct,
	year = {2016},
	keywords = {Hypertrophy, Mechanotransduction, Muscle adaptation, Muscle strength},
	pages = {345--352},
}

@article{pearson_review_2015,
	title = {A {Review} on the {Mechanisms} of {Blood}-{Flow} {Restriction} {Resistance} {Training}-{Induced} {Muscle} {Hypertrophy}},
	volume = {45},
	issn = {1179-2035},
	url = {https://doi.org/10.1007/s40279-014-0264-9},
	doi = {10.1007/s40279-014-0264-9},
	abstract = {It has traditionally been believed that resistance training can only induce muscle growth when the exercise intensity is greater than 65 \% of the 1-repetition maximum (RM). However, more recently, the use of low-intensity resistance exercise with blood-flow restriction (BFR) has challenged this theory and consistently shown that hypertrophic adaptations can be induced with much lower exercise intensities ({\textless}50 \% 1-RM). Despite the potent hypertrophic effects of BFR resistance training being demonstrated by numerous studies, the underlying mechanisms responsible for such effects are not well defined. Metabolic stress has been suggested to be a primary factor responsible, and this is theorised to activate numerous other mechanisms, all of which are thought to induce muscle growth via autocrine and/or paracrine actions. However, it is noteworthy that some of these mechanisms do not appear to be mediated to any great extent by metabolic stress but rather by mechanical tension (another primary factor of muscle hypertrophy). Given that the level of mechanical tension is typically low with BFR resistance exercise ({\textless}50 \% 1-RM), one may question the magnitude of involvement of these mechanisms aligned to the adaptations reported with BFR resistance training. However, despite the low level of mechanical tension, it is plausible that the effects induced by the primary factors (mechanical tension and metabolic stress) are, in fact, additive, which ultimately contributes to the adaptations seen with BFR resistance training. Exercise-induced mechanical tension and metabolic stress are theorised to signal a number of mechanisms for the induction of muscle growth, including increased fast-twitch fibre recruitment, mechanotransduction, muscle damage, systemic and localised hormone production, cell swelling, and the production of reactive oxygen species and its variants, including nitric oxide and heat shock proteins. However, the relative extent to which these specific mechanisms are induced by the primary factors with BFR resistance exercise, as well as their magnitude of involvement in BFR resistance training-induced muscle hypertrophy, requires further exploration.},
	language = {en},
	number = {2},
	urldate = {2023-10-30},
	journal = {Sports Medicine},
	author = {Pearson, Stephen John and Hussain, Syed Robiul},
	month = feb,
	year = {2015},
	keywords = {Eccentric Exercise, Metabolic Stress, Muscle Hypertrophy, Resistance Exercise, Satellite Cell},
	pages = {187--200},
}

@article{kvalseth_measuring_1988,
	title = {Measuring variation for nominal data},
	volume = {26},
	issn = {0090-5054},
	url = {http://link.springer.com/10.3758/BF03334906},
	doi = {10.3758/BF03334906},
	language = {en},
	number = {5},
	urldate = {2021-04-04},
	journal = {Bulletin of the Psychonomic Society},
	author = {Kvålseth, Tarald O.},
	month = nov,
	year = {1988},
	keywords = {categories, nominal, statistics, variance},
	pages = {433--436},
}

@inproceedings{Leordeanu2005a,
	title = {A spectral technique for correspondence problems using pairwise constraints},
	isbn = {0-7695-2334-X},
	url = {http://ieeexplore.ieee.org/document/1544893/},
	doi = {10.1109/ICCV.2005.20},
	urldate = {2018-07-24},
	booktitle = {Tenth {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV}'05) {Volume} 1},
	publisher = {IEEE},
	author = {Leordeanu, M. and Hebert, M.},
	year = {2005},
	pages = {1482--1489 Vol. 2},
}

@article{gagunashvili_chi-square_2010,
	title = {Chi-square tests for comparing weighted histograms},
	volume = {614},
	issn = {0168-9002},
	url = {https://www.sciencedirect.com/science/article/pii/S0168900209023547},
	doi = {10.1016/J.NIMA.2009.12.037},
	abstract = {Weighted histograms in Monte Carlo simulations are often used for the estimation of probability density functions. They are obtained as a result of random experiments with random events that have weights. In this paper, the bin contents of a weighted histogram are considered as a sum of random variables with a random number of terms. Generalizations of the classical chi-square test for comparing weighted histograms are proposed. Numerical examples illustrate an application of the tests for the histograms with different statistics of events and different weighted functions. The proposed tests can be used for the comparison of experimental data histograms with simulated data histograms as well as for the two simulated data histograms.},
	number = {2},
	urldate = {2018-07-30},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	author = {Gagunashvili, N.D.},
	month = mar,
	year = {2010},
	note = {Publisher: North-Holland},
	pages = {287--296},
}

@book{noauthor_statistical_2017,
	title = {Statistical {Shape} and {Deformation} {Analysis}},
	isbn = {978-0-12-810493-4},
	url = {http://linkinghub.elsevier.com/retrieve/pii/C20150067995},
	urldate = {2018-07-30},
	publisher = {Elsevier},
	year = {2017},
	doi = {10.1016/C2015-0-06799-5},
}

@article{Abney2011,
	title = {Principal {Component} {Analysis} of {Dynamic} {Relative} {Displacement} {Fields} {Estimated} from {MR} {Images}},
	volume = {6},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0022063},
	doi = {10.1371/journal.pone.0022063},
	abstract = {Non-destructive measurement of acceleration-induced displacement fields within a closed object is a fundamental challenge. Inferences of how the brain deforms following skull impact have thus relied largely on indirect estimates and course-resolution cadaver studies. We developed a magnetic resonance technique to quantitatively identify the modes of displacement of an accelerating soft object relative to an object enclosing it, and applied it to study acceleration-induced brain deformation in human volunteers. We show that, contrary to the prevailing hypotheses of the field, the dominant mode of interaction between the brain and skull in mild head acceleration is one of sliding arrested by meninges.},
	number = {7},
	urldate = {2018-07-31},
	journal = {PLoS ONE},
	author = {Abney, Teresa M. and Feng, Yuan and Pless, Robert and Okamoto, Ruth J. and Genin, Guy M. and Bayly, Philip V.},
	editor = {Samuel, Aravinthan},
	month = jul,
	year = {2011},
	note = {Publisher: Public Library of Science},
	pages = {e22063},
}

@book{deza_dictionary_2006,
	title = {Dictionary of distances},
	isbn = {978-0-444-52087-6},
	abstract = {1st ed. This book comes out of need and urgency (expressed especially in areas of Information Retrieval with respect to Image, Audio, Internet and Biology) to have a working tool to compare data. The book will provide powerful resource for all researchers using Mathematics as well as for mathematicians themselves. In the time when over-specialization and terminology fences isolate researchers, this Dictionary try to be "centripedal" and "oikoumeni", providing some access and altitude of vision but without taking the route of scientific vulgarisation. This attempted balance is the main philosophy of this Dictionary which defined its structure and style. Key features: - Unicity: it is the first book treating the basic notion of Distance in whole generality. - Interdisciplinarity: this Dictionary is larger in scope than majority of thematic dictionaries. - Encyclopedicity: while an Encyclopedia of Distances seems now too difficult to produce, this book (by its scope, short introductions and organization) provides the main material for it and for future tutorials on some parts of this material. - Applicability: the distances, as well as distance-related notions and paradigms, are provided in ready-to-use fashion. - Worthiness: the need and urgency for such dictionary was great in several huge areas, esp. Information Retrieval, Image Analysis, Speech Recognition and Biology. - Accessibility: the definitions are easy to locate by subject or, in Index, by alphabetic order; the introductions and definitions are reader-friendly and maximally independent one from another; still the text is structured, in the 3D HTML style, by hyperlink-like boldfaced references to similar definitions. * Covers a large range of subjects in pure and applied mathematics * Designed to be easily applied--the distances and distance-related notions and paradigms are ready to use * Helps users quickly locate definitions by subject or in alphabetical order; stand-alone entries include references to other entries and sources for further investigation. Preface -- I. Mathematics of Distances -- 1. General Definitions -- 2. Topological Spaces -- 3. Generalizations of Metric Spaces -- 4. Metric Transforms -- 5. Metrics on Normed Structures -- II. Geometry and Distances -- 6. Distances in Geometry -- 7. Riemannian and Hermitian Metrics -- 8. Distances on Surfaces and Knots -- 9. Distances on Convex Bodies, Cones, and Simplicial Complexes -- III. Distances in Classical Mathematics -- 10. Distances in Algebra -- 11. Distances on Strings and Permutations -- 12. Distances on Numbers, Polynomials, and Matrices -- 13. Distances in Functional Analysis -- 14. Distances in Probability Theory -- IV. Distances in Applied Mathematics -- 15. Distances in Graph Theory -- 16. Distances in Coding Theory -- 17. Distances and Similarities in Data Analysis -- 18. Distances in Mathematical Engineering -- V. Computer-related Distances -- 19. Distances on Real and Digital Planes -- 20. Voronoi Diagram Distances -- 21. Image and Audio Distances -- 22. Distances in Internet and Similar Networks -- VI. Distances in Natural Sciences -- 23. Distances in Biology -- 24. Distances in Physics and Chemistry -- 25. Distances in Geography, Geophysics, and Astronomy -- 26. Distances in Cosmology ad Theory of Relativity -- VII. Real-world Distances -- 27. Length Measures and Scales -- 28. Non-mathematical and Figurative Meaning of Distance.},
	urldate = {2018-08-07},
	publisher = {Elsevier},
	author = {Deza, Elena. and Deza, M.},
	year = {2006},
}

@book{Deza2006,
	title = {Dictionary of distances},
	isbn = {978-0-08-046554-8},
	abstract = {1st ed. This book comes out of need and urgency (expressed especially in areas of Information Retrieval with respect to Image, Audio, Internet and Biology) to have a working tool to compare data. The book will provide powerful resource for all researchers using Mathematics as well as for mathematicians themselves. In the time when over-specialization and terminology fences isolate researchers, this Dictionary try to be "centripedal" and "oikoumeni", providing some access and altitude of vision but without taking the route of scientific vulgarisation. This attempted balance is the main philosophy of this Dictionary which defined its structure and style. Key features: - Unicity: it is the first book treating the basic notion of Distance in whole generality. - Interdisciplinarity: this Dictionary is larger in scope than majority of thematic dictionaries. - Encyclopedicity: while an Encyclopedia of Distances seems now too difficult to produce, this book (by its scope, short introductions and organization) provides the main material for it and for future tutorials on some parts of this material. - Applicability: the distances, as well as distance-related notions and paradigms, are provided in ready-to-use fashion. - Worthiness: the need and urgency for such dictionary was great in several huge areas, esp. Information Retrieval, Image Analysis, Speech Recognition and Biology. - Accessibility: the definitions are easy to locate by subject or, in Index, by alphabetic order; the introductions and definitions are reader-friendly and maximally independent one from another; still the text is structured, in the 3D HTML style, by hyperlink-like boldfaced references to similar definitions. * Covers a large range of subjects in pure and applied mathematics * Designed to be easily applied--the distances and distance-related notions and paradigms are ready to use * Helps users quickly locate definitions by subject or in alphabetical order; stand-alone entries include references to other entries and sources for further investigation. Preface -- I. Mathematics of Distances -- 1. General Definitions -- 2. Topological Spaces -- 3. Generalizations of Metric Spaces -- 4. Metric Transforms -- 5. Metrics on Normed Structures -- II. Geometry and Distances -- 6. Distances in Geometry -- 7. Riemannian and Hermitian Metrics -- 8. Distances on Surfaces and Knots -- 9. Distances on Convex Bodies, Cones, and Simplicial Complexes -- III. Distances in Classical Mathematics -- 10. Distances in Algebra -- 11. Distances on Strings and Permutations -- 12. Distances on Numbers, Polynomials, and Matrices -- 13. Distances in Functional Analysis -- 14. Distances in Probability Theory -- IV. Distances in Applied Mathematics -- 15. Distances in Graph Theory -- 16. Distances in Coding Theory -- 17. Distances and Similarities in Data Analysis -- 18. Distances in Mathematical Engineering -- V. Computer-related Distances -- 19. Distances on Real and Digital Planes -- 20. Voronoi Diagram Distances -- 21. Image and Audio Distances -- 22. Distances in Internet and Similar Networks -- VI. Distances in Natural Sciences -- 23. Distances in Biology -- 24. Distances in Physics and Chemistry -- 25. Distances in Geography, Geophysics, and Astronomy -- 26. Distances in Cosmology ad Theory of Relativity -- VII. Real-world Distances -- 27. Length Measures and Scales -- 28. Non-mathematical and Figurative Meaning of Distance.},
	urldate = {2018-08-07},
	publisher = {Elsevier},
	author = {Deza, Elena. and Deza, M.},
	year = {2006},
}

@article{Saxton1982a,
	title = {The correlation averaging of a regularly arranged bacterial cell envelope protein},
	volume = {127},
	issn = {00222720},
	url = {http://doi.wiley.com/10.1111/j.1365-2818.1982.tb00405.x},
	doi = {10.1111/j.1365-2818.1982.tb00405.x},
	number = {2},
	urldate = {2018-03-27},
	journal = {Journal of Microscopy},
	author = {Saxton, W. O. and Baumeister, W.},
	month = aug,
	year = {1982},
	note = {Publisher: Wiley/Blackwell (10.1111)},
	keywords = {Correlation averaging, cell envelopes, crystal distortions, regular proteins, resolution assessment, symmetry assessment},
	pages = {127--138},
}

@article{Sullivan2012,
	title = {Using {Effect} {Size}-or {Why} the {P} {Value} {Is} {Not} {Enough}.},
	volume = {4},
	issn = {1949-8349},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23997866},
	doi = {10.4300/JGME-D-12-00156.1},
	number = {3},
	urldate = {2018-03-28},
	journal = {Journal of graduate medical education},
	author = {Sullivan, Gail M and Feinn, Richard},
	month = sep,
	year = {2012},
	pmid = {23997866},
	note = {Publisher: Accreditation Council for Graduate Medical Education},
	pages = {279--82},
}

@article{Zeng2017,
	title = {Computational methods in super-resolution microscopy},
	volume = {18},
	issn = {2095-9184},
	url = {http://link.springer.com/10.1631/FITEE.1601628},
	doi = {10.1631/FITEE.1601628},
	number = {9},
	urldate = {2018-09-11},
	journal = {Frontiers of Information Technology \& Electronic Engineering},
	author = {Zeng, Zhi-ping and Xie, Hao and Chen, Long and Zhanghao, Karl and Zhao, Kun and Yang, Xu-san and Xi, Peng},
	month = sep,
	year = {2017},
	note = {Publisher: Zhejiang University Press},
	keywords = {10, 1601628, 1631, computational methods, deconvolution, doi, fitee, https, org, super-resolution microscopy},
	pages = {1222--1235},
}

@article{sohn_present_2016,
	title = {The present and future of \textit{de novo} whole-genome assembly},
	volume = {19},
	issn = {1467-5463},
	url = {https://academic.oup.com/bib/article-lookup/doi/10.1093/bib/bbw096},
	doi = {10.1093/bib/bbw096},
	number = {1},
	urldate = {2018-09-12},
	journal = {Briefings in Bioinformatics},
	author = {Sohn, Jang-il and Nam, Jin-Wu},
	month = oct,
	year = {2016},
	note = {Publisher: Oxford University Press},
	pages = {bbw096},
}

@incollection{Seetin2012,
	address = {Totowa, NJ},
	title = {{RNA} {Structure} {Prediction}: {An} {Overview} of {Methods}},
	url = {http://link.springer.com/10.1007/978-1-61779-949-5_8},
	urldate = {2018-09-23},
	booktitle = {Bacterial {Regulatory} {RNA}},
	publisher = {Humana Press},
	author = {Seetin, Matthew G. and Mathews, David H.},
	year = {2012},
	doi = {10.1007/978-1-61779-949-5_8},
	pages = {99--122},
}

@article{burton_elusive_2016,
	title = {The elusive quest for {RNA} knots},
	volume = {13},
	issn = {1547-6286},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26828280},
	doi = {10.1080/15476286.2015.1132069},
	abstract = {Physical entanglement, and particularly knots arise spontaneously in equilibrated polymers that are sufficiently long and densely packed. Biopolymers are no exceptions: knots have long been known to occur in proteins as well as in encapsidated viral DNA. The rapidly growing number of RNA structures has recently made it possible to investigate the incidence of physical knots in this type of biomolecule, too. Strikingly, no knots have been found to date in the known RNA structures. In this Point of View Article we discuss the absence of knots in currently available RNAs and consider the reasons why knots in RNA have not yet been found, despite the expectation that they should exist in Nature. We conclude by singling out a number of RNA sequences that, based on the properties of their predicted secondary structures, are good candidates for knotted RNAs.},
	number = {2},
	urldate = {2018-09-24},
	journal = {RNA Biology},
	author = {Burton, Aaron S. and Di Stefano, Marco and Lehman, Niles and Orland, Henri and Micheletti, Cristian},
	month = feb,
	year = {2016},
	pmid = {26828280},
	keywords = {Physical knots, RNA knots, RNA structure},
	pages = {134--139},
}

@article{reinharz_mining_2018,
	title = {Mining for recurrent long-range interactions in {RNA} structures reveals embedded hierarchies in network families},
	volume = {46},
	issn = {0305-1048},
	url = {https://academic.oup.com/nar/article/46/8/3841/4955759},
	doi = {10.1093/nar/gky197},
	number = {8},
	urldate = {2018-09-26},
	journal = {Nucleic Acids Research},
	author = {Reinharz, Vladimir and Soulé, Antoine and Westhof, Eric and Waldispühl, Jérôme and Denise, Alain},
	month = may,
	year = {2018},
	note = {Publisher: Oxford University Press},
	keywords = {base pairing, datasets, graphical displays, ligands, mining, molecule, nucleotides, rna},
	pages = {3841--3851},
}

@article{schmidt_intrinsic_2018,
	title = {Intrinsic refractive index matched {3D} {dSTORM} with two objectives: {Comparison} of detection techniques},
	volume = {8},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-018-31595-z},
	doi = {10.1038/s41598-018-31595-z},
	abstract = {We have built a setup for 3D single molecule localisation microscopy (SMLM) where a very high resolution is achieved by, firstly, the use of two objectives instead of one and, secondly, minimizing optical aberrations by refractive index matching with a glycerol-water mixture as immersion medium in conjunction with glycerol-immersion objectives. Multiple optical paths of the microscope allow to switch between astigmatic and interferometric localisation along the optical axis, thus enabling a direct comparison of the performance of these localisation methods.},
	number = {1},
	urldate = {2018-10-03},
	journal = {Scientific Reports},
	author = {Schmidt, Nora C. and Kahms, Martin and Hüve, Jana and Klingauf, Jürgen},
	month = dec,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biophysics, Super, Super-resolution microscopy, resolution microscopy},
	pages = {13343},
}

@book{chen_dproq_2022,
	title = {{DProQ}: {A} {Gated}-{Graph} {Transformer} for {Protein} {Complex} {Structure} {Assessment}},
	shorttitle = {{DProQ}},
	abstract = {Proteins interact to form complexes to carry out essential biological functions. Computational methods have been developed to predict the structures of protein complexes. However, an important challenge in protein complex structure prediction is to estimate the quality of predicted protein complex structures without any knowledge of the corresponding native structures. Such estimations can then be used to select high-quality predicted complex structures to facilitate biomedical research such as protein function analysis and drug discovery. We challenge this significant task with DP ro Q, which introduces a gated neighborhood-modulating Graph Transformer (GGT) designed to predict the quality of 3D protein complex structures. Notably, we incorporate node and edge gates within a novel Graph Transformer framework to control information flow during graph message passing. We train and evaluate DP ro Q on four newly-developed datasets that we make publicly available in this work. Our rigorous experiments demonstrate that DP ro Q achieves state-of-the-art performance in ranking protein complex structures.},
	author = {Chen, Xiao and Morehead, Alex and Liu, Jian and Cheng, Jianlin},
	month = may,
	year = {2022},
	doi = {10.1101/2022.05.19.492741},
	keywords = {deep learning, graph, protein, structure, transformer},
}

@article{andronov_practical_2021,
	title = {Practical {Aspects} of {Super}-{Resolution} {Imaging} and {Segmentation} of {Macromolecular} {Complexes} by {dSTORM}},
	volume = {2247},
	issn = {1940-6029},
	doi = {10.1007/978-1-0716-1126-5_15},
	abstract = {Super-resolution fluorescence microscopy allows imaging macromolecular complexes down to the nanoscopic scale and thus is a great tool to combine and integrate cellular imaging in the native cellular environment with structural analysis by X-ray crystallography or high-resolution cryo electron microscopy or tomography. Here we describe practical aspects of SMLM imaging by dSTORM, from the initial sample preparation using mounting media, antibodies and fluorescent markers, the experimental setup for data acquisition including multi-color colocalization and 3D data acquisition, and finally tips and clues on advanced data processing that includes image reconstruction and data segmentation using 2D or 3D clustering methods. This approach opens the path toward multi-resolution integration in cellular structural biology.},
	language = {eng},
	journal = {Methods in Molecular Biology (Clifton, N.J.)},
	author = {Andronov, Leonid and Vonesch, Jean-Luc and Klaholz, Bruno P.},
	year = {2021},
	pmid = {33301123},
	keywords = {Animals, Cell Line, Cells, Cultured, Cryoelectron Microscopy, Data Analysis, Fluorescence microscopy, Fluorescent Antibody Technique, Humans, Image Processing, Computer-Assisted, Imaging, Three-Dimensional, Immunofluorescence, Macromolecular Substances, Microscopy, Fluorescence, Molecular Imaging, SMLM, Super-resolution microscopy, Tomography, dSTORM},
	pages = {271--286},
}

@article{wen_image_2022,
	title = {Image quality improvements of diffuse optical tomography by using multiple polarization components},
	volume = {7},
	doi = {10.1016/j.rio.2022.100219},
	abstract = {The inverse process of diffuse optical tomography (DOT) is ill-posed, which has a significant effect on the quality of the reconstructed results. In this paper, the polarization characteristics of light are introduced into the inverse solution model of DOT to increase the solution constraints and improve the imaging quality. The spectral element method is used to numerically solve the vector radiative transfer equation, which is used to simulate the propagation of polarized light in a scattering medium. The DOT reverse solution algorithm based on the polarization component is constructed so that the Stokes vector can be used for absorption coefficient and scattering coefficient reconstruction. The simulation and experimental results show that when polarized light is used for incidence, using the intensity component and the multi-polarization component to solve the DOT inverse model can improve the reconstruction accuracy of the medium absorption coefficient distribution and the DOT image quality.},
	journal = {Results in Optics},
	author = {Wen, Ya and Liu, Tongjun and Chen, Ping and Wang, Jingfan and Xiao, Dong and Zhao, Xing},
	month = may,
	year = {2022},
	keywords = {Diffuse optical tomography, Image quality, Polarized light, The spectral element method},
	pages = {100219},
}

@article{rodrigues_fitness_2022,
	title = {Fitness landscape analysis of convolutional neural network architectures for image classification},
	doi = {10.1016/j.ins.2022.07.040},
	abstract = {The global structure of the hyperparameter spaces of neural networks is not well understood and it is therefore not clear which hyperparameter search algorithm will be most effective. In this paper we analyze the landscapes of convolutional neural network architecture search spaces to provide insight into appropriate search algorithms for these spaces. Using a classical fitness landscape analysis approach (fitness distance correlation) and a more recent tool (local optima networks) we study the global structure of these spaces. Our analysis on six image classification datasets reveals that the landscapes are multi-modal, but with relatively few local optima from which it is not hard to escape with a simple perturbation operator. This led us to explore the performance of iterated local search, which we found to more effectively search the training landscapes than three evolutionary algorithm variants. Evolutionary algorithms, however, outperformed iterated local search in terms of generalization on problems with larger discrepancies between the training and testing landscapes.},
	journal = {Information Sciences},
	author = {Rodrigues, Nuno and Malan, Katherine and Ochoa, Gabriela and Vanneschi, Leonardo and Silva, Sara},
	month = jul,
	year = {2022},
}

@article{Garber2011a,
	title = {Quantity and quality of exercise for developing and maintaining cardiorespiratory, musculoskeletal, and neuromotor fitness in apparently healthy adults: {Guidance} for prescribing exercise},
	volume = {43},
	issn = {01959131},
	doi = {10.1249/MSS.0b013e318213fefb},
	abstract = {The purpose of this Position Stand is to provide guidance to professionals who counsel and prescribe individualized exercise to apparently healthy adults of all ages. These recommendations also may apply to adults with certain chronic diseases or disabilities, when appropriately evaluated and advised by a health professional. This document supersedes the 1998 American College of Sports Medicine (ACSM) Position Stand, "The Recommended Quantity and Quality of Exercise for Developing and Maintaining Cardiorespiratory and Muscular Fitness, and Flexibility in Healthy Adults." The scientific evidence demonstrating the beneficial effects of exercise is indisputable, and the benefits of exercise far outweigh the risks in most adults. A program of regular exercise that includes cardiorespiratory, resistance, flexibility, and neuromotor exercise training beyond activities of daily living to improve and maintain physical fitness and health is essential for most adults. The ACSM recommends that most adults engage in moderate-intensity cardiorespiratory exercise training for ≥30 min•d-1 on ≥5 d•wk-1 for a total of ≥150 min•wk-1, vigorous-intensity cardiorespiratory exercise training for ≥20 min•d-1 on ≥3 d•wk-1 (≥75 min•wk-1), or a combination of moderate-and vigorous-intensity exercise to achieve a total energy expenditure of ≥500-1000 MET•min•wk-1. On 2-3 d•wk-1, adults should also perform resistance exercises for each of the major muscle groups, and neuromotor exercise involving balance, agility, and coordination. Crucial to maintaining joint range of movement, completing a series of flexibility exercises for each the major muscle-tendon groups (a total of 60 s per exercise) on ≥2 d•wk-1 is recommended. The exercise program should be modified according to an individual's habitual physical activity, physical function, health status, exercise responses, and stated goals. Adults who are unable or unwilling to meet the exercise targets outlined here still can benefit from engaging in amounts of exercise less than recommended. In addition to exercising regularly, there are health benefits in concurrently reducing total time engaged in sedentary pursuits and also by interspersing frequent, short bouts of standing and physical activity between periods of sedentary activity, even in physically active adults. Behaviorally based exercise interventions, the use of behavior change strategies, supervision by an experienced fitness instructor, and exercise that is pleasant and enjoyable can improve adoption and adherence to prescribed exercise programs. Educating adults about and screening for signs and symptoms of CHD and gradual progression of exercise intensity and volume may reduce the risks of exercise. Consultations with a medical professional and diagnostic exercise testing for CHD are useful when clinically indicated but are not recommended for universal screening to enhance the safety of exercise. Copyright © 2011 by the American College of Sports Medicine.},
	number = {7},
	journal = {Medicine and Science in Sports and Exercise},
	author = {Garber, Carol Ewing and Blissmer, Bryan and Deschenes, Michael R. and Franklin, Barry A. and Lamonte, Michael J. and Lee, I. Min and Nieman, David C. and Swain, David P.},
	year = {2011},
	pmid = {21694556},
	keywords = {aerobic exercise, fitness, flexibility exercise, functional fitness, health, neuromotor exercise, physical, physical activity, practice guidelines, prescription, resistance exercise},
	pages = {1334--1359},
}

@incollection{cai_causal_2018,
	title = {Causal {Discovery} from {Discrete} {Data} using {Hidden} {Compact} {Representation}},
	url = {http://papers.nips.cc/paper/7532-causal-discovery-from-discrete-data-using-hidden-compact-representation.pdf},
	urldate = {2020-09-13},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Cai, Ruichu and Qiao, Jie and Zhang, Kun and Zhang, Zhenjie and Hao, Zhifeng},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	keywords = {causal, causality, discovery, discrete, learning},
	pages = {2666--2674},
}

@article{raghu_comparison_2018,
	title = {Comparison of strategies for scalable causal discovery of latent variable models from mixed data},
	volume = {6},
	issn = {2364-4168},
	url = {https://doi.org/10.1007/s41060-018-0104-3},
	doi = {10.1007/s41060-018-0104-3},
	abstract = {Modern technologies allow large, complex biomedical datasets to be collected from patient cohorts. These datasets are comprised of both continuous and categorical data (“Mixed Data”), and essential variables may be unobserved in this data due to the complex nature of biomedical phenomena. Causal inference algorithms can identify important relationships from biomedical data; however, handling the challenges of causal inference over mixed data with unmeasured confounders in a scalable way is still an open problem. Despite recent advances into causal discovery strategies that could potentially handle these challenges; individually, no study currently exists that comprehensively compares these approaches in this setting. In this paper, we present a comparative study that addresses this problem by comparing the accuracy and efficiency of different strategies in large, mixed datasets with latent confounders. We experiment with two extensions of the Fast Causal Inference algorithm: a maximum probability search procedure we recently developed to identify causal orientations more accurately, and a strategy which quickly eliminates unlikely adjacencies in order to achieve scalability to high-dimensional data. We demonstrate that these methods significantly outperform the state of the art in the field by achieving both accurate edge orientations and tractable running time in simulation experiments on datasets with up to 500 variables. Finally, we demonstrate the usability of the best performing approach on real data by applying it to a biomedical dataset of HIV-infected individuals.},
	language = {en},
	number = {1},
	urldate = {2020-09-13},
	journal = {International Journal of Data Science and Analytics},
	author = {Raghu, Vineet K. and Ramsey, Joseph D. and Morris, Alison and Manatakis, Dimitrios V. and Sprites, Peter and Chrysanthis, Panos K. and Glymour, Clark and Benos, Panayiotis V.},
	month = aug,
	year = {2018},
	pages = {33--45},
}

@article{goyal_explaining_2020,
	title = {Explaining {Classifiers} with {Causal} {Concept} {Effect} ({CaCE})},
	url = {http://arxiv.org/abs/1907.07165},
	abstract = {How can we understand classification decisions made by deep neural networks? Many existing explainability methods rely solely on correlations and fail to account for confounding, which may result in potentially misleading explanations. To overcome this problem, we define the Causal Concept Effect (CaCE) as the causal effect of (the presence or absence of) a human-interpretable concept on a deep neural net's predictions. We show that the CaCE measure can avoid errors stemming from confounding. Estimating CaCE is difficult in situations where we cannot easily simulate the do-operator. To mitigate this problem, we use a generative model, specifically a Variational AutoEncoder (VAE), to measure VAE-CaCE. In an extensive experimental analysis, we show that the VAE-CaCE is able to estimate the true concept causal effect, compared to baselines for a number of datasets including high dimensional images.},
	urldate = {2020-09-15},
	journal = {arXiv:1907.07165 [cs, stat]},
	author = {Goyal, Yash and Feder, Amir and Shalit, Uri and Kim, Been},
	month = feb,
	year = {2020},
	note = {arXiv: 1907.07165},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, causality, classification, inference},
}

@book{spirtes_causation_2000,
	title = {Causation, {Prediction}, and {Search}},
	isbn = {978-0-262-19440-2},
	abstract = {What assumptions and methods allow us to turn observations into causal knowledge, and how can even incomplete causal knowledge be used in planning and prediction to influence and control our environment? In this book Peter Spirtes, Clark Glymour, and Richard Scheines address these questions using the formalism of Bayes networks, with results that have been applied in diverse areas of research in the social, behavioral, and physical sciences. The authors show that although experimental and observational study designs may not always permit the same inferences, they are subject to uniform principles. They axiomatize the connection between causal structure and probabilistic independence, explore several varieties of causal indistinguishability, formulate a theory of manipulation, and develop asymptotically reliable procedures for searching over equivalence classes of causal models, including models of categorical data and structural equation models with and without latent variables. The authors show that the relationship between causality and probability can also help to clarify such diverse topics in statistics as the comparative power of experimentation versus observation, Simpson's paradox, errors in regression models, retrospective versus prospective sampling, and variable selection. The second edition contains a new introduction and an extensive survey of advances and applications that have appeared since the first edition was published in 1993.},
	language = {en},
	publisher = {MIT Press},
	author = {Spirtes, Peter and Glymour, Clark N. and Scheines, Richard and Heckerman, David},
	year = {2000},
	keywords = {Mathematics / Probability \& Statistics / General, causality},
}

@article{liu_virus-induced_2021,
	title = {Virus-induced cell gigantism and asymmetric cell division in archaea},
	volume = {118},
	copyright = {© 2021 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/118/15/e2022578118},
	doi = {10.1073/pnas.2022578118},
	abstract = {Archaeal viruses represent one of the most mysterious parts of the global virosphere, with many virus groups sharing no evolutionary relationship to viruses of bacteria or eukaryotes. How these viruses interact with their hosts remains largely unexplored. Here we show that nonlytic lemon-shaped virus STSV2 interferes with the cell cycle control of its host, hyperthermophilic and acidophilic archaeon Sulfolobus islandicus, arresting the cell cycle in the S phase. STSV2 infection leads to transcriptional repression of the cell division machinery, which is homologous to the eukaryotic endosomal sorting complexes required for transport (ESCRT) system. The infected cells grow up to 20-fold larger in size, have 8,000-fold larger volume compared to noninfected cells, and accumulate massive amounts of viral and cellular DNA. Whereas noninfected Sulfolobus cells divide symmetrically by binary fission, the STSV2-infected cells undergo asymmetric division, whereby giant cells release normal-sized cells by budding, resembling the division of budding yeast. Reinfection of the normal-sized cells produces a new generation of giant cells. If the CRISPR-Cas system is present, the giant cells acquire virus-derived spacers and terminate the virus spread, whereas in its absence, the cycle continues, suggesting that CRISPR-Cas is the primary defense system in Sulfolobus against STSV2. Collectively, our results show how an archaeal virus manipulates the cell cycle, transforming the cell into a giant virion-producing factory.},
	language = {en},
	number = {15},
	urldate = {2021-03-30},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Liu, Junfeng and Cvirkaite-Krupovic, Virginija and Baquero, Diana P. and Yang, Yunfeng and Zhang, Qi and Shen, Yulong and Krupovic, Mart},
	month = apr,
	year = {2021},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {ESCRT system, Saccharolobus, archaea, archaeal viruses, asymmetric cell division, cell strategy, gigantism, virus},
}

@article{das_mitochondrial_2020,
	title = {Mitochondrial hyperfusion: {A} friend or a foe},
	volume = {48},
	shorttitle = {Mitochondrial hyperfusion},
	doi = {10.1042/BST20190987},
	abstract = {The cellular mitochondrial population undergoes repeated cycles of fission and fusion to maintain its integrity, as well as overall cellular homeostasis. While equilibrium usually exists between the fission–fusion dynamics, their rates are influenced by organellar and cellular metabolic and pathogenic conditions. Under conditions of cellular stress, there is a disruption of this fission and fusion balance and mitochondria undergo either increased fusion, forming a hyperfused meshwork or excessive fission to counteract stress and remove damaged mitochondria via mitophagy. While some previous reports suggest that hyperfusion is initiated to ameliorate cellular stress, recent studies show its negative impact on cellular health in disease conditions. The exact mechanism of mitochondrial hyperfusion and its role in maintaining cellular health and homeostasis, however, remain unclear. In this review, we aim to highlight the different aspects of mitochondrial hyperfusion in either promoting or mitigating stress and also its role in immunity and diseases.},
	journal = {Biochemical Society Transactions},
	author = {Das, Rajdeep and Chakrabarti, Oishee},
	month = mar,
	year = {2020},
	keywords = {ER, hyperfusion, mitochondria},
}

@article{Baumgart2016,
	title = {Varying label density allows artifact-free analysis of membrane-protein nanoclusters},
	volume = {13},
	issn = {1548-7091},
	url = {http://www.nature.com/articles/nmeth.3897},
	doi = {10.1038/nmeth.3897},
	abstract = {PALM and STORM are powerful methods for studying membrane-protein clustering. However, fluorophore blinking can lead to miscounting artifacts. A new method shows that varying label density works for artifact-free analysis of membrane-protein nanoclusters.},
	number = {8},
	urldate = {2018-07-04},
	journal = {Nature Methods},
	author = {Baumgart, Florian and Arnold, Andreas M and Leskovar, Konrad and Staszek, Kaj and Fölser, Martin and Weghuber, Julian and Stockinger, Hannes and Schütz, Gerhard J},
	month = aug,
	year = {2016},
	note = {Publisher: Nature Publishing Group},
	keywords = {Fluorescence imaging, Imaging the immune system, Single, Super, molecule biophysics, resolution microscopy},
	pages = {661--664},
}

@article{Yang2017,
	title = {Super-resolution {Visualization} of {Caveola} {Deformation} in {Response} to {Osmotic} {Stress}.},
	volume = {292},
	issn = {1083-351X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/28096469},
	doi = {10.1074/jbc.M116.768499},
	abstract = {Caveolae are protein-dense plasma membrane domains structurally composed of caveolin-1 or -3 along with other proteins. Our previous studies have shown that caveolae enhance calcium signals generated through the Gαq/phospholipase Cβ signaling pathway and that subjecting cells to hypo-osmotic stress reverses this enhancement. In this study, we have used super-resolution fluorescence microscopy supplemented by fluorescence correlation studies to determine the structural factors that underlie this behavior. We find similar and significant population of Gαq and one of its receptors, bradykinin type 2 receptor (B2R), as well as a significant population of Gαi and its coupled β2-adrenergic receptor (βAR), are localized to caveola domains. Although mild osmotic stress deforms caveolae and alters interactions between the caveolae and these proteins, the general structure and the localization of caveola components remain largely unchanged. This deformation eliminates the ability of caveolae to stabilize calcium signals mediated through Gαq-B2R, but does not affect cAMP signals mediated through Gαi and βAR. Structurally, we find that mild osmotic stress corresponding roughly to a pressure of 3.82 newtons/m2 increases the domain diameter by ∼30\% and increases the fluorescence intensity in the center of the domain mouth suggesting a flattening of the invagination. Approximate calculations show that caveolae in muscle tissue have the strength to handle the stress of muscle movement.},
	number = {9},
	urldate = {2018-12-19},
	journal = {The Journal of biological chemistry},
	author = {Yang, Lu and Scarlata, Suzanne},
	month = mar,
	year = {2017},
	pmid = {28096469},
	note = {Publisher: American Society for Biochemistry and Molecular Biology},
	keywords = {G protein, caveolae, fluorescence, membrane structure, osmotic swelling},
	pages = {3779--3788},
}

@article{jayasinghe_nanoscale_2012,
	title = {Nanoscale organization of junctophilin-2 and ryanodine receptors within peripheral couplings of rat ventricular cardiomyocytes},
	issn = {00063495},
	doi = {10.1016/j.bpj.2012.01.034},
	abstract = {The peripheral distributions of the cardiac ryanodine receptor (RyR) and a junctional protein, junctophilin-2 (JPH2), were examined using single fluorophore localization-based super-resolution microscopy in rat ventricular myocytes. JPH2 was strongly associated with RyR clusters. Estimates of the colocalizing fraction of JPH labeling with RyR was ∼90\% within 30 nm of RyR clusters. This is comparable to fractions estimated from confocal data (∼87\%). Similarly, most RyRs were associated with JPH2 labeling in super-resolution images (∼81\% within 30 nm of JPH2 clusters). The shape of associated RyR clusters and JPH2 clusters were very similar, but not identical, suggesting that JPH2 is dispersed throughout RyR clusters and that the packing of JPH2 into junctions and the assembly of RyR clusters are tightly linked. © 2012 Biophysical Society.},
	journal = {Biophysical Journal},
	author = {Jayasinghe, Isuru D. and Baddeley, David and Kong, Cherrie H.T. and Wehrens, Xander H.T. and Cannell, Mark B. and Soeller, Christian},
	year = {2012},
}

@article{Culley2018,
	title = {Quantitative mapping and minimization of super-resolution optical imaging artifacts},
	volume = {15},
	issn = {15487105},
	doi = {10.1038/nmeth.4605},
	abstract = {This paper reports an approach to map errors in super-resolution images, based on quantitative comparison to diffraction-limited equivalents.},
	number = {4},
	journal = {Nature Methods},
	author = {Culley, Siân and Albrecht, David and Jacobs, Caron and Pereira, Pedro Matos and Leterrier, Christophe and Mercer, Jason and Henriques, Ricardo},
	year = {2018},
}

@article{Lee2012,
	title = {Identification of potential treatments for {COVID}-19 through artificial intelligence-enabled phenomic analysis of human cells infected with {SARS}-{CoV}-2},
	volume = {91},
	issn = {00157120},
	url = {http://dx.doi.org/10.1016/j.tws.2012.02.007},
	doi = {10.1017/CBO9781107415324.004},
	abstract = {To identify potential therapeutic stop-gaps for SARS-CoV-2, we evaluated a library of 1,670 approved and reference compounds in an unbiased, cellular image-based screen for their ability to suppress the broad impacts of the SARS-CoV-2 virus on phenomic profiles of human renal cortical epithelial cells using deep learning. In our assay, remdesivir is the only antiviral tested with strong efficacy, neither chloroquine nor hydroxychloroquine have any beneficial effect in this human cell model, and a small number of compounds not currently being pursued clinically for SARS-CoV-2 have efficacy. We observed weak but beneficial class effects of ??-blockers, mTOR/PI3K inhibitors and Vitamin D analogues and a mild amplification of the viral phenotype with ??-agonists.},
	number = {5},
	journal = {Foreign Affairs},
	author = {Nathan, Andrew J. and Scobell, Andrew},
	year = {2012},
	pmid = {25246403},
	note = {arXiv: 1011.1669v3
ISBN: 9788578110796},
	keywords = {Axial crushing, Energy absorption, Impact absorption energy, Origami pattern, Space frame, Thin-walled tubes, Triggering dent, icle},
	pages = {1689--1699},
}

@article{Kato2017,
	title = {Neurobiological basis of bipolar disorder: {Mitochondrial} dysfunction hypothesis and beyond},
	volume = {187},
	issn = {15732509},
	url = {http://dx.doi.org/10.1016/j.schres.2016.10.037},
	doi = {10.1016/j.schres.2016.10.037},
	abstract = {Bipolar disorder is one of two major psychotic disorders together with schizophrenia and causes severe psychosocial disturbance. Lack of adequate animal models hampers development of new mood stabilizers. We proposed a mitochondrial dysfunction hypothesis and have been studying the neurobiology of bipolar disorder based on this hypothesis. We showed that deletions of mitochondrial DNA (ΔmtDNA) play a pathophysiological role at least in some patients with bipolar disorder possibly by affecting intracellular calcium regulation. Mutant polymerase γ transgenic mice that accumulate ΔmtDNA in the brain showed recurrent spontaneous depression-like episodes which were prevented by a serotonin-selective reuptake inhibitor and worsened by lithium withdrawal. The animal model would be useful to develop new mood stabilizers.},
	journal = {Schizophrenia Research},
	author = {Kato, Tadafumi},
	year = {2017},
	pmid = {27839913},
	note = {Publisher: The Author},
	keywords = {Animal model, Bipolar disorder, Calcium, Mitochondrial DNA, Paraventricular thalamic nucleus},
	pages = {62--66},
}

@article{Lopresti2013,
	title = {A review of lifestyle factors that contribute to important pathways associated with major depression: {Diet}, sleep and exercise},
	volume = {148},
	issn = {01650327},
	url = {http://dx.doi.org/10.1016/j.jad.2013.01.014},
	doi = {10.1016/j.jad.2013.01.014},
	abstract = {Research on major depression has confirmed that it is caused by an array of biopsychosocial and lifestyle factors. Diet, exercise and sleep are three such influences that play a significant mediating role in the development, progression and treatment of this condition. This review summarises animal- and human-based studies on the relationship between these three lifestyle factors and major depressive disorder, and their influence on dysregulated pathways associated with depression: namely neurotransmitter processes, immuno-inflammatory pathways, hypothalamic-pituitary-adrenal (HPA) axis disturbances, oxidative stress and antioxidant defence systems, neuroprogression, and mitochondrial disturbances. Increased attention in future clinical studies on the influence of diet, sleep and exercise on major depressive disorder and investigations of their effect on physiological processes will help to expand our understanding and treatment of major depressive disorder. Mental health interventions, taking into account the bidirectional relationship between these lifestyle factors and major depression are also likely to enhance the efficacy of interventions associated with this disorder. © 2013 Elsevier B.V.},
	number = {1},
	journal = {Journal of Affective Disorders},
	author = {Lopresti, Adrian L. and Hood, Sean D. and Drummond, Peter D.},
	year = {2013},
	pmid = {23415826},
	note = {Publisher: Elsevier},
	keywords = {Depression, Diet, Exercise, Physical activity, Sleep, ★},
	pages = {12--27},
}

@misc{sabanayagam_graphon_2021,
	title = {Graphon based {Clustering} and {Testing} of {Networks}: {Algorithms} and {Theory}},
	shorttitle = {Graphon based {Clustering} and {Testing} of {Networks}},
	url = {http://arxiv.org/abs/2110.02722},
	doi = {10.48550/arXiv.2110.02722},
	abstract = {Network-valued data are encountered in a wide range of applications and pose challenges in learning due to their complex structure and absence of vertex correspondence. Typical examples of such problems include classification or grouping of protein structures and social networks. Various methods, ranging from graph kernels to graph neural networks, have been proposed that achieve some success in graph classification problems. However, most methods have limited theoretical justification, and their applicability beyond classification remains unexplored. In this work, we propose methods for clustering multiple graphs, without vertex correspondence, that are inspired by the recent literature on estimating graphons -- symmetric functions corresponding to infinite vertex limit of graphs. We propose a novel graph distance based on sorting-and-smoothing graphon estimators. Using the proposed graph distance, we present two clustering algorithms and show that they achieve state-of-the-art results. We prove the statistical consistency of both algorithms under Lipschitz assumptions on the graph degrees. We further study the applicability of the proposed distance for graph two-sample testing problems.},
	urldate = {2022-08-02},
	publisher = {arXiv},
	author = {Sabanayagam, Mahalakshmi and Vankadara, Leena Chennuru and Ghoshdastidar, Debarghya},
	month = nov,
	year = {2021},
	note = {arXiv:2110.02722 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{brain_virtual_nodate,
	title = {The {Virtual} {Brain}},
	url = {http://www.thevirtualbrain.org/tvb/zwei},
	abstract = {The Virtual Brain: Delivering practical results. For novel clinical applications.},
	language = {en},
	urldate = {2022-09-12},
	journal = {The Virtual Brain},
	author = {Brain, The Virtual},
}

@article{doi:10.1198/000313001300339897,
	title = {The {Abuse} of {Power}},
	volume = {55},
	url = {https://doi.org/10.1198/000313001300339897},
	doi = {10.1198/000313001300339897},
	number = {1},
	journal = {The American Statistician},
	author = {Hoenig, John M and Heisey, Dennis M},
	year = {2001},
	note = {Publisher: Taylor \& Francis},
	keywords = {Bioequivalence testing, Burden of proof, Observed power, Retrospective power analysis, Statistical power, Type II error, power, significance, statistics},
	pages = {19--24},
}

@article{Laketa2018,
	title = {Microscopy in {Infectious} {Disease} {Research}—{Imaging} {Across} {Scales}},
	volume = {430},
	issn = {10898638},
	url = {https://doi.org/10.1016/j.jmb.2018.06.018},
	doi = {10.1016/j.jmb.2018.06.018},
	abstract = {A comprehensive understanding of host–pathogen interactions requires quantitative assessment of molecular events across a wide range of spatiotemporal scales and organizational complexities. Due to recent technical developments, this is currently only achievable with microscopy. This article is providing a general perspective on the importance of microscopy in infectious disease research, with a focus on new imaging modalities that promise to have a major impact in biomedical research in the years to come. Every major technological breakthrough in light microscopy depends on, and is supported by, advancements in computing and information technologies. Bioimage acquisition and analysis based on machine learning will pave the way toward more robust, automated and objective implementation of new imaging modalities and in biomedical research in general. The combination of novel imaging technologies with machine learning and near-physiological model systems promises to accelerate discoveries and breakthroughs in our understanding of infectious diseases, from basic research all the way to clinical applications.},
	number = {17},
	journal = {Journal of Molecular Biology},
	author = {Laketa, Vibor},
	year = {2018},
	note = {Publisher: Elsevier Ltd},
	keywords = {CLEM, SPIM, machine learning, super-resolution light microscopy, virus},
	pages = {2612--2625},
}

@book{liu_online_2022,
	title = {Online {Deep} {Equilibrium} {Learning} for {Regularization} by {Denoising}},
	abstract = {Plug-and-Play Priors (PnP) and Regularization by Denoising (RED) are widely-used frameworks for solving imaging inverse problems by computing fixed-points of operators combining physical measurement models and learned image priors. While traditional PnP/RED formulations have focused on priors specified using image denoisers, there is a growing interest in learning PnP/RED priors that are end-to-end optimal. The recent Deep Equilibrium Models (DEQ) framework has enabled memory-efficient end-to-end learning of PnP/RED priors by implicitly differentiating through the fixed-point equations without storing intermediate activation values. However, the dependence of the computational/memory complexity of the measurement models in PnP/RED on the total number of measurements leaves DEQ impractical for many imaging applications. We propose ODER as a new strategy for improving the efficiency of DEQ through stochastic approximations of the measurement models. We theoretically analyze ODER giving insights into its convergence and ability to approximate the traditional DEQ approach. Our numerical results suggest the potential improvements in training/testing complexity due to ODER on three distinct imaging applications.},
	author = {Liu, Jiaming and Xu, Xiaojian and Gan, Weijie and Shoushtari, Shirin and Kamilov, Ulugbek},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.13051},
}

@article{frechin_high-resolution_2022,
	title = {High-resolution cryo-{EM} performance comparison of two latest-generation cryo electron microscopes on the human ribosome},
	issn = {1047-8477},
	url = {https://www.sciencedirect.com/science/article/pii/S1047847722000752},
	doi = {10.1016/j.jsb.2022.107905},
	abstract = {Recent technological advances in cryo electron microscopy (cryo-EM) have led to new opportunities in the structural biology field. Here we benchmark the performance of two 300 kV latest-generation cryo electron microscopes, Titan Krios G4 from Thermofisher Scientific and CRYO ARM 300 from Jeol, with regards to achieving high resolution single particle reconstructions on a real case sample. We compare potentially limiting factors such as drift rates, astigmatism \& coma aberrations and performance during image processing and show that both microscopes, while comprising rather different technical setups \& parameter settings and equipped with different types of energy filters \& cameras, achieve a resolution of around 2 Å on the human ribosome, a non-symmetric object which constitutes a key drug target. Astigmatism correction, CTF refinement and correction of higher order aberrations through refinement in separate optics groups helped to account for astigmatism/coma caused by beam tilting during multi-spot and multi-hole acquisition in neighbouring holes without stage movement. The obtained maps resolve Mg2+ ions, water molecules, inhibitors and side-chains including chemical modifications. The fact that both instruments can resolve such features will greatly facilitate understanding molecular mechanisms and helps in cryo-EM structure based drug design. The methods and analysis tools used here will be useful also to characterize existing instruments and optimize data acquisition settings and are applicable broadly to other drug targets in structural biology.},
	language = {en},
	urldate = {2022-10-23},
	journal = {Journal of Structural Biology},
	author = {Fréchin, Léo and Holvec, Samuel and von Loeffelholz, Ottilie and Hazemann, Isabelle and Klaholz, Bruno P.},
	month = oct,
	year = {2022},
	pages = {107905},
}

@article{kreutzer_natural-gradient_2022,
	title = {Natural-gradient learning for spiking neurons},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.66526},
	doi = {10.7554/eLife.66526},
	abstract = {In many normative theories of synaptic plasticity, weight updates implicitly depend on the chosen parametrization of the weights. This problem relates, for example, to neuronal morphology: synapses which are functionally equivalent in terms of their impact on somatic firing can differ substantially in spine size due to their different positions along the dendritic tree. Classical theories based on Euclidean-gradient descent can easily lead to inconsistencies due to such parametrization dependence. The issues are solved in the framework of Riemannian geometry, in which we propose that plasticity instead follows natural-gradient descent. Under this hypothesis, we derive a synaptic learning rule for spiking neurons that couples functional efficiency with the explanation of several well-documented biological phenomena such as dendritic democracy, multiplicative scaling, and heterosynaptic plasticity. We therefore suggest that in its search for functional synaptic plasticity, evolution might have come up with its own version of natural-gradient descent.},
	urldate = {2023-01-14},
	journal = {eLife},
	author = {Kreutzer, Elena and Senn, Walter and Petrovici, Mihai A},
	editor = {Latham, Peter and Huguenard, John R},
	month = apr,
	year = {2022},
	keywords = {dendritic learning, efficient learning, homeostasis, natural-gradient descent, parametrization invariance, synaptic plasticity},
	pages = {e66526},
}

@article{van_heel_fourier_2005,
	title = {Fourier shell correlation threshold criteria},
	volume = {151},
	issn = {1047-8477},
	url = {https://www.sciencedirect.com/science/article/pii/S1047847705001292},
	doi = {10.1016/j.jsb.2005.05.009},
	abstract = {The resolution value claimed for an electron microscopical three-dimensional reconstruction indicates the overall quality of the experiment. The Fourier shell correlation (FSC) criterion has now become the standard quality measure. However, what has continued to be controversial is the issue of the FSC threshold level at which one defines the reproducible resolution. Here, we discuss the theoretical behaviour of the FSC in conjunction with the various factors which influence it: the number of “voxels” in a given Fourier shell, the symmetry of the structure, and the size of the structure within the reconstruction volume. Both the theoretical considerations and our model experiments show that fixed-valued FSC threshold (like “0.5”) may never be used in a reproducible criterion. Fixed threshold values are—as we show here—simply the result of incorrect assumptions in the basic statistics. Two families of FSC threshold curves are discussed: the σ-factor curves and the new family of bit-based information threshold curves. Whereas σ-factor curves indicate the resolution level at which one has collected information significantly above the noise level, the information curves indicate the resolution level at which enough information has been collected for interpretation.},
	language = {en},
	number = {3},
	urldate = {2023-04-18},
	journal = {Journal of Structural Biology},
	author = {van Heel, Marin and Schatz, Michael},
	month = sep,
	year = {2005},
	keywords = {Fourier shell correlation, Information, Resolution criteria, Single particles, cryo-EM},
	pages = {250--262},
}

@article{mancebo_efficient_2021,
	title = {Efficient {Cross}-{Correlation} {Filtering} of {One}- and {Two}-{Color} {Single} {Molecule} {Localization} {Microscopy} {Data}},
	volume = {1},
	issn = {2673-7647},
	url = {https://www.frontiersin.org/articles/10.3389/fbinf.2021.739769},
	abstract = {Single molecule localization microscopy has become a prominent technique to quantitatively study biological processes below the optical diffraction limit. By fitting the intensity profile of single sparsely activated fluorophores, which are often attached to a specific biomolecule within a cell, the locations of all imaged fluorophores are obtained with ∼20 nm resolution in the form of a coordinate table. While rendered super-resolution images reveal structural features of intracellular structures below the optical diffraction limit, the ability to further analyze the molecular coordinates presents opportunities to gain additional quantitative insights into the spatial distribution of a biomolecule of interest. For instance, pair-correlation or radial distribution functions are employed as a measure of clustering, and cross-correlation analysis reveals the colocalization of two biomolecules in two-color SMLM data. Here, we present an efficient filtering method for SMLM data sets based on pair- or cross-correlation to isolate localizations that are clustered or appear in proximity to a second set of localizations in two-color SMLM data. In this way, clustered or colocalized localizations can be separately rendered and analyzed to compare other molecular properties to the remaining localizations, such as their oligomeric state or mobility in live cell experiments. Current matrix-based cross-correlation analyses of large data sets quickly reach the limitations of computer memory due to the space complexity of constructing the distance matrices. Our approach leverages k-dimensional trees to efficiently perform range searches, which dramatically reduces memory needs and the time for the analysis. We demonstrate the versatile applications of this method with simulated data sets as well as examples of two-color SMLM data. The provided MATLAB code and its description can be integrated into existing localization analysis packages and provides a useful resource to analyze SMLM data with new detail.},
	urldate = {2023-04-19},
	journal = {Frontiers in Bioinformatics},
	author = {Mancebo, Angel and Mehra, Dushyant and Banerjee, Chiranjib and Kim, Do-Hyung and Puchner, Elias M.},
	year = {2021},
}

@article{levet_tessellation-based_2019,
	title = {A tessellation-based colocalization analysis approach for single-molecule localization microscopy},
	volume = {10},
	copyright = {2019 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-10007-4},
	doi = {10.1038/s41467-019-10007-4},
	abstract = {Multicolor single-molecule localization microscopy (λSMLM) is a powerful technique to reveal the relative nanoscale organization and potential colocalization between different molecular species. While several standard analysis methods exist for pixel-based images, λSMLM still lacks such a standard. Moreover, existing methods only work on 2D data and are usually sensitive to the relative molecular organization, a very important parameter to consider in quantitative SMLM. Here, we present an efficient, parameter-free colocalization analysis method for 2D and 3D λSMLM using tessellation analysis. We demonstrate that our method allows for the efficient computation of several popular colocalization estimators directly from molecular coordinates and illustrate its capability to analyze multicolor SMLM data in a robust and efficient manner.},
	language = {en},
	number = {1},
	urldate = {2023-04-20},
	journal = {Nature Communications},
	author = {Levet, Florian and Julien, Guillaume and Galland, Rémi and Butler, Corey and Beghin, Anne and Chazeau, Anaël and Hoess, Philipp and Ries, Jonas and Giannone, Grégory and Sibarita, Jean-Baptiste},
	month = may,
	year = {2019},
	keywords = {Data processing, Software},
	pages = {2379},
}

@article{marsh_artifact-free_2018,
	title = {Artifact-free high-density localization microscopy analysis},
	volume = {15},
	copyright = {2018 The Author(s)},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-018-0072-5},
	doi = {10.1038/s41592-018-0072-5},
	abstract = {High-density analysis methods for localization microscopy increase acquisition speed but produce artifacts. We demonstrate that these artifacts can be eliminated by the combination of Haar wavelet kernel (HAWK) analysis with standard single-frame fitting. We tested the performance of this method on synthetic, fixed-cell, and live-cell data, and found that HAWK preprocessing yielded reconstructions that reflected the structure of the sample, thus enabling high-speed, artifact-free super-resolution imaging of live cells.},
	language = {en},
	number = {9},
	urldate = {2023-05-10},
	journal = {Nature Methods},
	author = {Marsh, Richard J. and Pfisterer, Karin and Bennett, Pauline and Hirvonen, Liisa M. and Gautel, Mathias and Jones, Gareth E. and Cox, Susan},
	month = sep,
	year = {2018},
	keywords = {Fluorescence imaging, Software, Super, Super-resolution microscopy, resolution microscopy},
	pages = {689--692},
}

@article{loschberger_correlative_2014,
	title = {Correlative super-resolution fluorescence and electron microscopy of the nuclear pore complex with molecular resolution},
	volume = {127},
	issn = {0021-9533},
	url = {https://doi.org/10.1242/jcs.156620},
	doi = {10.1242/jcs.156620},
	abstract = {Here, we combine super-resolution fluorescence localization microscopy with scanning electron microscopy to map the position of proteins of nuclear pore complexes in isolated Xenopus laevis oocyte nuclear envelopes with molecular resolution in both imaging modes. We use the periodic molecular structure of the nuclear pore complex to superimpose direct stochastic optical reconstruction microscopy images with a precision of \&lt;20 nm on electron micrographs. The correlative images demonstrate quantitative molecular labeling and localization of nuclear pore complex proteins by standard immunocytochemistry with primary and secondary antibodies and reveal that the nuclear pore complex is composed of eight gp210 (also known as NUP210) protein homodimers. In addition, we find subpopulations of nuclear pore complexes with ninefold symmetry, which are found occasionally among the more typical eightfold symmetrical structures.},
	number = {20},
	urldate = {2023-05-10},
	journal = {Journal of Cell Science},
	author = {Löschberger, Anna and Franke, Christian and Krohne, Georg and van de Linde, Sebastian and Sauer, Markus},
	month = oct,
	year = {2014},
	keywords = {Animals, Correlative electron and super-resolution fluorescence microscopy, Image Processing, Computer-Assisted, Immunohistochemistry, Localization microscopy, Microscopy, Electron, Scanning, Microscopy, Fluorescence, Molecular Structure, Nuclear Envelope, Nuclear Pore, Nuclear Pore Complex Proteins, Nuclear pore complex, Oocytes, Protein Multimerization, Quantification, Xenopus Proteins, Xenopus laevis, dSTORM},
	pages = {4351--4355},
}

@article{nicovich_turning_2017,
	title = {Turning single-molecule localization microscopy into a quantitative bioanalytical tool},
	volume = {12},
	issn = {1750-2799},
	doi = {10.1038/nprot.2016.166},
	abstract = {Single-molecule localization microscopy (SMLM) generates super-resolution images by serially detecting individual fluorescent molecules. The power of SMLM, however, goes beyond images: biologically relevant information can be extracted from the mathematical relationships between the positions of the fluorophores in space and time. Here we review the history of SMLM and how recent progress in methods for spatial point analysis has enabled quantitative measurement of SMLM data, providing insights into biomolecule patterning, clustering and oligomerization in biological systems.},
	language = {eng},
	number = {3},
	journal = {Nature Protocols},
	author = {Nicovich, Philip R. and Owen, Dylan M. and Gaus, Katharina},
	month = mar,
	year = {2017},
	pmid = {28151466},
	keywords = {Chemistry Techniques, Analytical, Single Molecule Imaging},
	pages = {453--460},
}

@article{glymour_review_2019,
	title = {Review of {Causal} {Discovery} {Methods} {Based} on {Graphical} {Models}},
	volume = {10},
	issn = {1664-8021},
	url = {https://www.frontiersin.org/articles/10.3389/fgene.2019.00524},
	abstract = {A fundamental task in various disciplines of science, including biology, is to find underlying causal relations and make use of them. Causal relations can be seen if interventions are properly applied; however, in many cases they are difficult or even impossible to conduct. It is then necessary to discover causal relations by analyzing statistical properties of purely observational data, which is known as causal discovery or causal structure search. This paper aims to give a introduction to and a brief review of the computational methods for causal discovery that were developed in the past three decades, including constraint-based and score-based methods and those based on functional causal models, supplemented by some illustrations and applications.},
	urldate = {2023-06-29},
	journal = {Frontiers in Genetics},
	author = {Glymour, Clark and Zhang, Kun and Spirtes, Peter},
	year = {2019},
	keywords = {Conditional independence, Directed graphical causal models, Non-linear models, Statistical independence, Structural Equation Models, causal, causal discovery, causality, graphs, non-Gaussian distribution, statistics},
}

@incollection{ulman_chapter_2022,
	series = {The {MICCAI} {Society} book  {Series}},
	title = {Chapter 21 - {Review} of cell image synthesis for image processing},
	isbn = {978-0-12-824349-7},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128243497000281},
	abstract = {Opposites attract, also in the biomedical field and during the processing of cell microscopy images. In the same spirit, image processing, the indispensable analyst tool, is often supported by image synthesis applications. Image synthesis is a methodology implemented in computer program intended to create artificial cell images similar to images from real microscopy. The generation of artificial images has had a stable tradition in image processing and is currently gaining more attention with the rising popularity of deep learning. This chapter reviews the current state of cell image synthesis, including terminology, broader context, goals, and peculiarities. It offers a brief historical introspection and, most importantly, surveys all contemporary methodology and applications. The light descriptions of procedural methods with explicit parameters and deep learning-based methods with implicit parameters, such as the generative adversarial networks, are also included. Last but not least, this chapter discusses what kind of artificial images and ground-truth data the methods generate, including the subsequent usage of this data for image processing such as cell segmentation or data augmentation for deep learning. Among the covered methods are approaches generating artificial cell microscopy images of fluorescence stained proteins, actin filaments, chromatin stained nuclei, membranes, and even populations of cells or full cells in differential inference contrast microscopy, to name a few. The generated data is often accompanied by ground truth annotation, whose forms are also discussed, including cell detection markers, full cell segmentation, and cell tracking data.},
	language = {en},
	urldate = {2023-03-14},
	booktitle = {Biomedical {Image} {Synthesis} and {Simulation}},
	publisher = {Academic Press},
	author = {Ulman, Vladimír and Wiesner, David},
	editor = {Burgos, Ninon and Svoboda, David},
	month = jan,
	year = {2022},
	doi = {10.1016/B978-0-12-824349-7.00028-1},
	keywords = {Biomedical application, Cell segmentation, Deep learning, Ground-truth data, Image synthesis},
	pages = {447--489},
}

@article{venkataramani_suresim_2016,
	title = {{SuReSim}: simulating localization microscopy experiments from ground truth models},
	volume = {13},
	issn = {1548-7105},
	shorttitle = {{SuReSim}},
	doi = {10.1038/nmeth.3775},
	abstract = {Super-resolution fluorescence microscopy has become a widely used tool in many areas of research. However, designing and validating super-resolution experiments to address a research question in a technically feasible and scientifically rigorous manner remains a fundamental challenge. We developed SuReSim, a software tool that simulates localization data of arbitrary three-dimensional structures represented by ground truth models, allowing users to systematically explore how changing experimental parameters can affect potential imaging outcomes.},
	language = {eng},
	number = {4},
	journal = {Nature Methods},
	author = {Venkataramani, Varun and Herrmannsdörfer, Frank and Heilemann, Mike and Kuner, Thomas},
	month = apr,
	year = {2016},
	pmid = {26928761},
	keywords = {Algorithms, Computational Biology, Humans, Image Processing, Computer-Assisted, Imaging, Three-Dimensional, Microscopy, Fluorescence, Software, Synaptic Vesicles},
	pages = {319--321},
}

@article{rossy_method_2014,
	title = {Method for co-cluster analysis in multichannel single-molecule localisation data},
	volume = {141},
	issn = {1432-119X},
	doi = {10.1007/s00418-014-1208-z},
	abstract = {We demonstrate a combined univariate and bivariate Getis and Franklin's local point pattern analysis method to investigate the co-clustering of membrane proteins in two-dimensional single-molecule localisation data. This method assesses the degree of clustering of each molecule relative to its own species and relative to a second species. Using simulated data, we show that this approach can quantify the degree of cluster overlap in multichannel point patterns. The method is validated using photo-activated localisation microscopy and direct stochastic optical reconstruction microscopy data of the proteins Lck and CD45 at the T cell immunological synapse. Analysing co-clustering in this manner is generalizable to higher numbers of fluorescent species and to three-dimensional or live cell data sets.},
	language = {eng},
	number = {6},
	journal = {Histochemistry and Cell Biology},
	author = {Rossy, Jérémie and Cohen, Edward and Gaus, Katharina and Owen, Dylan M.},
	month = jun,
	year = {2014},
	pmid = {24643361},
	keywords = {Cluster analysis, Co-localisation, Humans, Image Processing, Computer-Assisted, Immunological Synapses, Jurkat Cells, Leukocyte Common Antigens, Lymphocyte Specific Protein Tyrosine Kinase p56(lck), Microscopy, Fluorescence, PALM, STORM, Super-resolution, T-Lymphocytes},
	pages = {605--612},
}

@article{aberg_single-molecule_2021,
	title = {Single-molecule localisation microscopy: accounting for chance co-localisation between foci in bacterial cells},
	volume = {50},
	issn = {1432-1017},
	shorttitle = {Single-molecule localisation microscopy},
	url = {https://doi.org/10.1007/s00249-021-01555-z},
	doi = {10.1007/s00249-021-01555-z},
	abstract = {Using single-molecule fluorescence microscopes, individual biomolecules can be observed within live bacterial cells. Using differently coloured probes, physical associations between two different molecular species can be assessed through co-localisation measurements. However, bacterial cells are finite and small ({\textasciitilde} 1 μm) relative to the resolution limit of optical microscopes ({\textasciitilde} 0.25 μm). Furthermore, the images produced by optical microscopes are typically two-dimensional projections of three-dimensional objects. These limitations mean that a certain proportion of object pairs (molecules) will inevitably be assigned as being co-localised, even when they are distant at molecular distance scales (nm). What is this proportion? Here, we attack this problem, theoretically and computationally, by creating a model of the co-localisation expected purely due to chance. We thus consider a bacterial cell wherein objects are distributed at random and evaluate the co-localisation in a fashion that emulates an experimental analysis. We consider simplified geometries where we can most transparently investigate the effect of a finite size of the cell and the effect of probing a three-dimensional cell in only two dimensions. Coupling theory to simulations, we also study the co-localisation expected due to chance using parameters relevant to bacterial cells. Overall, we show that the co-localisation expected purely due to chance can be quite substantial and describe the parameters that it depends upon.},
	language = {en},
	number = {7},
	urldate = {2023-05-23},
	journal = {European Biophysics Journal},
	author = {Åberg, Christoffer and Robinson, Andrew},
	month = oct,
	year = {2021},
	keywords = {Bacterial cells, Co-localisation, Fluorescence microscopy, Pair distribution function, Radial distribution function, Single-molecule experiments},
	pages = {941--950},
}

@misc{noauthor_levy_nodate,
	title = {Lévy {Flight} - an overview {\textbar} {ScienceDirect} {Topics}},
	url = {https://www.sciencedirect.com/topics/physics-and-astronomy/levy-flight},
	urldate = {2023-08-15},
}

@article{giacomello_coming_2016,
	title = {The coming of age of the mitochondria–{ER} contact: a matter of thickness},
	volume = {23},
	issn = {1350-9047, 1476-5403},
	shorttitle = {The coming of age of the mitochondria–{ER} contact},
	url = {https://www.nature.com/articles/cdd201652},
	doi = {10.1038/cdd.2016.52},
	language = {en},
	number = {9},
	urldate = {2023-10-29},
	journal = {Cell Death \& Differentiation},
	author = {Giacomello, M and Pellegrini, L},
	month = sep,
	year = {2016},
	keywords = {Alzheimer Disease, Animals, Calcium, Endoplasmic Reticulum, Humans, Mitochondria, Mitochondrial Membranes, Phospholipids},
	pages = {1417--1427},
}

@article{matthaeus_flat_2022,
	title = {From {Flat} to {Bulb} - {Novel} {Insights} in {Caveolae} {Membrane} {Curvature}},
	volume = {36},
	url = {https://faseb.onlinelibrary.wiley.com/doi/abs/10.1096/fasebj.2022.36.S1.0R426},
	doi = {https://doi.org/10.1096/fasebj.2022.36.S1.0R426},
	number = {S1},
	journal = {The FASEB Journal},
	author = {Matthaeus, Claudia and Sochacki, Kem and Puchkov, Dmytro and Haucke, Volker and Lehmann, Martin and Taraska, Justin},
	year = {2022},
	note = {\_eprint: https://faseb.onlinelibrary.wiley.com/doi/pdf/10.1096/fasebj.2022.36.S1.0R426},
}

@article{kolln_label2label_2022,
	title = {Label2label: {Training} a neural network to selectively restore cellular structures in fluorescence microscopy},
	volume = {135},
	doi = {10.1242/jcs.258994},
	journal = {Journal of Cell Science},
	author = {Kölln, Lisa and Salem, Omar and Valli, Jessica and Hansen, Carsten and McConnell, Gail},
	month = jan,
	year = {2022},
}

@article{alam_characterization_2022,
	title = {Characterization of mitochondrial dysfunction due to laser damage by 2-photon {FLIM} microscopy},
	volume = {12},
	number = {1},
	journal = {Scientific reports},
	author = {Alam, Shagufta Rehman and Wallrabe, Horst and Christopher, Kathryn G and Siller, Karsten H and Periasamy, Ammasi},
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	pages = {1--12},
}

@article{bosquet_stdnet-st_2021,
	title = {{STDnet}-{ST}: {Spatio}-temporal {ConvNet} for small object detection},
	volume = {116},
	doi = {10.1016/j.patcog.2021.107929},
	journal = {Pattern Recognition},
	author = {Bosquet, Brais and Mucientes, Manuel and Brea, Victor},
	month = mar,
	year = {2021},
	pages = {107929},
}

@article{hill_ptrf-cavin_2008,
	title = {{PTRF}-{Cavin}, a conserved cytoplasmic protein required for caveola formation and function},
	volume = {132},
	number = {1},
	journal = {Cell},
	author = {Hill, Michelle M and Bastiani, Michele and Luetterforst, Robert and Kirkham, Matthew and Kirkham, Annika and Nixon, Susan J and Walser, Piers and Abankwa, Daniel and Oorschot, Viola MJ and Martin, Sally and {others}},
	year = {2008},
	note = {Publisher: Elsevier},
	pages = {113--124},
}

@misc{noauthor_handbook_nodate,
	title = {Handbook of {Fuzzy} {Computation} {\textbar} {E} {Ruspini}, {P} {Bonissone}, {W} {Pedrycz} {\textbar} {Ta}},
	url = {https://www-taylorfrancis-com.proxy.lib.sfu.ca/pdfviewer/},
	urldate = {2023-01-05},
}

@book{jolicoeur-martineau_relativistic_2018,
	title = {The relativistic discriminator: a key element missing from standard {GAN}},
	shorttitle = {The relativistic discriminator},
	abstract = {In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real. The generator is trained to increase the probability that fake data is real. We argue that it should also simultaneously decrease the probability that real data is real because 1) this would account for a priori knowledge that half of the data in the mini-batch is fake, 2) this would be observed with divergence minimization, and 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. We show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data. We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average. We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs which use the identity function. Empirically, we observe that 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400\%), and 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization.},
	author = {Jolicoeur-Martineau, Alexia},
	month = jul,
	year = {2018},
}

@article{Scaini2016a,
	title = {Mitochondrial dysfunction in bipolar disorder: {Evidence}, pathophysiology and translational implications},
	volume = {68},
	issn = {18737528},
	url = {http://dx.doi.org/10.1016/j.neubiorev.2016.06.040},
	doi = {10.1016/j.neubiorev.2016.06.040},
	abstract = {Bipolar disorder (BD) is a chronic psychiatric illness characterized by severe and biphasic changes in mood. Several pathophysiological mechanisms have been hypothesized to underpin the neurobiology of BD, including the presence of mitochondrial dysfunction. A confluence of evidence points to an underlying dysfunction of mitochondria, including decreases in mitochondrial respiration, high-energy phosphates and pH; changes in mitochondrial morphology; increases in mitochondrial DNA polymorphisms; and downregulation of nuclear mRNA molecules and proteins involved in mitochondrial respiration. Mitochondria play a pivotal role in neuronal cell survival or death as regulators of both energy metabolism and cell survival and death pathways. Thus, in this review, we discuss the genetic and physiological components of mitochondria and the evidence for mitochondrial abnormalities in BD. The final part of this review discusses mitochondria as a potential target of therapeutic interventions in BD.},
	journal = {Neuroscience and Biobehavioral Reviews},
	author = {Scaini, Giselli and Rezin, Gislaine T. and Carvalho, Andre F. and Streck, Emilio L. and Berk, Michael and Quevedo, João},
	year = {2016},
	pmid = {27377693},
	note = {Publisher: Elsevier Ltd},
	keywords = {Apoptosis, Bipolar disorder, Depression, Inflammation, Mania, Mitochondria, Mitochondrial dysfunction, Neurogenesis, Oxidative stress},
	pages = {694--713},
}

@article{Burroughs2007,
	title = {Depression and anxiety: {Role} of mitochondria},
	volume = {18},
	issn = {09537112},
	doi = {10.1016/j.cacc.2007.01.007},
	abstract = {Depressive and anxiety disorders appear to share an underlying element of distress, forming a general class of mood disorders. The diagnosis of chronic stress-related disorders can be difficult because of non-specific symptoms being masked by other co-morbid states that may also be inadequately described by the patient. Co-morbidity with psychiatric disorders is common, especially in major depressive disorder. It is important to differentiate chronic and acute stress-related disorders, triggered by life events or stressors. Dysfunction in monoamine neurotransmitter systems have for the last 40 years remained the central model considered to play an important role in mediating the physiological and cognitive aspects of depression. The pharmacological action of antidepressants occurs within minutes to hours after administration, but the clinical effect and alleviation of symptoms can take 10-14 days following chronic administration. The discrepancy between pharmacological action and clinical relief of symptoms implies that monoamine depletion alone forming the underlying pathogenesis of depression may be oversimplified. Several neurotransmitters and neuropeptides play a role in the complex neuroanatomical pathways in anxiety. Complex intracellular cascades upregulated in stress-related disorders appear to be intimately associated with the metabolic integrity and capacity of mitochondria to maintain energetic parameters and ultimately cellular stability. Future therapeutic intervention may lie in understanding the interrelationship between hormonal, metabolic and molecular intracellular signaling pathways involved in these conditions. Thus, targeting mitochondrial function may represent a novel avenue for the development of therapies for the treatment of stress-related disorders. © 2007 Elsevier Ltd. All rights reserved.},
	number = {1},
	journal = {Current Anaesthesia and Critical Care},
	author = {Burroughs, Stephanie and French, Denise},
	year = {2007},
	keywords = {Ant-depressants, BDNF, Glutamate, Mitochondria, Mood disorders},
	pages = {34--41},
}

@misc{wei_theoretical_2022,
	title = {Theoretical {Analysis} of {Self}-{Training} with {Deep} {Networks} on {Unlabeled} {Data}},
	url = {http://arxiv.org/abs/2010.03622},
	doi = {10.48550/arXiv.2010.03622},
	abstract = {Self-training algorithms, which train a model to fit pseudolabels predicted by another previously-learned model, have been very successful for learning with unlabeled data using neural networks. However, the current theoretical understanding of self-training only applies to linear models. This work provides a unified theoretical analysis of self-training with deep networks for semi-supervised learning, unsupervised domain adaptation, and unsupervised learning. At the core of our analysis is a simple but realistic "expansion" assumption, which states that a low probability subset of the data must expand to a neighborhood with large probability relative to the subset. We also assume that neighborhoods of examples in different classes have minimal overlap. We prove that under these assumptions, the minimizers of population objectives based on self-training and input-consistency regularization will achieve high accuracy with respect to ground-truth labels. By using off-the-shelf generalization bounds, we immediately convert this result to sample complexity guarantees for neural nets that are polynomial in the margin and Lipschitzness. Our results help explain the empirical successes of recently proposed self-training algorithms which use input consistency regularization.},
	urldate = {2023-03-13},
	publisher = {arXiv},
	author = {Wei, Colin and Shen, Kendrick and Chen, Yining and Ma, Tengyu},
	month = apr,
	year = {2022},
	note = {arXiv:2010.03622 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hayer_biogenesis_2010,
	title = {Biogenesis of {Caveolae}: stepwise assembly of large caveolin and {Cavin} complexes},
	volume = {11},
	number = {3},
	journal = {Traffic},
	author = {Hayer, Arnold and Stoeber, Miriam and Bissig, Christin and Helenius, Ari},
	year = {2010},
	note = {Publisher: Wiley Online Library},
	keywords = {Caveolae, Caveolin, Cavin, ER, Exocytosis, GFP-GPI, GFP‐GPI, Golgi, PTRF, Secretory pathway, VSVG, caveolae, caveolin, cavin, exocytosis, secretory pathway},
	pages = {361--382},
}

@article{reyes_interpretability_2020,
	title = {On the {Interpretability} of {Artificial} {Intelligence} in {Radiology}: {Challenges} and {Opportunities}},
	volume = {2},
	number = {3},
	journal = {Radiology: Artificial Intelligence},
	author = {Reyes, Mauricio et al.},
	year = {2020},
	note = {Publisher: Radiological Society of North America},
	keywords = {interpretable, radiology, review},
	pages = {e190043},
}

@inproceedings{zhang_mdnet_2017,
	title = {{MDNet}: {A} {Semantically} and {Visually} {Interpretable} {Medical} {Image} {Diagnosis} {Network}},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Zhang, Zizhao and Xie, Yuanpu and Xing, Fuyong and McGough, Mason and Yang, Lin},
	month = jul,
	year = {2017},
	keywords = {deep learning, diagnosis, interpretable, multi-modal},
}

@misc{author,
	title = {No {Title}},
}

@article{ioannidis_why_2005,
	title = {Why most published research findings are false},
	volume = {2},
	number = {8},
	journal = {PLos Medicine},
	author = {Ioannidis, John PA},
	year = {2005},
	note = {Publisher: Public Library of Science},
	pages = {e124},
}

@article{andrews_isometric_2014,
	title = {The isometric log-ratio transform for probabilistic multi-label anatomical shape representation},
	volume = {33},
	number = {9},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Andrews, Shawn and Changizi, Neda and Hamarneh, Ghassan},
	year = {2014},
	note = {Publisher: IEEE},
	keywords = {Aitchison geometry, Bayesian inference, LogOdds, isometric log-ratio (ILR), probabilistic labels, probabilistic segmentation, statistical shape analysis, uncertainty},
	pages = {1890--1899},
}

@article{meng_galectin-3_2015,
	title = {Galectin-3 overrides {PTRF}/{Cavin}-1 reduction of {PC3} prostate cancer cell migration},
	volume = {10},
	number = {5},
	journal = {PloS one},
	author = {Meng, Fanrui and Joshi, Bharat and Nabi, Ivan Robert},
	year = {2015},
	note = {Publisher: Public Library of Science},
	pages = {e0126056},
}

@article{monier_vip21-caveolin_1995,
	title = {{VIP21}-caveolin, a membrane protein constituent of the caveolar coat, oligomerizes in vivo and in vitro.},
	volume = {6},
	number = {7},
	journal = {Molecular Biology of the Cell},
	author = {Monier, Solange and Parton, Robert G and Vogel, Frank and Behlke, Joachim and Henske, Annemarie and Kurzchalia, Teymuras V},
	year = {1995},
	note = {Publisher: Am Soc Cell Biol},
	pages = {911--927},
}

@article{stoeber_model_2016,
	title = {Model for the architecture of {Caveolae} based on a flexible, net-like assembly of {Cavin1} and {Caveolin} discs},
	volume = {113},
	number = {50},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Stoeber, Miriam et al.},
	year = {2016},
	note = {Publisher: National Acad Sciences},
	pages = {E8069--E8078},
}

@article{vecchiarelli_membrane-bound_2016,
	title = {Membrane-bound {MinDE} complex acts as a toggle switch that drives {Min} oscillation coupled to cytoplasmic depletion of {MinD}},
	volume = {113},
	number = {11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Vecchiarelli, Anthony G et al.},
	year = {2016},
	note = {Publisher: National Acad Sciences},
	pages = {E1479--E1488},
}

@article{gao_reticulon_2019,
	title = {Reticulon and {CLIMP}-63 regulate nanodomain organization of peripheral {ER} tubules},
	volume = {17},
	number = {8},
	journal = {PLoS Biology},
	author = {Gao, Guang and Zhu, Chengjia and Liu, Emma and Nabi, Ivan R},
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Animals, COS Cells, Cell Line, Tumor, Chlorocebus aethiops, Cytoskeleton, Endoplasmic Reticulum, Humans, Membrane Proteins, Membranes, Microtubules, Nogo Proteins, Nonlinear Optical Microscopy},
	pages = {e3000355},
}

@article{khater_super-resolution_2019,
	title = {Super-resolution modularity analysis shows polyhedral {Caveolin}-1 oligomers combine to form scaffolds and {Caveolae}},
	volume = {9},
	number = {1},
	journal = {Scientific Reports},
	author = {Khater, Ismail M and Liu, Qian and Chou, Keng C and Hamarneh, Ghassan and Nabi, Ivan Robert},
	year = {2019},
	note = {Publisher: Nature Publishing Group},
	keywords = {Caveolae, Image processing, Super-resolution microscopy},
	pages = {1--10},
}

@article{qiu_development_2020,
	title = {Development and validation of an interpretable deep learning framework for {Alzheimer}’s disease classification},
	volume = {143},
	issn = {0006-8950},
	number = {6},
	journal = {Brain},
	author = {Qiu, Shangran et al.},
	month = may,
	year = {2020},
	note = {\_eprint: https://academic.oup.com/brain/article-pdf/143/6/1920/33446057/awaa137.pdf},
	keywords = {alzheimer, classification, deep learning, interpretable},
	pages = {1920--1933},
}

@inproceedings{qu_joint_2019,
	title = {Joint {Segmentation} and {Fine}-{Grained} {Classification} of {Nuclei} in {Histopathology} {Images}},
	booktitle = {2019 {IEEE} 16th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI} 2019)},
	author = {Qu, H. and Riedlinger, G. and Wu, P. and Huang, Q. and Yi, J. and De, S. and Metaxas, D.},
	year = {2019},
	keywords = {Cancer, Feature extraction, Image color analysis, Image segmentation, Nuclei segmentation, Task analysis, Training, Tumors, biomedical optical imaging, cancer, cancer diagnosis, cellular biophysics, classification, deep learning, deep learning based method, histopathology, histopathology image analysis, image classification, image segmentation, learning (artificial intelligence), lung, lymphocyte, medical image processing, morphological features, neural nets, nuclei classification, nuclei distributions, nucleus, prognosis, relatively small lung cancer dataset, segment individual nuclei, spatial distributions, spatial heterogeneity, stroma nuclei, tumours},
	pages = {900--904},
}

@article{quellec_multiple-instance_2017,
	title = {Multiple-instance learning for medical image and video analysis},
	volume = {10},
	journal = {IEEE Reviews in Biomedical Engineering},
	author = {Quellec, Gwenolé and Cazuguel, Guy and Cochener, Béatrice and Lamard, Mathieu},
	year = {2017},
	note = {Publisher: IEEE},
	keywords = {Algorithm design and analysis, Algorithms, Biomedical image processing, Cancer, Databases as Topic, Feature extraction, Humans, Image Interpretation, Computer-Assisted, Image segmentation, Lesions, MIL algorithms, MIVA-specific MIL algorithms, Medical image analysis, Models, Theoretical, Video Recording, image classification, image segmentation, image segmentations, learning (artificial intelligence), machine-learning paradigm, medical image analysis, medical image datasets, medical image processing, medical video analysis, medical video datasets, multiple instance learning, multiple-instance learning, multiple-instance learning (MIL), reviews},
	pages = {213--234},
}

@article{girard_joint_2019,
	title = {Joint segmentation and classification of retinal arteries/veins from fundus images},
	volume = {94},
	journal = {Artificial Intelligence in Medicine},
	author = {Girard, Fantin and Kavalec, Conrad and Cheriet, Farida},
	year = {2019},
	note = {Publisher: Elsevier},
	keywords = {Artery and vein classification, CNN, Fundus images, Retina, Vessel segmentation, arteries, classfication, graph, joint, retinopathy, segmentation},
	pages = {96--109},
}

@article{lagache_statistical_2015,
	title = {Statistical analysis of molecule colocalization in bioimaging},
	volume = {87},
	number = {6},
	journal = {Cytometry Part A},
	author = {Lagache, Thibault and Sauvonnet, Nathalie and Danglot, Lydia and Olivo-Marin, Jean-Christophe},
	year = {2015},
	note = {Publisher: Wiley Online Library},
	keywords = {Colocalization, Endocytosis, Light microscopy, Quantitative measurements, Spatial statistics},
	pages = {568--579},
}

@article{yong_combining_2004,
	title = {Combining belief functions based on distance of evidence},
	volume = {38},
	issn = {01679236},
	number = {3},
	journal = {Decision Support Systems},
	author = {Yong, Deng and WenKang, Shi and ZhenFu, Zhu and Qi, Liu},
	year = {2004},
	keywords = {Decision-making, Distance function, Evidence theory},
	pages = {489--493},
}

@article{zimek_survey_2012,
	title = {A survey on unsupervised outlier detection in high-dimensional numerical data},
	volume = {5},
	number = {5},
	journal = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
	author = {Zimek, Arthur and Schubert, Erich and Kriegel, Hans-Peter},
	year = {2012},
	note = {Publisher: Wiley Online Library},
	pages = {363--387},
}

@article{florea_robust_2009,
	title = {Robust combination rules for evidence theory},
	volume = {10},
	number = {2},
	journal = {Information Fusion},
	author = {Florea, Mihai Cristian and Jousselme, Anne-Laure and Bossé, Éloi and Grenier, Dominic},
	year = {2009},
	note = {Publisher: Elsevier},
	keywords = {Adaptive weightings, Evidence theory, Information fusion, Reliability, Robust combination rules},
	pages = {183--197},
}

@article{kraus_classifying_2016,
	title = {Classifying and segmenting microscopy images with deep multiple instance learning},
	volume = {32},
	number = {12},
	journal = {Bioinformatics},
	author = {Kraus, Oren Z and Ba, Jimmy Lei and Frey, Brendan J},
	year = {2016},
	note = {Publisher: Oxford University Press},
	keywords = {classification, deep learning, microscopy, segmentation},
	pages = {i52--i59},
}

@article{yang_discounted_2013,
	title = {Discounted combination of unreliable evidence using degree of disagreement},
	volume = {54},
	issn = {0888613X},
	number = {8},
	journal = {International Journal of Approximate Reasoning},
	author = {Yang, Yi and Han, Deqiang and Han, Chongzhao},
	year = {2013},
	note = {Publisher: Elsevier Inc.},
	keywords = {Belief function, Discounting, Distance of evidence, Evidence theory},
	pages = {1197--1216},
}

@article{sinha_cells_2011,
	title = {Cells respond to mechanical stress by rapid disassembly of caveolae},
	volume = {144},
	number = {3},
	journal = {Cell},
	author = {Sinha, Bidisha and Köster, Darius and Ruez, Richard and Gonnord, Pauline and Bastiani, Michele and Abankwa, Daniel and Stan, Radu V and Butler-Browne, Gillian and Vedie, Benoit and Johannes, Ludger and {others}},
	year = {2011},
	note = {Publisher: Elsevier},
	pages = {402--413},
}

@article{segebarth_objectivity_2020,
	title = {On the objectivity, reliability, and validity of deep learning enabled bioimage analyses},
	volume = {9},
	journal = {Elife},
	author = {Segebarth, Dennis and Griebel, Matthias and Stein, Nikolai and von Collenberg, Cora R and Martin, Corinna and Fiedler, Dominik and Comeras, Lucas B and Sah, Anupam and Schoeffler, Victoria and Lüffe, Teresa and {others}},
	year = {2020},
	note = {Publisher: eLife Sciences Publications, Ltd},
}

@article{falk_u-net_2019,
	title = {U-{Net}: deep learning for cell counting, detection, and morphometry},
	volume = {16},
	number = {1},
	journal = {Nature methods},
	author = {Falk, Thorsten and Mai, Dominic and Bensch, Robert and Çiçek, Özgün and Abdulkadir, Ahmed and Marrakchi, Yassine and Böhm, Anton and Deubner, Jan and Jäckel, Zoe and Seiwald, Katharina and {others}},
	year = {2019},
	note = {Publisher: Nature Publishing Group},
	pages = {67--70},
}

@article{collier_assessment_2003,
	title = {Assessment of consistency in contouring of normal-tissue anatomic structures},
	volume = {4},
	number = {1},
	journal = {Journal of applied clinical medical physics},
	author = {Collier, Dawn C and Burnett, Stuart SC and Amin, Mayankkumar and Bilton, Stephen and Brooks, Christopher and Ryan, Amanda and Roniger, Dominique and Tran, Danny and Starkschall, George},
	year = {2003},
	note = {Publisher: Wiley Online Library},
	pages = {17--24},
}

@article{nagao_robust_2020,
	title = {Robust classification of cell cycle phase and biological feature extraction by image-based deep learning},
	volume = {31},
	number = {13},
	journal = {Molecular biology of the cell},
	author = {Nagao, Yukiko and Sakamoto, Mika and Chinen, Takumi and Okada, Yasushi and Takao, Daisuke},
	year = {2020},
	note = {Publisher: Am Soc Cell Biol},
	pages = {1346--1354},
}

@article{schmitz_design-based_1999,
	title = {Design-based counting techniques: the real problems},
	volume = {22},
	number = {8},
	journal = {Trends in neurosciences},
	author = {Schmitz, Christoph and Korr, Hubert and Heinsen, Helmut},
	year = {1999},
	note = {Publisher: Elsevier},
	pages = {345},
}

@article{wang_multi-scale_2022,
	title = {Multi-scale deep learning for the imbalanced multi-label protein subcellular localization prediction based on immunohistochemistry images},
	volume = {38},
	number = {9},
	journal = {Bioinformatics},
	author = {Wang, Fengsheng and Wei, Leyi},
	year = {2022},
	note = {Publisher: Oxford University Press},
	pages = {2602--2611},
}

@article{segebarth_deepflash_2018,
	title = {{DeepFLaSh}, a deep learning pipeline for segmentation of fluorescent labels in microscopy images},
	journal = {bioRxiv},
	author = {Segebarth, Dennis and Griebel, Matthias and Duerr, Alexander and von Collenberg, Cora R and Martin, Corinna and Fiedler, Dominik and Comeras, Lucas B and Sah, Anupam and Stein, Nikolai and Gupta, Rohini and {others}},
	year = {2018},
	pages = {473199},
}

@article{guirado_automated_2018,
	title = {Automated analysis of images for molecular quantification in immunohistochemistry},
	volume = {4},
	number = {6},
	journal = {Heliyon},
	author = {Guirado, Ramon and Carceller, Hector and Castillo-Gomez, Esther and Castren, Eero and Nacher, Juan},
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {e00669},
}

@article{parton_caveolae_2013,
	title = {Caveolae as plasma membrane sensors, protectors and organizers},
	volume = {14},
	number = {2},
	journal = {Nature reviews Molecular cell biology},
	author = {Parton, Robert G and Del Pozo, Miguel A},
	year = {2013},
	note = {Publisher: Nature Publishing Group},
	pages = {98--112},
}

@article{caicedo_nucleus_2019,
	title = {Nucleus segmentation across imaging experiments: the 2018 {Data} {Science} {Bowl}},
	volume = {16},
	number = {12},
	journal = {Nature methods},
	author = {Caicedo, Juan C and Goodman, Allen and Karhohs, Kyle W and Cimini, Beth A and Ackerman, Jeanelle and Haghighi, Marzieh and Heng, CherKeng and Becker, Tim and Doan, Minh and McQuin, Claire and {others}},
	year = {2019},
	note = {Publisher: Nature Publishing Group},
	pages = {1247--1253},
}

@article{von_chamier_artificial_2019,
	title = {Artificial intelligence for microscopy: what you should know},
	volume = {47},
	number = {4},
	journal = {Biochemical Society Transactions},
	author = {von Chamier, Lucas and Laine, Romain F and Henriques, Ricardo},
	year = {2019},
	note = {Publisher: Portland Press Ltd.},
	pages = {1029--1040},
}

@article{sezgin_survey_2004,
	title = {Survey over image thresholding techniques and quantitative performance evaluation},
	volume = {13},
	number = {1},
	journal = {Journal of Electronic imaging},
	author = {Sezgin, Mehmet and Sankur, Bülent},
	year = {2004},
	note = {Publisher: SPIE},
	pages = {146--165},
}

@article{moon_ptrfcavin-1_2014,
	title = {{PTRF}/cavin-1 neutralizes non-caveolar caveolin-1 microdomains in prostate cancer},
	volume = {33},
	number = {27},
	journal = {Oncogene},
	author = {Moon, Hyeongsun and Lee, Cheok Soon and Inder, Kerry L and Sharma, Sowmya and Choi, Eunju and Black, Debra M and Le Cao, Kim-Anh and Winterford, Clay and Coward, Jermaine I and Ling, MT and {others}},
	year = {2014},
	note = {Publisher: Nature Publishing Group},
	pages = {3561--3570},
}

@incollection{dempster_upper_2008,
	title = {Upper and lower probabilities induced by a multivalued mapping},
	booktitle = {Classic {Works} of the {Dempster}-{Shafer} {Theory} of {Belief} functions},
	publisher = {Springer},
	author = {Dempster, Arthur P},
	year = {2008},
	pages = {57--72},
}

@article{taghanaki_combo_2019,
	title = {Combo loss: {Handling} input and output imbalance in multi-organ segmentation},
	volume = {75},
	journal = {Computerized Medical Imaging and Graphics},
	author = {Taghanaki, Saeid Asgari, {\textbackslash}emphet al.},
	year = {2019},
	note = {Publisher: Elsevier},
	pages = {24--33},
}

@article{cleveland_robust_1979,
	title = {Robust locally weighted regression and smoothing scatterplots},
	volume = {74},
	number = {368},
	journal = {Journal of the American Statistical Association},
	author = {Cleveland, William S},
	year = {1979},
	note = {Publisher: Taylor \& Francis},
	pages = {829--836},
}

@article{sudharshan_multiple_2019,
	title = {Multiple instance learning for histopathological breast cancer image classification},
	volume = {117},
	journal = {Expert Systems with Applications},
	author = {Sudharshan, PJ and Petitjean, Caroline and Spanhol, Fabio and Oliveira, Luiz Eduardo and Heutte, Laurent and Honeine, Paul},
	year = {2019},
	note = {Publisher: Elsevier},
	pages = {103--111},
}

@book{shafer_mathematical_1976,
	title = {A mathematical theory of evidence},
	volume = {42},
	publisher = {Princeton university press},
	author = {Shafer, Glenn},
	year = {1976},
}

@article{dempster_dempstershafer_2008,
	title = {The {Dempster}–{Shafer} calculus for statisticians},
	volume = {48},
	number = {2},
	journal = {International Journal of Approximate Reasoning},
	author = {Dempster, Arthur P},
	year = {2008},
	note = {Publisher: Elsevier},
	pages = {365--377},
}

@inproceedings{zhou_learning_2016,
	title = {Learning deep features for discriminative localization},
	booktitle = {Proceedings of the {IEEE} conference on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
	year = {2016},
	pages = {2921--2929},
}

@inproceedings{gluckman_kurtosis_2003,
	title = {Kurtosis and the phase structure of images},
	booktitle = {3rd {International} {Workshop} on {Statistical} and {Computational} {Theories} of {Vision}, {Nice}, {France}, {October} 2003 (in conjunction with {ICCV}’03)},
	publisher = {Citeseer},
	author = {Gluckman, Joshua},
	year = {2003},
	pages = {12--15},
}

@article{steven_diffusion_2014,
	title = {Diffusion kurtosis imaging: an emerging technique for evaluating the microstructural environment of the brain},
	volume = {202},
	number = {1},
	journal = {American Journal of Roentgenology},
	author = {Steven, Andrew J and Zhuo, Jiachen and Melhem, Elias R},
	year = {2014},
	note = {Publisher: Am Roentgen Ray Soc},
	pages = {W26--W33},
}

@article{wong_single_2021,
	title = {Single molecule network analysis identifies structural changes to caveolae and scaffolds due to mutation of the caveolin-1 scaffolding domain},
	volume = {11},
	number = {1},
	journal = {Scientific reports},
	author = {Wong, Timothy H and Khater, Ismail M and Joshi, Bharat and Shahsavari, Mona and Hamarneh, Ghassan and Nabi, Ivan R},
	year = {2021},
	note = {Publisher: Nature Publishing Group},
	pages = {1--14},
}

@inproceedings{george_deep_2019,
	title = {Deep {Learned} {Nucleus} {Features} for {Breast} {Cancer} {Histopathological} {Image} {Analysis} based on {Belief} {Theoretical} {Classifier} {Fusion}},
	booktitle = {{TENCON} 2019-2019 {IEEE} {Region} 10 {Conference} ({TENCON})},
	publisher = {IEEE},
	author = {George, Kalpana and Faziludeen, Shameer and Sankaran, Praveen and Paul, Joseph K},
	year = {2019},
	pages = {344--349},
}

@article{voorbraak_justification_1991,
	title = {On the justification of {Dempster}'s rule of combination},
	volume = {48},
	number = {2},
	journal = {Artificial Intelligence},
	author = {Voorbraak, Frans},
	year = {1991},
	note = {Publisher: Elsevier},
	pages = {171--197},
}

@article{perez_-amyloid_2009,
	title = {β-amyloid deposition and functional impairment in the retina of the {APPswe}/{PS1ΔE9} transgenic mouse model of {Alzheimer}’s disease},
	volume = {50},
	number = {2},
	journal = {Investigative Ophthalmology \& Visual Science},
	author = {Perez, Sylvia E and Lumayag, Stephen and Kovacs, Beatrix and Mufson, Elliott J and Xu, Shunbin},
	year = {2009},
	note = {Publisher: The Association for Research in Vision and Ophthalmology},
	pages = {793--800},
}

@article{dong_amyloid_2018,
	title = {Amyloid beta deposition related retinal pigment epithelium cell impairment and subretinal microglia activation in aged {APPswePS1} transgenic mice},
	volume = {11},
	number = {5},
	journal = {International Journal of Ophthalmology},
	author = {Dong, Zhi-Zhang and Li, Juan and Gan, Yi-Feng and Sun, Xue-Rong and Leng, Yun-Xia and Ge, Jian},
	year = {2018},
	note = {Publisher: Press of International Journal of Ophthalmology},
	pages = {747},
}

@article{popper_science_1963,
	title = {Science as falsification},
	volume = {1},
	journal = {Conjectures and Refutations},
	author = {Popper, Karl R},
	year = {1963},
	note = {Publisher: Routledge and Keagan Paul London},
	pages = {33--39},
}

@inproceedings{mehta_y-net_2018,
	title = {Y-{Net}: joint segmentation and classification for diagnosis of breast biopsy images},
	booktitle = {International {Conference} on {Medical} {Image} {Computing} and {Computer}-{Assisted} {Intervention}},
	publisher = {Springer},
	author = {Mehta, Sachin and Mercan, Ezgi and Bartlett, Jamen and Weaver, Donald and Elmore, Joann G and Shapiro, Linda},
	year = {2018},
	pages = {893--901},
}

@article{koronyo-hamaoui_identification_2011,
	title = {Identification of amyloid plaques in retinas from {Alzheimer}'s patients and noninvasive in vivo optical imaging of retinal plaques in a mouse model},
	volume = {54},
	journal = {Neuroimage},
	author = {Koronyo-Hamaoui, Maya and Koronyo, Yosef and Ljubimov, Alexander V and Miller, Carol A and Ko, MinHee K and Black, Keith L and Schwartz, Michal and Farkas, Daniel L},
	year = {2011},
	note = {Publisher: Elsevier},
	pages = {S204--S217},
}

@article{kam_viewing_2010,
	title = {Viewing ageing eyes: diverse sites of amyloid {Beta} accumulation in the ageing mouse retina and the up-regulation of macrophages},
	volume = {5},
	number = {10},
	journal = {PloS one},
	author = {Kam, Jaimie Hoh and Lenassi, Eva and Jeffery, Glen},
	year = {2010},
	note = {Publisher: Public Library of Science},
}

@article{hart_ocular_2016,
	title = {Ocular indicators of {Alzheimer}’s: exploring disease in the retina},
	volume = {132},
	number = {6},
	journal = {Acta Neuropathologica},
	author = {Hart, Nadav J and Koronyo, Yosef and Black, Keith L and Koronyo-Hamaoui, Maya},
	year = {2016},
	note = {Publisher: Springer},
	pages = {767--787},
}

@article{singh_explainable_2020,
	title = {Explainable {Deep} {Learning} {Models} in {Medical} {Image} {Analysis}},
	volume = {6},
	issn = {2313-433X},
	number = {6},
	journal = {Journal of Imaging},
	author = {Singh, Amitojdeep and Sengupta, Sourya and Lakshminarayanan, Vasudevan},
	year = {2020},
}

@article{schwartzkopf_maximum-likelihood_2005,
	title = {Maximum-likelihood techniques for joint segmentation-classification of multispectral chromosome images},
	volume = {24},
	number = {12},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Schwartzkopf, Wade Carl and Bovik, Alan C and Evans, Brian L},
	year = {2005},
	note = {Publisher: IEEE},
	pages = {1593--1610},
}

@inproceedings{bentaieb_multi-loss_2016,
	title = {Multi-loss convolutional networks for gland analysis in microscopy},
	booktitle = {2016 {IEEE} 13th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	publisher = {IEEE},
	author = {BenTaieb, Aïcha and Kawahara, Jeremy and Hamarneh, Ghassan},
	year = {2016},
	pages = {642--645},
}

@article{khater_super_2018,
	title = {Super resolution network analysis defines the molecular architecture of {Caveolae} and {Caveolin}-1 scaffolds},
	volume = {8},
	number = {1},
	journal = {Scientific Reports},
	author = {Khater, Ismail M and Meng, Fanrui and Wong, Timothy H and Nabi, Ivan Robert and Hamarneh, Ghassan},
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	pages = {1--15},
}

@incollection{zadeh_simple_1996,
	title = {A simple view of the {Dempster}-{Shafer} theory of evidence and its implication for the rule of combination},
	booktitle = {Fuzzy sets, fuzzy logic, and fuzzy systems: selected papers by {Lotfi} {A}. {Zadeh}},
	author = {Zadeh, Lotfi A},
	year = {1996},
	pages = {674--679},
}

@article{lindeberg_scale-space_1994,
	title = {Scale-space theory: {A} basic tool for analyzing structures at different scales},
	volume = {21},
	number = {1-2},
	journal = {Journal of Applied Statistics},
	author = {Lindeberg, Tony},
	year = {1994},
	note = {Publisher: Taylor \& Francis},
	pages = {225--270},
}

@inproceedings{xu_blob_2014,
	title = {Blob detection with the determinant of the {Hessian}},
	booktitle = {Chinese {Conference} on {Pattern} {Recognition}},
	publisher = {Springer},
	author = {Xu, Xiaopeng},
	year = {2014},
	pages = {72--80},
}

@article{marsh_hessian_2018,
	title = {The {Hessian} blob algorithm: {Precise} particle detection in atomic force microscopy imagery},
	volume = {8},
	number = {1},
	journal = {Scientific Reports},
	author = {Marsh, Brendan P et al.},
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	pages = {1--12},
}

@inproceedings{han_structural_2018,
	title = {Structural contrast function improves image alignment precision of ghost imaging},
	booktitle = {Laser {Science}},
	publisher = {Optical Society of America},
	author = {Han, Dongchu et al.},
	year = {2018},
	pages = {JTu2A--137},
}

@article{mabaso_spot_2018,
	title = {{SPOT} {DETECTION} {METHODS} {IN} {FLUORESCENCE} {MICROSCOPY} {IMAGING}: {A} {REVIEW}},
	volume = {37},
	number = {3},
	journal = {Image Analysis \& Stereology},
	author = {Mabaso, Matsilele Aubrey and Withey, Daniel James and Twala, Bhekisipho},
	year = {2018},
	pages = {173--190},
}

@article{lajoie_lattices_2009,
	title = {Lattices, rafts, and scaffolds: domain regulation of receptor signaling at the plasma membrane},
	volume = {185},
	number = {3},
	journal = {Journal of Cell Biology},
	author = {Lajoie, Patrick and Goetz, Jacky G and Dennis, James W and Nabi, Ivan R},
	year = {2009},
	note = {Publisher: The Rockefeller University Press},
	pages = {381--385},
}

@article{hell_breaking_1994,
	title = {Breaking the diffraction resolution limit by stimulated emission: stimulated-emission-depletion fluorescence microscopy},
	volume = {19},
	number = {11},
	journal = {Optics Letters},
	author = {Hell, Stefan W and Wichmann, Jan},
	year = {1994},
	note = {Publisher: Optical Society of America},
	pages = {780--782},
}

@article{vaux_replicates_2012,
	title = {Replicates and repeats—what is the difference and is it significant?},
	volume = {13},
	number = {4},
	journal = {EMBO Reports},
	author = {Vaux, David L and Fidler, Fiona and Cumming, Geoff},
	year = {2012},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {291--296},
}

@book{jackman_bayesian_2009,
	title = {Bayesian analysis for the social sciences},
	volume = {846},
	publisher = {John Wiley \& Sons},
	author = {Jackman, Simon},
	year = {2009},
}

@inproceedings{wan_c-mil_2019,
	title = {C-{MIL}: {Continuation} {Multiple} {Instance} {Learning} for {Weakly} {Supervised} {Object} {Detection}},
	booktitle = {The {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Wan, Fang and Liu, Chang and Ke, Wei and Ji, Xiangyang and Jiao, Jianbin and Ye, Qixiang},
	month = jun,
	year = {2019},
}

@article{doran_multiple-instance_2016,
	title = {Multiple-instance learning from distributions},
	volume = {17},
	number = {1},
	journal = {The Journal of Machine Learning Research},
	author = {Doran, Gary and Ray, Soumya},
	year = {2016},
	note = {Publisher: JMLR. org},
	pages = {4384--4433},
}

@techreport{chan_image_2000,
	title = {Image segmentation using level sets and the piecewise-constant {Mumford}-{Shah} model},
	institution = {Tech. Rep. 0014, Computational Applied Math Group},
	author = {Chan, Tony F. and Vese, Luminita A.},
	year = {2000},
}

@article{dong_enhanced_2014,
	title = {Enhanced {MIL} tracker with distribution field-based features and temporal fusion framework},
	volume = {50},
	number = {24},
	journal = {Electronics Letters},
	author = {Dong, Qiang and Liu, Aidong},
	year = {2014},
	note = {Publisher: IET},
	pages = {1830--1832},
}

@inproceedings{taghanaki_infomask_2019,
	title = {Infomask: {Masked} variational latent representation to localize chest disease},
	booktitle = {International {Conference} on {Medical} {Image} {Computing} and {Computer}-{Assisted} {Intervention}},
	publisher = {Springer},
	author = {Taghanaki, Saeid Asgari et al.},
	year = {2019},
	pages = {739--747},
}

@inproceedings{satopaa_finding_2011,
	title = {Finding a" kneedle" in a haystack: {Detecting} knee points in system behavior},
	booktitle = {2011 31st {International} {Conference} on {Distributed} {Computing} {Systems} {Workshops}},
	publisher = {IEEE},
	author = {Satopaa, Ville and Albrecht, Jeannie and Irwin, David and Raghavan, Barath},
	year = {2011},
	pages = {166--171},
}

@article{he_spatial_2015,
	title = {Spatial pyramid pooling in deep convolutional networks for visual recognition},
	volume = {37},
	number = {9},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year = {2015},
	note = {Publisher: IEEE},
	pages = {1904--1916},
}

@article{zhang_weakly_2021,
	title = {Weakly {Supervised} {Object} {Localization} and {Detection}: {A} {Survey}},
	doi = {10.1109/TPAMI.2021.3074313},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Zhang, Dingwen and Han, Junwei and Cheng, Gong and Yang, Ming-Hsuan},
	year = {2021},
	pages = {1--1},
}

@inproceedings{li_efficient_2020,
	title = {Efficient {Shapley} {Explanation} for {Features} {Importance} {Estimation} {Under} {Uncertainty}},
	booktitle = {International {Conference} on {Medical} {Image} {Computing} and {Computer}-{Assisted} {Intervention}},
	publisher = {Springer},
	author = {Li, Xiaoxiao and Zhou, Yuan and Dvornek, Nicha C and Gu, Yufeng and Ventola, Pamela and Duncan, James S},
	year = {2020},
	pages = {792--801},
}

@article{zadeh_fuzzy_1978,
	title = {Fuzzy sets as a basis for a theory of possibility},
	volume = {1},
	number = {1},
	journal = {Fuzzy Sets and Systems},
	author = {Zadeh, Lotfi Asker},
	year = {1978},
	note = {Publisher: North-Holland},
	pages = {3--28},
}

@article{carbonneau_multiple_2018,
	title = {Multiple instance learning: {A} survey of problem characteristics and applications},
	volume = {77},
	journal = {Pattern Recognition},
	author = {Carbonneau, Marc-André and Cheplygina, Veronika and Granger, Eric and Gagnon, Ghyslain},
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {329--353},
}

@article{moors_meaning_1986,
	title = {The meaning of kurtosis: {Darlington} reexamined},
	volume = {40},
	number = {4},
	journal = {The American Statistician},
	author = {Moors, Johannes J A},
	year = {1986},
	note = {Publisher: Taylor \& Francis},
	pages = {283--284},
}

@article{larochelle_learning_2010,
	title = {Learning to combine foveal glimpses with a third-order boltzmann machine},
	volume = {23},
	journal = {Advances in neural information processing systems},
	author = {Larochelle, Hugo and Hinton, Geoffrey E},
	year = {2010},
	pages = {1243--1251},
}

@inproceedings{lee_dynamic_2016,
	title = {Dynamic belief fusion for object detection},
	doi = {10.1109/WACV.2016.7477574},
	booktitle = {2016 {IEEE} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	author = {Lee, Hyungtae and Kwon, Heesung and Robinson, Ryan M. and Nothwang, William D. and Marathe, Amar M.},
	year = {2016},
	pages = {1--9},
}

@article{saberian_deemd_2021,
	title = {{DEEMD}: {Drug} {Efficacy} {Estimation} against {SARS}-{CoV}-2 based on cell {Morphology} with {Deep} multiple instance learning},
	journal = {arXiv preprint arXiv:2105.05758},
	author = {Saberian, M Sadegh and Moriarty, Kathleen P and Olmstead, Andrea D and Nabi, Ivan R and Jean, François and Libbrecht, Maxwell W and Hamarneh, Ghassan},
	year = {2021},
}

@article{lindeberg_feature_1998,
	title = {Feature detection with automatic scale selection},
	volume = {30},
	number = {2},
	journal = {International journal of computer vision},
	author = {Lindeberg, Tony},
	year = {1998},
	note = {Publisher: Springer},
	pages = {79--116},
}

@article{otsu_threshold_1979,
	title = {A threshold selection method from gray-level histograms},
	volume = {9},
	number = {1},
	journal = {IEEE transactions on systems, man, and cybernetics},
	author = {Otsu, Nobuyuki},
	year = {1979},
	note = {Publisher: IEEE},
	pages = {62--66},
}

@article{basset_adaptive_2015,
	title = {Adaptive spot detection with optimal scale selection in fluorescence microscopy images},
	volume = {24},
	number = {11},
	journal = {IEEE Transactions on Image Processing},
	author = {Basset, Antoine and Boulanger, Jerome and Salamero, Jean and Bouthemy, Patrick and Kervrann, Charles},
	year = {2015},
	note = {Publisher: IEEE},
	pages = {4512--4527},
}

@article{smal_quantitative_2009,
	title = {Quantitative comparison of spot detection methods in fluorescence microscopy},
	volume = {29},
	number = {2},
	journal = {IEEE transactions on medical imaging},
	author = {Smal, Ihor and Loog, Marco and Niessen, Wiro and Meijering, Erik},
	year = {2009},
	note = {Publisher: IEEE},
	pages = {282--301},
}

@article{axelrod_total_1989,
	title = {Total internal reflection fluorescence microscopy},
	volume = {30},
	journal = {Methods in cell biology},
	author = {Axelrod, Daniel},
	year = {1989},
	note = {Publisher: Elsevier},
	pages = {245--270},
}

@article{cores_spatiotemporal_2022,
	title = {Spatiotemporal tubelet feature aggregation and object linking for small object detection in videos},
	doi = {10.1007/s10489-022-03529-w},
	journal = {Applied Intelligence},
	author = {Cores, Daniel and Brea, Victor and Mucientes, Manuel},
	month = apr,
	year = {2022},
}

@article{ruan_fusion_2021,
	title = {Fusion of clathrin and caveolae endocytic vesicles revealed by line-switching dual-color {STED} microscopy},
	volume = {14},
	url = {https://doi.org/10.1142/S1793545821500176},
	doi = {10.1142/S1793545821500176},
	number = {06},
	journal = {Journal of Innovative Optical Health Sciences},
	author = {Ruan, Hefei and Yu, Jianqiang and Wu, Yayun and Tang, Xiaojun and Yuan, Jinghe and Fang, Xiaohong},
	year = {2021},
	note = {\_eprint: https://doi.org/10.1142/S1793545821500176},
	pages = {2150017},
}

@article{wagner_dynamic_2011,
	title = {Dynamic force spectroscopy on the binding of monoclonal antibodies and tau peptides},
	volume = {7},
	number = {9},
	journal = {Soft Matter},
	author = {Wagner, Carolin and Singer, David and Ueberschär, Olaf and Stangner, Tim and Gutsche, Christof and Hoffmann, Ralf and Kremer, Friedrich},
	year = {2011},
	note = {Publisher: Royal Society of Chemistry},
	pages = {4370--4378},
}

@inproceedings{chen_memory_2020,
	title = {Memory enhanced global-local aggregation for video object detection},
	booktitle = {Proceedings of the {IEEE}/{CVF} conference on computer vision and pattern recognition},
	author = {Chen, Yihong and Cao, Yue and Hu, Han and Wang, Liwei},
	year = {2020},
	pages = {10337--10346},
}

@article{collins_imagej_2007,
	title = {{ImageJ} for microscopy},
	volume = {43},
	number = {S1},
	journal = {Biotechniques},
	author = {Collins, Tony J},
	year = {2007},
	note = {Publisher: Future Science},
	pages = {S25--S30},
}

@article{lee_amyloid_2020,
	title = {Amyloid beta immunoreactivity in the retinal ganglion cell layer of the {Alzheimer}’s eye},
	volume = {14},
	journal = {Frontiers in neuroscience},
	author = {Lee, Sieun and Jiang, Kailun and McIlmoyle, Brandon and To, Eleanor and Xu, Qinyuan Alis and Hirsch-Reinshagen, Veronica and Mackenzie, Ian R and Hsiung, Ging-Yuek R and Eadie, Brennan D and Sarunic, Marinko V and {others}},
	year = {2020},
	note = {Publisher: Frontiers},
	pages = {758},
}

@inproceedings{cantelli_sui_1929,
	title = {Sui confini della probabilita},
	booktitle = {Atti del {Congresso} {Internazionale} dei {Matematici}: {Bologna} del 3 al 10 de settembre di 1928},
	author = {Cantelli, Francesco Paolo},
	year = {1929},
	pages = {47--60},
}

@article{mukherjee_ubiquitin-mediated_2016,
	title = {Ubiquitin-mediated regulation of the {E3} ligase {GP78} by {MGRN1} in trans affects mitochondrial homeostasis},
	volume = {129},
	issn = {1477-9137},
	doi = {10.1242/jcs.176537},
	abstract = {Cellular quality control provides an efficient surveillance system to regulate mitochondrial turnover. This study elucidates a new interaction between the cytosolic E3 ligase mahogunin RING finger 1 (MGRN1) and the endoplasmic reticulum (ER) ubiquitin E3 ligase GP78 (also known as AMFR). Loss of Mgrn1 function has been implicated in late-onset spongiform neurodegeneration and congenital heart defects, among several developmental defects. Here, we show that MGRN1 ubiquitylates GP78 in trans through non-canonical K11 linkages. This helps maintain constitutively low levels of GP78 in healthy cells, in turn downregulating mitophagy. GP78, however, does not regulate MGRN1. When mitochondria are stressed, cytosolic Ca(2+) increases. This leads to a reduced interaction between MGRN1 and GP78 and its compromised ubiquitylation. Chelating Ca(2+) restores association between the two ligases and the in trans ubiquitylation. Catalytic inactivation of MGRN1 results in elevated levels of GP78 and a consequential increase in the initiation of mitophagy. This is important because functional depletion of MGRN1 by the membrane-associated disease-causing prion protein (Ctm)PrP affects polyubiquitylation and degradation of GP78, also leading to an increase in mitophagy events. This suggests that MGRN1 participates in mitochondrial quality control and could contribute to neurodegeneration in a subset of (Ctm)PrP-mediated prion diseases.},
	language = {eng},
	number = {4},
	journal = {Journal of Cell Science},
	author = {Mukherjee, Rukmini and Chakrabarti, Oishee},
	month = feb,
	year = {2016},
	pmid = {26743086},
	keywords = {Animals, GP78, HeLa Cells, Homeostasis, Humans, MGRN1, Mice, Mitochondria, Mitophagy, Proteasome Endopeptidase Complex, Proteolysis, Receptors, Autocrine Motility Factor, Ubiquitin, Ubiquitin-Protein Ligases, Ubiquitination, Ubiquitylation},
	pages = {757--773},
}

@article{helle_organization_2013,
	title = {Organization and function of membrane contact sites},
	volume = {1833},
	issn = {0006-3002},
	doi = {10.1016/j.bbamcr.2013.01.028},
	abstract = {Membrane-bound organelles are a wonderful evolutionary acquisition of the eukaryotic cell, allowing the segregation of sometimes incompatible biochemical reactions into specific compartments with tailored microenvironments. On the flip side, these isolating membranes that crowd the interior of the cell, constitute a hindrance to the diffusion of metabolites and information to all corners of the cell. To ensure coordination of cellular activities, cells use a network of contact sites between the membranes of different organelles. These membrane contact sites (MCSs) are domains where two membranes come to close proximity, typically less than 30nm. Such contacts create microdomains that favor exchange between two organelles. MCSs are established and maintained in durable or transient states by tethering structures, which keep the two membranes in proximity, but fusion between the membranes does not take place. Since the endoplasmic reticulum (ER) is the most extensive cellular membrane network, it is thus not surprising to find the ER involved in most MCSs within the cell. The ER contacts diverse compartments such as mitochondria, lysosomes, lipid droplets, the Golgi apparatus, endosomes and the plasma membrane. In this review, we will focus on the common organizing principles underlying the many MCSs found between the ER and virtually all compartments of the cell, and on how the ER establishes a network of MCSs for the trafficking of vital metabolites and information. This article is part of a Special Issue entitled: Functional and structural diversity of endoplasmic reticulum.},
	language = {eng},
	number = {11},
	journal = {Biochimica Et Biophysica Acta},
	author = {Helle, Sebastian C. J. and Kanfer, Gil and Kolar, Katja and Lang, Alexander and Michel, Agnès H. and Kornmann, Benoît},
	month = nov,
	year = {2013},
	pmid = {23380708},
	keywords = {Animals, Calcium, Cell Membrane, Endoplasmic Reticulum, Endoplasmic reticulum, Golgi Apparatus, Humans, Interorganelle communication, Intracellular Membranes, Lipid, Membrane contact site, Organelle, Organelles, Protein Transport},
	pages = {2526--2541},
}

@article{anastasia_mitochondria-rough-er_2021,
	title = {Mitochondria-rough-{ER} contacts in the liver regulate systemic lipid homeostasis},
	volume = {34},
	issn = {2211-1247},
	doi = {10.1016/j.celrep.2021.108873},
	abstract = {Contacts between organelles create microdomains that play major roles in regulating key intracellular activities and signaling pathways, but whether they also regulate systemic functions remains unknown. Here, we report the ultrastructural organization and dynamics of the inter-organellar contact established by sheets of curved rough endoplasmic reticulum closely wrapped around the mitochondria (wrappER). To elucidate the in vivo function of this contact, mouse liver fractions enriched in wrappER-associated mitochondria are analyzed by transcriptomics, proteomics, and lipidomics. The biochemical signature of the wrappER points to a role in the biogenesis of very-low-density lipoproteins (VLDL). Altering wrappER-mitochondria contacts curtails VLDL secretion and increases hepatic fatty acids, lipid droplets, and neutral lipid content. Conversely, acute liver-specific ablation of Mttp, the most upstream regulator of VLDL biogenesis, recapitulates this hepatic dyslipidemia phenotype and promotes remodeling of the wrappER-mitochondria contact. The discovery that liver wrappER-mitochondria contacts participate in VLDL biology suggests an involvement of inter-organelle contacts in systemic lipid homeostasis.},
	language = {eng},
	number = {11},
	journal = {Cell Reports},
	author = {Anastasia, Irene and Ilacqua, Nicolò and Raimondi, Andrea and Lemieux, Philippe and Ghandehari-Alavijeh, Rana and Faure, Guilhem and Mekhedov, Sergei L. and Williams, Kevin J. and Caicci, Federico and Valle, Giorgio and Giacomello, Marta and Quiroga, Ariel D. and Lehner, Richard and Miksis, Michael J. and Toth, Katalin and de Aguiar Vallim, Thomas Q. and Koonin, Eugene V. and Scorrano, Luca and Pellegrini, Luca},
	month = mar,
	year = {2021},
	pmid = {33730569},
	keywords = {Animals, Endoplasmic Reticulum, Enterocytes, Gene Silencing, Hepatocytes, Homeostasis, Imaging, Three-Dimensional, Intestine, Small, Lipids, Lipoproteins, VLDL, Liver, MAM, MUP, Male, Metabolomics, Mice, Inbred C57BL, Mitochondria, Mitochondrial Membranes, Phospholipids, Proteins, Rrbp1, VLDL, endoplasmic reticulum, inter-organelle contact, lipoprotein, liver metabolism, mitochondria, wrappER},
	pages = {108873},
}

@article{barazzuol_mitochondria_2021,
	title = {Mitochondria {Associated} {Membranes} ({MAMs}): {Architecture} and physiopathological role},
	volume = {94},
	issn = {1532-1991},
	shorttitle = {Mitochondria {Associated} {Membranes} ({MAMs})},
	doi = {10.1016/j.ceca.2020.102343},
	abstract = {In the last decades, the communication between the Endoplasmic reticulum (ER) and mitochondria has obtained great attention: mitochondria-associated membranes (MAMs), which represent the contact sites between the two organelles, have indeed emerged as central hub involved in different fundamental cell processes, such as calcium signalling, apoptosis, autophagy and lipid biosynthesis. Consistently, dysregulation of ER-mitochondria crosstalk has been associated with different pathological conditions, ranging from diabetes to cancer and neurodegenerative diseases. In this review, we will try to summarize the current knowledge on MAMs' structure and functions in health and their relevance for human diseases.},
	language = {eng},
	journal = {Cell Calcium},
	author = {Barazzuol, Lucia and Giamogante, Flavia and Calì, Tito},
	month = mar,
	year = {2021},
	pmid = {33418313},
	keywords = {Animals, Autophagy, Calcium signaling, Disease, Endoplasmic Reticulum, Health, Humans, Lipids, MAMs, Mitochondria, Mitochondrial Membranes, Neurodegeneration, Organelle contact sites},
	pages = {102343},
}

@article{bottanelli_two-colour_2016,
	title = {Two-colour live-cell nanoscale imaging of intracellular targets},
	volume = {7},
	issn = {2041-1723},
	doi = {10.1038/ncomms10778},
	abstract = {Stimulated emission depletion (STED) nanoscopy allows observations of subcellular dynamics at the nanoscale. Applications have, however, been severely limited by the lack of a versatile STED-compatible two-colour labelling strategy for intracellular targets in living cells. Here we demonstrate a universal labelling method based on the organic, membrane-permeable dyes SiR and ATTO590 as Halo and SNAP substrates. SiR and ATTO590 constitute the first suitable dye pair for two-colour STED imaging in living cells below 50 nm resolution. We show applications with mitochondria, endoplasmic reticulum, plasma membrane and Golgi-localized proteins, and demonstrate continuous acquisition for up to 3 min at 2-s time resolution.},
	language = {eng},
	journal = {Nature Communications},
	author = {Bottanelli, Francesca and Kromann, Emil B. and Allgeyer, Edward S. and Erdmann, Roman S. and Wood Baguley, Stephanie and Sirinakis, George and Schepartz, Alanna and Baddeley, David and Toomre, Derek K. and Rothman, James E. and Bewersdorf, Joerg},
	month = mar,
	year = {2016},
	pmid = {26940217},
	pmcid = {PMC4785223},
	keywords = {Animals, COS Cells, Chlorocebus aethiops, HeLa Cells, Heterocyclic Compounds, 4 or More Rings, Humans, Luminescent Proteins, Microscopy, Fluorescence, Nanotechnology, Rhodamines},
	pages = {10778},
}

@article{cieri_splics_2018,
	title = {{SPLICS}: a split green fluorescent protein-based contact site sensor for narrow and wide heterotypic organelle juxtaposition},
	volume = {25},
	issn = {1476-5403},
	shorttitle = {{SPLICS}},
	doi = {10.1038/s41418-017-0033-z},
	abstract = {Contact sites are discrete areas of organelle proximity that coordinate essential physiological processes across membranes, including Ca2+ signaling, lipid biosynthesis, apoptosis, and autophagy. However, tools to easily image inter-organelle proximity over a range of distances in living cells and in vivo are lacking. Here we report a split-GFP-based contact site sensor (SPLICS) engineered to fluoresce when organelles are in proximity. Two SPLICS versions efficiently measured narrow (8-10 nm) and wide (40-50 nm) juxtapositions between endoplasmic reticulum and mitochondria, documenting the existence of at least two types of contact sites in human cells. Narrow and wide ER-mitochondria contact sites responded differently to starvation, ER stress, mitochondrial shape modifications, and changes in the levels of modulators of ER-mitochondria juxtaposition. SPLICS detected contact sites in soma and axons of D. rerio Rohon Beard (RB) sensory neurons in vivo, extending its use to analyses of organelle juxtaposition in the whole animal.},
	language = {eng},
	number = {6},
	journal = {Cell Death and Differentiation},
	author = {Cieri, Domenico and Vicario, Mattia and Giacomello, Marta and Vallese, Francesca and Filadi, Riccardo and Wagner, Tina and Pozzan, Tullio and Pizzo, Paola and Scorrano, Luca and Brini, Marisa and Calì, Tito},
	month = jun,
	year = {2018},
	pmid = {29229997},
	pmcid = {PMC5988678},
	keywords = {Animals, Apoptosis, Autophagy, Calcium Signaling, Endoplasmic Reticulum, Green Fluorescent Proteins, HEK293 Cells, HeLa Cells, Humans, Mitochondria, Mitochondrial Membranes, Zebrafish},
	pages = {1131--1145},
}

@article{cosson_mitofusin-2_2012,
	title = {Mitofusin-2 independent juxtaposition of endoplasmic reticulum and mitochondria: an ultrastructural study},
	volume = {7},
	issn = {1932-6203},
	shorttitle = {Mitofusin-2 independent juxtaposition of endoplasmic reticulum and mitochondria},
	doi = {10.1371/journal.pone.0046293},
	abstract = {Besides its role in controlling the morphology of mitochondria, mitofusin-2 has been proposed to tether mitochondria to the endoplasmic reticulum (ER), based largely on light microscopic analysis. In this study we have examined by electron microscopy the organization of ER and mitochondria in cells expressing or not mitofusin-2. Contrary to previous studies, we observed that loss of mitofusin-2 increased ER-mitochondria juxtaposition. These results suggest that mitofusin-2 does not play a critical role in the juxtapostion of ER and mitochondria, and highlight the essential role of ultrastructural analysis to visualize and measure contact between two intracellular compartments.},
	language = {eng},
	number = {9},
	journal = {PloS One},
	author = {Cosson, Pierre and Marchetti, Anna and Ravazzola, Mariella and Orci, Lelio},
	year = {2012},
	pmid = {23029466},
	pmcid = {PMC3460865},
	keywords = {Animals, Cells, Cultured, Cytoplasm, Embryo, Mammalian, Endoplasmic Reticulum, Fibroblasts, GTP Phosphohydrolases, Gene Knockout Techniques, Genes, Reporter, Green Fluorescent Proteins, Mice, Microscopy, Electron, Microscopy, Fluorescence, Mitochondria, Transfection},
	pages = {e46293},
}

@article{costantini_palette_2015,
	title = {A palette of fluorescent proteins optimized for diverse cellular environments},
	volume = {6},
	issn = {2041-1723},
	doi = {10.1038/ncomms8670},
	abstract = {To perform quantitative live cell imaging, investigators require fluorescent reporters that accurately report protein localization and levels, while minimally perturbing the cell. Yet, within the biochemically distinct environments of cellular organelles, popular fluorescent proteins (FPs), including EGFP, can be unreliable for quantitative imaging, resulting in the underestimation of protein levels and incorrect localization. Specifically, within the secretory pathway, significant populations of FPs misfold and fail to fluoresce due to non-native disulphide bond formation. Furthermore, transmembrane FP-fusion constructs can disrupt organelle architecture due to oligomerizing tendencies of numerous common FPs. Here, we describe a powerful set of bright and inert FPs optimized for use in multiple cellular compartments, especially oxidizing environments and biological membranes. Also, we provide new insights into the use of red FPs in the secretory pathway. Our monomeric 'oxFPs' finally resolve long-standing, underappreciated and important problems of cell biology and should be useful for a number of applications.},
	language = {eng},
	journal = {Nature Communications},
	author = {Costantini, Lindsey M. and Baloban, Mikhail and Markwardt, Michele L. and Rizzo, Megan A. and Guo, Feng and Verkhusha, Vladislav V. and Snapp, Erik L.},
	month = jul,
	year = {2015},
	pmid = {26158227},
	pmcid = {PMC4499870},
	keywords = {Animals, Bacterial Proteins, Cell Line, Tumor, Cell Membrane, Dogs, Fluorescent Dyes, Green Fluorescent Proteins, HeLa Cells, Humans, Luminescent Proteins, Madin Darby Canine Kidney Cells, Microscopy, Fluorescence, Optical Imaging, Staining and Labeling},
	pages = {7670},
}

@article{csordas_structural_2006,
	title = {Structural and functional features and significance of the physical linkage between {ER} and mitochondria},
	volume = {174},
	issn = {1540-8140, 0021-9525},
	url = {https://rupress.org/jcb/article/174/7/915/44577/Structural-and-functional-features-and},
	doi = {10.1083/jcb.200604016},
	abstract = {The role of mitochondria in cell metabolism and survival is controlled by calcium signals that are commonly transmitted at the close associations between mitochondria and endoplasmic reticulum (ER). However, the physical linkage of the ER–mitochondria interface and its relevance for cell function remains elusive. We show by electron tomography that ER and mitochondria are adjoined by tethers that are ∼10 nm at the smooth ER and ∼25 nm at the rough ER. Limited proteolysis separates ER from mitochondria, whereas expression of a short “synthetic linker” (\&lt;5 nm) leads to tightening of the associations. Although normal connections are necessary and sufficient for proper propagation of ER-derived calcium signals to the mitochondria, tightened connections, synthetic or naturally observed under apoptosis-inducing conditions, make mitochondria prone to Ca2+ overloading and ensuing permeability transition. These results reveal an unexpected dependence of cell function and survival on the maintenance of proper spacing between the ER and mitochondria.},
	language = {en},
	number = {7},
	urldate = {2023-10-29},
	journal = {The Journal of Cell Biology},
	author = {Csordás, György and Renken, Christian and Várnai, Péter and Walter, Ludivine and Weaver, David and Buttle, Karolyn F. and Balla, Tamás and Mannella, Carmen A. and Hajnóczky, György},
	month = sep,
	year = {2006},
	pages = {915--921},
}

@article{csordas_imaging_2010,
	title = {Imaging interorganelle contacts and local calcium dynamics at the {ER}-mitochondrial interface},
	volume = {39},
	issn = {1097-4164},
	doi = {10.1016/j.molcel.2010.06.029},
	abstract = {The ER-mitochondrial junction provides a local calcium signaling domain that is critical for both matching energy production with demand and the control of apoptosis. Here, we visualize ER-mitochondrial contact sites and monitor the localized [Ca(2+)] changes ([Ca(2+)](ER-mt)) using drug-inducible fluorescent interorganelle linkers. We show that all mitochondria have contacts with the ER, but plasma membrane (PM)-mitochondrial contacts are less frequent because of interleaving ER stacks in both RBL-2H3 and H9c2 cells. Single mitochondria display discrete patches of ER contacts and show heterogeneity in the ER-mitochondrial Ca(2+) transfer. Pericam-tagged linkers revealed IP(3)-induced [Ca(2+)](ER-mt) signals that exceeded 9 microM and endured buffering bulk cytoplasmic [Ca(2+)] increases. Altering linker length to modify the space available for the Ca(2+) transfer machinery had a biphasic effect on [Ca(2+)](ER-mt) signals. These studies provide direct evidence for the existence of high-Ca(2+) microdomains between the ER and mitochondria and suggest an optimal gap width for efficient Ca(2+) transfer.},
	language = {eng},
	number = {1},
	journal = {Molecular Cell},
	author = {Csordás, György and Várnai, Péter and Golenár, Tünde and Roy, Swati and Purkins, George and Schneider, Timothy G. and Balla, Tamás and Hajnóczky, György},
	month = jul,
	year = {2010},
	pmid = {20603080},
	pmcid = {PMC3178184},
	keywords = {Animals, Calcium, Calcium Signaling, Cell Line, Cell Membrane, Cell Membrane Permeability, Cell Survival, Endoplasmic Reticulum, Imaging, Three-Dimensional, Inositol 1,4,5-Trisphosphate Receptors, Mitochondria, Mitochondrial Membranes, Rats, Time Factors},
	pages = {121--132},
}

@article{csordas_endoplasmic_2018,
	title = {Endoplasmic {Reticulum}-{Mitochondrial} {Contactology}: {Structure} and {Signaling} {Functions}},
	volume = {28},
	issn = {1879-3088},
	shorttitle = {Endoplasmic {Reticulum}-{Mitochondrial} {Contactology}},
	doi = {10.1016/j.tcb.2018.02.009},
	abstract = {Interorganellar contacts are increasingly recognized as central to the control of cellular behavior. These contacts, which typically involve a small fraction of the endomembrane surface, are local communication hubs that resemble synapses. We propose the term contactology to denote the analysis of interorganellar contacts. Endoplasmic reticulum (ER) contacts with mitochondria were recognized several decades ago; major roles in ion and lipid transfer, signaling, and membrane dynamics have been established, while others continue to emerge. The functional diversity of ER-mitochondrial (ER-mito) contacts is mirrored in their structural heterogeneity, with subspecialization likely supported by multiple, different linker-forming protein structures. The nanoscale size of the contacts has made studying their structure, function, and dynamics difficult. This review focuses on the structure of the ER-mito contacts, methods for studying them, and the roles of contacts in Ca2+ and reactive oxygen species (ROS) signaling.},
	language = {eng},
	number = {7},
	journal = {Trends in Cell Biology},
	author = {Csordás, György and Weaver, David and Hajnóczky, György},
	month = jul,
	year = {2018},
	pmid = {29588129},
	pmcid = {PMC6005738},
	keywords = {Animals, Calcium, Endoplasmic Reticulum, Humans, IP3 receptor, Mitochondria, Reactive Oxygen Species, Signal Transduction, calcium ion, linkers, mitochondrion-associated membrane, ryanodine receptor, sarcoplasmic reticulum},
	pages = {523--540},
}

@article{de_brito_mitofusin_2008,
	title = {Mitofusin 2 tethers endoplasmic reticulum to mitochondria},
	volume = {456},
	issn = {1476-4687},
	doi = {10.1038/nature07534},
	abstract = {Juxtaposition between endoplasmic reticulum (ER) and mitochondria is a common structural feature, providing the physical basis for intercommunication during Ca(2+) signalling; yet, the molecular mechanisms controlling this interaction are unknown. Here we show that mitofusin 2, a mitochondrial dynamin-related protein mutated in the inherited motor neuropathy Charcot-Marie-Tooth type IIa, is enriched at the ER-mitochondria interface. Ablation or silencing of mitofusin 2 in mouse embryonic fibroblasts and HeLa cells disrupts ER morphology and loosens ER-mitochondria interactions, thereby reducing the efficiency of mitochondrial Ca(2+) uptake in response to stimuli that generate inositol-1,4,5-trisphosphate. An in vitro assay as well as genetic and biochemical evidences support a model in which mitofusin 2 on the ER bridges the two organelles by engaging in homotypic and heterotypic complexes with mitofusin 1 or 2 on the surface of mitochondria. Thus, mitofusin 2 tethers ER to mitochondria, a juxtaposition required for efficient mitochondrial Ca(2+) uptake.},
	language = {eng},
	number = {7222},
	journal = {Nature},
	author = {de Brito, Olga Martins and Scorrano, Luca},
	month = dec,
	year = {2008},
	pmid = {19052620},
	keywords = {Animals, Calcium, Calcium Signaling, Charcot-Marie-Tooth Disease, Endoplasmic Reticulum, Fibroblasts, GTP Phosphohydrolases, HeLa Cells, Humans, Inositol 1,4,5-Trisphosphate, Membrane Proteins, Mice, Mitochondria, Mitochondrial Proteins, Organelle Shape},
	pages = {605--610},
}

@article{dentoni_mitochondria-endoplasmic_2022,
	title = {Mitochondria-{Endoplasmic} {Reticulum} {Interplay} {Regulates} {Exo}-{Cytosis} in {Human} {Neuroblastoma} {Cells}},
	volume = {11},
	issn = {2073-4409},
	doi = {10.3390/cells11030514},
	abstract = {Mitochondria-endoplasmic reticulum (ER) contact sites (MERCS) have been emerging as a multifaceted subcellular region of the cell which affects several physiological and pathological mechanisms. A thus far underexplored aspect of MERCS is their contribution to exocytosis. Here, we set out to understand the role of these contacts in exocytosis and find potential mechanisms linking these structures to vesicle release in human neuroblastoma SH-SY5Y cells. We show that increased mitochondria to ER juxtaposition through Mitofusin 2 (Mfn2) knock-down resulted in a substantial upregulation of the number of MERCS, confirming the role of Mfn2 as a negative regulator of these structures. Furthermore, we report that both vesicle numbers and vesicle protein levels were decreased, while a considerable upregulation in exocytotic events upon cellular depolarization was detected. Interestingly, in Mfn2 knock-down cells, the inhibition of the inositol 1,4,5-trisphosphate receptor (IP3R) and the mitochondrial calcium (Ca2+) uniporter (MCU) restored vesicle protein content and attenuated exocytosis. We thus suggest that MERCS could be targeted to prevent increased exocytosis in conditions in which ER to mitochondria proximity is upregulated.},
	language = {eng},
	number = {3},
	journal = {Cells},
	author = {Dentoni, Giacomo and Naia, Luana and Ankarcrona, Maria},
	month = feb,
	year = {2022},
	pmid = {35159324},
	pmcid = {PMC8834387},
	keywords = {Calcium, Endoplasmic Reticulum, Humans, MAM, MCU, MERCS, Mitochondria, Mitochondrial Membranes, Neuroblastoma, exocytosis, inositol 1,4,5-trisphosphate receptor, mitochondria},
	pages = {514},
}

@article{diaz_perspectives_2021,
	title = {Perspectives on {Organelle} {Interaction}, {Protein} {Dysregulation}, and {Cancer} {Disease}},
	volume = {9},
	issn = {2296-634X},
	doi = {10.3389/fcell.2021.613336},
	abstract = {In recent decades, compelling evidence has emerged showing that organelles are not static structures but rather form a highly dynamic cellular network and exchange information through membrane contact sites. Although high-throughput techniques facilitate identification of novel contact sites (e.g., organelle-organelle and organelle-vesicle interactions), little is known about their impact on cellular physiology. Moreover, even less is known about how the dysregulation of these structures impacts on cellular function and therefore, disease. Particularly, cancer cells display altered signaling pathways involving several cell organelles; however, the relevance of interorganelle communication in oncogenesis and/or cancer progression remains largely unknown. This review will focus on organelle contacts relevant to cancer pathogenesis. We will highlight specific proteins and protein families residing in these organelle-interfaces that are known to be involved in cancer-related processes. First, we will review the relevance of endoplasmic reticulum (ER)-mitochondria interactions. This section will focus on mitochondria-associated membranes (MAMs) and particularly the tethering proteins at the ER-mitochondria interphase, as well as their role in cancer disease progression. Subsequently, the role of Ca2+ at the ER-mitochondria interphase in cancer disease progression will be discussed. Members of the Bcl-2 protein family, key regulators of cell death, also modulate Ca2+ transport pathways at the ER-mitochondria interphase. Furthermore, we will review the role of ER-mitochondria communication in the regulation of proteostasis, focusing on the ER stress sensor PERK (PRKR-like ER kinase), which exerts dual roles in cancer. Second, we will review the relevance of ER and mitochondria interactions with other organelles. This section will focus on peroxisome and lysosome organelle interactions and their impact on cancer disease progression. In this context, the peroxisome biogenesis factor (PEX) gene family has been linked to cancer. Moreover, the autophagy-lysosome system is emerging as a driving force in the progression of numerous human cancers. Thus, we will summarize our current understanding of the role of each of these organelles and their communication, highlighting how alterations in organelle interfaces participate in cancer development and progression. A better understanding of specific organelle communication sites and their relevant proteins may help to identify potential pharmacological targets for novel therapies in cancer control.},
	language = {eng},
	journal = {Frontiers in Cell and Developmental Biology},
	author = {Díaz, Paula and Sandoval-Bórquez, Alejandra and Bravo-Sagua, Roberto and Quest, Andrew F. G. and Lavandero, Sergio},
	year = {2021},
	pmid = {33718356},
	pmcid = {PMC7946981},
	keywords = {cancer, endoplasmic reticulum, interorganelle communication, lysosome, mitochondria, peroxisome},
	pages = {613336},
}

@article{fang_tumor_2001,
	title = {The tumor autocrine motility factor receptor, gp78, is a ubiquitin protein ligase implicated in degradation from the endoplasmic reticulum},
	volume = {98},
	issn = {0027-8424},
	doi = {10.1073/pnas.251401598},
	abstract = {gp78, also known as the tumor autocrine motility factor receptor, is a transmembrane protein whose expression is correlated with tumor metastasis. We establish that gp78 is a RING finger-dependent ubiquitin protein ligase (E3) of the endoplasmic reticulum (ER). Consistent with this, gp78 specifically recruits MmUBC7, a ubiquitin-conjugating enzyme (E2) implicated in ER-associated degradation (ERAD), through a region distinct from the RING finger. gp78 can target itself for proteasomal degradation in a RING finger- and MmUBC7-dependent manner. Importantly, gp78 can also mediate degradation of CD3-delta, a well-characterized ERAD substrate. In contrast, gp78 lacking an intact RING finger or its multiple membrane-spanning domains stabilizes CD3-delta. gp78 has thus been found to be an example of a mammalian cellular E3 intrinsic to the ER, suggesting a potential link between ubiquitylation, ERAD, and metastasis.},
	language = {eng},
	number = {25},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Fang, S. and Ferrone, M. and Yang, C. and Jensen, J. P. and Tiwari, S. and Weissman, A. M.},
	month = dec,
	year = {2001},
	pmid = {11724934},
	pmcid = {PMC64697},
	keywords = {Animals, Cell Line, Endoplasmic Reticulum, Humans, Ligases, Receptors, Autocrine Motility Factor, Receptors, Cytokine, Recombinant Proteins, Transfection, Ubiquitin, Ubiquitin-Conjugating Enzymes, Ubiquitin-Protein Ligases},
	pages = {14422--14427},
}

@article{fortun_reconstruction_2018,
	title = {Reconstruction {From} {Multiple} {Particles} for {3D} {Isotropic} {Resolution} in {Fluorescence} {Microscopy}},
	volume = {37},
	issn = {1558-254X},
	doi = {10.1109/TMI.2018.2795464},
	abstract = {The imaging of proteins within macromolecular complexes has been limited by the low axial resolution of optical microscopes. To overcome this problem, we propose a novel computational reconstruction method that yields isotropic resolution in fluorescence imaging. The guiding principle is to reconstruct a single volume from the observations of multiple rotated particles. Our new operational framework detects particles, estimates their orientation, and reconstructs the final volume. The main challenge comes from the absence of initial template and a priori knowledge about the orientations. We formulate the estimation as a blind inverse problem, and propose a block-coordinate stochastic approach to solve the associated non-convex optimization problem. The reconstruction is performed jointly in multiple channels. We demonstrate that our method is able to reconstruct volumes with 3D isotropic resolution on simulated data. We also perform isotropic reconstructions from real experimental data of doubly labeled purified human centrioles. Our approach revealed the precise localization of the centriolar protein Cep63 around the centriole microtubule barrel. Overall, our method offers new perspectives for applications in biology that require the isotropic mapping of proteins within macromolecular assemblies.},
	language = {eng},
	number = {5},
	journal = {IEEE transactions on medical imaging},
	author = {Fortun, Denis and Guichard, Paul and Hamel, Virginie and Sorzano, Carlos Oscar S. and Banterle, Niccolo and Gonczy, Pierre and Unser, Michael},
	month = may,
	year = {2018},
	pmid = {29727286},
	keywords = {Algorithms, Centrioles, Humans, Imaging, Three-Dimensional, Microscopy, Fluorescence, Proteins},
	pages = {1235--1246},
}

@article{friedman_er_2011,
	title = {{ER} tubules mark sites of mitochondrial division},
	volume = {334},
	issn = {1095-9203},
	doi = {10.1126/science.1207385},
	abstract = {Mitochondrial structure and distribution are regulated by division and fusion events. Mitochondrial division is regulated by Dnm1/Drp1, a dynamin-related protein that forms helices around mitochondria to mediate fission. Little is known about what determines sites of mitochondrial fission within the mitochondrial network. The endoplasmic reticulum (ER) and mitochondria exhibit tightly coupled dynamics and have extensive contacts. We tested whether ER plays a role in mitochondrial division. We found that mitochondrial division occurred at positions where ER tubules contacted mitochondria and mediated constriction before Drp1 recruitment. Thus, ER tubules may play an active role in defining the position of mitochondrial division sites.},
	language = {eng},
	number = {6054},
	journal = {Science (New York, N.Y.)},
	author = {Friedman, Jonathan R. and Lackner, Laura L. and West, Matthew and DiBenedetto, Jared R. and Nunnari, Jodi and Voeltz, Gia K.},
	month = oct,
	year = {2011},
	pmid = {21885730},
	pmcid = {PMC3366560},
	keywords = {Animals, COS Cells, Chlorocebus aethiops, Dynamins, Endoplasmic Reticulum, GTP Phosphohydrolases, Humans, Membrane Proteins, Microscopy, Electron, Microscopy, Fluorescence, Microtubule-Associated Proteins, Mitochondria, Mitochondrial Proteins, Saccharomyces cerevisiae, Saccharomyces cerevisiae Proteins, Transfection},
	pages = {358--362},
}

@article{fu_regulation_2013,
	title = {Regulation of mitophagy by the {Gp78} {E3} ubiquitin ligase},
	volume = {24},
	issn = {1939-4586},
	doi = {10.1091/mbc.E12-08-0607},
	abstract = {Glycoprotein 78 (Gp78) is a critical E3 ubiquitin ligase in endoplasmic reticulum-associated degradation. Overexpression of Flag-tagged Gp78 (Flag-gp78), but not Flag-gp78 mutated in its RING-finger domain (Flag-RINGmut) with deficient ubiquitin ligase activity, induces mitochondrial fragmentation and ubiquitination and proteasome-dependent degradation of the mitofusin (Mfn) mitochondrial fusion factors Mfn1/Mfn2. After mitochondrial depolarization with carbonyl cyanide m-chlorophenylhydrazone (CCCP), Flag-gp78 induced a threefold loss of depolarized mitochondria and significant loss of the inner mitochondrial protein OxPhosV. Flag-gp78-dependent loss of OxPhosV, but not Mfn1 or Mfn2, was prevented by small interfering RNA (siRNA) knockdown of the autophagy protein Atg5 in CCCP-treated cells. Gp78-induced mitophagy required ubiquitin ligase activity, as it is not observed upon transfection of Flag-RINGmut or cotransfection of Flag-gp78 with ubiquitin mutated at three critical lysine residues (K29, 48, 63R) involved in polyubiquitin chain elongation. Short hairpin RNA knockdown of Gp78 in HT-1080 fibrosarcoma cells increased mitofusin levels and reduced depolarization-induced mitophagy, whereas siRNA knockdown showed that Mfn1, but not Mfn2, was required for Gp78-dependent depolarization-induced mitophagy. Mitochondrial depolarization induced Gp78-dependent expression of the autophagic marker LC3II and recruitment of enhanced green fluorescent protein-LC3 to the Gp78- and calnexin-labeled, mitochondria-associated ER. Finally, Gp78-induced mitophagy is Parkin independent, as it occurs in Parkin-null HeLa cells and upon siRNA-mediated Parkin knockdown in HEK293 cells. This study therefore describes a novel role for the ER-associated Gp78 ubiquitin ligase and the Mfn1 mitochondrial fusion factor in mitophagy.},
	language = {eng},
	number = {8},
	journal = {Molecular Biology of the Cell},
	author = {Fu, Min and St-Pierre, Pascal and Shankar, Jay and Wang, Peter T. C. and Joshi, Bharat and Nabi, Ivan R.},
	month = apr,
	year = {2013},
	pmid = {23427266},
	pmcid = {PMC3623636},
	keywords = {Animals, COS Cells, Chlorocebus aethiops, Endoplasmic Reticulum, GTP Phosphohydrolases, Gene Knockdown Techniques, Green Fluorescent Proteins, HEK293 Cells, HeLa Cells, Humans, Microtubule-Associated Proteins, Mitochondria, Mitochondrial Membrane Transport Proteins, Mitochondrial Proteins, Mitophagy, Proteasome Endopeptidase Complex, Proteolysis, RNA, Small Interfering, Receptors, Autocrine Motility Factor, Ubiquitin-Protein Ligases, Ubiquitination},
	pages = {1153--1162},
}

@article{goetz_interaction_2006,
	title = {Interaction of the smooth endoplasmic reticulum and mitochondria},
	volume = {34},
	issn = {0300-5127},
	doi = {10.1042/BST0340370},
	abstract = {The ER (endoplasmic reticulum) is composed of multiple domains including the nuclear envelope, ribosome-studded rough ER and the SER (smooth ER). The SER can also be functionally segregated into domains that regulate ER-Golgi traffic (transitional ER), ERAD (ER-associated degradation), sterol and lipid biosynthesis and calcium sequestration. The last two, as well as apoptosis, are critically regulated by the close association of the SER with mitochondria. Studies with AMFR (autocrine motility factor receptor) have defined an SER domain whose integrity and mitochondrial association can be modulated by ilimaquinone as well as by free cytosolic calcium levels in the normal physiological range. AMFR is an E3 ubiquitin ligase that targets its ligand directly to the SER via a caveolae/raft-dependent pathway. In the present review, we will address the relationship between the calcium-dependent morphology and mitochondrial association of the SER and its various functional roles in the cell.},
	language = {eng},
	number = {Pt 3},
	journal = {Biochemical Society Transactions},
	author = {Goetz, J. G. and Nabi, I. R.},
	month = jun,
	year = {2006},
	pmid = {16709164},
	keywords = {Animals, Cells, Cultured, Endoplasmic Reticulum, Smooth, Humans, Mitochondria},
	pages = {370--373},
}

@article{hajnoczky_mitochondrial_2006,
	title = {Mitochondrial calcium signalling and cell death: approaches for assessing the role of mitochondrial {Ca2}+ uptake in apoptosis},
	volume = {40},
	issn = {0143-4160},
	shorttitle = {Mitochondrial calcium signalling and cell death},
	doi = {10.1016/j.ceca.2006.08.016},
	abstract = {Local Ca(2+) transfer between adjoining domains of the sarcoendoplasmic reticulum (ER/SR) and mitochondria allows ER/SR Ca(2+) release to activate mitochondrial Ca(2+) uptake and to evoke a matrix [Ca(2+)] ([Ca(2+)](m)) rise. [Ca(2+)](m) exerts control on several steps of energy metabolism to synchronize ATP generation with cell function. However, calcium signal propagation to the mitochondria may also ignite a cell death program through opening of the permeability transition pore (PTP). This occurs when the Ca(2+) release from the ER/SR is enhanced or is coincident with sensitization of the PTP. Recent studies have shown that several pro-apoptotic factors, including members of the Bcl-2 family proteins and reactive oxygen species (ROS) regulate the Ca(2+) sensitivity of both the Ca(2+) release channels in the ER and the PTP in the mitochondria. To test the relevance of the mitochondrial Ca(2+) accumulation in various apoptotic paradigms, methods are available for buffering of [Ca(2+)], for dissipation of the driving force of the mitochondrial Ca(2+) uptake and for inhibition of the mitochondrial Ca(2+) transport mechanisms. However, in intact cells, the efficacy and the specificity of these approaches have to be established. Here we discuss mechanisms that recruit the mitochondrial calcium signal to a pro-apoptotic cascade and the approaches available for assessment of the relevance of the mitochondrial Ca(2+) handling in apoptosis. We also present a systematic evaluation of the effect of ruthenium red and Ru360, two inhibitors of mitochondrial Ca(2+) uptake on cytosolic [Ca(2+)] and [Ca(2+)](m) in intact cultured cells.},
	language = {eng},
	number = {5-6},
	journal = {Cell Calcium},
	author = {Hajnóczky, György and Csordás, György and Das, Sudipto and Garcia-Perez, Cecilia and Saotome, Masao and Sinha Roy, Soumya and Yi, Muqing},
	year = {2006},
	pmid = {17074387},
	pmcid = {PMC2692319},
	keywords = {Animals, Apoptosis, Calcium, Calcium Channels, Calcium Signaling, Endoplasmic Reticulum, Mitochondria, Mitochondrial Membrane Transport Proteins, Mitochondrial Permeability Transition Pore, Sarcoplasmic Reticulum},
	pages = {553--560},
}

@article{harmon_bi-fluorescence_2017,
	title = {A {Bi}-fluorescence complementation system to detect associations between the {Endoplasmic} reticulum and mitochondria},
	volume = {7},
	issn = {2045-2322},
	doi = {10.1038/s41598-017-17278-1},
	abstract = {Close contacts between the endoplasmic reticulum membrane and the mitochondrial outer membrane facilitate efficient transfer of lipids between the organelles and coordinate Ca2+ signalling and stress responses. Changes to this coupling is associated with a number of metabolic disorders and neurodegenerative diseases including Alzheimer's, Parkinson's and motor neuron disease. The distance between the two membranes at regions of close apposition is below the resolution of conventional light microscopy, which makes analysis of these interactions challenging. Here we describe a new bifluorescence complementation (BiFC) method that labels a subset of ER-mitochondrial associations in fixed and living cells. The total number of ER-mitochondria associations detected by this approach increases in response to tunicamycin-induced ER stress, serum deprivation or reduced levels of mitofusin 2 (MFN2). This method will facilitate the analysis of dynamic interactions between the ER and mitochondrial membranes.},
	language = {eng},
	number = {1},
	journal = {Scientific Reports},
	author = {Harmon, Mark and Larkman, Philip and Hardingham, Giles and Jackson, Mandy and Skehel, Paul},
	month = dec,
	year = {2017},
	pmid = {29234100},
	pmcid = {PMC5727038},
	keywords = {Animals, COS Cells, Cell Line, Tumor, Chlorocebus aethiops, Endoplasmic Reticulum, Endoplasmic Reticulum Stress, HEK293 Cells, Humans, Immunohistochemistry, Luminescent Proteins, Mice, Microscopy, Confocal, Microscopy, Fluorescence, Mitochondria, Transfection},
	pages = {17467},
}

@article{herrera-cruz_yeast_2017,
	title = {Of yeast, mice and men: {MAMs} come in two flavors},
	volume = {12},
	issn = {1745-6150},
	shorttitle = {Of yeast, mice and men},
	doi = {10.1186/s13062-017-0174-5},
	abstract = {The past decade has seen dramatic progress in our understanding of membrane contact sites (MCS). Important examples of these are endoplasmic reticulum (ER)-mitochondria contact sites. ER-mitochondria contacts have originally been discovered in mammalian tissue, where they have been designated as mitochondria-associated membranes (MAMs). It is also in this model system, where the first critical MAM proteins have been identified, including MAM tethering regulators such as phospho-furin acidic cluster sorting protein 2 (PACS-2) and mitofusin-2. However, the past decade has seen the discovery of the MAM also in the powerful yeast model system Saccharomyces cerevisiae. This has led to the discovery of novel MAM tethers such as the yeast ER-mitochondria encounter structure (ERMES), absent in the mammalian system, but whose regulators Gem1 and Lam6 are conserved. While MAMs, sometimes referred to as mitochondria-ER contacts (MERCs), regulate lipid metabolism, Ca2+ signaling, bioenergetics, inflammation, autophagy and apoptosis, not all of these functions exist in both systems or operate differently. This biological difference has led to puzzling discrepancies on findings obtained in yeast or mammalian cells at the moment. Our review aims to shed some light onto mechanistic differences between yeast and mammalian MAM and their underlying causes.
REVIEWERS: This article was reviewed by Paola Pizzo (nominated by Luca Pellegrini), Maya Schuldiner and György Szabadkai (nominated by Luca Pellegrini).},
	language = {eng},
	number = {1},
	journal = {Biology Direct},
	author = {Herrera-Cruz, Maria Sol and Simmen, Thomas},
	month = jan,
	year = {2017},
	pmid = {28122638},
	pmcid = {PMC5267431},
	keywords = {Animals, Calcium Signaling, Endoplasmic Reticulum, Human, Humans, Intracellular Membranes, MAM, MERCs, Mice, Mitochondria-ER contacts, Mitochondria-associated membrane, Mitochondrial Membranes, Models, Biological, S. cerevisiae, Saccharomyces cerevisiae, Yeast},
	pages = {3},
}

@article{hung_proteomic_2017,
	title = {Proteomic mapping of cytosol-facing outer mitochondrial and {ER} membranes in living human cells by proximity biotinylation},
	volume = {6},
	issn = {2050-084X},
	doi = {10.7554/eLife.24463},
	abstract = {The cytosol-facing membranes of cellular organelles contain proteins that enable signal transduction, regulation of morphology and trafficking, protein import and export, and other specialized processes. Discovery of these proteins by traditional biochemical fractionation can be plagued with contaminants and loss of key components. Using peroxidase-mediated proximity biotinylation, we captured and identified endogenous proteins on the outer mitochondrial membrane (OMM) and endoplasmic reticulum membrane (ERM) of living human fibroblasts. The proteomes of 137 and 634 proteins, respectively, are highly specific and highlight 94 potentially novel mitochondrial or ER proteins. Dataset intersection identified protein candidates potentially localized to mitochondria-ER contact sites. We found that one candidate, the tail-anchored, PDZ-domain-containing OMM protein SYNJ2BP, dramatically increases mitochondrial contacts with rough ER when overexpressed. Immunoprecipitation-mass spectrometry identified ribosome-binding protein 1 (RRBP1) as SYNJ2BP's ERM binding partner. Our results highlight the power of proximity biotinylation to yield insights into the molecular composition and function of intracellular membranes.},
	language = {eng},
	journal = {eLife},
	author = {Hung, Victoria and Lam, Stephanie S. and Udeshi, Namrata D. and Svinkina, Tanya and Guzman, Gaelen and Mootha, Vamsi K. and Carr, Steven A. and Ting, Alice Y.},
	month = apr,
	year = {2017},
	pmid = {28441135},
	pmcid = {PMC5404927},
	keywords = {APEX2, Animals, Biotinylation, COS Cells, Chlorocebus aethiops, Endoplasmic Reticulum, HEK293 Cells, HeLa Cells, Humans, Intracellular Membranes, Membrane Proteins, Mitochondria, Peroxidase, Proteomics, biochemistry, cell biology, human, microscopy, mitochondria-ER junctions, mitochondria-associated membrane, promiscuous enzymatic labeling, subcellular regions},
	pages = {e24463},
}

@article{ilacqua_three-organelle_2022,
	title = {A three-organelle complex made by {wrappER} contacts with peroxisomes and mitochondria responds to liver lipid flux changes},
	volume = {135},
	issn = {1477-9137},
	doi = {10.1242/jcs.259091},
	abstract = {Hepatic lipid homeostasis depends on intracellular pathways that respire fatty acid in peroxisomes and mitochondria, and on systemic pathways that secrete fatty acid into the bloodstream, either free or condensed in very-low-density lipoprotein (VLDL) triglycerides. These systemic and intracellular pathways are interdependent, but it is unclear whether and how they integrate into a single cellular circuit. Here, we report that mouse liver wrappER, a distinct endoplasmic reticulum (ER) compartment with apparent fatty acid- and VLDL-secretion functions, connects peroxisomes and mitochondria. Correlative light electron microscopy, quantitative serial section electron tomography and three-dimensional organelle reconstruction analysis show that the number of peroxisome-wrappER-mitochondria complexes changes throughout fasting-to-feeding transitions and doubles when VLDL synthesis stops following acute genetic ablation of Mttp in the liver. Quantitative proteomic analysis of peroxisome-wrappER-mitochondria complex-enriched fractions indicates that the loss of Mttp upregulates global fatty acid β-oxidation, thereby integrating the dynamics of this three-organelle association into hepatic fatty acid flux responses. Therefore, liver lipid homeostasis occurs through the convergence of systemic and intracellular fatty acid-elimination pathways in the peroxisome-wrappER-mitochondria complex.},
	language = {eng},
	number = {5},
	journal = {Journal of Cell Science},
	author = {Ilacqua, Nicolò and Anastasia, Irene and Raimondi, Andrea and Lemieux, Philippe and de Aguiar Vallim, Thomas Q. and Toth, Katalin and Koonin, Eugene V. and Pellegrini, Luca},
	month = mar,
	year = {2022},
	pmid = {34672330},
	pmcid = {PMC8627550},
	keywords = {Animals, Fatty acid, Inter-organelle contacts, Lipid Metabolism, Liver, Liver lipid homeostasis, Mice, Mitochondria, Peroxisome, Peroxisomes, Proteomics},
	pages = {jcs259091},
}

@article{leal_mitofusin-2_2016,
	title = {Mitofusin-2 knockdown increases {ER}-mitochondria contact and decreases amyloid β-peptide production},
	volume = {20},
	issn = {1582-4934},
	doi = {10.1111/jcmm.12863},
	abstract = {Mitochondria are physically and biochemically in contact with other organelles including the endoplasmic reticulum (ER). Such contacts are formed between mitochondria-associated ER membranes (MAM), specialized subregions of ER, and the outer mitochondrial membrane (OMM). We have previously shown increased expression of MAM-associated proteins and enhanced ER to mitochondria Ca(2+) transfer from ER to mitochondria in Alzheimer's disease (AD) and amyloid β-peptide (Aβ)-related neuronal models. Here, we report that siRNA knockdown of mitofusin-2 (Mfn2), a protein that is involved in the tethering of ER and mitochondria, leads to increased contact between the two organelles. Cells depleted in Mfn2 showed increased Ca(2+) transfer from ER to mitchondria and longer stretches of ER forming contacts with OMM. Interestingly, increased contact resulted in decreased concentrations of intra- and extracellular Aβ40 and Aβ42 . Analysis of γ-secretase protein expression, maturation and activity revealed that the low Aβ concentrations were a result of impaired γ-secretase complex function. Amyloid-β precursor protein (APP), β-site APP-cleaving enzyme 1 and neprilysin expression as well as neprilysin activity were not affected by Mfn2 siRNA treatment. In summary, our data shows that modulation of ER-mitochondria contact affects γ-secretase activity and Aβ generation. Increased ER-mitochondria contact results in lower γ-secretase activity suggesting a new mechanism by which Aβ generation can be controlled.},
	language = {eng},
	number = {9},
	journal = {Journal of Cellular and Molecular Medicine},
	author = {Leal, Nuno Santos and Schreiner, Bernadette and Pinho, Catarina Moreira and Filadi, Riccardo and Wiehager, Birgitta and Karlström, Helena and Pizzo, Paola and Ankarcrona, Maria},
	month = sep,
	year = {2016},
	pmid = {27203684},
	pmcid = {PMC4988279},
	keywords = {Adenosine Triphosphate, Alzheimer's disease, Amyloid Precursor Protein Secretases, Amyloid beta-Peptides, Aβ, Calcium, Down-Regulation, ER-mitochondria contacts, Endoplasmic Reticulum, GTP Phosphohydrolases, Gene Knockdown Techniques, HEK293 Cells, Humans, Mitochondria, Mitochondrial Proteins, Mitofusin-2, RNA, Small Interfering, γ-secretase},
	pages = {1686--1695},
}

@article{markovinovic_endoplasmic_2022,
	title = {Endoplasmic reticulum-mitochondria signaling in neurons and neurodegenerative diseases},
	volume = {135},
	issn = {1477-9137},
	doi = {10.1242/jcs.248534},
	abstract = {Recent advances have revealed common pathological changes in neurodegenerative diseases, such as Alzheimer's disease, Parkinson's disease and amyotrophic lateral sclerosis with related frontotemporal dementia (ALS/FTD). Many of these changes can be linked to alterations in endoplasmic reticulum (ER)-mitochondria signaling, including dysregulation of Ca2+ signaling, autophagy, lipid metabolism, ATP production, axonal transport, ER stress responses and synaptic dysfunction. ER-mitochondria signaling involves specialized regions of ER, called mitochondria-associated membranes (MAMs). Owing to their role in neurodegenerative processes, MAMs have gained attention as they appear to be associated with all the major neurodegenerative diseases. Furthermore, their specific role within neuronal maintenance is being revealed as mutant genes linked to major neurodegenerative diseases have been associated with damage to these specialized contacts. Several studies have now demonstrated that these specialized contacts regulate neuronal health and synaptic transmission, and that MAMs are damaged in patients with neurodegenerative diseases. This Review will focus on the role of MAMs and ER-mitochondria signaling within neurons and how damage of the ER-mitochondria axis leads to a disruption of vital processes causing eventual neurodegeneration.},
	language = {eng},
	number = {3},
	journal = {Journal of Cell Science},
	author = {Markovinovic, Andrea and Greig, Jenny and Martín-Guerrero, Sandra María and Salam, Shaakir and Paillusson, Sebastien},
	month = feb,
	year = {2022},
	pmid = {35129196},
	keywords = {Amyotrophic Lateral Sclerosis, Endoplasmic Reticulum, Endoplasmic Reticulum Stress, Endoplasmic reticulum, Frontotemporal Dementia, Humans, MAMs, Mitochondria, Neurodegenerative Diseases, Neurodegenerative diseases, Neurons, Tethers},
	pages = {jcs248534},
}

@article{van_den_boomen_ubiquitin-mediated_2020,
	title = {Ubiquitin-mediated regulation of sterol homeostasis},
	volume = {65},
	issn = {1879-0410},
	doi = {10.1016/j.ceb.2020.04.010},
	abstract = {Cholesterol is an essential component of mammalian membranes, and its homeostasis is strictly regulated, with imbalances causing atherosclerosis, Niemann Pick disease, and familial hypercholesterolemia. Cellular cholesterol supply is mediated by LDL-cholesterol import and de novo cholesterol biosynthesis, and both pathways are adjusted to cellular demand by the cholesterol-sensitive SREBP2 transcription factor. Cholesterol homeostasis is modulated by a wide variety of metabolic pathways and the ubiquitination machinery, in particular E3 ubiquitin ligases. In this article, we review recent progress in understanding the role of E3 ubiquitin ligases in the metabolic control of cellular sterol homeostasis.},
	language = {eng},
	journal = {Current Opinion in Cell Biology},
	author = {van den Boomen, Dick J. H. and Volkmar, Norbert and Lehner, Paul J.},
	month = aug,
	year = {2020},
	pmid = {32580085},
	keywords = {Animals, Cholesterol, E3 ubiquitin ligases, ER associated degradation (ERAD), HMG-CoA reductase, Homeostasis, Humans, Hydroxymethylglutaryl CoA Reductases, LDL-cholesterol import, Proteolysis, RNF145, SCAP, SREBP2, Sterol-induced HMGCR degradation, Sterols, Ubiquitin, Ubiquitin-Protein Ligases, Ubiquitin-mediated cholesterol homeostasis, gp78},
	pages = {103--111},
}

@article{naon_critical_2016,
	title = {Critical reappraisal confirms that {Mitofusin} 2 is an endoplasmic reticulum-mitochondria tether},
	volume = {113},
	issn = {1091-6490},
	doi = {10.1073/pnas.1606786113},
	abstract = {The discovery of the multiple roles of mitochondria-endoplasmic reticulum (ER) juxtaposition in cell biology often relied upon the exploitation of Mitofusin (Mfn) 2 as an ER-mitochondria tether. However, this established Mfn2 function was recently questioned, calling for a critical re-evaluation of Mfn2's role in ER-mitochondria cross-talk. Electron microscopy and fluorescence-based probes of organelle proximity confirmed that ER-mitochondria juxtaposition was reduced by constitutive or acute Mfn2 deletion. Functionally, mitochondrial uptake of Ca2+ released from the ER was reduced following acute Mfn2 ablation, as well as in Mfn2-/- cells overexpressing the mitochondrial calcium uniporter. Mitochondrial Ca2+ uptake rate and extent were normal in isolated Mfn2-/- liver mitochondria, consistent with the finding that acute or chronic Mfn2 ablation or overexpression did not alter mitochondrial calcium uniporter complex component levels. Hence, Mfn2 stands as a bona fide ER-mitochondria tether whose ablation decreases interorganellar juxtaposition and communication.},
	language = {eng},
	number = {40},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Naon, Deborah and Zaninello, Marta and Giacomello, Marta and Varanita, Tatiana and Grespi, Francesca and Lakshminaranayan, Sowmya and Serafini, Annalisa and Semenzato, Martina and Herkenne, Stephanie and Hernández-Alvarez, Maria Isabel and Zorzano, Antonio and De Stefani, Diego and Dorn, Gerald W. and Scorrano, Luca},
	month = oct,
	year = {2016},
	pmid = {27647893},
	pmcid = {PMC5056088},
	keywords = {Animals, Ca2+, Calcium, Calcium Channels, Embryo, Mammalian, Endoplasmic Reticulum, Fibroblasts, GTP Phosphohydrolases, Gene Deletion, Human Umbilical Vein Endothelial Cells, Humans, Liver, Mfn2, Mice, Knockout, Mitochondria, Molecular Probes, interorganellar communication, mitochondria, tethering},
	pages = {11249--11254},
}

@article{neuspiel_cargo-selected_2008,
	title = {Cargo-selected transport from the mitochondria to peroxisomes is mediated by vesicular carriers},
	volume = {18},
	issn = {0960-9822},
	doi = {10.1016/j.cub.2007.12.038},
	abstract = {Mitochondria and peroxisomes share a number of common biochemical processes, including the beta oxidation of fatty acids and the scavenging of peroxides. Here, we identify a new outer-membrane mitochondria-anchored protein ligase (MAPL) containing a really interesting new gene (RING)-finger domain. Overexpression of MAPL leads to mitochondrial fragmentation, indicating a regulatory function controlling mitochondrial morphology. In addition, confocal- and electron-microscopy studies of MAPL-YFP led to the observation that MAPL is also incorporated within unique, DRP1-independent, 70-100 nm diameter mitochondria-derived vesicles (MDVs). Importantly, vesicles containing MAPL exclude another outer-membrane marker, TOM20, and vesicles containing TOM20 exclude MAPL, indicating that MDVs selectively incorporate their cargo. We further demonstrate that MAPL-containing vesicles fuse with a subset of peroxisomes, marking the first evidence for a direct relationship between these two functionally related organelles. In contrast, a distinct vesicle population labeled with TOM20 does not fuse with peroxisomes, indicating that the incorporation of specific cargo is a primary determinant of MDV fate. These data are the first to identify MAPL, describe and characterize MDVs, and define a new intracellular transport route between mitochondria and peroxisomes.},
	language = {eng},
	number = {2},
	journal = {Current biology: CB},
	author = {Neuspiel, Margaret and Schauss, Astrid C. and Braschi, Emelie and Zunino, Rodolfo and Rippstein, Peter and Rachubinski, Richard A. and Andrade-Navarro, Miguel A. and McBride, Heidi M.},
	month = jan,
	year = {2008},
	pmid = {18207745},
	keywords = {Animals, COS Cells, Chlorocebus aethiops, HeLa Cells, Humans, Mitochondria, Mitochondrial Proteins, Peroxisomes, RING Finger Domains, Transcription Factors, Transport Vesicles, Ubiquitin-Protein Ligases},
	pages = {102--108},
}

@article{nixon-abell_increased_2016,
	title = {Increased spatiotemporal resolution reveals highly dynamic dense tubular matrices in the peripheral {ER}},
	volume = {354},
	issn = {1095-9203},
	doi = {10.1126/science.aaf3928},
	abstract = {The endoplasmic reticulum (ER) is an expansive, membrane-enclosed organelle that plays crucial roles in numerous cellular functions. We used emerging superresolution imaging technologies to clarify the morphology and dynamics of the peripheral ER, which contacts and modulates most other intracellular organelles. Peripheral components of the ER have classically been described as comprising both tubules and flat sheets. We show that this system consists almost exclusively of tubules at varying densities, including structures that we term ER matrices. Conventional optical imaging technologies had led to misidentification of these structures as sheets because of the dense clustering of tubular junctions and a previously uncharacterized rapid form of ER motion. The existence of ER matrices explains previous confounding evidence that had indicated the occurrence of ER "sheet" proliferation after overexpression of tubular junction-forming proteins.},
	language = {eng},
	number = {6311},
	journal = {Science (New York, N.Y.)},
	author = {Nixon-Abell, Jonathon and Obara, Christopher J. and Weigel, Aubrey V. and Li, Dong and Legant, Wesley R. and Xu, C. Shan and Pasolli, H. Amalia and Harvey, Kirsten and Hess, Harald F. and Betzig, Eric and Blackstone, Craig and Lippincott-Schwartz, Jennifer},
	month = oct,
	year = {2016},
	pmid = {27789813},
	pmcid = {PMC6528812},
	keywords = {Animals, COS Cells, Calnexin, Chlorocebus aethiops, Endoplasmic Reticulum, GTP Phosphohydrolases, HeLa Cells, Humans, Microscopy, Confocal, Microscopy, Electron, Microtubules, Molecular Imaging, SEC Translocation Channels},
	pages = {aaf3928},
}

@article{rowland_endoplasmic_2012,
	title = {Endoplasmic reticulum-mitochondria contacts: function of the junction},
	volume = {13},
	issn = {1471-0080},
	shorttitle = {Endoplasmic reticulum-mitochondria contacts},
	doi = {10.1038/nrm3440},
	abstract = {The most well-characterized organelle contact sites are those between the endoplasmic reticulum (ER) and mitochondria. Increased understanding is being gained of how ER-mitochondria contact sites are organized and which factors converge at this interface, some of which may provide a tethering function. The role of the ER-mitochondria junction in coordinating the functions of these two organelles is also becoming clearer, and it has been shown to be involved in the regulation of lipid synthesis, Ca(2+) signalling and the control of mitochondrial biogenesis and intracellular trafficking.},
	language = {eng},
	number = {10},
	journal = {Nature Reviews. Molecular Cell Biology},
	author = {Rowland, Ashley A. and Voeltz, Gia K.},
	month = oct,
	year = {2012},
	pmid = {22992592},
	pmcid = {PMC5111635},
	keywords = {Animals, Calcium Signaling, Endoplasmic Reticulum, Lipids, Mitochondria, Mitochondrial Membranes, Mitochondrial Turnover, Protein Transport, Signal Transduction},
	pages = {607--625},
}

@article{schroeder_dynamic_2019,
	title = {Dynamic nanoscale morphology of the {ER} surveyed by {STED} microscopy},
	volume = {218},
	issn = {1540-8140},
	doi = {10.1083/jcb.201809107},
	abstract = {The endoplasmic reticulum (ER) is composed of interconnected membrane sheets and tubules. Superresolution microscopy recently revealed densely packed, rapidly moving ER tubules mistaken for sheets by conventional light microscopy, highlighting the importance of revisiting classical views of ER structure with high spatiotemporal resolution in living cells. In this study, we use live-cell stimulated emission depletion (STED) microscopy to survey the architecture of the ER at 50-nm resolution. We determine the nanoscale dimensions of ER tubules and sheets for the first time in living cells. We demonstrate that ER sheets contain highly dynamic, subdiffraction-sized holes, which we call nanoholes, that coexist with uniform sheet regions. Reticulon family members localize to curved edges of holes within sheets and are required for their formation. The luminal tether Climp63 and microtubule cytoskeleton modulate their nanoscale dynamics and organization. Thus, by providing the first quantitative analysis of ER membrane structure and dynamics at the nanoscale, our work reveals that the ER in living cells is not limited to uniform sheets and tubules; instead, we suggest the ER contains a continuum of membrane structures that includes dynamic nanoholes in sheets as well as clustered tubules.},
	language = {eng},
	number = {1},
	journal = {The Journal of Cell Biology},
	author = {Schroeder, Lena K. and Barentine, Andrew E. S. and Merta, Holly and Schweighofer, Sarah and Zhang, Yongdeng and Baddeley, David and Bewersdorf, Joerg and Bahmanyar, Shirin},
	month = jan,
	year = {2019},
	pmid = {30442642},
	pmcid = {PMC6314542},
	keywords = {Animals, COS Cells, Chlorocebus aethiops, Cytoskeleton, Endoplasmic Reticulum, Gene Expression Regulation, Intracellular Membranes, Microscopy, Microtubules, Molecular Imaging, Nocodazole, Nogo Proteins, Nuclear Pore Complex Proteins, Receptors, Cell Surface, Time-Lapse Imaging, Tubulin Modulators},
	pages = {83--96},
}

@article{scorrano_coming_2019,
	title = {Coming together to define membrane contact sites},
	volume = {10},
	issn = {2041-1723},
	doi = {10.1038/s41467-019-09253-3},
	abstract = {Close proximities between organelles have been described for decades. However, only recently a specific field dealing with organelle communication at membrane contact sites has gained wide acceptance, attracting scientists from multiple areas of cell biology. The diversity of approaches warrants a unified vocabulary for the field. Such definitions would facilitate laying the foundations of this field, streamlining communication and resolving semantic controversies. This opinion, written by a panel of experts in the field, aims to provide this burgeoning area with guidelines for the experimental definition and analysis of contact sites. It also includes suggestions on how to operationally and tractably measure and analyze them with the hope of ultimately facilitating knowledge production and dissemination within and outside the field of contact-site research.},
	language = {eng},
	number = {1},
	journal = {Nature Communications},
	author = {Scorrano, Luca and De Matteis, Maria Antonietta and Emr, Scott and Giordano, Francesca and Hajnóczky, György and Kornmann, Benoît and Lackner, Laura L. and Levine, Tim P. and Pellegrini, Luca and Reinisch, Karin and Rizzuto, Rosario and Simmen, Thomas and Stenmark, Harald and Ungermann, Christian and Schuldiner, Maya},
	month = mar,
	year = {2019},
	pmid = {30894536},
	pmcid = {PMC6427007},
	keywords = {Animals, Cell Fractionation, Cell Membrane, Eukaryotic Cells, Humans, Intracellular Membranes, Microscopy, Organelles, Proteins, Staining and Labeling, Terminology as Topic},
	pages = {1287},
}

@article{shim_super-resolution_2012,
	title = {Super-resolution fluorescence imaging of organelles in live cells with photoswitchable membrane probes},
	volume = {109},
	issn = {1091-6490},
	doi = {10.1073/pnas.1201882109},
	abstract = {Imaging membranes in live cells with nanometer-scale resolution promises to reveal ultrastructural dynamics of organelles that are essential for cellular functions. In this work, we identified photoswitchable membrane probes and obtained super-resolution fluorescence images of cellular membranes. We demonstrated the photoswitching capabilities of eight commonly used membrane probes, each specific to the plasma membrane, mitochondria, the endoplasmic recticulum (ER) or lysosomes. These small-molecule probes readily label live cells with high probe densities. Using these probes, we achieved dynamic imaging of specific membrane structures in living cells with 30-60 nm spatial resolution at temporal resolutions down to 1-2 s. Moreover, by using spectrally distinguishable probes, we obtained two-color super-resolution images of mitochondria and the ER. We observed previously obscured details of morphological dynamics of mitochondrial fusion/fission and ER remodeling, as well as heterogeneous membrane diffusivity on neuronal processes.},
	language = {eng},
	number = {35},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Shim, Sang-Hee and Xia, Chenglong and Zhong, Guisheng and Babcock, Hazen P. and Vaughan, Joshua C. and Huang, Bo and Wang, Xun and Xu, Cheng and Bi, Guo-Qiang and Zhuang, Xiaowei},
	month = aug,
	year = {2012},
	pmid = {22891300},
	pmcid = {PMC3435176},
	keywords = {Boron Compounds, Carbocyanines, Cell Membrane, Dendrites, Endoplasmic Reticulum, Fluorescent Dyes, Hippocampus, Lipid Bilayers, Lysosomes, Microscopy, Fluorescence, Mitochondria, Nanostructures, Neurons, Organelles, Pseudopodia, Stochastic Processes},
	pages = {13978--13983},
}

@article{st-pierre_peripheral_2012,
	title = {Peripheral {Endoplasmic} {Reticulum} {Localization} of {Gp78} {Ubiquitin} {Ligase} {Activity}},
	issn = {1477-9137, 0021-9533},
	url = {https://journals.biologists.com/jcs/article/doi/10.1242/jcs.096396/258442/Peripheral-Endoplasmic-Reticulum-Localization-of},
	doi = {10.1242/jcs.096396},
	abstract = {Gp78 is an E3 ubiquitin ligase that targets proteins for proteasomal degradation through endoplasmic reticulum-associated degradation (ERAD). Here, we show that gp78-mediated ubiquitylation is initiated in the peripheral ER. Substrate monoubiquitylation and gp78 Cue domain integrity restrict substrate to the peripheral ER where Cue domain interactions and polyubiquitylation reduce gp78 mobility. Derlin-1 and derlin-2, involved in retrotranslocation of ERAD substrates, localize to a central, juxtanuclear ER domain where polyubiquitylated proteins accumulate upon proteasome inhibition. Transfer of polyubiquitylated substrate to the central ER is dependent on ubiquitin chain elongation and recruitment of the AAA ATPase p97. HT-1080 fibrosarcoma cells express elevated levels of endogenous gp78 that is associated with segregation of ubiquitylated substrate to the peripheral ER and its polyubiquitin-dependent redistribution to the central ER upon proteasome inhibition. The peripheral ER is therefore the site of gp78 ubiquitin ligase activity. Delivery of ubiquitylated substrate to the central ER is regulated by ubiquitin chain elongation and opposing actions of gp78 Cue domain interactions and p97 recruitment.},
	language = {en},
	urldate = {2023-10-29},
	journal = {Journal of Cell Science},
	author = {St-Pierre, Pascal and Dang, Thao and Joshi, Bharat and Nabi, Ivan R.},
	month = jan,
	year = {2012},
	pages = {jcs.096396},
}

@article{sun_lunapark_2020,
	title = {{LUNAPARK} {Is} an {E3} {Ligase} {That} {Mediates} {Degradation} of {ROOT} {HAIR} {DEFECTIVE3} to {Maintain} a {Tubular} {ER} {Network} in {Arabidopsis}},
	volume = {32},
	issn = {1532-298X},
	doi = {10.1105/tpc.18.00937},
	abstract = {ROOT HAIR DEFECTIVE3 (RHD3) is an atlastin GTPase involved in homotypic fusion of endoplasmic reticulum (ER) tubules in the formation of the interconnected ER network. Because excessive fusion of ER tubules will lead to the formation of sheet-like ER, the action of atlastin GTPases must be tightly regulated. We show here that RHD3 physically interacts with two Arabidopsis (Arabidopsis thaliana) LUNAPARK proteins, LNP1 and LNP2, at three-way junctions of the ER, the sites where different ER tubules fuse. Recruited by RHD3 to newly formed three-way junctions, LNPs act negatively with RHD3 to stabilize the nascent three-way junctions of the ER. Without this LNP-mediated stabilization, in Arabidopsis lnp1-1 lnp2-1 mutant cells, the ER becomes a dense tubular network. Interestingly, in lnp1-1 lnp2-1 mutant cells, the expression level of RHD3 is higher than that in wild-type plants. RHD3 is degraded more slowly in the absence of LNPs as well as in the presence of MG132 and concanamycin A. However, in the presence of LNPs, the degradation of RHD3 is promoted. We have provided in vitro evidence that Arabidopsis LNPs have E3 ubiquitin ligase activity and that LNP1 can directly ubiquitinate RHD3. Our data show that after ER fusion is completed, RHD3 is degraded by LNPs so that nascent three-way junctions can be stabilized and a tubular ER network can be maintained.},
	language = {eng},
	number = {9},
	journal = {The Plant Cell},
	author = {Sun, Jiaqi and Movahed, Nooshin and Zheng, Huanquan},
	month = sep,
	year = {2020},
	pmid = {32616662},
	pmcid = {PMC7474291},
	keywords = {Arabidopsis, Arabidopsis Proteins, Endoplasmic Reticulum, GTP-Binding Proteins, Microtubules, Mutation, Plant Cells, Plants, Genetically Modified, Protein Interaction Maps, Ubiquitination},
	pages = {2964--2978},
}

@article{tameling_colocalization_2021,
	title = {Colocalization for super-resolution microscopy via optimal transport},
	volume = {1},
	issn = {2662-8457},
	doi = {10.1038/s43588-021-00050-x},
	abstract = {Super-resolution fluorescence microscopy is a widely used technique in cell biology. Stimulated emission depletion (STED) microscopy enables the recording of multiple-color images with subdiffraction resolution. The enhanced resolution leads to new challenges regarding colocalization analysis of macromolecule distributions. We demonstrate that well-established methods for the analysis of colocalization in diffraction-limited datasets and for coordinate-stochastic nanoscopy are not equally well suited for the analysis of high-resolution STED images. We propose optimal transport colocalization, which measures the minimal transporting cost below a given spatial scale to match two protein intensity distributions. Its validity on simulated data as well as on dual-color STED recordings of yeast and mammalian cells is demonstrated. We also extend the optimal transport colocalization methodology to coordinate-stochastic nanoscopy.},
	language = {eng},
	journal = {Nature Computational Science},
	author = {Tameling, Carla and Stoldt, Stefan and Stephan, Till and Naas, Julia and Jakobs, Stefan and Munk, Axel},
	month = mar,
	year = {2021},
	pmid = {35874932},
	pmcid = {PMC7613136},
	pages = {199--211},
}

@article{tsai_ubiquitin_2007,
	title = {The ubiquitin ligase gp78 promotes sarcoma metastasis by targeting {KAI1} for degradation},
	volume = {13},
	issn = {1546-170X},
	doi = {10.1038/nm1686},
	abstract = {Metastasis is the primary cause of mortality from cancer, but the mechanisms leading to metastasis are poorly understood. In particular, relatively little is known about metastasis in cancers of mesenchymal origins, which are known as sarcomas. Approximately ten proteins have been characterized as 'metastasis suppressors', but how these proteins function and are regulated is, in general, not well understood. Gp78 (also known as AMFR or RNF45) is a RING finger E3 ubiquitin ligase that is integral to the endoplasmic reticulum (ER) and involved in ER-associated degradation (ERAD) of diverse substrates. Here we report that expression of gp78 has a causal role in the metastasis of an aggressive human sarcoma and that this prometastatic activity requires the E3 activity of gp78. Further, gp78 associates with and targets the transmembrane metastasis suppressor, KAI1 (also known as CD82), for degradation. Suppression of gp78 increases KAI1 abundance and reduces the metastatic potential of tumor cells, an effect that is largely blocked by concomitant suppression of KAI1. An inverse relationship between these proteins was confirmed in a human sarcoma tissue microarray. Whereas most previous efforts have focused on genetic mechanisms for the loss of metastasis suppressor genes, our results provide new evidence for post-translational downregulation of a metastasis suppressor by its ubiquitin ligase, resulting in abrogation of its metastasis-suppressing effects.},
	language = {eng},
	number = {12},
	journal = {Nature Medicine},
	author = {Tsai, Yien Che and Mendoza, Arnulfo and Mariano, Jennifer M. and Zhou, Ming and Kostova, Zlatka and Chen, Bo and Veenstra, Timothy and Hewitt, Stephen M. and Helman, Lee J. and Khanna, Chand and Weissman, Allan M.},
	month = dec,
	year = {2007},
	pmid = {18037895},
	keywords = {Animals, Cell Line, Tumor, Endoplasmic Reticulum, Humans, Kangai-1 Protein, Mesoderm, Mice, Neoplasm Metastasis, Oligonucleotide Array Sequence Analysis, Proteins, RING Finger Domains, Receptors, Autocrine Motility Factor, Receptors, Cytokine, Sarcoma, Transfection, Ubiquitin-Protein Ligases},
	pages = {1504--1509},
}

@article{vallese_expanded_2020,
	title = {An expanded palette of improved {SPLICS} reporters detects multiple organelle contacts in vitro and in vivo},
	volume = {11},
	issn = {2041-1723},
	doi = {10.1038/s41467-020-19892-6},
	abstract = {Membrane contact sites between virtually any known organelle have been documented and, in the last decades, their study received momentum due to their importance for fundamental activities of the cell and for the subtle comprehension of many human diseases. The lack of tools to finely image inter-organelle proximity hindered our understanding on how these subcellular communication hubs mediate and regulate cell homeostasis. We develop an improved and expanded palette of split-GFP-based contact site sensors (SPLICS) for the detection of single and multiple organelle contact sites within a scalable distance range. We demonstrate their flexibility under physiological conditions and in living organisms.},
	language = {eng},
	number = {1},
	journal = {Nature Communications},
	author = {Vallese, Francesca and Catoni, Cristina and Cieri, Domenico and Barazzuol, Lucia and Ramirez, Omar and Calore, Valentina and Bonora, Massimo and Giamogante, Flavia and Pinton, Paolo and Brini, Marisa and Calì, Tito},
	month = nov,
	year = {2020},
	pmid = {33247103},
	pmcid = {PMC7699637},
	keywords = {Animals, Calcium, Cell Membrane, Cytosol, Endoplasmic Reticulum, Genes, Reporter, Green Fluorescent Proteins, HeLa Cells, Humans, Neurons, Organelles, Rats, Sprague-Dawley, Zebrafish},
	pages = {6069},
}

@article{valm_applying_2017,
	title = {Applying systems-level spectral imaging and analysis to reveal the organelle interactome},
	volume = {546},
	issn = {1476-4687},
	doi = {10.1038/nature22369},
	abstract = {The organization of the eukaryotic cell into discrete membrane-bound organelles allows for the separation of incompatible biochemical processes, but the activities of these organelles must be coordinated. For example, lipid metabolism is distributed between the endoplasmic reticulum for lipid synthesis, lipid droplets for storage and transport, mitochondria and peroxisomes for β-oxidation, and lysosomes for lipid hydrolysis and recycling. It is increasingly recognized that organelle contacts have a vital role in diverse cellular functions. However, the spatial and temporal organization of organelles within the cell remains poorly characterized, as fluorescence imaging approaches are limited in the number of different labels that can be distinguished in a single image. Here we present a systems-level analysis of the organelle interactome using a multispectral image acquisition method that overcomes the challenge of spectral overlap in the fluorescent protein palette. We used confocal and lattice light sheet instrumentation and an imaging informatics pipeline of five steps to achieve mapping of organelle numbers, volumes, speeds, positions and dynamic inter-organelle contacts in live cells from a monkey fibroblast cell line. We describe the frequency and locality of two-, three-, four- and five-way interactions among six different membrane-bound organelles (endoplasmic reticulum, Golgi, lysosome, peroxisome, mitochondria and lipid droplet) and show how these relationships change over time. We demonstrate that each organelle has a characteristic distribution and dispersion pattern in three-dimensional space and that there is a reproducible pattern of contacts among the six organelles, that is affected by microtubule and cell nutrient status. These live-cell confocal and lattice light sheet spectral imaging approaches are applicable to any cell system expressing multiple fluorescent probes, whether in normal conditions or when cells are exposed to disturbances such as drugs, pathogens or stress. This methodology thus offers a powerful descriptive tool and can be used to develop hypotheses about cellular organization and dynamics.},
	language = {eng},
	number = {7656},
	journal = {Nature},
	author = {Valm, Alex M. and Cohen, Sarah and Legant, Wesley R. and Melunis, Justin and Hershberg, Uri and Wait, Eric and Cohen, Andrew R. and Davidson, Michael W. and Betzig, Eric and Lippincott-Schwartz, Jennifer},
	month = jun,
	year = {2017},
	pmid = {28538724},
	pmcid = {PMC5536967},
	keywords = {Animals, COS Cells, Cell Survival, Chlorocebus aethiops, Color, Cytoskeleton, Endoplasmic Reticulum, Golgi Apparatus, Lipid Metabolism, Lysosomes, Microscopy, Confocal, Microtubules, Mitochondria, Molecular Imaging, Organelles, Peroxisomes, Spatio-Temporal Analysis, Systems Biology},
	pages = {162--167},
}

@article{vance_phospholipid_1990,
	title = {Phospholipid synthesis in a membrane fraction associated with mitochondria},
	volume = {265},
	issn = {0021-9258},
	abstract = {A crude rat liver mitochondrial fraction that was capable of the rapid, linked synthesis of phosphatidylserine (PtdSer), phosphatidylethanolamine (PtdEtn), and phosphatidylcholine (PtdCho) labeled from [3-3H] serine has been fractionated. PtdSer synthase, PtdEtn methyltransferase, and CDP-choline:diacylglycerol cholinephosphotransferase activities were present in the crude mitochondrial preparation but were absent from highly purified mitochondria and could be attributed to the presence of a membrane fraction, X. Thus, previous claims of the mitochondrial location of some of these enzymes might be explained by the presence of fraction X in the mitochondrial preparation. Fraction X had many similarities to microsomes except that it sedimented with mitochondria (at 10,000 x g). However, the specific activities of PtdSer synthase and glucose-6-phosphate phosphatase in fraction X were almost twice that of microsomes, and the specific activities of CTP:phosphocholine cytidylyltransferase and NADPH:cytochrome c reductase in fraction X were much lower than in microsomes. The marker enzymes for mitochondria, Golgi apparatus, plasma membrane, lysosomes, and peroxisomes all had low activities in fraction X. Polyacrylamide gel electrophoresis revealed distinct differences, as well as similarities, among the proteins of fraction X, microsomes, and rough and smooth endoplasmic reticulum. The combined mitochondria-fraction X membranes can synthesize PtdSer, PtdEtn, and PtdCho from serine. Thus, fraction X in combination with mitochondria might be responsible for the observed compartmentalization of a serine-labeled pool of phospholipids previously identified (Vance, J. E., and Vance, D. E. (1986) J. Biol. Chem. 261, 4486-4491) and might be involved in the transfer of lipids between the endoplasmic reticulum and mitochondria.},
	language = {eng},
	number = {13},
	journal = {The Journal of Biological Chemistry},
	author = {Vance, J. E.},
	month = may,
	year = {1990},
	pmid = {2332429},
	keywords = {Animals, Cell Fractionation, Centrifugation, Density Gradient, Female, Intracellular Membranes, Kinetics, Lysosomes, Microsomes, Liver, Mitochondria, Liver, Models, Biological, Phospholipids, Rats, Rats, Inbred Strains, Submitochondrial Particles},
	pages = {7248--7256},
}

@article{wang_revisiting_2021,
	title = {Revisiting colocalization via optimal transport},
	volume = {1},
	copyright = {2021 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
	issn = {2662-8457},
	url = {https://www.nature.com/articles/s43588-021-00046-7},
	doi = {10.1038/s43588-021-00046-7},
	abstract = {The advent of STED microscopy, which allows observation at a sub-diffraction resolution, raises a challenge in studying spatial proximities of biomolecules’ distributions. In this issue, researchers have attempted to study colocalization of molecules by employing optimal transport.},
	language = {en},
	number = {3},
	urldate = {2023-10-29},
	journal = {Nature Computational Science},
	author = {Wang, Shulei and Yuan, Ming},
	month = mar,
	year = {2021},
	note = {Number: 3
Publisher: Nature Publishing Group},
	keywords = {Computational biophysics, Statistical methods, Super-resolution microscopy},
	pages = {177--178},
}

@article{wang_distinct_2015,
	title = {Distinct mechanisms controlling rough and smooth endoplasmic reticulum-mitochondria contacts},
	issn = {1477-9137, 0021-9533},
	url = {https://journals.biologists.com/jcs/article/doi/10.1242/jcs.171132/260021/Distinct-mechanisms-controlling-rough-and-smooth},
	doi = {10.1242/jcs.171132},
	abstract = {Gp78, an ERAD-associated E3 ubiquitin ligase, localizes to mitochondria-associated ER and targets the mitofusin (Mfn1/Mfn2) mitochondrial fusion proteins for degradation. Gp78 is also the cell surface receptor for autocrine motility factor (AMF) that prevents Gp78-dependent mitofusin degradation. Gp78 ubiquitin ligase activity promotes ER-mitochondria association and ER-mitochondria calcium coupling, processes that are reversed by AMF. Electron microscopy of HT-1080 fibrosarcoma cancer cells identified both smooth (∼8 nm) and wider (∼50-60 nm) rough ER-mitochondria contacts. Gp78 shRNA knockdown and AMF treatment selectively reduced the extent of rough ER-mitochondria contacts without impacting smooth ER-mitochondria contacts. Concomitant siRNA knockdown of Mfn1 increased smooth ER-mitochondria contacts in both control and shGp78 cells while knockdown of Mfn2 increased rough ER-mitochondria contacts selectively in shGp78 HT-1080 cells. The mitofusins therefore inhibit ER-mitochondria interaction. Regulation of close ER-mitochondria contacts by Mfn1 and of rough ER-mitochondria contacts by AMF-sensitive Gp78 degradation of Mfn2 define novel mechanisms that regulate ER-mitochondria interactions.},
	language = {en},
	urldate = {2023-10-29},
	journal = {Journal of Cell Science},
	author = {Wang, Peter T. C. and Garcin, Pierre O. and Fu, Min and Masoudi, Matthew and St-Pierre, Pascal and Panté, Nelly and Nabi, Ivan R.},
	month = jan,
	year = {2015},
	pages = {jcs.171132},
}

@article{vance_newly_1991,
	title = {Newly made phosphatidylserine and phosphatidylethanolamine are preferentially translocated between rat liver mitochondria and endoplasmic reticulum.},
	volume = {266},
	issn = {00219258},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021925818524066},
	doi = {10.1016/S0021-9258(18)52406-6},
	language = {en},
	number = {1},
	urldate = {2023-10-29},
	journal = {Journal of Biological Chemistry},
	author = {Vance, J E},
	month = jan,
	year = {1991},
	pages = {89--97},
}

@book{peck_introduction_2020,
	title = {Introduction to statistics and data analysis},
	isbn = {978-1-337-79361-2},
	url = {https://thuvienso.hoasen.edu.vn/handle/123456789/12547},
	abstract = {In order to get students thinking statistically, this text stresses interpretation and communication of statistical information through hands-on, activity based learning using real data. Written in compliance with the GAISE college report and employing techniques based on modern research into student learning, this text places emphasis on how concepts apply to students and the world around them, then gets into methods using data analysis tools or hand-calculations where necessary. This 6th Edition contains new sections on randomization-based inference: bootstrap methods for simulation-based confidence intervals and randomization tests of hypotheses. These new sections are accompanied by online Shiny apps, which can be used to construct bootstrap confidence intervals and to carry out randomization tests.},
	language = {en},
	urldate = {2023-10-29},
	publisher = {Cengage Learning},
	author = {Peck, Roxy and Short, Tom and Olsen, Chris},
	year = {2020},
}

@book{tukey_exploratory_1977,
	title = {Exploratory {Data} {Analysis}},
	volume = {2},
	publisher = {Reading, MA},
	author = {Tukey, John W},
	year = {1977},
}

@article{olivier_logarithmic_2008,
	title = {The logarithmic transformation and the geometric mean in reporting experimental {IgE} results: what are they and when and why to use them?},
	volume = {100},
	issn = {10811206},
	shorttitle = {The logarithmic transformation and the geometric mean in reporting experimental {IgE} results},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1081120610605959},
	doi = {10.1016/S1081-1206(10)60595-9},
	language = {en},
	number = {4},
	urldate = {2023-10-29},
	journal = {Annals of Allergy, Asthma \& Immunology},
	author = {Olivier, Jake and Johnson, William D. and Marshall, Gailen D.},
	month = apr,
	year = {2008},
	pages = {333--337},
}

@book{milne-thomson_calculus_2000,
	title = {The {Calculus} of {Finite} {Differences}},
	isbn = {978-0-8218-2107-7},
	language = {en},
	publisher = {American Mathematical Soc.},
	author = {Milne-Thomson, Louis Melville},
	year = {2000},
	note = {Google-Books-ID: NXRLajGtgjEC},
}

@misc{noauthor_geomstats_nodate,
	title = {Geomstats — {Geomstats} latest documentation},
	url = {https://geomstats.github.io/},
	urldate = {2022-10-26},
}

@article{durel_quantitative_2021,
	title = {Quantitative {dSTORM} super‐resolution microscopy localizes {Aurora} kinase {A}/{AURKA} in the mitochondrial matrix},
	volume = {113},
	doi = {10.1111/boc.202100021},
	abstract = {Mitochondria are dynamic organelles playing essential metabolic and signaling functions in cells. Their ultrastructure has been largely investigated with electron microscopy (EM) techniques. Super-resolution microscopy approaches such as direct stochastic optical reconstruction microscopy (dSTORM) provide a fluorescent-based, quantitative alternative to EM. However, dSTORM is mainly used to image integral mitochondrial proteins, and there is little or no information on proteins transiently present at this compartment. Here, we first benchmark the power of dSTORM to resolve protein proximities on individual mitochondrial subcompartments, coupled to Geo-coPositioning System (GcoPS) to quantify the degree of protein colocalization. With our dSTORM/GcoPS method, we then analyze the submitochondrial distribution of the cancer-related Aurora kinase A/AURKA, a protein localized at various subcellular locations including mitochondria. We show that dSTORM provides sufficient spatial resolution to detect a large pool of endogenous AURKA within the matrix, and we also uncover a second pool of the kinase at the Outer Mitochondrial Membrane (OMM). We conclude by demonstrating that an aldehyde-based fixation allows for a more specific detection of the OMM pool of AURKA. Our results indicate that dSTORM coupled to GcoPS colocalization analysis is a suitable approach to explore the compartmentalization of non-integral mitochondrial proteins as AURKA, in a qualitative and quantitative manner. This method also opens up the possibility of analyzing the proximity between AURKA and its multiple mitochondrial partners with exquisite spatial resolution, thereby allowing novel insights into the mitochondrial functions controlled by AURKA.
This article is protected by copyright. All rights reserved},
	journal = {Biology of the Cell},
	author = {Durel, Béatrice and Kervrann, Charles and Bertolin, Giulia},
	month = aug,
	year = {2021},
	keywords = {AURKA, GcoPS, colocalization, mitochondria, super-resolution, two-color dSTORM},
}

@article{lavancier_testing_2020,
	title = {Testing independence between two random sets for the analysis of colocalization in bioimaging},
	volume = {76},
	issn = {1541-0420},
	doi = {10.1111/biom.13115},
	abstract = {Colocalization aims at characterizing spatial associations between two fluorescently tagged biomolecules by quantifying the co-occurrence and correlation between the two channels acquired in fluorescence microscopy. Colocalization is presented either as the degree of overlap between the two channels or the overlays of the red and green images, with areas of yellow indicating colocalization of the molecules. This problem remains an open issue in diffraction-limited microscopy and raises new challenges with the emergence of superresolution imaging, a microscopic technique awarded by the 2014 Nobel prize in chemistry. We propose GcoPS, for Geo-coPositioning System, an original method that exploits the random sets structure of the tagged molecules to provide an explicit testing procedure. Our simulation study shows that GcoPS unequivocally outperforms the best competitive methods in adverse situations (noise, irregularly shaped fluorescent patterns, and different optical resolutions). GcoPS is also much faster, a decisive advantage to face the huge amount of data in superresolution imaging. We demonstrate the performances of GcoPS on two biological real data sets, obtained by conventional diffraction-limited microscopy technique and by superresolution technique, respectively.},
	language = {eng},
	number = {1},
	journal = {Biometrics},
	author = {Lavancier, Frédéric and Pécot, Thierry and Zengzhen, Liu and Kervrann, Charles},
	month = mar,
	year = {2020},
	pmid = {31271216},
	keywords = {Animals, Antigens, CD, Biometry, Brain-Derived Neurotrophic Factor, Cell Line, Computer Simulation, Databases, Factual, Fluorescent Dyes, Humans, Lectins, C-Type, Luminescent Proteins, Mannose-Binding Lectins, Mice, Microscopy, Fluorescence, Recombinant Fusion Proteins, Stochastic Processes, Vesicular Glutamate Transport Proteins, quantitative fluorescence microscopy, rab GTP-Binding Proteins, spatial statistics, stochastic geometry, superresolution microscopy},
	pages = {36--46},
}

@article{smets_combination_1990,
	title = {The combination of evidence in the transferable belief model},
	volume = {12},
	issn = {1939-3539},
	doi = {10.1109/34.55104},
	abstract = {A description of the transferable belief model, which is used to quantify degrees of belief based on belief functions, is given. The impact of open- and closed-world assumption on conditioning is discussed. The nature of the frame of discernment on which a degree of belief will be established is discussed. A set of axioms justifying Dempster's rule for the combination of belief functions induced by two distinct evidences is presented.{\textless}{\textgreater}},
	number = {5},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Smets, P.},
	month = may,
	year = {1990},
	keywords = {Arithmetic, Artificial intelligence, Bayesian methods, Computer simulation, Fuzzy set theory, Fuzzy sets, Humans, Mathematical model, Psychology, Uncertainty},
	pages = {447--458},
}

@inproceedings{spilger_deep_2022,
	title = {Deep {Neural} {Network} for {Combined} {Particle} {Tracking} and {Colocalization} {Analysis} in {Two}-{Channel} {Microscopy} {Images}},
	doi = {10.1109/ISBI52829.2022.9761696},
	abstract = {Analyzing protein dynamics in multi-channel fluorescence microscopy data is important to understand biological processes. We present a novel deep learning approach for combined particle tracking and colocalization analysis in two-channel microscopy image sequences. The approach is based on a convolutional long short-term memory network and exploits colocalization information to improve tracking. Short and long-term temporal dependencies of object motion as well as image intensities are taken into account to compute assignment probabilities jointly across multiple detections. Colocalization probabilities are also determined by the neural network. We evaluated the performance of the proposed approach based on synthetic images and real two-channel fluorescence microscopy data. It turned out that our approach outperforms previous methods.},
	booktitle = {2022 {IEEE} 19th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Spilger, Roman and Lee, Ji-Young and Bartenschlager, Ralf and Rohr, Karl},
	month = mar,
	year = {2022},
	note = {ISSN: 1945-8452},
	keywords = {Deep learning, Microscopy, Multi-channel microscopy images, Neural networks, Protein engineering, Proteins, Tracking, Training, colocalization analysis, deep learning, particle tracking},
	pages = {1--4},
}

@misc{noauthor_correlative_nodate,
	title = {Correlative three-dimensional super-resolution and block-face electron microscopy of whole vitreously frozen cells {\textbar} {Science}},
	url = {https://www.science.org/doi/full/10.1126/science.aaz5357?casa_token=xuJlKGFD1AMAAAAA%3AOwQRu1lunUsJLF8WoIw9pQ9UC28dVh6Jvp4XqLgQNnotDUx-Tnmfk7ZR088PELPP-aKAImTcBKUzpR4},
	urldate = {2023-04-18},
}

@article{kapoor_mtrack_2019,
	title = {{MTrack}: {Automated} {Detection}, {Tracking}, and {Analysis} of {Dynamic} {Microtubules}},
	volume = {9},
	issn = {2045-2322},
	shorttitle = {{MTrack}},
	doi = {10.1038/s41598-018-37767-1},
	abstract = {Microtubules are polar, dynamic filaments fundamental to many cellular processes. In vitro reconstitution approaches with purified tubulin are essential to elucidate different aspects of microtubule behavior. To date, deriving data from fluorescence microscopy images by manually creating and analyzing kymographs is still commonplace. Here, we present MTrack, implemented as a plug-in for the open-source platform Fiji, which automatically identifies and tracks dynamic microtubules with sub-pixel resolution using advanced objection recognition. MTrack provides automatic data interpretation yielding relevant parameters of microtubule dynamic instability together with population statistics. The application of our software produces unbiased and comparable quantitative datasets in a fully automated fashion. This helps the experimentalist to achieve higher reproducibility at higher throughput on a user-friendly platform. We use simulated data and real data to benchmark our algorithm and show that it reliably detects, tracks, and analyzes dynamic microtubules and achieves sub-pixel precision even at low signal-to-noise ratios.},
	language = {eng},
	number = {1},
	journal = {Scientific Reports},
	author = {Kapoor, Varun and Hirst, William G. and Hentschel, Christoph and Preibisch, Stephan and Reber, Simone},
	month = mar,
	year = {2019},
	pmid = {30846705},
	pmcid = {PMC6405942},
	keywords = {Algorithms, Image Processing, Computer-Assisted, Microscopy, Fluorescence, Microtubules, Reproducibility of Results, Signal-To-Noise Ratio, Software},
	pages = {3794},
}

@article{schnitzbauer_super-resolution_2017,
	title = {Super-resolution microscopy with {DNA}-{PAINT}},
	volume = {12},
	issn = {1750-2799},
	doi = {10.1038/nprot.2017.024},
	abstract = {Super-resolution techniques have begun to transform biological and biomedical research by allowing researchers to observe structures well below the classic diffraction limit of light. DNA points accumulation for imaging in nanoscale topography (DNA-PAINT) offers an easy-to-implement approach to localization-based super-resolution microscopy, owing to the use of DNA probes. In DNA-PAINT, transient binding of short dye-labeled ('imager') oligonucleotides to their complementary target ('docking') strands creates the necessary 'blinking' to enable stochastic super-resolution microscopy. Using the programmability and specificity of DNA molecules as imaging and labeling probes allows researchers to decouple blinking from dye photophysics, alleviating limitations of current super-resolution techniques, making them compatible with virtually any single-molecule-compatible dye. Recent developments in DNA-PAINT have enabled spectrally unlimited multiplexing, precise molecule counting and ultra-high, molecular-scale (sub-5-nm) spatial resolution, reaching ∼1-nm localization precision. DNA-PAINT can be applied to a multitude of in vitro and cellular applications by linking docking strands to antibodies. Here, we present a protocol for the key aspects of the DNA-PAINT framework for both novice and expert users. This protocol describes the creation of DNA origami test samples, in situ sample preparation, multiplexed data acquisition, data simulation, super-resolution image reconstruction and post-processing such as drift correction, molecule counting (qPAINT) and particle averaging. Moreover, we provide an integrated software package, named Picasso, for the computational steps involved. The protocol is designed to be modular, so that individual components can be chosen and implemented per requirements of a specific application. The procedure can be completed in 1-2 d.},
	language = {eng},
	number = {6},
	journal = {Nature Protocols},
	author = {Schnitzbauer, Joerg and Strauss, Maximilian T. and Schlichthaerle, Thomas and Schueder, Florian and Jungmann, Ralf},
	month = jun,
	year = {2017},
	pmid = {28518172},
	keywords = {Cytological Techniques, DNA, Image Processing, Computer-Assisted, Macromolecular Substances, Microscopy, Fluorescence, Staining and Labeling},
	pages = {1198--1228},
}

@inproceedings{rao_adaptive_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Adaptive {Regularization} for {Image} {Segmentation} {Using} {Local} {Image} {Curvature} {Cues}},
	isbn = {978-3-642-15561-1},
	doi = {10.1007/978-3-642-15561-1_47},
	abstract = {Image segmentation techniques typically require proper weighting of competing data fidelity and regularization terms. Conventionally, the associated parameters are set through tedious trial and error procedures and kept constant over the image. However, spatially varying structural characteristics, such as object curvature, combined with varying noise and imaging artifacts, significantly complicate the selection process of segmentation parameters. In this work, we propose a novel approach for automating the parameter selection by employing a robust structural cue to prevent excessive regularization of trusted (i.e. low noise) high curvature image regions. Our approach autonomously adapts local regularization weights by combining local measures of image curvature and edge evidence that are gated by a signal reliability measure. We demonstrate the utility and favorable performance of our approach within two major segmentation frameworks, graph cuts and active contours, and present quantitative and qualitative results on a variety of natural and medical images.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2010},
	publisher = {Springer},
	author = {Rao, Josna and Abugharbieh, Rafeef and Hamarneh, Ghassan},
	editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
	year = {2010},
	keywords = {Active Contour, Adaptive Weight, Image Segmentation Technique, Regularization Weight, Texture Edge},
	pages = {651--665},
}

@book{steele_cauchy-schwarz_2004,
	title = {The {Cauchy}-{Schwarz} {Master} {Class}: {An} {Introduction} to the {Art} of {Mathematical} {Inequalities}},
	isbn = {978-0-521-54677-5},
	shorttitle = {The {Cauchy}-{Schwarz} {Master} {Class}},
	abstract = {This lively, problem-oriented text, first published in 2004, is designed to coach readers toward mastery of the most fundamental mathematical inequalities. With the Cauchy-Schwarz inequality as the initial guide, the reader is led through a sequence of fascinating problems whose solutions are presented as they might have been discovered - either by one of history's famous mathematicians or by the reader. The problems emphasize beauty and surprise, but along the way readers will find systematic coverage of the geometry of squares, convexity, the ladder of power means, majorization, Schur convexity, exponential sums, and the inequalities of Hölder, Hilbert, and Hardy. The text is accessible to anyone who knows calculus and who cares about solving problems. It is well suited to self-study, directed study, or as a supplement to courses in analysis, probability, and combinatorics.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Steele, J. Michael},
	month = apr,
	year = {2004},
	note = {Google-Books-ID: 7GDyRMrlgDsC},
	keywords = {Mathematics / Calculus, Mathematics / Combinatorics, Mathematics / History \& Philosophy, Mathematics / Mathematical Analysis, Mathematics / Probability \& Statistics / General},
}

@article{gwanyama_hm-gm-am-qm_2004,
	title = {The {HM}-{GM}-{AM}-{QM} {Inequalities}},
	volume = {35},
	issn = {07468342},
	url = {http://www.jstor.org/stable/10.2307/4146884?origin=crossref},
	doi = {10.2307/4146884},
	number = {1},
	urldate = {2023-10-29},
	journal = {The College Mathematics Journal},
	author = {Gwanyama, Philip Wagala},
	month = jan,
	year = {2004},
	pages = {47},
}

@misc{osf_osf_nodate,
	title = {{OSF}},
	url = {https://osf.io/},
	urldate = {2023-05-12},
	author = {OSF, OSF},
}

@article{nabi_ai-based_2023,
	title = {{AI}-based analysis of super-resolution microscopy: {Biological} discovery in the absence of ground truth},
	volume = {1},
	copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
	shorttitle = {{AI}-based analysis of super-resolution microscopy},
	url = {https://arxiv.org/abs/2305.17193},
	doi = {10.48550/ARXIV.2305.17193},
	abstract = {The nanoscale resolution of super-resolution microscopy has now enabled the use of fluorescent based molecular localization tools to study whole cell structural biology. Machine learning based analysis of super-resolution data offers tremendous potential for discovery of new biology, that by definition is not known and lacks ground truth. Herein, we describe the application of weakly supervised learning paradigms to super-resolution microscopy and its potential to enable the accelerated exploration of the molecular architecture of subcellular macromolecules and organelles.},
	number = {1},
	urldate = {2023-07-08},
	journal = {Arxiv},
	author = {Nabi, Ivan R. and Cardoen, Ben and Khater, Ismail M. and Gao, Guang and Wong, Timothy H. and Hamarneh, Ghassan},
	year = {2023},
	keywords = {Artificial Intelligence (cs.AI), Biological Physics (physics.bio-ph), Computer Vision and Pattern Recognition (cs.CV), FOS: Biological sciences, FOS: Computer and information sciences, FOS: Physical sciences, Machine Learning (cs.LG), Quantitative Methods (q-bio.QM), Subcellular Processes (q-bio.SC)},
}

@article{metcalf_test_2013,
	title = {Test {Samples} for {Optimizing} {STORM} {Super}-{Resolution} {Microscopy}},
	volume = {1},
	issn = {1940-087X},
	url = {https://www.jove.com/t/50579/test-samples-for-optimizing-storm-super--resolution-microscopy},
	doi = {10.3791/50579},
	language = {en},
	number = {79},
	urldate = {2023-06-12},
	journal = {Journal of Visualized Experiments},
	author = {Metcalf, Daniel J. and Edwards, Rebecca and Kumarswami, Neelam and Knight, Alex E.},
	month = sep,
	year = {2013},
	pages = {50579},
}

@incollection{Endesfelder2015,
	title = {Direct {Stochastic} {Optical} {Reconstruction} {Microscopy} ({dSTORM})},
	volume = {1251},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25391804},
	abstract = {Single-molecule localization-based super-resolution microscopy can be performed with regular, bright, and photostable organic fluorophores. We review a concept termed direct stochastic optical reconstruction microscopy (dSTORM), which operates conventional fluorophores as photoswitches and provides an optical resolution of {\textasciitilde}20 nm. We introduce the principle of dSTORM, illustrate experimental schemes, and discuss approaches for data analysis.},
	urldate = {2018-04-19},
	booktitle = {Methods in molecular biology ({Clifton}, {N}.{J}.)},
	publisher = {Clifton, N.J.},
	author = {Endesfelder, Ulrike and Heilemann, Mike},
	year = {2015},
	pmid = {25391804},
	doi = {10.1007/978-1-4939-2080-8_14},
	note = {ISSN: 1940-6029},
	pages = {263--276},
}

@inproceedings{chen_3d_2020,
	title = {{3D} {Sketch}-{Aware} {Semantic} {Scene} {Completion} via {Semi}-{Supervised} {Structure} {Prior}},
	url = {https://openaccess.thecvf.com/content_CVPR_2020/html/Chen_3D_Sketch-Aware_Semantic_Scene_Completion_via_Semi-Supervised_Structure_Prior_CVPR_2020_paper.html},
	urldate = {2022-12-15},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Chen, Xiaokang and Lin, Kwan-Yee and Qian, Chen and Zeng, Gang and Li, Hongsheng},
	year = {2020},
	pages = {4193--4202},
}

@misc{zhong_neural_2023,
	title = {Neural {Fields} with {Hard} {Constraints} of {Arbitrary} {Differential} {Order}},
	url = {http://arxiv.org/abs/2306.08943},
	doi = {10.48550/arXiv.2306.08943},
	abstract = {While deep learning techniques have become extremely popular for solving a broad range of optimization problems, methods to enforce hard constraints during optimization, particularly on deep neural networks, remain underdeveloped. Inspired by the rich literature on meshless interpolation and its extension to spectral collocation methods in scientific computing, we develop a series of approaches for enforcing hard constraints on neural fields, which we refer to as {\textbackslash}emph\{Constrained Neural Fields\} (CNF). The constraints can be specified as a linear operator applied to the neural field and its derivatives. We also design specific model representations and training strategies for problems where standard models may encounter difficulties, such as conditioning of the system, memory consumption, and capacity of the network when being constrained. Our approaches are demonstrated in a wide range of real-world applications. Additionally, we develop a framework that enables highly efficient model and constraint specification, which can be readily applied to any downstream task where hard constraints need to be explicitly satisfied during optimization.},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Zhong, Fangcheng and Fogarty, Kyle and Hanji, Param and Wu, Tianhao and Sztrajman, Alejandro and Spielberg, Andrew and Tagliasacchi, Andrea and Bosilj, Petra and Oztireli, Cengiz},
	month = jun,
	year = {2023},
	note = {arXiv:2306.08943 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@article{ovchinnikov_structure-based_2021,
	series = {Mechanistic {Biology} * {Machine} {Learning} in {Chemical} {Biology}},
	title = {Structure-based protein design with deep learning},
	volume = {65},
	issn = {1367-5931},
	url = {https://www.sciencedirect.com/science/article/pii/S1367593121001125},
	doi = {10.1016/j.cbpa.2021.08.004},
	abstract = {Since the first revelation of proteins functioning as macromolecular machines through their three dimensional structures, researchers have been intrigued by the marvelous ways the biochemical processes are carried out by proteins. The aspiration to understand protein structures has fueled extensive efforts across different scientific disciplines. In recent years, it has been demonstrated that proteins with new functionality or shapes can be designed via structure-based modeling methods, and the design strategies have combined all available information — but largely piece-by-piece — from sequence derived statistics to the detailed atomic-level modeling of chemical interactions. Despite the significant progress, incorporating data-derived approaches through the use of deep learning methods can be a game changer. In this review, we summarize current progress, compare the arc of developing the deep learning approaches with the conventional methods, and describe the motivation and concepts behind current strategies that may lead to potential future opportunities.},
	urldate = {2023-10-19},
	journal = {Current Opinion in Chemical Biology},
	author = {Ovchinnikov, Sergey and Huang, Po-Ssu},
	month = dec,
	year = {2021},
	keywords = {Deep learning, Neural networks, Protein design, Protein sequence design, Protein structure, Protein structure design},
	pages = {136--144},
}

@article{last_scnodes_2023,
	title = {{scNodes}: a correlation and processing toolkit for super-resolution fluorescence and electron microscopy},
	volume = {20},
	copyright = {2023 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{scNodes}},
	url = {https://www.nature.com/articles/s41592-023-01991-z},
	doi = {10.1038/s41592-023-01991-z},
	language = {en},
	number = {10},
	urldate = {2023-10-19},
	journal = {Nature Methods},
	author = {Last, Mart G. F. and Voortman, Lenard M. and Sharp, Thomas H.},
	month = oct,
	year = {2023},
	note = {Number: 10
Publisher: Nature Publishing Group},
	keywords = {Cryoelectron microscopy, Super-resolution microscopy},
	pages = {1445--1446},
}

@article{van_heel_reassessing_2017,
	title = {Reassessing the {Revolution}’s {Resolutions}},
	copyright = {© 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/224402v1},
	doi = {10.1101/224402},
	abstract = {We are currently facing an avalanche of cryo-EM (cryogenic Electron Microscopy) publications presenting beautiful structures at resolution levels of {\textasciitilde}3Å: a true “resolution revolution” [Kühlbrandt, Science 343(2014)1443-1444]. Impressive as these results may be, a fundamental statistical error has persisted in the literature that affects the numerical resolution values for practically all published structures. The error goes back to a misinterpretation of basic statistics and pervades virtually all popular cryo-EM quality metrics. The resolution in cryo-EM is typically assessed by the Fourier Shell Correlation “FSC” [Harauz \& van Heel: Optik 73(1986)146-156] using a fixed threshold value of 0.143 (“FSC0.143”) [Rosenthal, Henderson, J. Mol. Biol. 333(2003)721–745]. Using a simple model experiment we illustrate why this fixed threshold is flawed and we pinpoint the source of the resolution confusion. When two vectors are uncorrelated the expectation value of their inner-product is zero. That, however, does not imply that each individual inner-product of the vectors is zero (the vectors are not orthogonal). This error was introduced to electron microscopy in [Frank \& Al-Ali, Nature 256(1975)376-379] and has since proliferated into virtually all quality and resolution-related metrics in EM. One criterion not affected by this error is the information-based ½-bit FSC threshold [van Heel \& Schatz: J. Struct. Biol. 151(2005)250-262].},
	language = {en},
	urldate = {2022-10-24},
	journal = {Arxiv},
	author = {Van Heel, Marin and Schatz, Michael},
	month = nov,
	year = {2017},
}

@article{cardoen_log-paradox_2023,
	title = {Log-{Paradox}: {Necessary} and sufficient conditions for confounding statistically significant pattern reversal under the log-transform},
	volume = {1},
	shorttitle = {Log-{Paradox}},
	url = {http://arxiv.org/abs/2302.04780},
	doi = {10.48550/arXiv.2302.04780},
	abstract = {The log-transform is a common tool in statistical analysis, reducing the impact of extreme values, compressing the range of reported values for improved visualization, enabling the usage of parametric statistical tests requiring normally distributed data, or enabling linear models on non-linear data. Practitioners are rarely aware that log-transformed results can reverse findings: a hypothesis test without the transform can show a negative trend, while with the log-transform, it can show a positive trend, both statistically significant. We derive necessary and sufficient conditions underlying this paradoxical pattern reversal using finite difference notation. We show that biomedical image quantification is very susceptible to these conditions. Using a novel heuristic maximizing the reversal, we show that statistical significance of the paradoxical pattern reversal can be easily induced by changing as little as 5\% of a dataset. We illustrate how quantifying the sizes of objects in proportional data, especially where object sizes capture underlying creation and destruction dynamics, satisfies the precondition for the paradox. We discuss recommendations on proper use of the log-transform, discuss methods to explore the underlying patterns robustly, and emphasize that any transformed result should always be accompanied by its non-transformed source equivalent to exclude accidental confounded findings.},
	number = {1},
	urldate = {2023-02-13},
	journal = {Arxiv},
	author = {Cardoen, Ben and Yedder, Hanene Ben and Lee, Sieun and Nabi, Ivan Robert and Hamarneh, Ghassan},
	month = feb,
	year = {2023},
	note = {arXiv:2302.04780 [math, stat]},
	keywords = {2-02 (Primary), 92C55 (Secondary), Mathematics - Statistics Theory, Statistics - Methodology},
}

@article{redpath_precision_2022,
	title = {Precision {Super}-{Resolution} {Cryo}-{Correlative} {Light} and {Electron} {Microscopy} for {Rapid} \textit{in situ} {Structural} {Analyses} of {Optogenetically}-{Positioned} {Organelles}},
	volume = {1},
	url = {https://papers.ssrn.com/abstract=4309027},
	doi = {10.2139/ssrn.4309027},
	abstract = {Unambiguous targeting of cellular structures for in situ cryo-electron microscopy in the heterogeneous, dense, and compacted environment of the cytoplasm remains challenging. Here we have developed a novel cryogenic correlative light and electron microscopy (cryo-CLEM) workflow which combines thin cells grown on a mechanically defined substratum to rapidly analyse organelles and macromolecular complexes in the cell by cryo-electron tomography (cryo-ET). We coupled these advancements with optogenetics to redistribute perinuclear-localised organelles to the cell periphery for cryo-ET. This reliable and robust workflow allows for fast in situ analyses without the requirement for cryo-focused ion beam milling. We have developed a protocol where cells can be frozen, imaged by cryo-fluorescence microscopy and ready for batch cryo-ET within a day.},
	language = {en},
	number = {1},
	urldate = {2023-06-12},
	journal = {Arxiv},
	author = {Redpath, Gregory M. I. and Rae, James and Yao, Yin and Ruan, Juanfang and Cagigas, Maria L. and Whan, Renee and Hardeman, Edna C. and Gunning, Peter W. and Ananthanarayanan, Vaishnavi and Parton, Robert G. and Ariotti, Nicholas},
	month = dec,
	year = {2022},
	keywords = {Cell Biology, Optogenetics, cryo-CLEM, endolysosomes},
}

@misc{zenodo_zenodo_nodate,
	title = {Zenodo - {Research}. {Shared}.},
	url = {https://zenodo.org/},
	urldate = {2023-05-12},
	journal = {Zenodo},
	author = {Zenodo},
}

@article{ruszczycki_quality_2018,
	title = {Quality of biological images, reconstructed using localization microscopy data},
	volume = {34},
	issn = {1367-4811},
	doi = {10.1093/bioinformatics/btx597},
	language = {eng},
	number = {5},
	journal = {Bioinformatics (Oxford, England)},
	author = {Ruszczycki, Blazej and Bernas, Tytus},
	month = mar,
	year = {2018},
	pmid = {29028905},
	pmcid = {PMC6192211},
	keywords = {Animals, Dentate Gyrus, Image Processing, Computer-Assisted, Microscopy, Fluorescence, Neurons, Rats, Signal-To-Noise Ratio, Software},
	pages = {845--852},
}

@article{ioannidis_what_2019,
	title = {What {Have} {We} ({Not}) {Learnt} from {Millions} of {Scientific} {Papers} with \textit{{P}} {Values}?},
	volume = {73},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1447512},
	doi = {10.1080/00031305.2018.1447512},
	language = {en},
	number = {sup1},
	urldate = {2023-09-25},
	journal = {The American Statistician},
	author = {Ioannidis, John P. A.},
	month = mar,
	year = {2019},
	pages = {20--25},
}

@article{koptev_implicit_2023,
	title = {Implicit {Distance} {Functions}: {Learning} and {Applications} in {Robotics}},
	shorttitle = {Implicit {Distance} {Functions}},
	url = {http://infoscience.epfl.ch/record/305181},
	doi = {10.5075/EPFL-THESIS-10197},
	language = {en},
	urldate = {2023-09-24},
	author = {Koptev, Mikhail},
	month = sep,
	year = {2023},
}

@article{sbalzarini_modeling_2013,
	title = {Modeling and simulation of biological systems from image data},
	volume = {35},
	copyright = {Copyright © 2013 WILEY Periodicals, Inc.},
	issn = {1521-1878},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.201200051},
	doi = {10.1002/bies.201200051},
	abstract = {This essay provides an introduction to the terminology, concepts, methods, and challenges of image-based modeling in biology. Image-based modeling and simulation aims at using systematic, quantitative image data to build predictive models of biological systems that can be simulated with a computer. This allows one to disentangle molecular mechanisms from effects of shape and geometry. Questions like “what is the functional role of shape” or “how are biological shapes generated and regulated” can be addressed in the framework of image-based systems biology. The combination of image quantification, model building, and computer simulation is illustrated here using the example of diffusion in the endoplasmic reticulum.},
	language = {en},
	number = {5},
	urldate = {2023-09-05},
	journal = {BioEssays},
	author = {Sbalzarini, Ivo F.},
	year = {2013},
	keywords = {computational biology, image-based systems biology, simulation, spatiotemporal modeling, systems biology},
	pages = {482--490},
}

@article{friedl_assessing_2023,
	title = {Assessing crosstalk in simultaneous multicolor single-molecule localization microscopy},
	volume = {0},
	issn = {2667-2375},
	url = {https://www.cell.com/cell-reports-methods/abstract/S2667-2375(23)00215-1},
	doi = {10.1016/j.crmeth.2023.100571},
	language = {English},
	number = {0},
	urldate = {2023-09-04},
	journal = {Cell Reports Methods},
	author = {Friedl, Karoline and Mau, Adrien and Boroni-Rueda, Fanny and Caorsi, Valentina and Bourg, Nicolas and Lévêque-Fort, Sandrine and Leterrier, Christophe},
	month = sep,
	year = {2023},
	keywords = {CP: Imaging, DNA-PAINT, SMLM, STORM, crosstalk, dSTORM, fluorescence, multicolor, multitarget, spectral demixing, super resolution microscopy},
}

@article{longo_fasting_2014,
	title = {Fasting: {Molecular} {Mechanisms} and {Clinical} {Applications}},
	volume = {19},
	issn = {1550-4131},
	shorttitle = {Fasting},
	url = {https://www.sciencedirect.com/science/article/pii/S1550413113005032},
	doi = {10.1016/j.cmet.2013.12.008},
	abstract = {Fasting has been practiced for millennia, but, only recently, studies have shed light on its role in adaptive cellular responses that reduce oxidative damage and inflammation, optimize energy metabolism, and bolster cellular protection. In lower eukaryotes, chronic fasting extends longevity, in part, by reprogramming metabolic and stress resistance pathways. In rodents intermittent or periodic fasting protects against diabetes, cancers, heart disease, and neurodegeneration, while in humans it helps reduce obesity, hypertension, asthma, and rheumatoid arthritis. Thus, fasting has the potential to delay aging and help prevent and treat diseases while minimizing the side effects caused by chronic dietary interventions.},
	number = {2},
	urldate = {2023-08-31},
	journal = {Cell Metabolism},
	author = {Longo, Valter D. and Mattson, Mark P.},
	month = feb,
	year = {2014},
	pages = {181--192},
}

@article{chen_parkinsons_2023,
	title = {Parkinson’s disease neurons exhibit alterations in mitochondrial quality control proteins},
	volume = {9},
	copyright = {2023 Springer Nature Limited},
	issn = {2373-8057},
	url = {https://www.nature.com/articles/s41531-023-00564-3},
	doi = {10.1038/s41531-023-00564-3},
	abstract = {Mitochondrial dysfunction has been suggested to contribute to Parkinson’s disease pathogenesis, though an understanding of the extent or exact mechanism of this contribution remains elusive. This has been complicated by challenging nature of pathway-based analysis and an inability simultaneously study multiple related proteins within human brain tissue. We used imaging mass cytometry (IMC) to overcome these challenges, measuring multiple protein targets, whilst retaining the spatial relationship between targets in post-mortem midbrain sections. We used IMC to simultaneously interrogate subunits of the mitochondrial oxidative phosphorylation complexes, and several key signalling pathways important for mitochondrial homoeostasis, in a large cohort of PD patient and control cases. We revealed a generalised and synergistic reduction in mitochondrial quality control proteins in dopaminergic neurons from Parkinson’s patients. Further, protein-protein abundance relationships appeared significantly different between PD and disease control tissue. Our data showed a significant reduction in the abundance of PINK1, Parkin and phosphorylated ubiquitinSer65, integral to the mitophagy machinery; two mitochondrial chaperones, HSP60 and PHB1; and regulators of mitochondrial protein synthesis and the unfolded protein response, SIRT3 and TFAM. Further, SIRT3 and PINK1 did not show an adaptive response to an ATP synthase defect in the Parkinson’s neurons. We also observed intraneuronal aggregates of phosphorylated ubiquitinSer65, alongside increased abundance of mitochondrial proteases, LONP1 and HTRA2, within the Parkinson’s neurons with Lewy body pathology, compared to those without. Taken together, these findings suggest an inability to turnover mitochondria and maintain mitochondrial proteostasis in Parkinson’s neurons. This may exacerbate the impact of oxidative phosphorylation defects and ageing related oxidative stress, leading to neuronal degeneration. Our data also suggest that that Lewy pathology may affect mitochondrial quality control regulation through the disturbance of mitophagy and intramitochondrial proteostasis.},
	language = {en},
	number = {1},
	urldate = {2023-08-25},
	journal = {npj Parkinson's Disease},
	author = {Chen, Chun and McDonald, David and Blain, Alasdair and Mossman, Emily and Atkin, Kiera and Marusich, Michael F. and Capaldi, Roderick and Bone, Laura and Smith, Anna and Filby, Andrew and Erskine, Daniel and Russell, Oliver and Hudson, Gavin and Vincent, Amy E. and Reeve, Amy K.},
	month = aug,
	year = {2023},
	keywords = {Cellular neuroscience, Parkinson's disease},
	pages = {1--14},
}

@article{van_damme_complement_2023,
	title = {A complement atlas identifies interleukin-6–dependent alternative pathway dysregulation as a key druggable feature of {COVID}-19},
	volume = {15},
	url = {https://www.science.org/doi/10.1126/scitranslmed.adi0252},
	doi = {10.1126/scitranslmed.adi0252},
	abstract = {Improvements in COVID-19 treatments, especially for the critically ill, require deeper understanding of the mechanisms driving disease pathology. The complement system is not only a crucial component of innate host defense but can also contribute to tissue injury. Although all complement pathways have been implicated in COVID-19 pathogenesis, the upstream drivers and downstream effects on tissue injury remain poorly defined. We demonstrate that complement activation is primarily mediated by the alternative pathway, and we provide a comprehensive atlas of the complement alterations around the time of respiratory deterioration. Proteomic and single-cell sequencing mapping across cell types and tissues reveals a division of labor between lung epithelial, stromal, and myeloid cells in complement production, in addition to liver-derived factors. We identify IL-6 and STAT1/3 signaling as an upstream driver of complement responses, linking complement dysregulation to approved COVID-19 therapies. Furthermore, an exploratory proteomic study indicates that inhibition of complement C5 decreases epithelial damage and markers of disease severity. Collectively, these results support complement dysregulation as a key druggable feature of COVID-19.},
	number = {710},
	urldate = {2023-08-24},
	journal = {Science Translational Medicine},
	author = {Van Damme, Karel F. A. and Hoste, Levi and Declercq, Jozefien and De Leeuw, Elisabeth and Maes, Bastiaan and Martens, Liesbet and Colman, Roos and Browaeys, Robin and Bosteels, Cédric and Verwaerde, Stijn and Vermeulen, Nicky and Lameire, Sahine and Debeuf, Nincy and Deckers, Julie and Stordeur, Patrick and Depuydt, Pieter and Van Braeckel, Eva and Vandekerckhove, Linos and Guilliams, Martin and Schetters, Sjoerd T. T. and Haerynck, Filomeen and Tavernier, Simon J. and Lambrecht, Bart N.},
	month = aug,
	year = {2023},
	pages = {eadi0252},
}

@article{obara_structural_2023,
	title = {Structural {Diversity} within the {Endoplasmic} {Reticulum}—{From} the {Microscale} to the {Nanoscale}},
	volume = {15},
	issn = {, 1943-0264},
	url = {http://cshperspectives.cshlp.org/content/15/6/a041259},
	doi = {10.1101/cshperspect.a041259},
	abstract = {The endoplasmic reticulum (ER) is a continuous, highly dynamic membrane compartment that is crucial for numerous basic cellular functions. The ER stretches from the nuclear envelope to the outer periphery of all living eukaryotic cells. This ubiquitous organelle shows remarkable structural complexity, adopting a range of shapes, curvatures, and length scales. Canonically, the ER is thought to be composed of two simple membrane elements: sheets and tubules. However, recent advances in superresolution light microscopy and three-dimensional electron microscopy have revealed an astounding diversity of nanoscale ER structures, greatly expanding our view of ER organization. In this review, we describe these diverse ER structures, focusing on what is known of their regulation and associated functions in mammalian cells.},
	language = {en},
	number = {6},
	urldate = {2023-08-23},
	journal = {Cold Spring Harbor Perspectives in Biology},
	author = {Obara, Christopher J. and Moore, Andrew S. and Lippincott-Schwartz, Jennifer},
	month = jun,
	year = {2023},
	pmid = {36123032},
	pages = {a041259},
}

@article{davis_long_2023,
	title = {Long {COVID}: major findings, mechanisms and recommendations},
	volume = {21},
	copyright = {2023 Springer Nature Limited},
	issn = {1740-1534},
	shorttitle = {Long {COVID}},
	url = {https://www.nature.com/articles/s41579-022-00846-2},
	doi = {10.1038/s41579-022-00846-2},
	abstract = {Long COVID is an often debilitating illness that occurs in at least 10\% of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infections. More than 200 symptoms have been identified with impacts on multiple organ systems. At least 65 million individuals worldwide are estimated to have long COVID, with cases increasing daily. Biomedical research has made substantial progress in identifying various pathophysiological changes and risk factors and in characterizing the illness; further, similarities with other viral-onset illnesses such as myalgic encephalomyelitis/chronic fatigue syndrome and postural orthostatic tachycardia syndrome have laid the groundwork for research in the field. In this Review, we explore the current literature and highlight key findings, the overlap with other conditions, the variable onset of symptoms, long COVID in children and the impact of vaccinations. Although these key findings are critical to understanding long COVID, current diagnostic and treatment options are insufficient, and clinical trials must be prioritized that address leading hypotheses. Additionally, to strengthen long COVID research, future studies must account for biases and SARS-CoV-2 testing issues, build on viral-onset research, be inclusive of marginalized populations and meaningfully engage patients throughout the research process.},
	language = {en},
	number = {3},
	urldate = {2023-08-23},
	journal = {Nature Reviews Microbiology},
	author = {Davis, Hannah E. and McCorkell, Lisa and Vogel, Julia Moore and Topol, Eric J.},
	month = mar,
	year = {2023},
	keywords = {Research data, SARS-CoV-2, Viral infection},
	pages = {133--146},
}

@article{parisi_continual_2019,
	title = {Continual lifelong learning with neural networks: {A} review},
	volume = {113},
	issn = {0893-6080},
	shorttitle = {Continual lifelong learning with neural networks},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608019300231},
	doi = {10.1016/j.neunet.2019.01.012},
	abstract = {Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for computational learning systems and autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. Although significant advances have been made in domain-specific learning with neural networks, extensive research efforts are required for the development of robust lifelong learning on autonomous agents and robots. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.},
	urldate = {2023-08-17},
	journal = {Neural Networks},
	author = {Parisi, German I. and Kemker, Ronald and Part, Jose L. and Kanan, Christopher and Wermter, Stefan},
	month = may,
	year = {2019},
	keywords = {Catastrophic forgetting, Continual learning, Developmental systems, Lifelong learning, Memory consolidation},
	pages = {54--71},
}

@misc{heydarian_software_2021,
	title = {Software for {3D} particle averaging of {SMLM} data},
	copyright = {Apache-2.0},
	url = {https://data.4tu.nl/articles/_/13743703},
	abstract = {Software for 3D particle averaging of SMLM data},
	urldate = {2023-08-08},
	publisher = {4TU.ResearchData},
	author = {Heydarian, Hamidreza and Rieger, B. (Bernd) and Jungmann, R. (Ralf) and Schueder, Florian and Ries, Jonas and Stallinga, S. (Sjoerd) and van Werkhoven, B. (Ben) and Joosten, Maarten},
	collaborator = {{TU Delft, Faculty Of Applied Sciences, Department Of Imaging Physics}},
	month = feb,
	year = {2021},
	doi = {10.4121/13743703},
	keywords = {Biochemistry and Cell Biology, FOS: Biological sciences, Localization microscopy, SMLM methods, Single Molecule Localization Microscopy, superresolution technique},
}

@misc{heydarian_single-molecule_2021,
	title = {Single-{Molecule} {Localization} {Microscopy} ({SMLM}) {3D} datasets},
	copyright = {Creative Commons Attribution Non Commercial 4.0 International},
	url = {https://data.4tu.nl/articles/_/13797686},
	doi = {10.4121/13797686},
	abstract = {Supplementary data: "3D particle averaging and detection of macromolecular symmetry in localization microscopy". The dataset contains images of nuclear pore complex NUP107 imaged using PAINT and STORM techniques and also DNA-origami nanostructures in the shape of a tetrahedron.},
	urldate = {2023-08-08},
	publisher = {4TU.ResearchData},
	author = {Heydarian, Hamidreza and Rieger, B. (Bernd) and Jungmann, R. (Ralf) and Schueder, F. (Florian) and Stallinga, S. (Sjoerd) and Ries, Jonas},
	collaborator = {{TU Delft, Faculty Of Applied Sciences, Department Of Imaging Physics}},
	month = feb,
	year = {2021},
	keywords = {Biochemistry and Cell Biology, DNA-origami, FOS: Biological sciences, Nuclear Pore Complex, Single-Molecule Localization Microscopy (SMLM)},
}

@misc{heydarian_single-molecule_2021-1,
	title = {Single-{Molecule} {Localization} {Microscopy} ({SMLM}) {3D} datasets},
	copyright = {Creative Commons Attribution Non Commercial 4.0 International},
	url = {https://data.4tu.nl/articles/_/13797686/1},
	doi = {10.4121/13797686.V1},
	abstract = {Supplementary data: "3D particle averaging and detection of macromolecular symmetry in localization microscopy". The dataset contains images of nuclear pore complex NUP107 imaged using PAINT and STORM techniques and also DNA-origami nanostructures in the shape of a tetrahedron.},
	urldate = {2023-08-08},
	publisher = {4TU.ResearchData},
	author = {Heydarian, Hamidreza and Rieger, B. (Bernd) and Jungmann, R. (Ralf) and Schueder, F. (Florian) and Stallinga, S. (Sjoerd) and Ries, Jonas},
	collaborator = {{TU Delft, Faculty Of Applied Sciences, Department Of Imaging Physics}},
	month = feb,
	year = {2021},
	keywords = {Biochemistry and Cell Biology, DNA-origami, FOS: Biological sciences, Nuclear Pore Complex, Single-Molecule Localization Microscopy (SMLM)},
}

@inproceedings{cardoen_interaction_2019,
	address = {Le Pouliguen, France},
	title = {Interaction zone analysis of {CAV1} - {CAVIN1} in breast cancer cells},
	url = {http://www.cs.sfu.ca/~hamarneh/ecopy/embo2019a.pdf},
	booktitle = {European {Molecular} {Biology} {Organization} {EMBO} {Workshop} {Caveolae} and nanodomains: {Translating} structural principles and dynamics into function, {Le} {Pouliguen}, {France}},
	author = {Cardoen, Ben and Dickson, Fiona and Khater, Ismail and Nabi, Ivan Robert and Hamarneh, Ghassan},
	year = {2019},
}

@article{sullivan_pyvista_2019,
	title = {{PyVista}: {3D} plotting and mesh analysis through a streamlined interface for the {Visualization} {Toolkit} ({VTK})},
	volume = {4},
	issn = {2475-9066},
	shorttitle = {{PyVista}},
	url = {http://joss.theoj.org/papers/10.21105/joss.01450},
	doi = {10.21105/joss.01450},
	number = {37},
	urldate = {2023-07-20},
	journal = {Journal of Open Source Software},
	author = {Sullivan, C. and Kaszynski, Alexander},
	month = may,
	year = {2019},
	pages = {1450},
}

@article{amezquita_shape_2020,
	title = {The shape of things to come: {Topological} data analysis and biology, from molecules to organisms},
	volume = {249},
	copyright = {© 2020 The Authors. Developmental Dynamics published by Wiley Periodicals, Inc. on behalf of American Association of Anatomists.},
	issn = {1097-0177},
	shorttitle = {The shape of things to come},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/dvdy.175},
	doi = {10.1002/dvdy.175},
	abstract = {Shape is data and data is shape. Biologists are accustomed to thinking about how the shape of biomolecules, cells, tissues, and organisms arise from the effects of genetics, development, and the environment. Less often do we consider that data itself has shape and structure, or that it is possible to measure the shape of data and analyze it. Here, we review applications of topological data analysis (TDA) to biology in a way accessible to biologists and applied mathematicians alike. TDA uses principles from algebraic topology to comprehensively measure shape in data sets. Using a function that relates the similarity of data points to each other, we can monitor the evolution of topological features—connected components, loops, and voids. This evolution, a topological signature, concisely summarizes large, complex data sets. We first provide a TDA primer for biologists before exploring the use of TDA across biological sub-disciplines, spanning structural biology, molecular biology, evolution, and development. We end by comparing and contrasting different TDA approaches and the potential for their use in biology. The vision of TDA, that data are shape and shape is data, will be relevant as biology transitions into a data-driven era where the meaningful interpretation of large data sets is a limiting factor.},
	language = {en},
	number = {7},
	urldate = {2023-07-11},
	journal = {Developmental Dynamics},
	author = {Amézquita, Erik J. and Quigley, Michelle Y. and Ophelders, Tim and Munch, Elizabeth and Chitwood, Daniel H.},
	year = {2020},
	keywords = {biology, data science, mathematical biology, persistent homology, shape, topological data analysis},
	pages = {816--833},
}

@misc{noauthor_maths_nodate,
	title = {Maths in a minute: {Topology}},
	shorttitle = {Maths in a minute},
	url = {https://plus.maths.org/content/maths-minute-topology},
	abstract = {When you let go of the notions of distance, area, and angles, all you are left with is holes.},
	language = {en},
	urldate = {2023-07-11},
	journal = {Plus Maths},
}

@article{hensel_survey_2021,
	title = {A {Survey} of {Topological} {Machine} {Learning} {Methods}},
	volume = {4},
	issn = {2624-8212},
	url = {https://www.frontiersin.org/articles/10.3389/frai.2021.681108},
	abstract = {The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as “topological machine learning,” i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges.},
	urldate = {2023-07-11},
	journal = {Frontiers in Artificial Intelligence},
	author = {Hensel, Felix and Moor, Michael and Rieck, Bastian},
	year = {2021},
}

@misc{noauthor_frontiers_nodate,
	title = {Frontiers {\textbar} {A} {Survey} of {Topological} {Machine} {Learning} {Methods}},
	url = {https://www.frontiersin.org/articles/10.3389/frai.2021.681108/full},
	urldate = {2023-07-11},
}

@misc{noauthor_notitle_nodate,
}

@article{alan_basal_2022,
	title = {Basal {Gp78}-dependent mitophagy promotes mitochondrial health and limits mitochondrial {ROS}},
	volume = {79},
	issn = {1420-9071},
	url = {https://doi.org/10.1007/s00018-022-04585-8},
	doi = {10.1007/s00018-022-04585-8},
	abstract = {Mitochondria are major sources of cytotoxic reactive oxygen species (ROS), such as superoxide and hydrogen peroxide, that when uncontrolled contribute to cancer progression. Maintaining a finely tuned, healthy mitochondrial population is essential for cellular homeostasis and survival. Mitophagy, the selective elimination of mitochondria by autophagy, monitors and maintains mitochondrial health and integrity, eliminating damaged ROS-producing mitochondria. However, mechanisms underlying mitophagic control of mitochondrial homeostasis under basal conditions remain poorly understood. E3 ubiquitin ligase Gp78 is an endoplasmic reticulum membrane protein that induces mitochondrial fission and mitophagy of depolarized mitochondria. Here, we report that CRISPR/Cas9 knockout of Gp78 in HT-1080 fibrosarcoma cells increased mitochondrial volume, elevated ROS production and rendered cells resistant to carbonyl cyanide m-chlorophenyl hydrazone (CCCP)-induced mitophagy. These effects were phenocopied by knockdown of the essential autophagy protein ATG5 in wild-type HT-1080 cells. Use of the mito-Keima mitophagy probe confirmed that Gp78 promoted both basal and damage-induced mitophagy. Application of a spot detection algorithm (SPECHT) to GFP-mRFP tandem fluorescent-tagged LC3 (tfLC3)-positive autophagosomes reported elevated autophagosomal maturation in wild-type HT-1080 cells relative to Gp78 knockout cells, predominantly in proximity to mitochondria. Mitophagy inhibition by either Gp78 knockout or ATG5 knockdown reduced mitochondrial potential and increased mitochondrial ROS. Live cell analysis of tfLC3 in HT-1080 cells showed the preferential association of autophagosomes with mitochondria of reduced potential. Xenograft tumors of HT-1080 knockout cells show increased labeling for mitochondria and the cell proliferation marker Ki67 and reduced labeling for the TUNEL cell death reporter. Basal Gp78-dependent mitophagic flux is, therefore, selectively associated with reduced potential mitochondria promoting maintenance of a healthy mitochondrial population, limiting ROS production and tumor cell proliferation.},
	language = {en},
	number = {11},
	urldate = {2023-07-08},
	journal = {Cellular and Molecular Life Sciences},
	author = {Alan, Parsa and Vandevoorde, Kurt R. and Joshi, Bharat and Cardoen, Ben and Gao, Guang and Mohammadzadeh, Yahya and Hamarneh, Ghassan and Nabi, Ivan R.},
	month = oct,
	year = {2022},
	keywords = {GFP-mRFP tandem fluorescent-tagged LC3, Gp78 ubiquitin ligase, Mitochondria, Mitophagy, Reactive oxygen species, SPECHT, Spot detection},
	pages = {565},
}

@article{ben_yedder_deep_2021,
	title = {Deep learning for biomedical image reconstruction: a survey},
	volume = {54},
	issn = {0269-2821, 1573-7462},
	shorttitle = {Deep learning for biomedical image reconstruction},
	url = {https://link.springer.com/10.1007/s10462-020-09861-2},
	doi = {10.1007/s10462-020-09861-2},
	language = {en},
	number = {1},
	urldate = {2023-07-08},
	journal = {Artificial Intelligence Review},
	author = {Ben Yedder, Hanene and Cardoen, Ben and Hamarneh, Ghassan},
	month = jan,
	year = {2021},
	pages = {215--251},
}

@article{ben_yedder_multitask_2022,
	title = {Multitask {Deep} {Learning} {Reconstruction} and {Localization} of {Lesions} in {Limited} {Angle} {Diffuse} {Optical} {Tomography}},
	volume = {41},
	issn = {0278-0062, 1558-254X},
	url = {https://ieeexplore.ieee.org/document/9557304/},
	doi = {10.1109/TMI.2021.3117276},
	number = {3},
	urldate = {2023-07-08},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Ben Yedder, Hanene and Cardoen, Ben and Shokoufi, Majid and Golnaraghi, Farid and Hamarneh, Ghassan},
	month = mar,
	year = {2022},
	pages = {515--530},
}

@incollection{shen_limited-angle_2019,
	address = {Cham},
	title = {Limited-{Angle} {Diffuse} {Optical} {Tomography} {Image} {Reconstruction} {Using} {Deep} {Learning}},
	volume = {11764},
	isbn = {9783030322380 9783030322397},
	url = {http://link.springer.com/10.1007/978-3-030-32239-7_8},
	language = {en},
	urldate = {2023-07-08},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} – {MICCAI} 2019},
	publisher = {Springer International Publishing},
	author = {Ben Yedder, Hanene and Shokoufi, Majid and Cardoen, Ben and Golnaraghi, Farid and Hamarneh, Ghassan},
	editor = {Shen, Dinggang and Liu, Tianming and Peters, Terry M. and Staib, Lawrence H. and Essert, Caroline and Zhou, Sean and Yap, Pew-Thian and Khan, Ali},
	year = {2019},
	doi = {10.1007/978-3-030-32239-7_8},
	pages = {66--74},
}

@misc{ben_yedder_deep_2023,
	title = {Deep {Orthogonal} {Multi}-{Frequency} {Fusion} for {Tomogram}-{Free} {Diagnosis} in {Diffuse} {Optical} {Imaging}},
	url = {https://www.techrxiv.org/articles/preprint/Orthogonal_Multi-frequency_Fusion_Based_Image_Reconstruction_and_Diagnosis_in_Diffuse_Optical_Tomography/21574533/3},
	doi = {10.36227/techrxiv.21574533.v3},
	abstract = {Identifying breast cancer lesions with a portable diffuse optical tomography (DOT) device can improve early detection while avoiding otherwise unnecessarily invasive, ionizing, and more expensive modalities such as CT, as well as enabling pre-screening efficiency. Critical to this capability is not just the identification of lesions but rather the complex problem of discriminating between malignant and benign lesions. To accurately capture the highly heterogeneous tissue of a cancer lesion embedded in healthy breast tissue with non-invasive DOT, multiple frequencies can be combined to optimize signal penetration and reduce sensitivity to noise. However, these frequency responses can overlap, capture common information, and correlate, potentially confounding reconstruction and downstream end tasks. We show that an orthogonal fusion loss of multi-frequency DOT can improve reconstruction. More importantly, the orthogonal fusion leads to more accurate end-to-end identification of malignant versus benign lesions, illustrating its regularization properties in the multi-frequency input space. While the deployment of portable DOT probes requires a severely constrained computational budget, we show that our raw-to-task model, for direct prediction of the end task from signal, significantly reduces computational complexity without sacrificing accuracy, enabling a high real-time throughput, desiredin medical settings. Furthermore, our results indicate that image reconstruction is not necessary for unbiased classiication of lesions with a balanced accuracy of 77\% and 66\% on the synthetic dataset and clinical dataset, espectively, using the raw-to-task model. Code is available at https: //github.com/sfu-mial/FuseNet},
	language = {en},
	urldate = {2023-07-08},
	publisher = {TechRxiv},
	author = {Ben Yedder, Hanene and Cardoen, Ben and Shokoufi, Majid and Golnaraghi, Farid and Hamarneh, Ghassan},
	month = jun,
	year = {2023},
}

@techreport{cardoen_membrane_2022,
	type = {preprint},
	title = {Membrane contact site detection ({MCS}-{DETECT}) reveals dual control of rough mitochondria-{ER} contacts},
	url = {http://biorxiv.org/lookup/doi/10.1101/2022.06.23.497346},
	abstract = {Abstract 
          Identification and morphological analysis of mitochondria-ER contacts (MERCs) by fluorescent microscopy is limited by sub-pixel resolution inter-organelle distances. Application of a Membrane Contact Site (MCS) detection algorithm, MCS-DETECT, to 3D STED super-resolution image volumes reconstructs sub-resolution MERCs. MCS-DETECT shows that elongated ribosome-studded riboMERCs, present in HT-1080 but not COS-7 cells, are morphologically distinct from smaller smooth contacts and larger contacts induced by mitochondria-ER linker expression in COS-7 cells. riboMERC expression is reduced in Gp78 knockout HT-1080 cells and induced by Gp78 ubiquitin ligase activity in COS-7 cells. Knockdown of the riboMERC tether RRBP1 eliminates riboMERCs in both wild-type and Gp78 knockout HT-1080 cells. By MCS-DETECT, Gp78-dependent riboMERCs present complex tubular shapes that intercalate between and contact multiple mitochondria, that are lost upon RRBP1 knockdown. MCS-DETECT of 3D whole cell super-resolution image volumes therefore identifies a novel dual regulatory mechanism for tubular riboMERCs, whose formation is dependent on RRBP1 and size modulated by Gp78 E3 ubiquitin ligase activity. 
           
            eTOC Summary 
            Application of the sub-pixel resolution Membrane Contact Site (MCS) detection algorithm, MCS-DETECT, to 3D STED super-resolution image volumes identifies a novel dual regulatory mechanism for tubular riboMERCs, whose formation is dependent on RRBP1 and size modulated by Gp78 E3 ubiquitin ligase activity.},
	language = {en},
	urldate = {2023-07-07},
	institution = {Cell Biology},
	author = {Cardoen, Ben and Vandevoorde, Kurt and Gao, Guang and Alan, Parsa and Liu, William and Tiliakou, Ellie and Vogl, A. Wayne and Hamarneh, Ghassan and Nabi, Ivan R.},
	month = jun,
	year = {2022},
	doi = {10.1101/2022.06.23.497346},
}

@inproceedings{lin_incorporating_2022,
	title = {Incorporating knowledge of plates in batch normalization improves generalization of deep learning for microscopy images},
	url = {https://proceedings.mlr.press/v200/lin22a.html},
	abstract = {Data collected by high-throughput microscopy experiments are affected by batch effects, stemming from slight technical differences between experimental batches. Batch effects significantly impede machine learning efforts, as models learn spurious technical variation that do not generalize.  We introduce batch effects normalization (BEN), a simple method for correcting batch effects that can be applied to any neural network with batch normalization (BN) layers.  BEN aligns the concept of a ”batch” in biological experiments with that of a ”batch” in deep learning. During each training step, data points forming the deep learning batch are always sampled from the same experimental batch. This small tweak turns the batch normalization layers into an estimate of the shared batch effects between images, allowing for these technical effects to be standardized out during training and inference. We demonstrate that BEN results in dramatic performance boosts in both supervised and unsupervised learning, leading to state-of-the-art performance on the RxRx1-Wilds benchmark.},
	language = {en},
	urldate = {2023-06-30},
	booktitle = {Proceedings of the 17th {Machine} {Learning} in {Computational} {Biology} meeting},
	publisher = {PMLR},
	author = {Lin, Alexander and Lu, Alex},
	month = dec,
	year = {2022},
	pages = {74--93},
}

@article{kenworthy_role_2023,
	title = {The {Role} of {Membrane} {Lipids} in the {Formation} and {Function} of {Caveolae}},
	issn = {, 1943-0264},
	url = {http://cshperspectives.cshlp.org/content/early/2023/06/05/cshperspect.a041413},
	doi = {10.1101/cshperspect.a041413},
	abstract = {A new type of review journal, featuring comprehensive collections of expert review articles on important topics in the molecular life sciences},
	language = {en},
	urldate = {2023-06-27},
	journal = {Cold Spring Harbor Perspectives in Biology},
	author = {Kenworthy, Anne K. and Han, Bing and Ariotti, Nicholas and Parton, Robert G.},
	month = jun,
	year = {2023},
	pmid = {37277189},
	pages = {a041413},
}

@article{de_almeida_caveolin-1_2017,
	title = {Caveolin-1 and {Caveolin}-2 {Can} {Be} {Antagonistic} {Partners} in {Inflammation} and {Beyond}},
	volume = {8},
	issn = {1664-3224},
	url = {https://www.frontiersin.org/articles/10.3389/fimmu.2017.01530},
	abstract = {Caveolins, encoded by the CAV gene family, are the main protein components of caveolae. In most tissues, caveolin-1 (Cav-1) and caveolin-2 (Cav-2) are co-expressed, and Cav-2 targeting to caveolae depends on the formation of heterooligomers with Cav-1. Notwithstanding, Cav-2 has unpredictable activities, opposing Cav-1 in the regulation of some cellular processes. While the major roles of Cav-1 as a modulator of cell signaling in inflammatory processes and in immune responses have been extensively discussed elsewhere, the aim of this review is to focus on data revealing the distinct activity of Cav-1 and Cav-2, which suggest that these proteins act antagonistically to fine-tune a variety of cellular processes relevant to inflammation.},
	urldate = {2023-06-20},
	journal = {Frontiers in Immunology},
	author = {de Almeida, Cecília Jacques Gonçalves},
	year = {2017},
}

@article{gottschling_upsides_2017,
	title = {The {Upsides} and {Downsides} of {Organelle} {Interconnectivity}},
	volume = {169},
	issn = {0092-8674},
	url = {https://www.sciencedirect.com/science/article/pii/S0092867417302453},
	doi = {10.1016/j.cell.2017.02.030},
	abstract = {Interconnectivity and feedback control are hallmarks of biological systems. This includes communication between organelles, which allows them to function and adapt to changing cellular environments. While the specific mechanisms for all communications remain opaque, unraveling the wiring of organelle networks is critical to understand how biological systems are built and why they might collapse, as occurs in aging. A comprehensive understanding of all the routes involved in inter-organelle communication is still lacking, but important themes are beginning to emerge, primarily in budding yeast. These routes are reviewed here in the context of sub-system proteostasis and complex adaptive systems theory.},
	language = {en},
	number = {1},
	urldate = {2023-06-20},
	journal = {Cell},
	author = {Gottschling, Daniel E. and Nyström, Thomas},
	month = mar,
	year = {2017},
	keywords = {aging, inter-organelle communication, protein quality control, yeast},
	pages = {24--34},
}

@article{fujiwara_ultrafast_2023,
	title = {Ultrafast single-molecule imaging reveals focal adhesion nano-architecture and molecular dynamics},
	volume = {222},
	issn = {0021-9525},
	url = {https://doi.org/10.1083/jcb.202110162},
	doi = {10.1083/jcb.202110162},
	abstract = {Using our newly developed ultrafast camera described in the companion paper, we reduced the data acquisition periods required for photoactivation/photoconversion localization microscopy (PALM, using mEos3.2) and direct stochastic reconstruction microscopy (dSTORM, using HMSiR) by a factor of ≈30 compared with standard methods, for much greater view-fields, with localization precisions of 29 and 19 nm, respectively, thus opening up previously inaccessible spatiotemporal scales to cell biology research. Simultaneous two-color PALM-dSTORM and PALM-ultrafast (10 kHz) single fluorescent-molecule imaging-tracking has been realized. They revealed the dynamic nanoorganization of the focal adhesion (FA), leading to the compartmentalized archipelago FA model, consisting of FA-protein islands with broad diversities in size (13–100 nm; mean island diameter ≈30 nm), protein copy numbers, compositions, and stoichiometries, which dot the partitioned fluid membrane (74-nm compartments in the FA vs. 109-nm compartments outside the FA). Integrins are recruited to these islands by hop diffusion. The FA-protein islands form loose ≈320 nm clusters and function as units for recruiting FA proteins.},
	number = {8},
	urldate = {2023-06-14},
	journal = {Journal of Cell Biology},
	author = {Fujiwara, Takahiro K. and Tsunoyama, Taka A. and Takeuchi, Shinji and Kalay, Ziya and Nagai, Yosuke and Kalkbrenner, Thomas and Nemoto, Yuri L. and Chen, Limin H. and Shibata, Akihiro C.E. and Iwasawa, Kokoro and Ritchie, Ken P. and Suzuki, Kenichi G.N. and Kusumi, Akihiro},
	month = jun,
	year = {2023},
	pages = {e202110162},
}

@article{ostersehlt_dna-paint_2022,
	title = {{DNA}-{PAINT} {MINFLUX} nanoscopy},
	volume = {19},
	copyright = {2022 The Author(s)},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-022-01577-1},
	doi = {10.1038/s41592-022-01577-1},
	abstract = {MINimal fluorescence photon FLUXes (MINFLUX) nanoscopy, providing photon-efficient fluorophore localizations, has brought about three-dimensional resolution at nanometer scales. However, by using an intrinsic on–off switching process for single fluorophore separation, initial MINFLUX implementations have been limited to two color channels. Here we show that MINFLUX can be effectively combined with sequentially multiplexed DNA-based labeling (DNA-PAINT), expanding MINFLUX nanoscopy to multiple molecular targets. Our method is exemplified with three-color recordings of mitochondria in human cells.},
	language = {en},
	number = {9},
	urldate = {2023-06-13},
	journal = {Nature Methods},
	author = {Ostersehlt, Lynn M. and Jans, Daniel C. and Wittek, Anna and Keller-Findeisen, Jan and Inamdar, Kaushik and Sahl, Steffen J. and Hell, Stefan W. and Jakobs, Stefan},
	month = sep,
	year = {2022},
	keywords = {Nanoscale biophysics, Super-resolution microscopy},
	pages = {1072--1075},
}

@article{grabner_resolving_2022,
	title = {Resolving the molecular architecture of the photoreceptor active zone with {3D}-{MINFLUX}},
	volume = {8},
	issn = {2375-2548},
	url = {https://www.science.org/doi/10.1126/sciadv.abl7560},
	doi = {10.1126/sciadv.abl7560},
	abstract = {Cells assemble macromolecular complexes into scaffoldings that serve as substrates for catalytic processes. Years of molecular neurobiology research indicate that neurotransmission depends on such optimization strategies. However, the molecular topography of the presynaptic active zone (AZ), where transmitter is released upon synaptic vesicle (SV) fusion, remains to be visualized. Therefore, we implemented MINFLUX optical nanoscopy to resolve the AZ of rod photoreceptors. This was facilitated by a novel sample immobilization technique that we name heat-assisted rapid dehydration (HARD), wherein a thin layer of rod synaptic terminals (spherules) was transferred onto glass coverslips from fresh retinal slices. Rod ribbon AZs were readily immunolabeled and imaged in 3D with a precision of a few nanometers. Our 3D-MINFLUX results indicate that the SV release site in rods is a molecular complex of bassoon–RIM2–ubMunc13-2–Ca 
              v 
              1.4, which repeats longitudinally on both sides of the ribbon. 
             
          ,  
            3D-MINFLUX nanoscopy of heat-immobilized retinal sections reveals the molecular topography of rod photoreceptor active zones.},
	language = {en},
	number = {28},
	urldate = {2023-06-13},
	journal = {Science Advances},
	author = {Grabner, Chad P. and Jansen, Isabelle and Neef, Jakob and Weihs, Tobias and Schmidt, Roman and Riedel, Dietmar and Wurm, Christian A. and Moser, Tobias},
	month = jul,
	year = {2022},
	pages = {eabl7560},
}

@article{vasudevan_off--shelf_2021,
	title = {Off-the-shelf deep learning is not enough, and requires parsimony, {Bayesianity}, and causality},
	volume = {7},
	copyright = {2021 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
	issn = {2057-3960},
	url = {https://www.nature.com/articles/s41524-020-00487-0},
	doi = {10.1038/s41524-020-00487-0},
	abstract = {Deep neural networks (‘deep learning’) have emerged as a technology of choice to tackle problems in speech recognition, computer vision, finance, etc. However, adoption of deep learning in physical domains brings substantial challenges stemming from the correlative nature of deep learning methods compared to the causal, hypothesis driven nature of modern science. We argue that the broad adoption of Bayesian methods incorporating prior knowledge, development of solutions with incorporated physical constraints and parsimonious structural descriptors and generative models, and ultimately adoption of causal models, offers a path forward for fundamental and applied research.},
	language = {en},
	number = {1},
	urldate = {2023-06-13},
	journal = {npj Computational Materials},
	author = {Vasudevan, Rama K. and Ziatdinov, Maxim and Vlcek, Lukas and Kalinin, Sergei V.},
	month = jan,
	year = {2021},
	keywords = {Applied physics, Theory and computation},
	pages = {1--6},
}

@article{herbert_edelsbrunner_persistent_2008,
	title = {Persistent {Homology} — a {Survey}},
	volume = {453},
	number = {26},
	journal = {Contemporary mathematics},
	author = {Herbert Edelsbrunner, Herbert Edelsbrunner {and} John Harer},
	year = {2008},
	pages = {257--282},
}

@inproceedings{pandey_self-supervised_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Self-supervised {Learning} {Through} {Colorization} for {Microscopy} {Images}},
	isbn = {9783031064302},
	doi = {10.1007/978-3-031-06430-2_52},
	abstract = {Training effective models for segmentation or classification of microscopy images is a hard task, complicated by the scarcity of adequately labeled data sets. In this context, self-supervised learning strategies can be deployed to learn suitable image representations from the available large quantity of unlabeled data, e.g. the 500k electron microscopy images that compose the CEM500k data sets.},
	language = {en},
	booktitle = {Image {Analysis} and {Processing} – {ICIAP} 2022},
	publisher = {Springer International Publishing},
	author = {Pandey, Vaidehi and Brune, Christoph and Strisciuglio, Nicola},
	editor = {Sclaroff, Stan and Distante, Cosimo and Leo, Marco and Farinella, Giovanni M. and Tombari, Federico},
	year = {2022},
	keywords = {BYOL, Colorization, Microscopy images, Pre-training, Self-supervised learning},
	pages = {621--632},
}

@inproceedings{bahr_cellcyclegan_2021,
	address = {Nice, France},
	title = {Cellcyclegan: {Spatiotemporal} {Microscopy} {Image} {Synthesis} {Of} {Cell} {Populations} {Using} {Statistical} {Shape} {Models} {And} {Conditional} {Gans}},
	isbn = {9781665412469},
	shorttitle = {Cellcyclegan},
	url = {https://ieeexplore.ieee.org/document/9433896/},
	doi = {10.1109/ISBI48211.2021.9433896},
	urldate = {2023-06-12},
	booktitle = {2021 {IEEE} 18th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	publisher = {IEEE},
	author = {Bahr, Dennis and Eschweiler, Dennis and Bhattacharyya, Anuk and Moreno-Andres, Daniel and Antonin, Wolfram and Stegmaier, Johannes},
	month = apr,
	year = {2021},
	pages = {15--19},
}

@book{volpe_roadmap_2023,
	title = {Roadmap on {Deep} {Learning} for {Microscopy}},
	abstract = {Through digital imaging, microscopy has evolved from primarily being a means for visual observation of life at the micro- and nano-scale, to a quantitative tool with ever-increasing resolution and throughput. Artificial intelligence, deep neural networks, and machine learning are all niche terms describing computational methods that have gained a pivotal role in microscopy-based research over the past decade. This Roadmap is written collectively by prominent researchers and encompasses selected aspects of how machine learning is applied to microscopy image data, with the aim of gaining scientific knowledge by improved image quality, automated detection, segmentation, classification and tracking of objects, and efficient merging of information from multiple imaging modalities. We aim to give the reader an overview of the key developments and an understanding of possibilities and limitations of machine learning for microscopy. It will be of interest to a wide cross-disciplinary audience in the physical sciences and life sciences.},
	publisher = {Arxiv},
	author = {Volpe, Giovanni and Wählby, Carolina and Tian, Lei and Hecht, Michael and Yakimovich, Artur and Monakhova, Kristina and Waller, Laura and Sbalzarini, Ivo and Metzler, Christopher and Xie, Mingyang and Zhang, Kevin and Lenton, Isaac and Rubinsztein-Dunlop, Halina and Brunner, Daniel and Bai, Bijie and Ozcan, Aydogan and Midtvedt, Daniel and Wang, Hao and Sladoje, Natasa and Bergman, Johanna},
	month = mar,
	year = {2023},
}

@inproceedings{khater_sub-cellular_2016,
	title = {Sub-cellular network analysis of ryanodine receptor positioning in control and phosphorylated states},
	abstract = {Type 2 ryanodine receptors (RyR2) are large (mass=2.2 MegaDalton) proteins expressed in heart cells that mediate the release of calcium ions (Ca2+) that, in turn, modulate contraction of the heart. In this work, we analyze the sub-cellular spatial distribution of RyR2 using data from superresolution microscopy, an imaging technique that allows highly accurate positioning ({\textless}10 nm in x and y; {\textless}40 nm in z) of the RyR2 within the heart muscle cell. In particular, we present the first work to examine network measures of extracted RyR2 locations to examine the clustering behaviour of these channels. We collected images from two groups of healthy cardiac cells; the control consisted of 8 cells, while the second group of 8 cells were treated with a chemical cocktail to phosphorylate the RyR2 and to inhibit dephosphorylation. We examined the classification accuracy (using random forest classifier) and the group differences (using Mann-Whitney statistical test and Bonferroni multiple comparison correction) based on several network measures, at multiple proximity thresholds. Several network measures we examined revealed features (e.g. network clustering) that enabled us to differentiate between these two populations (p{\textless}0.00045) with high classification accuracy ({\textgreater}95\% at proximity thresholds 200 and 250 nm). Our findings may help in better understanding Ca2+ signaling during contraction and give insight into the changes that underlie its regulation.},
	booktitle = {2016 {Computing} in {Cardiology} {Conference} ({CinC})},
	author = {Khater, Ismail M. and Scriven, David R.L. and Moore, Edwin D.W. and Hamarneh, Ghassan},
	month = sep,
	year = {2016},
	note = {ISSN: 2325-887X},
	keywords = {Feature extraction, Microscopy, Proteins, Signal resolution, Spatial resolution, Three-dimensional displays},
	pages = {821--824},
}

@inproceedings{erdelyi_enhanced_2017,
	title = {Enhanced simulator software for image validation and interpretation for multimodal localization super-resolution fluorescence microscopy},
	volume = {10071},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10071/100710X/Enhanced-simulator-software-for-image-validation-and-interpretation-for-multimodal/10.1117/12.2250116.full},
	doi = {10.1117/12.2250116},
	abstract = {Optical super-resolution techniques such as single molecule localization have become one of the most dynamically developed areas in optical microscopy. These techniques routinely provide images of fixed cells or tissues with sub-diffraction spatial resolution, and can even be applied for live cell imaging under appropriate circumstances. Localization techniques are based on the precise fitting of the point spread functions (PSF) to the measured images of stochastically excited, identical fluorescent molecules. These techniques require controlling the rate between the on, off and the bleached states, keeping the number of active fluorescent molecules at an optimum value, so their diffraction limited images can be detected separately both spatially and temporally. Because of the numerous (and sometimes unknown) parameters, the imaging system can only be handled stochastically. For example, the rotation of the dye molecules obscures the polarization dependent PSF shape, and only an averaged distribution – typically estimated by a Gaussian function – is observed. TestSTORM software was developed to generate image stacks for traditional localization microscopes, where localization meant the precise determination of the spatial position of the molecules. However, additional optical properties (polarization, spectra, etc.) of the emitted photons can be used for further monitoring the chemical and physical properties (viscosity, pH, etc.) of the local environment. The image stack generating program was upgraded by several new features, such as: multicolour, polarization dependent PSF, built-in 3D visualization, structured background. These features make the program an ideal tool for optimizing the imaging and sample preparation conditions.},
	urldate = {2023-06-12},
	booktitle = {Single {Molecule} {Spectroscopy} and {Superresolution} {Imaging} {X}},
	publisher = {SPIE},
	author = {Erdélyi, Miklós and Sinkó, József and Gajdos, Tamás and Novák, Tibor},
	month = feb,
	year = {2017},
	pages = {70--75},
}

@article{khater_review_2020,
	title = {A {Review} of {Super}-{Resolution} {Single}-{Molecule} {Localization} {Microscopy} {Cluster} {Analysis} and {Quantification} {Methods}},
	volume = {1},
	issn = {2666-3899},
	url = {https://www.sciencedirect.com/science/article/pii/S266638992030043X},
	doi = {10.1016/j.patter.2020.100038},
	abstract = {Single-molecule localization microscopy (SMLM) is a relatively new imaging modality, winning the 2014 Nobel Prize in Chemistry, and considered as one of the key super-resolution techniques. SMLM resolution goes beyond the diffraction limit of light microscopy and achieves resolution on the order of 10–20 nm. SMLM thus enables imaging single molecules and study of the low-level molecular interactions at the subcellular level. In contrast to standard microscopy imaging that produces 2D pixel or 3D voxel grid data, SMLM generates big data of 2D or 3D point clouds with millions of localizations and associated uncertainties. This unprecedented breakthrough in imaging helps researchers employ SMLM in many fields within biology and medicine, such as studying cancerous cells and cell-mediated immunity and accelerating drug discovery. However, SMLM data quantification and interpretation methods have yet to keep pace with the rapid advancement of SMLM imaging. Researchers have been actively exploring new computational methods for SMLM data analysis to extract biosignatures of various biological structures and functions. In this survey, we describe the state-of-the-art clustering methods adopted to analyze and quantify SMLM data and examine the capabilities and shortcomings of the surveyed methods. We classify the methods according to (1) the biological application (i.e., the imaged molecules/structures), (2) the data acquisition (such as imaging modality, dimension, resolution, and number of localizations), and (3) the analysis details (2D versus 3D, field of view versus region of interest, use of machine-learning and multi-scale analysis, biosignature extraction, etc.). We observe that the majority of methods that are based on second-order statistics are sensitive to noise and imaging artifacts, have not been applied to 3D data, do not leverage machine-learning formulations, and are not scalable for big-data analysis. Finally, we summarize state-of-the-art methodology, discuss some key open challenges, and identify future opportunities for better modeling and design of an integrated computational pipeline to address the key challenges.},
	language = {en},
	number = {3},
	urldate = {2023-06-12},
	journal = {Patterns},
	author = {Khater, Ismail M. and Nabi, Ivan Robert and Hamarneh, Ghassan},
	month = jun,
	year = {2020},
	keywords = {SMLM, cluster analysis, localization microscopy, molecular complexes, point clouds, quantification of biological structures, single molecule, super-resolution nanoscopy},
	pages = {100038},
}

@article{maier-hein_metrics_2022,
	title = {Metrics reloaded: {Pitfalls} and recommendations for image analysis validation},
	copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
	shorttitle = {Metrics reloaded},
	url = {https://arxiv.org/abs/2206.01653},
	doi = {10.48550/ARXIV.2206.01653},
	abstract = {Increasing evidence shows that flaws in machine learning (ML) algorithm validation are an underestimated global problem. Particularly in automatic biomedical image analysis, chosen performance metrics often do not reflect the domain interest, thus failing to adequately measure scientific progress and hindering translation of ML techniques into practice. To overcome this, our large international expert consortium created Metrics Reloaded, a comprehensive framework guiding researchers in the problem-aware selection of metrics. Following the convergence of ML methodology across application domains, Metrics Reloaded fosters the convergence of validation methodology. The framework was developed in a multi-stage Delphi process and is based on the novel concept of a problem fingerprint - a structured representation of the given problem that captures all aspects that are relevant for metric selection, from the domain interest to the properties of the target structure(s), data set and algorithm output. Based on the problem fingerprint, users are guided through the process of choosing and applying appropriate validation metrics while being made aware of potential pitfalls. Metrics Reloaded targets image analysis problems that can be interpreted as a classification task at image, object or pixel level, namely image-level classification, object detection, semantic segmentation, and instance segmentation tasks. To improve the user experience, we implemented the framework in the Metrics Reloaded online tool, which also provides a point of access to explore weaknesses, strengths and specific recommendations for the most common validation metrics. The broad applicability of our framework across domains is demonstrated by an instantiation for various biological and medical image analysis use cases.},
	urldate = {2023-06-12},
	journal = {Arxiv},
	author = {Maier-Hein, Lena and Reinke, Annika and Godau, Patrick and Tizabi, Minu D. and Büttner, Florian and Christodoulou, Evangelia and Glocker, Ben and Isensee, Fabian and Kleesiek, Jens and Kozubek, Michal and Reyes, Mauricio and Riegler, Michael A. and Wiesenfarth, Manuel and Kavur, Emre and Sudre, Carole H. and Baumgartner, Michael and Eisenmann, Matthias and Heckmann-Nötzel, Doreen and Rädsch, A. Tim and Acion, Laura and Antonelli, Michela and Arbel, Tal and Bakas, Spyridon and Benis, Arriel and Blaschko, Matthew and Cardoso, M. Jorge and Cheplygina, Veronika and Cimini, Beth A. and Collins, Gary S. and Farahani, Keyvan and Ferrer, Luciana and Galdran, Adrian and van Ginneken, Bram and Haase, Robert and Hashimoto, Daniel A. and Hoffman, Michael M. and Huisman, Merel and Jannin, Pierre and Kahn, Charles E. and Kainmueller, Dagmar and Kainz, Bernhard and Karargyris, Alexandros and Karthikesalingam, Alan and Kenngott, Hannes and Kofler, Florian and Kopp-Schneider, Annette and Kreshuk, Anna and Kurc, Tahsin and Landman, Bennett A. and Litjens, Geert and Madani, Amin and Maier-Hein, Klaus and Martel, Anne L. and Mattson, Peter and Meijering, Erik and Menze, Bjoern and Moons, Karel G. M. and Müller, Henning and Nichyporuk, Brennan and Nickel, Felix and Petersen, Jens and Rajpoot, Nasir and Rieke, Nicola and Saez-Rodriguez, Julio and Sánchez, Clara I. and Shetty, Shravya and van Smeden, Maarten and Summers, Ronald M. and Taha, Abdel A. and Tiulpin, Aleksei and Tsaftaris, Sotirios A. and Van Calster, Ben and Varoquaux, Gaël and Jäger, Paul F.},
	year = {2022},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
}

@article{jonsson_parallel_2022,
	title = {Parallel {Discrete} {Convolutions} on {Adaptive} {Particle} {Representations} of {Images}},
	volume = {31},
	issn = {1941-0042},
	doi = {10.1109/TIP.2022.3181487},
	abstract = {We present data structures and algorithms for native implementations of discrete convolution operators over Adaptive Particle Representations (APR) of images on parallel computer architectures. The APR is a content-adaptive image representation that locally adapts the sampling resolution to the image signal. It has been developed as an alternative to pixel representations for large, sparse images as they typically occur in fluorescence microscopy. It has been shown to reduce the memory and runtime costs of storing, visualizing, and processing such images. This, however, requires that image processing natively operates on APRs, without intermediately reverting to pixels. Designing efficient and scalable APR-native image processing primitives, however, is complicated by the APR’s irregular memory structure. Here, we provide the algorithmic building blocks required to efficiently and natively process APR images using a wide range of algorithms that can be formulated in terms of discrete convolutions. We show that APR convolution naturally leads to scale-adaptive algorithms that efficiently parallelize on multi-core CPU and GPU architectures. We quantify the speedups in comparison to pixel-based algorithms and convolutions on evenly sampled data. We achieve pixel-equivalent throughputs of up to 1TB/s on a single Nvidia GeForce RTX 2080 gaming GPU, requiring up to two orders of magnitude less memory than a pixel-based implementation.},
	journal = {IEEE Transactions on Image Processing},
	author = {Jonsson, Joel and Cheeseman, Bevan L. and Maddu, Suryanarayana and Gonciarz, Krzysztof and Sbalzarini, Ivo F.},
	year = {2022},
	keywords = {Biomedical image processing, Convolution, Data structures, Image processing, Image reconstruction, Image resolution, Microscopy, Signal resolution, convolution, data compression, data structures / octrees, deconvolution, image filtering, image representation, image restoration, parallel processing},
	pages = {4197--4212},
}

@article{whittaker_xviiifunctions_1915,
	title = {{XVIII}.—{On} the {Functions} which are represented by the {Expansions} of the {Interpolation}-{Theory}},
	volume = {35},
	issn = {0370-1646},
	url = {https://www.cambridge.org/core/product/identifier/S0370164600017806/type/journal_article},
	doi = {10.1017/S0370164600017806},
	abstract = {Let 
              ƒ(x) 
              be a given function of a variable 
              x 
              . We shall suppose that 
              ƒ(x) 
              is a one-valued 
              analytic 
              function, so that its Taylor's expansion in any part of the plane of the complex variable 
              x 
              can be derived from its Taylor's expansion in any other part of the plane by the process of analytic continuation.},
	language = {en},
	urldate = {2023-06-12},
	journal = {Proceedings of the Royal Society of Edinburgh},
	author = {Whittaker, E. T.},
	year = {1915},
	pages = {181--194},
}

@article{zhang_lat_1998,
	title = {{LAT}: {The} {ZAP}-70 {Tyrosine} {Kinase} {Substrate} that {Links} {T} {Cell} {Receptor} to {Cellular} {Activation}},
	volume = {92},
	issn = {0092-8674},
	shorttitle = {{LAT}},
	url = {https://www.sciencedirect.com/science/article/pii/S0092867400809010},
	doi = {10.1016/S0092-8674(00)80901-0},
	abstract = {Despite extensive study, several of the major components involved in T cell receptor–mediated signaling remain unidentified. Here we report the cloning of the cDNA for a highly tyrosine-phosphorylated 36–38 kDa protein, previously characterized by its association with Grb2, phospholipase C-γ1, and the p85 subunit of phosphoinositide 3-kinase. Deduced amino acid sequence identifies a novel integral membrane protein containing multiple potential tyrosine phosphorylation sites. We show that this protein is phosphorylated by ZAP-70/Syk protein tyrosine kinases leading to recruitment of multiple signaling molecules. Its function is demonstrated by inhibition of T cell activation following overexpression of a mutant form lacking critical tyrosine residues. Therefore, we propose to name the molecule LAT—linker for activation of T cells.},
	language = {en},
	number = {1},
	urldate = {2023-06-12},
	journal = {Cell},
	author = {Zhang, Weiguo and Sloan-Lancaster, Joanne and Kitchen, Jason and Trible, Ronald P and Samelson, Lawrence E},
	month = jan,
	year = {1998},
	pages = {83--92},
}

@article{shivanandan_mosaicia_2013,
	title = {{MosaicIA}: an {ImageJ}/{Fiji} plugin for spatial pattern and interaction analysis},
	volume = {14},
	issn = {1471-2105},
	shorttitle = {{MosaicIA}},
	url = {https://doi.org/10.1186/1471-2105-14-349},
	doi = {10.1186/1471-2105-14-349},
	abstract = {Analyzing spatial distributions of objects in images is a fundamental task in many biological studies. The relative arrangement of a set of objects with respect to another set of objects contains information about potential interactions between the two sets of objects. If they do not “feel” each other’s presence, their spatial distributions are expected to be independent of one another. Spatial correlations in their distributions are indicative of interactions and can be modeled by an effective interaction potential acting between the points of the two sets. This can be used to generalize co-localization analysis to spatial interaction analysis. However, no user-friendly software for this type of analysis was available so far.},
	number = {1},
	urldate = {2023-06-10},
	journal = {BMC Bioinformatics},
	author = {Shivanandan, Arun and Radenovic, Aleksandra and Sbalzarini, Ivo F.},
	month = dec,
	year = {2013},
	keywords = {Co-localization analysis, Fiji, Image analysis, ImageJ, Interaction analysis, Microscopy, PALM, Spatial pattern analysis},
	pages = {349},
}

@article{hofmann_using_2018,
	title = {Using {Persistent} {Homology} as a {New} {Approach} for {Super}-{Resolution} {Localization} {Microscopy} {Data} {Analysis} and {Classification} of {H2AX} {Foci}/{Clusters}},
	volume = {19},
	issn = {1422-0067},
	url = {http://www.mdpi.com/1422-0067/19/8/2263},
	doi = {10.3390/ijms19082263},
	abstract = {DNA double strand breaks (DSB) are the most severe damages in chromatin induced by ionizing radiation. In response to such environmentally determined stress situations, cells have developed repair mechanisms. Although many investigations have contributed to a detailed understanding of repair processes, e.g., homologous recombination repair or non-homologous end-joining, the question is not sufficiently answered, how a cell decides to apply a certain repair process at a certain damage site, since all different repair pathways could simultaneously occur in the same cell nucleus. One of the first processes after DSB induction is phosphorylation of the histone variant H2AX to γH2AX in the given surroundings of the damaged locus. Since the spatial organization of chromatin is not random, it may be conclusive that the spatial organization of γH2AX foci is also not random, and rather, contributes to accessibility of special repair proteins to the damaged site, and thus, to the following repair pathway at this given site. The aim of this article is to demonstrate a new approach to analyze repair foci by their topology in order to obtain a cell independent method of categorization. During the last decade, novel super-resolution fluorescence light microscopic techniques have enabled new insights into genome structure and spatial organization on the nano-scale in the order of 10 nm. One of these techniques is single molecule localization microscopy (SMLM) with which the spatial coordinates of single fluorescence molecules can precisely be determined and density and distance distributions can be calculated. This method is an appropriate tool to quantify complex changes of chromatin and to describe repair foci on the single molecule level. Based on the pointillist information obtained by SMLM from specifically labeled heterochromatin and γH2AX foci reflecting the chromatin morphology and repair foci topology, we have developed a new analytical methodology of foci or foci cluster characterization, respectively, by means of persistence homology. This method allows, for the first time, a cell independent comparison of two point distributions (here the point distributions of two γH2AX clusters) with each other of a selected ensample and to give a mathematical measure of their similarity. In order to demonstrate the feasibility of this approach, cells were irradiated by low LET (linear energy transfer) radiation with different doses and the heterochromatin and γH2AX foci were fluorescently labeled by antibodies for SMLM. By means of our new analysis method, we were able to show that the topology of clusters of γH2AX foci can be categorized depending on the distance to heterochromatin. This method opens up new possibilities to categorize spatial organization of point patterns by parameterization of topological similarity.},
	language = {en},
	number = {8},
	urldate = {2023-06-03},
	journal = {International Journal of Molecular Sciences},
	author = {Hofmann, Andreas and Krufczik, Matthias and Heermann, Dieter and Hausmann, Michael},
	month = aug,
	year = {2018},
	pages = {2263},
}

@article{yang_multicolor_2022,
	title = {Multicolor expansion fluorescence emission difference microscopy to reveal potential organelle contacts},
	volume = {520},
	issn = {0030-4018},
	url = {https://www.sciencedirect.com/science/article/pii/S0030401822003261},
	doi = {10.1016/j.optcom.2022.128474},
	abstract = {Biologists have long been interested in the submicroscopic structures of cells and interactions between organelles. However, due to resolution limitations, investigating cell biology using fluorescence microscopy remains a challenge. In recent decades, super-resolution microscopy has been developed as an essential solution. Recently, a new microscopic technique called expansion microscopy has been developed, which circumvents this resolution limit by increasing the size of the biological sample, thus allowing for super-resolution of the enlarged structure. In this study, we combined expansion microscopy with fluorescence emission difference microscopy (ExFED) and achieved a spatial resolution of approximately 40 nm in mammalian cells. Delicate subcellular and sub-organelle structures were investigated, and potential contacts were detected. The results indicated that ExFED is a simple and powerful super-resolution method for studying biological specimens.},
	language = {en},
	urldate = {2023-06-02},
	journal = {Optics Communications},
	author = {Yang, Lu and Huang, Yuran and Zhang, Zhimin and Han, Yubing and Kuang, Cuifang},
	month = oct,
	year = {2022},
	keywords = {Expansion microscopy, Fluorescence microscopy, Imaging systems, Super resolution},
	pages = {128474},
}

@article{han_novel_2023,
	title = {A novel fluorescent endoplasmic reticulum marker for super-resolution imaging in live cells},
	volume = {597},
	copyright = {© 2023 Federation of European Biochemical Societies.},
	issn = {1873-3468},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/1873-3468.14581},
	doi = {10.1002/1873-3468.14581},
	abstract = {Endoplasmic reticulum (ER) is a highly complicated and dynamic organelle that actively changes its shape and communicates with other organelles. Visualization of ER in live cells is of great importance to understand cellular activities. Here, we designed a novel ER marker, RR-mNeonGreen, which comprised an N-terminal ER retention signal, a bright fluorescent protein (mNeonGreen), and a C-terminal transmembrane region. Colocalization of RR-mNeonGreen with mCherry-KDEL verified that RR-mNeonGreen perfectly labeled the ER. RR-mNeonGreen showed better continuity of ER tubules when imaged by super-resolution microscopy. Moreover, RR-mNeonGreen is competent for live-cell imaging of ER dynamics and tracing of the interaction between ER and mitochondria at high spatiotemporal resolution. In summary, RR-mNeonGreen is a novel ER marker for super-resolution live-cell imaging with multiple merits.},
	language = {en},
	number = {5},
	urldate = {2023-06-02},
	journal = {FEBS Letters},
	author = {Han, Kai and Huang, Shuhan and Kong, Jie and Yang, Yang and Shi, Lei and Ci, Yali},
	year = {2023},
	keywords = {ER marker, RR-mNeonGreen, dynamics, live-cell imaging, super-resolution},
	pages = {693--701},
}

@article{damenti_sted_2021,
	title = {{STED} and parallelized {RESOLFT} optical nanoscopy of the tubular endoplasmic reticulum and its mitochondrial contacts in neuronal cells},
	volume = {155},
	issn = {1095-953X},
	doi = {10.1016/j.nbd.2021.105361},
	abstract = {The classic view of organelle cell biology is undergoing a constant revision fueled by the new insights unraveled by fluorescence nanoscopy, which enable sensitive, faster and gentler observation of specific proteins in situ. The endoplasmic reticulum (ER) is one of the most challenging structure to capture due the rapid and constant restructuring of fine sheets and tubules across the full 3D cell volume. Here we apply STED and parallelized 2D and 3D RESOLFT live imaging to uncover the tubular ER organization in the fine processes of neuronal cells with focus on mitochondria-ER contacts, which recently gained medical attention due to their role in neurodegeneration. Multi-color STED nanoscopy enables the simultaneous visualization of small transversal ER tubules crossing and constricting mitochondria all along axons and dendrites. Parallelized RESOLFT allows for dynamic studies of multiple contact sites within seconds and minutes with prolonged time-lapse imaging at {\textasciitilde}50 nm spatial resolution. When operated in 3D super resolution mode it enables a new isotropic visualization of such contacts extending our understanding of the three-dimensional architecture of these packed structures in axons and dendrites.},
	language = {eng},
	journal = {Neurobiology of Disease},
	author = {Damenti, Martina and Coceano, Giovanna and Pennacchietti, Francesca and Bodén, Andreas and Testa, Ilaria},
	month = jul,
	year = {2021},
	pmid = {33857635},
	keywords = {Animals, Endoplasmic Reticulum, Endoplasmic reticulum, Hippocampus, Imaging, Three-Dimensional, Microscopy, Fluorescence, Mitochondria-ER contacts, Nanotechnology, Neurons, RESOLFT, Rats, Rats, Sprague-Dawley, STED, Super resolution microscopy, Time-Lapse Imaging},
	pages = {105361},
}

@article{sharma_recent_2020,
	title = {Recent advances in {STED} and {RESOLFT} super-resolution imaging techniques},
	volume = {231},
	issn = {1386-1425},
	url = {https://www.sciencedirect.com/science/article/pii/S1386142519311059},
	doi = {10.1016/j.saa.2019.117715},
	abstract = {Stimulated emission depletion (STED) and reversible saturable optical fluorescence transition (RESOLFT) microscopy are the super-resolution imaging techniques that can acquire nanoscale spatial resolution. The spatial resolution of the other far-field optical microscopic techniques is bound by diffraction limit, however, STED/RESOLFT techniques eliminate the diffraction barrier. These microscopic techniques have taken the limits of optical image resolution down to the nanometer scale and opened new paths for biomedical and nanophosphor research. In this paper, we review the recent advancements of these techniques in the field of nanoscopy using continuous wave (CW) laser sources. Further, we discuss the main limitation of the STED microscopy in terms of essential requirements of higher depletion beam power and photobleaching issues. The RESOLFT microscopic technique can be considered as an alternate technique to overcome limitations of existing STED microscopy. Moreover, the Bessel and Gaussian-Bessel beam STED microscopic techniques are also reviewed to produce deep images with faster scanning of the samples. The organic molecules as well as the fluorescent doped nanoparticles like ZnSe:Mn having characteristics of excited state absorption can be investigated using RESOLFT microscopy.},
	language = {en},
	urldate = {2023-06-02},
	journal = {Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy},
	author = {Sharma, Reena and Singh, Manjot and Sharma, Rajesh},
	month = apr,
	year = {2020},
	keywords = {Bessel beam, Continuous wave lasers, Diffraction limit, Optical resolution, RESOLFT microscopy, STED microscopy},
	pages = {117715},
}

@article{heinrich_whole-cell_2021,
	title = {Whole-cell organelle segmentation in volume electron microscopy},
	volume = {599},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03977-3},
	doi = {10.1038/s41586-021-03977-3},
	abstract = {Cells contain hundreds of organelles and macromolecular assemblies. Obtaining a complete understanding of their intricate organization requires the nanometre-level, three-dimensional reconstruction of whole cells, which is only feasible with robust and scalable automatic methods. Here, to support the development of such methods, we annotated up to 35 different cellular organelle classes—ranging from endoplasmic reticulum to microtubules to ribosomes—in diverse sample volumes from multiple cell types imaged at a near-isotropic resolution of 4 nm per voxel with focused ion beam scanning electron microscopy (FIB-SEM)1. We trained deep learning architectures to segment these structures in 4 nm and 8 nm per voxel FIB-SEM volumes, validated their performance and showed that automatic reconstructions can be used to directly quantify previously inaccessible metrics including spatial interactions between cellular components. We also show that such reconstructions can be used to automatically register light and electron microscopy images for correlative studies. We have created an open data and open-source web repository, ‘OpenOrganelle’, to share the data, computer code and trained models, which will enable scientists everywhere to query and further improve automatic reconstruction of these datasets.},
	language = {en},
	number = {7883},
	urldate = {2023-06-02},
	journal = {Nature},
	author = {Heinrich, Larissa and Bennett, Davis and Ackerman, David and Park, Woohyun and Bogovic, John and Eckstein, Nils and Petruncio, Alyson and Clements, Jody and Pang, Song and Xu, C. Shan and Funke, Jan and Korff, Wyatt and Hess, Harald F. and Lippincott-Schwartz, Jennifer and Saalfeld, Stephan and Weigel, Aubrey V.},
	month = nov,
	year = {2021},
	keywords = {Cellular imaging, Data mining, Image processing, Machine learning, Organelles},
	pages = {141--146},
}

@inproceedings{antoran_adapting_2022,
	title = {Adapting the {Linearised} {Laplace} {Model} {Evidence} for {Modern} {Deep} {Learning}},
	url = {https://proceedings.mlr.press/v162/antoran22a.html},
	abstract = {The linearised Laplace method for estimating model uncertainty has received renewed attention in the Bayesian deep learning community. The method provides reliable error bars and admits a closed-form expression for the model evidence, allowing for scalable selection of model hyperparameters. In this work, we examine the assumptions behind this method, particularly in conjunction with model selection. We show that these interact poorly with some now-standard tools of deep learning–stochastic approximation methods and normalisation layers–and make recommendations for how to better adapt this classic method to the modern setting. We provide theoretical support for our recommendations and validate them empirically on MLPs, classic CNNs, residual networks with and without normalisation layers, generative autoencoders and transformers.},
	language = {en},
	urldate = {2023-05-23},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Antoran, Javier and Janz, David and Allingham, James U. and Daxberger, Erik and Barbano, Riccardo Rb and Nalisnick, Eric and Hernandez-Lobato, Jose Miguel},
	month = jun,
	year = {2022},
	pages = {796--821},
}

@article{marsaglia_evaluating_2003,
	title = {Evaluating {Kolmogorov}'s {Distribution}},
	volume = {8},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v08/i18/},
	doi = {10.18637/jss.v008.i18},
	language = {en},
	number = {18},
	urldate = {2023-05-23},
	journal = {Journal of Statistical Software},
	author = {Marsaglia, George and Tsang, Wai Wan and Wang, Jingbo},
	year = {2003},
}

@incollection{getis_second-order_2010,
	address = {Berlin, Heidelberg},
	series = {Advances in {Spatial} {Science}},
	title = {Second-{Order} {Neighborhood} {Analysis} of {Mapped} {Point} {Patterns}},
	isbn = {9783642019760},
	url = {https://doi.org/10.1007/978-3-642-01976-0_7},
	abstract = {A technique based on second-order methods, called second-order neighborhood analysis, is used to quantify clustering at various spatial scales. The theoretical model represents the degree of clustering in a Poisson process from the perspective of each individual point. The method is applied to point location data for a sample of ponderosa pine (Pinus ponderosa) trees, and shows that heterogeneity within the forest is clearly a function of the scale of analysis.},
	language = {en},
	urldate = {2023-05-23},
	booktitle = {Perspectives on {Spatial} {Data} {Analysis}},
	publisher = {Springer},
	author = {Getis, Arthur and Franklin, Janet},
	editor = {Anselin, Luc and Rey, Sergio J.},
	year = {2010},
	doi = {10.1007/978-3-642-01976-0_7},
	keywords = {Correct Border, Klamath National Forest, Mapped Point Patterns, Optimum Quadrat Size, Second-order Neighborhood Analysis},
	pages = {93--100},
}

@article{thompson_precise_2002,
	title = {Precise {Nanometer} {Localization} {Analysis} for {Individual} {Fluorescent} {Probes}},
	volume = {82},
	issn = {0006-3495},
	url = {https://www.cell.com/biophysj/abstract/S0006-3495(02)75618-X},
	doi = {10.1016/S0006-3495(02)75618-X},
	language = {English},
	number = {5},
	urldate = {2023-05-23},
	journal = {Biophysical Journal},
	author = {Thompson, Russell E. and Larson, Daniel R. and Webb, Watt W.},
	month = may,
	year = {2002},
	pmid = {11964263},
	pages = {2775--2783},
}

@techreport{fujiwara_development_2021,
	type = {preprint},
	title = {Development of ultrafast camera-based imaging of single fluorescent molecules and live-cell {PALM}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2021.10.26.465864},
	abstract = {Abstract 
          The spatial resolution of fluorescence microscopy has recently been greatly improved. However, its temporal resolution has not been improved much, despite its importance for examining living cells. Here, by developing an ultrafast camera system, we achieved the world’s highest time resolutions for single fluorescent-molecule imaging of 33 (100) µs (multiple single molecules simultaneously) with a single-molecule localization precision of 34 (20) nm for Cy3 (best dye found), and for PALM data acquisition of a view-field of 640×640 pixels at 1 kHz with a single-molecule localization precision of 29 nm for mEos3.2. Both are considered the ultimate rates with available probes. This camera system (1) successfully detected fast hop diffusion of membrane molecules in the plasma membrane, detectable previously only by using less preferable 40-nm gold probes and bright-field microscopy, and (2) enabled PALM imaging of the entire live cell, while revealing meso-scale dynamics and structures, caveolae and paxillin islands in the focal adhesion, proving its usefulness for cell biology research. 
           
            Summary 
            An ultrafast camera developed by Fujiwara et al. allows single fluorescent-molecule imaging every 33 μs with a localization precision of 34 nm (every 100 μs; 20 nm), and enables ultrafast PALM imaging of whole live cells.},
	language = {en},
	urldate = {2023-05-23},
	institution = {Cell Biology},
	author = {Fujiwara, Takahiro K. and Takeuchi, Shinji and Kalay, Ziya and Nagai, Yosuke and Tsunoyama, Taka A. and Kalkbrenner, Thomas and Iwasawa, Kokoro and Ritchie, Ken P. and Suzuki, Kenichi G.N. and Kusumi, Akihiro},
	month = oct,
	year = {2021},
	doi = {10.1101/2021.10.26.465864},
}

@mastersthesis{igbasanmi_cnn_2023,
	address = {United States -- Texas},
	title = {{CNN} {Based} {Object} {Classification} {Using} {Image} and {Poisson} {Vector} {Field} {Features}},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	url = {https://www.proquest.com/docview/2813631821/abstract/544EA80BEBA141BEPQ/1},
	abstract = {Convolutional Neural Networks (CNNs) have great applications in image and video object recognition, classification and segmentation. In the literature on CNN models, their efficiency and efficacy are determined by their classification metrics, speed and computational cost. This thesis aims to improve the classification metrics accuracy of a CNN model by fusing vector fields’ features with image features. The vector field features of importance are the singular points and separatrices. These features are embedded in the training and testing images to increase the latter set’s classification metrics. This study applies particular vector fields developed on the solution of a specific form of the Poisson equations. These vector fields have both real and complex singularities. Then the vector fields are embedded into an image database to create a fusion of the vector fields’ features and the image databases’ features. The main novelty of the thesis is the development of a new CNN optimized to efficiently classify image databases with embedded vector field features. The goal is to validate that the embedding in question brings the advantage of increasing the classification statistics. The conducted experiments with the public skin lesions database ISIC 2020 successfully confirmed the claim.},
	language = {English},
	urldate = {2023-05-23},
	school = {Texas A\&M University - Commerce},
	author = {Igbasanmi, Oluwaseyi},
	year = {2023},
	keywords = {Convolutional Neural Networks, Poisson vector field, Public skin lesions database, Video object recognition},
}

@article{bintu_super-resolution_2018,
	title = {Super-resolution chromatin tracing reveals domains and cooperative interactions in single cells},
	volume = {362},
	issn = {1095-9203},
	doi = {10.1126/science.aau1783},
	abstract = {The spatial organization of chromatin is pivotal for regulating genome functions. We report an imaging method for tracing chromatin organization with kilobase- and nanometer-scale resolution, unveiling chromatin conformation across topologically associating domains (TADs) in thousands of individual cells. Our imaging data revealed TAD-like structures with globular conformation and sharp domain boundaries in single cells. The boundaries varied from cell to cell, occurring with nonzero probabilities at all genomic positions but preferentially at CCCTC-binding factor (CTCF)- and cohesin-binding sites. Notably, cohesin depletion, which abolished TADs at the population-average level, did not diminish TAD-like structures in single cells but eliminated preferential domain boundary positions. Moreover, we observed widespread, cooperative, multiway chromatin interactions, which remained after cohesin depletion. These results provide critical insight into the mechanisms underlying chromatin domain and hub formation.},
	language = {eng},
	number = {6413},
	journal = {Science (New York, N.Y.)},
	author = {Bintu, Bogdan and Mateo, Leslie J. and Su, Jun-Han and Sinnott-Armstrong, Nicholas A. and Parker, Mirae and Kinrot, Seon and Yamaya, Kei and Boettiger, Alistair N. and Zhuang, Xiaowei},
	month = oct,
	year = {2018},
	pmid = {30361340},
	pmcid = {PMC6535145},
	keywords = {CCCTC-Binding Factor, Cell Cycle Proteins, Chromatin, Chromosomal Proteins, Non-Histone, Genome, Human, HCT116 Cells, Humans, In Situ Hybridization, Fluorescence, Protein Binding, Protein Domains, Single-Cell Analysis},
	pages = {eaau1783},
}

@article{lu_is_2022,
	title = {Is image-to-image translation the panacea for multimodal image registration? {A} comparative study},
	volume = {17},
	issn = {1932-6203},
	shorttitle = {Is image-to-image translation the panacea for multimodal image registration?},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0276196},
	doi = {10.1371/journal.pone.0276196},
	abstract = {Despite current advancement in the field of biomedical image processing, propelled by the deep learning revolution, multimodal image registration, due to its several challenges, is still often performed manually by specialists. The recent success of image-to-image (I2I) translation in computer vision applications and its growing use in biomedical areas provide a tempting possibility of transforming the multimodal registration problem into a, potentially easier, monomodal one. We conduct an empirical study of the applicability of modern I2I translation methods for the task of rigid registration of multimodal biomedical and medical 2D and 3D images. We compare the performance of four Generative Adversarial Network (GAN)-based I2I translation methods and one contrastive representation learning method, subsequently combined with two representative monomodal registration methods, to judge the effectiveness of modality translation for multimodal image registration. We evaluate these method combinations on four publicly available multimodal (2D and 3D) datasets and compare with the performance of registration achieved by several well-known approaches acting directly on multimodal image data. Our results suggest that, although I2I translation may be helpful when the modalities to register are clearly correlated, registration of modalities which express distinctly different properties of the sample are not well handled by the I2I translation approach. The evaluated representation learning method, which aims to find abstract image-like representations of the information shared between the modalities, manages better, and so does the Mutual Information maximisation approach, acting directly on the original multimodal images. We share our complete experimental setup as open-source (https://github.com/MIDA-group/MultiRegEval), including method implementations, evaluation code, and all datasets, for further reproducing and benchmarking.},
	language = {en},
	number = {11},
	urldate = {2023-05-22},
	journal = {PLOS ONE},
	author = {Lu, Jiahao and Öfverstedt, Johan and Lindblad, Joakim and Sladoje, Nataša},
	month = nov,
	year = {2022},
	keywords = {Bright field imaging, Fluorescence imaging, Histology, Imaging techniques, Magnetic resonance imaging, Optimization, Radiology and imaging, Similarity measures},
	pages = {e0276196},
}

@inproceedings{wu_multi-modality_2021,
	title = {Multi-modality {Large} {Deformation} {Diffeomorphic} {Metric} {Mapping} {Driven} by {Single}-modality {Images}},
	doi = {10.1109/EMBC46164.2021.9630617},
	abstract = {Multi-modality magnetic resonance image (MRI) registration is an essential step in various MRI analysis tasks. However, it is challenging to have all required modalities in clinical practice, and thus the application of multi-modality registration is limited. This paper tackles such problem by proposing a novel unsupervised deep learning based multi-modality large deformation diffeomorphic metric mapping (LDDMM) framework which is capable of performing multi-modality registration only using single-modality MRIs. Specifically, an unsupervised image-to-image translation model is trained and used to synthesize the missing modality MRIs from the available ones. Multi-modality LDDMM is then performed in a multi-channel manner. Experimental results obtained on one publicly- accessible datasets confirm the superior performance of the proposed approach.Clinical relevance—This work provides a tool for multi-modality MRI registration with solely single-modality images, which addresses the very common issue of missing modalities in clinical practice},
	booktitle = {2021 43rd {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} \& {Biology} {Society} ({EMBC})},
	author = {Wu, Jiong and Zhou, Shuang and Yang, Qi and Zhang, Yue and Tang, Xiaoying},
	month = nov,
	year = {2021},
	note = {ISSN: 2694-0604},
	keywords = {Biology, Deep learning, Magnetic resonance, Magnetic resonance imaging, Measurement, Task analysis, Tools},
	pages = {2610--2613},
}

@inproceedings{bogovic_robust_2016,
	title = {Robust registration of calcium images by learned contrast synthesis},
	doi = {10.1109/ISBI.2016.7493463},
	abstract = {Multi-modal image registration is a challenging task that is vital to fuse complementary signals for subsequent analyses. Despite much research into cost functions addressing this challenge, there exist cases in which these are ineffective. In this work, we show that (1) this is true for the registration of in-vivo Drosophila brain volumes visualizing genetically encoded calcium indicators to an nc82 atlas and (2) that machine learning based contrast synthesis can yield improvements. More specifically, the number of subjects for which the registration outright failed was greatly reduced (from 40\% to 15\%) by using a synthesized image.},
	booktitle = {2016 {IEEE} 13th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Bogovic, John A. and Hanslovsky, Philipp and Wong, Allan and Saalfeld, Stephan},
	month = apr,
	year = {2016},
	note = {ISSN: 1945-8452},
	keywords = {Calcium, Cost function, Image Registration, Image registration, Imaging, Machine Learning, Neurons, Radio frequency, Training},
	pages = {1123--1126},
}

@article{damstra_visualizing_2022,
	title = {Visualizing cellular and tissue ultrastructure using {Ten}-fold {Robust} {Expansion} {Microscopy} ({TREx})},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.73775},
	doi = {10.7554/eLife.73775},
	abstract = {Expansion microscopy (ExM) is a powerful technique to overcome the diffraction limit of light microscopy that can be applied in both tissues and cells. In ExM, samples are embedded in a swellable polymer gel to physically expand the sample and isotropically increase resolution in x, y, and z. The maximum resolution increase is limited by the expansion factor of the gel, which is four-fold for the original ExM protocol. Variations on the original ExM method have been reported that allow for greater expansion factors but at the cost of ease of adoption or versatility. Here, we systematically explore the ExM recipe space and present a novel method termed Ten-fold Robust Expansion Microscopy (TREx) that, like the original ExM method, requires no specialized equipment or procedures. We demonstrate that TREx gels expand 10-fold, can be handled easily, and can be applied to both thick mouse brain tissue sections and cultured human cells enabling high-resolution subcellular imaging with a single expansion step. Furthermore, we show that TREx can provide ultrastructural context to subcellular protein localization by combining antibody-stained samples with off-the-shelf small-molecule stains for both total protein and membranes.},
	urldate = {2023-05-22},
	journal = {eLife},
	author = {Damstra, Hugo GJ and Mohar, Boaz and Eddison, Mark and Akhmanova, Anna and Kapitein, Lukas C and Tillberg, Paul W},
	editor = {Lakadamyali, Melike and Pfeffer, Suzanne R and Shi, Xiaoyu},
	month = feb,
	year = {2022},
	keywords = {expansion microscopy, immunofluorescence, light microscopy, sub-organelle imaging, super-resolution},
	pages = {e73775},
}

@article{chen_expansion_2015,
	title = {Expansion microscopy},
	volume = {347},
	url = {https://www.science.org/doi/10.1126/science.1260088},
	doi = {10.1126/science.1260088},
	abstract = {In optical microscopy, fine structural details are resolved by using refraction to magnify images of a specimen. We discovered that by synthesizing a swellable polymer network within a specimen, it can be physically expanded, resulting in physical magnification. By covalently anchoring specific labels located within the specimen directly to the polymer network, labels spaced closer than the optical diffraction limit can be isotropically separated and optically resolved, a process we call expansion microscopy (ExM). Thus, this process can be used to perform scalable superresolution microscopy with diffraction-limited microscopes. We demonstrate ExM with apparent {\textasciitilde}70-nanometer lateral resolution in both cultured cells and brain tissue, performing three-color superresolution imaging of {\textasciitilde}107 cubic micrometers of the mouse hippocampus with a conventional confocal microscope.},
	number = {6221},
	urldate = {2023-05-22},
	journal = {Science},
	author = {Chen, Fei and Tillberg, Paul W. and Boyden, Edward S.},
	month = jan,
	year = {2015},
	pages = {543--548},
}

@article{kunz_using_2020,
	title = {Using {Expansion} {Microscopy} to {Visualize} and {Characterize} the {Morphology} of {Mitochondrial} {Cristae}},
	volume = {8},
	issn = {2296-634X},
	url = {https://www.frontiersin.org/articles/10.3389/fcell.2020.00617},
	abstract = {Mitochondria are double membrane bound organelles indispensable for biological processes such as apoptosis, cell signaling, and the production of many important metabolites, which includes ATP that is generated during the process known as oxidative phosphorylation (OXPHOS). The inner membrane contains folds called cristae, which increase the membrane surface and thus the amount of membrane-bound proteins necessary for the OXPHOS. These folds have been of great interest not only because of their importance for energy conversion, but also because changes in morphology have been linked to a broad range of diseases from cancer, diabetes, neurodegenerative diseases, to aging and infection. With a distance between opposing cristae membranes often below 100 nm, conventional fluorescence imaging cannot provide a resolution sufficient for resolving these structures. For this reason, various highly specialized super-resolution methods including dSTORM, PALM, STED, and SIM have been applied for cristae visualization. Expansion Microscopy (ExM) offers the possibility to perform super-resolution microscopy on conventional confocal microscopes by embedding the sample into a swellable hydrogel that is isotropically expanded by a factor of 4–4.5, improving the resolution to 60–70 nm on conventional confocal microscopes, which can be further increased to ∼ 30 nm laterally using SIM. Here, we demonstrate that the expression of the mitochondrial creatine kinase MtCK linked to marker protein GFP (MtCK-GFP), which localizes to the space between the outer and the inner mitochondrial membrane, can be used as a cristae marker. Applying ExM on mitochondria labeled with this construct enables visualization of morphological changes of cristae and localization studies of mitochondrial proteins relative to cristae without the need for specialized setups. For the first time we present the combination of specific mitochondrial intermembrane space labeling and ExM as a tool for studying internal structure of mitochondria.},
	urldate = {2023-05-22},
	journal = {Frontiers in Cell and Developmental Biology},
	author = {Kunz, Tobias C. and Götz, Ralph and Gao, Shiqiang and Sauer, Markus and Kozjak-Pavlovic, Vera},
	year = {2020},
}

@article{bird_understanding_2021,
	title = {Understanding the {Replication} {Crisis} as a {Base} {Rate} {Fallacy}},
	volume = {72},
	issn = {0007-0882},
	url = {https://www.journals.uchicago.edu/doi/abs/10.1093/bjps/axy051},
	doi = {10.1093/bjps/axy051},
	abstract = {The replication (replicability, reproducibility) crisis in social psychology and clinical medicine arises from the fact that many apparently well-confirmed experimental results are subsequently overturned by studies that aim to replicate the original study. The culprit is widely held to be poor science: questionable research practices, failure to publish negative results, bad incentives, and even fraud. In this article I argue that the high rate of failed replications is consistent with high-quality science. We would expect this outcome if the field of science in question produces a high proportion of false hypotheses prior to testing. If most of the hypotheses under test are false, then there will be many false hypotheses that are apparently supported by the outcomes of well conducted experiments and null hypothesis significance tests with a type-I error rate (α) of 5\%. Failure to recognize this is to commit the fallacy of ignoring the base rate. I argue that this is a plausible diagnosis of the replication crisis and examine what lessons we thereby learn for the future conduct of science.},
	number = {4},
	urldate = {2023-05-18},
	journal = {The British Journal for the Philosophy of Science},
	author = {Bird, Alexander},
	month = dec,
	year = {2021},
	pages = {965--993},
}

@article{mullard_half_2021,
	title = {Half of top cancer studies fail high-profile reproducibility effort},
	volume = {600},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-021-03691-0},
	doi = {10.1038/d41586-021-03691-0},
	abstract = {Barriers to reproducing preclinical results included unhelpful author communication, but critics argue that one-time replication attempts don’t tell the whole story.},
	language = {en},
	number = {7889},
	urldate = {2023-05-18},
	journal = {Nature},
	author = {Mullard, Asher},
	month = dec,
	year = {2021},
	keywords = {Cancer, Drug discovery},
	pages = {368--369},
}

@article{autzen_is_2021,
	title = {Is the replication crisis a base-rate fallacy?},
	volume = {42},
	issn = {1573-0980},
	doi = {10.1007/s11017-022-09561-8},
	abstract = {Is science in the midst of a crisis of replicability and false discoveries? In a recent article, Alexander Bird offers an explanation for the apparent lack of replicability in the biomedical sciences. Bird argues that the surprise at the failure to replicate biomedical research is a result of the fallacy of neglecting the base rate. The base-rate fallacy arises in situations in which one ignores the base rate-or prior probability-of an event when assessing the probability of this event in the light of some observed evidence. By extension, the replication crisis would result from ignoring the low prior probability of biomedical hypotheses. In this paper, my response to Bird's claim is twofold. First, I show that the argument according to which the replication crisis is due to the low prior of biomedical hypotheses is incomplete. Second, I claim that a simple base-rate fallacy model does not account for some important methodological insights that have emerged in discussions of the replication crisis.},
	language = {eng},
	number = {5-6},
	journal = {Theoretical Medicine and Bioethics},
	author = {Autzen, Bengt},
	month = dec,
	year = {2021},
	pmid = {35220515},
	pmcid = {PMC8907098},
	keywords = {Base-rate fallacy, Bayesianism, Philosophy of medicine, Philosophy of science, Replication crisis},
	pages = {233--243},
}

@article{mazidi_quantifying_2020,
	title = {Quantifying accuracy and heterogeneity in single-molecule super-resolution microscopy},
	volume = {11},
	issn = {2041-1723},
	doi = {10.1038/s41467-020-20056-9},
	abstract = {The resolution and accuracy of single-molecule localization microscopes (SMLMs) are routinely benchmarked using simulated data, calibration rulers, or comparisons to secondary imaging modalities. However, these methods cannot quantify the nanoscale accuracy of an arbitrary SMLM dataset. Here, we show that by computing localization stability under a well-chosen perturbation with accurate knowledge of the imaging system, we can robustly measure the confidence of individual localizations without ground-truth knowledge of the sample. We demonstrate that our method, termed Wasserstein-induced flux (WIF), measures the accuracy of various reconstruction algorithms directly on experimental 2D and 3D data of microtubules and amyloid fibrils. We further show that WIF confidences can be used to evaluate the mismatch between computational models and imaging data, enhance the accuracy and resolution of reconstructed structures, and discover hidden molecular heterogeneities. As a computational methodology, WIF is broadly applicable to any SMLM dataset, imaging system, and localization algorithm.},
	language = {eng},
	number = {1},
	journal = {Nature Communications},
	author = {Mazidi, Hesam and Ding, Tianben and Nehorai, Arye and Lew, Matthew D.},
	month = dec,
	year = {2020},
	pmid = {33311471},
	pmcid = {PMC7732856},
	keywords = {Algorithms, Amyloid, Calibration, Computer Simulation, Image Processing, Computer-Assisted, Microtubules, Single Molecule Imaging, Software},
	pages = {6353},
}

@article{mazidi_minimizing_2018,
	title = {Minimizing {Structural} {Bias} in {Single}-{Molecule} {Super}-{Resolution} {Microscopy}},
	volume = {8},
	issn = {2045-2322},
	doi = {10.1038/s41598-018-31366-w},
	abstract = {Single-molecule localization microscopy (SMLM) depends on sequential detection and localization of individual molecular blinking events. Due to the stochasticity of single-molecule blinking and the desire to improve SMLM's temporal resolution, algorithms capable of analyzing frames with a high density (HD) of active molecules, or molecules whose images overlap, are a prerequisite for accurate location measurements. Thus far, HD algorithms are evaluated using scalar metrics, such as root-mean-square error, that fail to quantify the structure of errors caused by the structure of the sample. Here, we show that the spatial distribution of localization errors within super-resolved images of biological structures are vectorial in nature, leading to systematic structural biases that severely degrade image resolution. We further demonstrate that the shape of the microscope's point-spread function (PSF) fundamentally affects the characteristics of imaging artifacts. We built a Robust Statistical Estimation algorithm (RoSE) to minimize these biases for arbitrary structures and PSFs. RoSE accomplishes this minimization by estimating the likelihood of blinking events to localize molecules more accurately and eliminate false localizations. Using RoSE, we measure the distance between crossing microtubules, quantify the morphology of and separation between vesicles, and obtain robust recovery using diverse 3D PSFs with unmatched accuracy compared to state-of-the-art algorithms.},
	language = {eng},
	number = {1},
	journal = {Scientific Reports},
	author = {Mazidi, Hesam and Lu, Jin and Nehorai, Arye and Lew, Matthew D.},
	month = sep,
	year = {2018},
	pmid = {30177692},
	pmcid = {PMC6120949},
	keywords = {Algorithms, Eukaryotic Cells, Humans, Image Processing, Computer-Assisted, Likelihood Functions, Microtubules, Single Molecule Imaging, Stochastic Processes},
	pages = {13133},
}

@article{descloux_parameter-free_2019,
	title = {Parameter-free image resolution estimation based on decorrelation analysis},
	volume = {16},
	issn = {1548-7105},
	doi = {10.1038/s41592-019-0515-7},
	abstract = {Super-resolution microscopy opened diverse new avenues of research by overcoming the resolution limit imposed by diffraction. Exploitation of the fluorescent emission of individual fluorophores made it possible to reveal structures beyond the diffraction limit. To accurately determine the resolution achieved during imaging is challenging with existing metrics. Here, we propose a method for assessing the resolution of individual super-resolved images based on image partial phase autocorrelation. The algorithm is model-free and does not require any user-defined parameters. We demonstrate its performance on a wide variety of imaging modalities, including diffraction-limited techniques. Finally, we show how our method can be used to optimize image acquisition and post-processing in super-resolution microscopy.},
	language = {eng},
	number = {9},
	journal = {Nature Methods},
	author = {Descloux, A. and Grußmayer, K. S. and Radenovic, A.},
	month = sep,
	year = {2019},
	pmid = {31451766},
	keywords = {Algorithms, Animals, COS Cells, Cells, Chlorocebus aethiops, Computer Simulation, Fluorescent Dyes, HeLa Cells, Humans, Image Processing, Computer-Assisted, Microscopy, Confocal, Microscopy, Fluorescence},
	pages = {918--924},
}

@article{descloux_parameter-free_2021,
	title = {Parameter-free rendering of single-molecule localization microscopy data for parameter-free resolution estimation},
	volume = {4},
	issn = {2399-3642},
	doi = {10.1038/s42003-021-02086-1},
	abstract = {Localization microscopy is a super-resolution imaging technique that relies on the spatial and temporal separation of blinking fluorescent emitters. These blinking events can be individually localized with a precision significantly smaller than the classical diffraction limit. This sub-diffraction localization precision is theoretically bounded by the number of photons emitted per molecule and by the sensor noise. These parameters can be estimated from the raw images. Alternatively, the resolution can be estimated from a rendered image of the localizations. Here, we show how the rendering of localization datasets can influence the resolution estimation based on decorrelation analysis. We demonstrate that a modified histogram rendering, termed bilinear histogram, circumvents the biases introduced by Gaussian or standard histogram rendering. We propose a parameter-free processing pipeline and show that the resolution estimation becomes a function of the localization density and the localization precision, on both simulated and state-of-the-art experimental datasets.},
	language = {eng},
	number = {1},
	journal = {Communications Biology},
	author = {Descloux, Adrien C. and Grußmayer, Kristin S. and Radenovic, Aleksandra},
	month = may,
	year = {2021},
	pmid = {33976358},
	pmcid = {PMC8113488},
	keywords = {Algorithms, Fluorescent Dyes, Image Processing, Computer-Assisted, Microscopy, Fluorescence, Optical Imaging, Single Molecule Imaging},
	pages = {550},
}

@article{krueger_facetto_2020,
	title = {Facetto: {Combining} {Unsupervised} and {Supervised} {Learning} for {Hierarchical} {Phenotype} {Analysis} in {Multi}-{Channel} {Image} {Data}},
	volume = {26},
	issn = {1941-0506},
	shorttitle = {Facetto},
	doi = {10.1109/TVCG.2019.2934547},
	abstract = {Facetto is a scalable visual analytics application that is used to discover single-cell phenotypes in high-dimensional multi-channel microscopy images of human tumors and tissues. Such images represent the cutting edge of digital histology and promise to revolutionize how diseases such as cancer are studied, diagnosed, and treated. Highly multiplexed tissue images are complex, comprising 109 or more pixels, 60-plus channels, and millions of individual cells. This makes manual analysis challenging and error-prone. Existing automated approaches are also inadequate, in large part, because they are unable to effectively exploit the deep knowledge of human tissue biology available to anatomic pathologists. To overcome these challenges, Facetto enables a semi-automated analysis of cell types and states. It integrates unsupervised and supervised learning into the image and feature exploration process and offers tools for analytical provenance. Experts can cluster the data to discover new types of cancer and immune cells and use clustering results to train a convolutional neural network that classifies new cells accordingly. Likewise, the output of classifiers can be clustered to discover aggregate patterns and phenotype subsets. We also introduce a new hierarchical approach to keep track of analysis steps and data subsets created by users; this assists in the identification of cell types. Users can build phenotype trees and interact with the resulting hierarchical structures of both high-dimensional feature and image spaces. We report on use-cases in which domain scientists explore various large-scale fluorescence imaging datasets. We demonstrate how Facetto assists users in steering the clustering and classification process, inspecting analysis results, and gaining new scientific insights into cancer biology.},
	language = {eng},
	number = {1},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Krueger, Robert and Beyer, Johanna and Jang, Won-Dong and Kim, Nam Wook and Sokolov, Artem and Sorger, Peter K. and Pfister, Hanspeter},
	month = jan,
	year = {2020},
	pmid = {31514138},
	pmcid = {PMC7045445},
	keywords = {Cluster Analysis, Humans, Image Interpretation, Computer-Assisted, Machine Learning, Neoplasms, Neural Networks, Computer, Phenotype, Software, Systems Biology},
	pages = {227--237},
}

@misc{noauthor_machine_nodate,
	title = {Machine learning for cluster analysis of localization microscopy data - {PubMed}},
	url = {https://pubmed.ncbi.nlm.nih.gov/32198352/},
	urldate = {2023-05-16},
}

@misc{noauthor_chromatin_nodate,
	title = {Chromatin modification and {NBS1}: their relationship in {DNA} double-strand break repair - {PubMed}},
	url = {https://pubmed.ncbi.nlm.nih.gov/26616756/},
	urldate = {2023-05-16},
}

@article{kovacs_application_2022,
	title = {Application of {Lacunarity} for {Quantification} of {Single} {Molecule} {Localization} {Microscopy} {Images}},
	volume = {11},
	issn = {2073-4409},
	doi = {10.3390/cells11193105},
	abstract = {The quantitative analysis of datasets achieved by single molecule localization microscopy is vital for studying the structure of subcellular organizations. Cluster analysis has emerged as a multi-faceted tool in the structural analysis of localization datasets. However, the results it produces greatly depend on the set parameters, and the process can be computationally intensive. Here we present a new approach for structural analysis using lacunarity. Unlike cluster analysis, lacunarity can be calculated quickly while providing definitive information about the structure of the localizations. Using simulated data, we demonstrate how lacunarity results can be interpreted. We use these interpretations to compare our lacunarity analysis with our previous cluster analysis-based results in the field of DNA repair, showing the new algorithm's efficiency.},
	language = {eng},
	number = {19},
	journal = {Cells},
	author = {Kovács, Bálint Barna H. and Varga, Dániel and Sebők, Dániel and Majoros, Hajnalka and Polanek, Róbert and Pankotai, Tibor and Hideghéty, Katalin and Kukovecz, Ákos and Erdélyi, Miklós},
	month = oct,
	year = {2022},
	pmid = {36231067},
	pmcid = {PMC9562870},
	keywords = {Cluster Analysis, DNA Repair, Microscopy, Single Molecule Imaging, dSTORM, lacunarity, quantitative analysis},
	pages = {3105},
}

@article{varga_quantification_2019,
	title = {Quantification of {DNA} damage induced repair focus formation via super-resolution {dSTORM} localization microscopy},
	volume = {11},
	issn = {2040-3372},
	doi = {10.1039/c9nr03696b},
	abstract = {In eukaryotic cells, each process, in which DNA is involved, should take place in the context of a chromatin structure. DNA double-strand breaks (DSBs) are one of the most deleterious lesions often leading to chromosomal rearrangement. In response to environmental stresses, cells have developed repair mechanisms to eliminate the DSBs. Upon DSB induction, several factors play roles in chromatin relaxation by catalysing the appropriate histone posttranslational modification (PTM) steps, therefore promoting the access of the repair factors to the DSBs. Among these PTMs, the phosphorylation of the histone variant H2AX at its Ser139 residue (also known as γH2AX) could be observed at the break sites. The structure of a DNA double-strand break induced repair focus has to be organized during the repair as it contributes to the accessibility of specific repair proteins to the damaged site. Our aim was to develop a quantitative approach to analyse the morphology of single repair foci by super-resolution dSTORM microscopy to gain insight into chromatin organization in DNA repair. We have established a specific dSTORM measurement process by developing a new analytical algorithm for gaining quantitative information about chromatin morphology and repair foci topology at an individual γH2AX enriched repair focus. Using this method we quantified single repair foci to show the distribution of γH2AX. The image of individual γH2AX referred to as the Single target Molecule response scatter Plot (SMPlot) was obtained by using high lateral resolution dSTORM images. Determination of the average localization numbers in an SMPlot was one of the key steps of quantitative dSTORM. A repair focus is made up of nanofoci. Such a substructure of repair foci can only be resolved and detected with super-resolution microscopy. Determination of the number of γH2AXs in the nanofoci was another key step of quantitative dSTORM. Additionally, based on our new analysis method, we were able to show the number of nucleosomes in each nanofocus that could allow us to define the possible chromatin structure and the nucleosome density around the break sites. This method is one of the first demonstrations of a single-cell based quantitative measurement of a discrete repair focus, which could provide new opportunities to categorize the spatial organization of nanofoci by parametric determination of topological similarity.},
	language = {eng},
	number = {30},
	journal = {Nanoscale},
	author = {Varga, Dániel and Majoros, Hajnalka and Ujfaludi, Zsuzsanna and Erdélyi, Miklós and Pankotai, Tibor},
	month = aug,
	year = {2019},
	pmid = {31317161},
	keywords = {Algorithms, Cell Line, Tumor, Cell Nucleus, Chromatin, DNA Breaks, Double-Stranded, DNA Repair, Histones, Humans, Microscopy, Tamoxifen},
	pages = {14226--14236},
}

@article{nieves_analysis_2020,
	title = {Analysis methods for interrogating spatial organisation of single molecule localisation microscopy data},
	volume = {123},
	issn = {1878-5875},
	doi = {10.1016/j.biocel.2020.105749},
	abstract = {Single-molecule localisation microscopy (SMLM) gives access to biological information below the diffraction limit, allowing nanoscale cellular structures to be probed. The data output is unlike that of conventional microscopy images, instead consisting of an array of molecular coordinates. These represent a spatial point pattern that attempts to approximate, as closely as possible, the underlying positions of the molecules of interest. Here, we review the analysis methods that can be used to extract biological insight from SMLM data, in particular for the application of quantifying nanoscale molecular clustering. We review how some of the common artefacts inherent in SMLM can corrupt the acquired data, and therefore, how the output of SMLM cluster analysis should be interpreted.},
	language = {eng},
	journal = {The International Journal of Biochemistry \& Cell Biology},
	author = {Nieves, Daniel J. and Owen, Dylan M.},
	month = jun,
	year = {2020},
	pmid = {32325279},
	keywords = {Algorithms, Cluster Analysis, Image Processing, Computer-Assisted, Molecular Imaging, PAINT, PALM, SMLM, Single Molecule Imaging, Single-Domain Antibodies, cluster analysis, dSTORM},
	pages = {105749},
}

@article{rajendran_single-molecule_2012,
	title = {Single-molecule analysis using {DNA} origami},
	volume = {51},
	issn = {1521-3773},
	doi = {10.1002/anie.201102113},
	abstract = {During the last two decades, scientists have developed various methods that allow the detection and manipulation of single molecules, which have also been called "in singulo" approaches. Fundamental understanding of biochemical reactions, folding of biomolecules, and the screening of drugs were achieved by using these methods. Single-molecule analysis was also performed in the field of DNA nanotechnology, mainly by using atomic force microscopy. However, until recently, the approaches used commonly in nanotechnology adopted structures with a dimension of 10-20 nm, which is not suitable for many applications. The recent development of scaffolded DNA origami by Rothemund made it possible for the construction of larger defined assemblies. One of the most salient features of the origami method is the precise addressability of the structures formed: Each staple can serve as an attachment point for different kinds of nanoobjects. Thus, the method is suitable for the precise positioning of various functionalities and for the single-molecule analysis of many chemical and biochemical processes. Here we summarize recent progress in the area of single-molecule analysis using DNA origami and discuss the future directions of this research.},
	language = {eng},
	number = {4},
	journal = {Angewandte Chemie (International Ed. in English)},
	author = {Rajendran, Arivazhagan and Endo, Masayuki and Sugiyama, Hiroshi},
	month = jan,
	year = {2012},
	pmid = {22121063},
	keywords = {Aptamers, Nucleotide, Click Chemistry, DNA, DNA Topoisomerases, Type I, G-Quadruplexes, Humans, Lab-On-A-Chip Devices, Nanotechnology, Polymorphism, Single Nucleotide, Protein Binding, Proteins},
	pages = {874--890},
}

@article{nangreave_dna_2010,
	title = {{DNA} origami: a history and current perspective},
	volume = {14},
	issn = {1879-0402},
	shorttitle = {{DNA} origami},
	doi = {10.1016/j.cbpa.2010.06.182},
	abstract = {Researchers have been using DNA for the rational design and construction of nanoscale objects for nearly 30 years. Recently, 'scaffolded DNA origami' has emerged as one of the most promising assembly techniques in DNA nanotechnology with a broad range of applications. In the past two years alone, DNA origami has been used to assemble water-soluble probe tiles for label-free RNA hybridization, to study single-molecule chemical reactions, to probe distance-dependent multivalent ligand-protein binding effects, and to organize a variety of relevant molecules including proteins, carbon nanotubes, and metal nanoparticles. This review will recount the origin, evolution, and current status of this extremely versatile assembly technique.},
	language = {eng},
	number = {5},
	journal = {Current Opinion in Chemical Biology},
	author = {Nangreave, Jeanette and Han, Dongran and Liu, Yan and Yan, Hao},
	month = oct,
	year = {2010},
	pmid = {20643573},
	keywords = {DNA, Nanotechnology, Nucleic Acid Conformation},
	pages = {608--615},
}

@article{bond_technological_2022,
	title = {Technological advances in super-resolution microscopy to study cellular processes},
	volume = {82},
	issn = {1097-4164},
	doi = {10.1016/j.molcel.2021.12.022},
	abstract = {Since its initial demonstration in 2000, far-field super-resolution light microscopy has undergone tremendous technological developments. In parallel, these developments have opened a new window into visualizing the inner life of cells at unprecedented levels of detail. Here, we review the technical details behind the most common implementations of super-resolution microscopy and highlight some of the recent, promising advances in this field.},
	language = {eng},
	number = {2},
	journal = {Molecular Cell},
	author = {Bond, Charles and Santiago-Ruiz, Adriana N. and Tang, Qing and Lakadamyali, Melike},
	month = jan,
	year = {2022},
	pmid = {35063099},
	pmcid = {PMC8852216},
	keywords = {Animals, Cell Biology, Cell Physiological Phenomena, Diffusion of Innovation, Humans, Image Processing, Computer-Assisted, Microscopy, Molecular Imaging, Optical Imaging, Single Molecule Imaging},
	pages = {315--332},
}

@article{li_dlbi_2018,
	title = {{DLBI}: deep learning guided {Bayesian} inference for structure reconstruction of super-resolution fluorescence microscopy},
	volume = {34},
	issn = {1367-4811},
	shorttitle = {{DLBI}},
	doi = {10.1093/bioinformatics/bty241},
	abstract = {MOTIVATION: Super-resolution fluorescence microscopy with a resolution beyond the diffraction limit of light, has become an indispensable tool to directly visualize biological structures in living cells at a nanometer-scale resolution. Despite advances in high-density super-resolution fluorescent techniques, existing methods still have bottlenecks, including extremely long execution time, artificial thinning and thickening of structures, and lack of ability to capture latent structures.
RESULTS: Here, we propose a novel deep learning guided Bayesian inference (DLBI) approach, for the time-series analysis of high-density fluorescent images. Our method combines the strength of deep learning and statistical inference, where deep learning captures the underlying distribution of the fluorophores that are consistent with the observed time-series fluorescent images by exploring local features and correlation along time-axis, and statistical inference further refines the ultrastructure extracted by deep learning and endues physical meaning to the final image. In particular, our method contains three main components. The first one is a simulator that takes a high-resolution image as the input, and simulates time-series low-resolution fluorescent images based on experimentally calibrated parameters, which provides supervised training data to the deep learning model. The second one is a multi-scale deep learning module to capture both spatial information in each input low-resolution image as well as temporal information among the time-series images. And the third one is a Bayesian inference module that takes the image from the deep learning module as the initial localization of fluorophores and removes artifacts by statistical inference. Comprehensive experimental results on both real and simulated datasets demonstrate that our method provides more accurate and realistic local patch and large-field reconstruction than the state-of-the-art method, the 3B analysis, while our method is more than two orders of magnitude faster.
AVAILABILITY AND IMPLEMENTATION: The main program is available at https://github.com/lykaust15/DLBI.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
	language = {eng},
	number = {13},
	journal = {Bioinformatics (Oxford, England)},
	author = {Li, Yu and Xu, Fan and Zhang, Fa and Xu, Pingyong and Zhang, Mingshu and Fan, Ming and Li, Lihua and Gao, Xin and Han, Renmin},
	month = jul,
	year = {2018},
	pmid = {29950012},
	pmcid = {PMC6022599},
	keywords = {Bayes Theorem, Cells, Computer Simulation, Deep Learning, Microscopy, Fluorescence, Software},
	pages = {i284--i294},
}

@article{han_recent_2013,
	title = {Recent advances in super-resolution fluorescence imaging and its applications in biology},
	volume = {40},
	issn = {1673-8527},
	doi = {10.1016/j.jgg.2013.11.003},
	abstract = {Fluorescence microscopy has become an essential tool for biological research because it can be minimally invasive, acquire data rapidly, and target molecules of interest with specific labeling strategies. However, the diffraction-limited spatial resolution, which is classically limited to about 200 nm in the lateral direction and about 500 nm in the axial direction, hampers its application to identify delicate details of subcellular structure. Extensive efforts have been made to break diffraction limit for obtaining high-resolution imaging of a biological specimen. Various methods capable of obtaining super-resolution images with a resolution of tens of nanometers are currently available. These super-resolution techniques can be generally divided into three primary classes: (1) patterned illumination-based super-resolution imaging, which employs spatially and temporally modulated illumination light to reconstruct sub-diffraction structures; (2) single-molecule localization-based super-resolution imaging, which localizes the profile center of each individual fluorophore at subdiffraction precision; (3) bleaching/blinking-based super-resolution imaging. These super-resolution techniques have been utilized in different biological fields and provide novel insights into several new aspects of life science. Given unique technical merits and commercial availability of super-resolution fluorescence microscope, increasing applications of this powerful technique in life science can be expected.},
	language = {eng},
	number = {12},
	journal = {Journal of Genetics and Genomics = Yi Chuan Xue Bao},
	author = {Han, Rongcheng and Li, Zhenghong and Fan, Yanyan and Jiang, Yuqiang},
	month = dec,
	year = {2013},
	pmid = {24377865},
	keywords = {Animals, Bio-imaging, Biology, Cell Biology, FPALM, Fluorescence microscopy, Humans, Microscopy, Fluorescence, Molecular Biology, NSOM, Optical diffraction limit, PALM, RESOLFT, SSIM, STED, STORM, Super-resolution, TIRF, fluorescence photoactivation localization microscopy, near-field scanning optical microscopy, photoactivated localization microscopy, reversible saturable optically linear fluorescence transitions, saturated structured-illumination microscopy, stimulated emission depletion, stochastic optical reconstruction microscopy, total internal reflection fluorescence microscopy},
	pages = {583--595},
}

@article{olkin_multivariate_1961,
	title = {Multivariate {Correlation} {Models} with {Mixed} {Discrete} and {Continuous} {Variables}},
	volume = {32},
	issn = {0003-4851},
	url = {https://www.jstor.org/stable/2237755},
	abstract = {A model which frequently arises from experimentation in psychology is one which contains both discrete and continuous variables. The concern in such a model may be with finding measures of association or with problems of inference on some of the parameters. In the simplest such model there is a discrete variable x which takes the values 0 or 1, and a continuous variable y. Such a random variable x is often used in psychology to denote the presence or absence of an attribute. Point-biserial correlation, which is the ordinary product-moment correlation between x and y, has been used as a measure of association. This model, when x has a binomial distribution, and the conditional distribution of y for fixed x is normal, was studied in some detail by Tate [13]. In the present paper, we consider a multivariate extension, in which x = (x0, x1, ⋯, xk) has a multinomial distribution, and the conditional distribution of y = (y1, ⋯, yp) for fixed x is multivariate normal.},
	number = {2},
	urldate = {2023-05-15},
	journal = {The Annals of Mathematical Statistics},
	author = {Olkin, I. and Tate, R. F.},
	year = {1961},
	pages = {448--465},
}

@article{zaripova_graph--graph_2023,
	title = {Graph-in-{Graph} ({GiG}): {Learning} interpretable latent graphs in non-{Euclidean} domain for biological and healthcare applications},
	issn = {1361-8415},
	shorttitle = {Graph-in-{Graph} ({GiG})},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841523000993},
	doi = {10.1016/j.media.2023.102839},
	abstract = {Graphs are a powerful tool for representing and analyzing unstructured, non-Euclidean data ubiquitous in the healthcare domain. Two prominent examples are molecule property prediction and brain connectome analysis. Importantly, recent works have shown that considering relationships between input data samples has a positive regularizing effect on the downstream task in healthcare applications. These relationships are naturally modeled by a (possibly unknown) graph structure between input samples. In this work, we propose Graph-in-Graph (GiG), a neural network architecture for protein classification and brain imaging applications that exploits the graph representation of the input data samples and their latent relation. We assume an initially unknown latent-graph structure between graph-valued input data and propose to learn a parametric model for message passing within and across input graph samples, end-to-end along with the latent structure connecting the input graphs. Further, we introduce a Node Degree Distribution Loss (NDDL) that regularizes the predicted latent relationships structure. This regularization can significantly improve the downstream task. Moreover, the obtained latent graph can represent patient population models or networks of molecule clusters, providing a level of interpretability and knowledge discovery in the input domain, which is of particular value in healthcare.},
	language = {en},
	urldate = {2023-05-14},
	journal = {Medical Image Analysis},
	author = {Zaripova, Kamilia and Cosmo, Luca and Kazi, Anees and Ahmadi, Seyed-Ahmad and Bronstein, Michael M. and Navab, Nassir},
	month = may,
	year = {2023},
	keywords = {Graph deep learning, Knowledge discovery},
	pages = {102839},
}

@article{bompas_systematic_2013,
	title = {Systematic biases in adult color perception persist despite lifelong information sufficient to calibrate them},
	volume = {13},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/13.1.19},
	doi = {10.1167/13.1.19},
	abstract = {Learning from visual experience is crucial for perceptual development. One crucial question is when this learning occurs and to what extent it compensates for changes in the visual system throughout life. To address this question, it is essential to compare human performance not only to the hypothetical state of no recalibration, but also to the ideal scenario of optimum learning given the information available from visual exposure. In the adult eye, macular pigment introduces nonhomogeneity in color filtering between the very center of vision and the periphery, which is known to introduce perceptual differences. By modeling cone responses to the spectra of everyday stimuli, we quantify the degree of calibration possible from visual exposure, and therefore the perceptual color distortion that should occur with and without recalibration. We find that perceptual distortions were halfway between those predicted from bare adaptation and from learning, despite nearly lifelong exposure to a very systematic bias. We also show that these distortions affect real stimuli and are already robust in the near-periphery. Our findings challenge an assumption that has fueled influential accounts of vision—that the apparent homogeneity of perceived colors across the visual field in everyday life is evidence for continuous learning in perception. Since macular pigment is absent at birth and reaches adult levels before age 2, we argue that the most plausible, though likely controversial, interpretation of our results is early development of color constancy across space and not much recalibration afterwards.},
	number = {1},
	urldate = {2023-05-12},
	journal = {Journal of Vision},
	author = {Bompas, Aline and Powell, Georgie and Sumner, Petroc},
	month = jan,
	year = {2013},
	pages = {19},
}

@article{kastner_neural_2001,
	title = {The neural basis of biased competition in human visual cortex},
	volume = {39},
	issn = {0028-3932},
	url = {https://www.sciencedirect.com/science/article/pii/S0028393201001166},
	doi = {10.1016/S0028-3932(01)00116-6},
	abstract = {A typical scene contains many different objects that compete for neural representation due to the limited processing capacity of the visual system. At the neural level, competition among multiple stimuli is evidenced by the mutual suppression of their visually evoked responses and occurs most strongly at the level of the receptive field. The competition among multiple objects can be biased by both bottom–up sensory-driven mechanisms and top–down influences, such as selective attention. Functional brain imaging studies reveal that biasing signals due to selective attention can modulate neural activity in visual cortex not only in the presence, but also in the absence of visual stimulation. Although the competition among stimuli for representation is ultimately resolved within visual cortex, the source of top–down biasing signals likely derives from a distributed network of areas in frontal and parietal cortex. Attention-related activity in frontal and parietal areas does not reflect attentional modulation of visually evoked responses, but rather the attentional operations themselves.},
	language = {en},
	number = {12},
	urldate = {2023-05-12},
	journal = {Neuropsychologia},
	author = {Kastner, Sabine and Ungerleider, Leslie G},
	month = jan,
	year = {2001},
	keywords = {Competition, Neural basis, Visual cortex},
	pages = {1263--1276},
}

@article{fischer_serial_2014,
	title = {Serial dependence in visual perception},
	volume = {17},
	copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.3689},
	doi = {10.1038/nn.3689},
	abstract = {Visual input is often noisy and discontinuous, even though the physical environment is generally stable. The authors show that the visual system trades off change sensitivity to capitalize on physical continuity via serial dependence: present perception is biased toward past visual input. This bias is modulated by attention and governed by a spatiotemporally-tuned operator, a continuity field.},
	language = {en},
	number = {5},
	urldate = {2023-05-12},
	journal = {Nature Neuroscience},
	author = {Fischer, Jason and Whitney, David},
	month = may,
	year = {2014},
	keywords = {Object vision, Pattern vision},
	pages = {738--743},
}

@article{silva_3-dimensional_2014,
	title = {The 3-dimensional, 4-channel model of human visual sensitivity to grayscale scrambles},
	volume = {101},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698914001370},
	doi = {10.1016/j.visres.2014.06.001},
	abstract = {Previous research supports the claim that human vision has three dimensions of sensitivity to grayscale scrambles (textures composed of randomly scrambled mixtures of different grayscales). However, the preattentive mechanisms (called here “field-capture channels”) that confer this sensitivity remain obscure. The current experiments sought to characterize the specific field-capture channels that confer this sensitivity using a task in which the participant is required to detect the location of a small patch of one type of grayscale scramble in an extended background of another type. Analysis of the results supports the existence of four field-capture channels: (1) the (previously characterized) “blackshot” channel, sharply tuned to the blackest grayscales; (2) a (previously unknown) “gray-tuned” field-capture channel whose sensitivity is zero for black rising sharply to maximum sensitivity for grayscales slightly darker than mid-gray then decreasing to half-height for brighter grayscales; (3) an “up-ramped” channel whose sensitivity is zero for black, increases linearly with increasing grayscale reaching a maximum near white; (4) a (complementary) “down-ramped” channel whose sensitivity is maximal for black, decreases linearly reaching a minimum near white. The sensitivity functions of field-capture channels (3) and (4) are linearly dependent; thus, these four field-capture channels collectively confer sensitivity to a 3-dimensional space of histogram variations.},
	language = {en},
	urldate = {2023-05-12},
	journal = {Vision Research},
	author = {Silva, Andrew E. and Chubb, Charles},
	month = aug,
	year = {2014},
	keywords = {Attention, Blackshot, Contrast, Scrambles, Search, Texture},
	pages = {94--107},
}

@article{bertalmio_evidence_2020,
	title = {Evidence for the intrinsically nonlinear nature of receptive fields in vision},
	volume = {10},
	copyright = {2020 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-73113-0},
	doi = {10.1038/s41598-020-73113-0},
	abstract = {The responses of visual neurons, as well as visual perception phenomena in general, are highly nonlinear functions of the visual input, while most vision models are grounded on the notion of a linear receptive field (RF). The linear RF has a number of inherent problems: it changes with the input, it presupposes a set of basis functions for the visual system, and it conflicts with recent studies on dendritic computations. Here we propose to model the RF in a nonlinear manner, introducing the intrinsically nonlinear receptive field (INRF). Apart from being more physiologically plausible and embodying the efficient representation principle, the INRF has a key property of wide-ranging implications: for several vision science phenomena where a linear RF must vary with the input in order to predict responses, the INRF can remain constant under different stimuli. We also prove that Artificial Neural Networks with INRF modules instead of linear filters have a remarkably improved performance and better emulate basic human perception. Our results suggest a change of paradigm for vision science as well as for artificial intelligence.},
	language = {en},
	number = {1},
	urldate = {2023-05-12},
	journal = {Scientific Reports},
	author = {Bertalmío, Marcelo and Gomez-Villa, Alex and Martín, Adrián and Vazquez-Corral, Javier and Kane, David and Malo, Jesús},
	month = oct,
	year = {2020},
	keywords = {Computational biology and bioinformatics, Neuroscience, Psychology},
	pages = {16277},
}

@article{kay_identifying_2008,
	title = {Identifying natural images from human brain activity},
	volume = {452},
	copyright = {2008 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature06713},
	doi = {10.1038/nature06713},
	abstract = {Recent functional magnetic resonance imaging (fMRI) studies have shown that, based on patterns of activity evoked by different categories of visual images, it is possible to deduce simple features in the visual scene, or to which category it belongs. Kay et al. take this approach a tantalizing step further. Their newly developed decoding method, based on quantitative receptive field models that characterize the relationship between visual stimuli and fMRI activity in early visual areas, can identify with high accuracy which specific natural image an observer saw, even for an image chosen at random from 1,000 distinct images. This prompts the thought that it may soon be possible to decode subjective perceptual experiences such as visual imagery and dreams, an idea previously restricted to the realm of science fiction.},
	language = {en},
	number = {7185},
	urldate = {2023-05-12},
	journal = {Nature},
	author = {Kay, Kendrick N. and Naselaris, Thomas and Prenger, Ryan J. and Gallant, Jack L.},
	month = mar,
	year = {2008},
	keywords = {Humanities and Social Sciences, Science, multidisciplinary},
	pages = {352--355},
}

@article{lee_data_2009,
	title = {Data hiding in grayscale images by dynamic programming based on a human visual model},
	volume = {42},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320309000429},
	doi = {10.1016/j.patcog.2009.01.014},
	abstract = {A new method for data hiding in grayscale images based on a human vision model with distortion-minimizing capabilities is proposed. Each of the eight bit planes of an input grayscale image is viewed as a binary image, into which message data are embedded horizontally. Two optimization techniques, namely, block pattern coding and dynamic programming, are proposed for image distortion minimization. Experimental results show good performs of the proposed method.},
	language = {en},
	number = {7},
	urldate = {2023-05-12},
	journal = {Pattern Recognition},
	author = {Lee, I-Shi and Tsai, Wen-Hsiang},
	month = jul,
	year = {2009},
	keywords = {Block pattern encoding, Data hiding, Dynamic programming, Grayscale image, Human visual system},
	pages = {1604--1611},
}

@article{liu_concepts_2021,
	title = {Concepts and {Application} of {DNA} {Origami} and {DNA} {Self}-{Assembly}: {A} {Systematic} {Review}},
	volume = {2021},
	issn = {1754-2103, 1176-2322},
	shorttitle = {Concepts and {Application} of {DNA} {Origami} and {DNA} {Self}-{Assembly}},
	url = {https://www.hindawi.com/journals/abb/2021/9112407/},
	doi = {10.1155/2021/9112407},
	abstract = {With the arrival of the post-Moore Era, the development of traditional silicon-based computers has reached the limit, and it is urgent to develop new computing technology to meet the needs of science and life. DNA computing has become an essential branch and research hotspot of new computer technology because of its powerful parallel computing capability and excellent data storage capability. Due to good biocompatibility and programmability properties, DNA molecules have been widely used to construct novel self-assembled structures. In this review, DNA origami is briefly introduced firstly. Then, the applications of DNA self-assembly in material physics, biogenetics, medicine, and other fields are described in detail, which will aid the development of DNA computational model in the future.},
	language = {en},
	urldate = {2023-05-12},
	journal = {Applied Bionics and Biomechanics},
	author = {Liu, Wei and Duan, Huaichuan and Zhang, Derong and Zhang, Xun and Luo, Qing and Xie, Tao and Yan, Hailian and Peng, Lianxin and Hu, Yichen and Liang, Li and Zhao, Gang and Xie, Zhenjian and Hu, Jianping},
	editor = {Penta, Raimondo},
	month = nov,
	year = {2021},
	pages = {1--15},
}

@article{bajaj_evolution_1984,
	title = {Evolution and the {Tertiary} {Structure} of {Proteins}},
	volume = {13},
	url = {https://doi.org/10.1146/annurev.bb.13.060184.002321},
	doi = {10.1146/annurev.bb.13.060184.002321},
	number = {1},
	urldate = {2023-05-11},
	journal = {Annual Review of Biophysics and Bioengineering},
	author = {Bajaj, M and Blundell, T},
	year = {1984},
	pmid = {6378074},
	pages = {453--492},
}

@article{nyquist_certain_1928,
	title = {Certain {Topics} in {Telegraph} {Transmission} {Theory}},
	volume = {47},
	issn = {0096-3860},
	url = {http://ieeexplore.ieee.org/document/5055024/},
	doi = {10.1109/T-AIEE.1928.5055024},
	number = {2},
	urldate = {2023-05-11},
	journal = {Transactions of the American Institute of Electrical Engineers},
	author = {Nyquist, H.},
	month = apr,
	year = {1928},
	pages = {617--644},
}

@article{shannon_mathematical_1948,
	title = {A {Mathematical} {Theory} of {Communication}},
	volume = {27},
	issn = {00058580},
	url = {https://ieeexplore.ieee.org/document/6773067},
	doi = {10.1002/j.1538-7305.1948.tb00917.x},
	language = {en},
	number = {4},
	urldate = {2023-05-11},
	journal = {Bell System Technical Journal},
	author = {Shannon, C. E.},
	month = oct,
	year = {1948},
	pages = {623--656},
}

@article{shannon_communication_1949,
	title = {Communication in the {Presence} of {Noise}},
	volume = {37},
	issn = {2162-6634},
	doi = {10.1109/JRPROC.1949.232969},
	abstract = {A method is developed for representing any communication system geometrically. Messages and the corresponding signals are points in two "function spaces," and the modulation process is a mapping of one space into the other. Using this representation, a number of results in communication theory are deduced concerning expansion and compression of bandwidth and the threshold effect. Formulas are found for the maxmum rate of transmission of binary digits over a system when the signal is perturbed by various types of noise. Some of the properties of "ideal" systems which transmit at this maxmum rate are discussed. The equivalent number of binary digits per second for certain information sources is calculated.},
	number = {1},
	journal = {Proceedings of the IRE},
	author = {Shannon, C.E.},
	month = jan,
	year = {1949},
	keywords = {Bandwidth, Circuits, Communication systems, Electron tubes, Frequency measurement, Gain measurement, Klystrons, Shape, Telephony, Voltage},
	pages = {10--21},
}

@article{biselli_optogenetic_2021,
	title = {Optogenetic and chemogenetic insights into the neurocircuitry of depression-like behaviour: {A} systematic review},
	volume = {53},
	issn = {1460-9568},
	shorttitle = {Optogenetic and chemogenetic insights into the neurocircuitry of depression-like behaviour},
	doi = {10.1111/ejn.14603},
	abstract = {Major depressive disorder (MDD) and its treatment are challenges for global health. Optogenetics and chemogenetics are driving MDD research forward by unveiling causal relations between cell-type-specific control of neurons and depressive-like behaviour in rodents. Using a systematic search process, in this review, a set of 43 original studies applying optogenetic or chemogenetic techniques in rodent models of depression was identified. Our aim was to provide an examination of all available studies elucidating central neuronal mechanisms leading to depressive-like behaviour in rodents and thereby unveiling the most promising routes for future research. A complex interacting network of relevant structures, in which central circuitries causally related to depressive-like behaviour are implicated, has been identified. As most relevant structures emerge: medial prefrontal cortex, anterior cingulate cortex, amygdala, nucleus accumbens, ventral tegmental area, hippocampus and raphe nuclei. Further evidence, though examined by only few studies, emerges for structures like the lateral habenula, or medial dorsal thalamus. Most of the identified brain areas have previously been associated with MDD neuropathology, but now evidence can be provided for causal pathological mechanisms within a complex cortico-limbic reward circuitry. However, the studies also show conflicting results concerning the mechanisms underlying the causal involvement of specific circuitries. Comparability of studies is partly limited since even small deviations in methodological approaches lead to different outcomes. Factors influencing study outcomes were identified and need to be considered in future studies (e.g. frequency used for stimulation, time and duration of stimulation, limitations of applied animal models of MDD).},
	language = {eng},
	number = {1},
	journal = {The European Journal of Neuroscience},
	author = {Biselli, Tom and Lange, Susen Sophie and Sablottny, Lynn and Steffen, Johannes and Walther, Andreas},
	month = jan,
	year = {2021},
	pmid = {31633833},
	keywords = {Animals, Depression, Depressive Disorder, Major, Nucleus Accumbens, Optogenetics, Reward, chemogenetics, depressive disorders, neurocircuitry, neuropsychiatry, optogenetics},
	pages = {9--38},
}

@article{burkitt_review_2006,
	title = {A {Review} of the {Integrate}-and-fire {Neuron} {Model}: {I}. {Homogeneous} {Synaptic} {Input}},
	volume = {95},
	issn = {1432-0770},
	shorttitle = {A {Review} of the {Integrate}-and-fire {Neuron} {Model}},
	url = {https://doi.org/10.1007/s00422-006-0068-6},
	doi = {10.1007/s00422-006-0068-6},
	abstract = {The integrate-and-fire neuron model is one of the most widely used models for analyzing the behavior of neural systems. It describes the membrane potential of a neuron in terms of the synaptic inputs and the injected current that it receives. An action potential (spike) is generated when the membrane potential reaches a threshold, but the actual changes associated with the membrane voltage and conductances driving the action potential do not form part of the model. The synaptic inputs to the neuron are considered to be stochastic and are described as a temporally homogeneous Poisson process. Methods and results for both current synapses and conductance synapses are examined in the diffusion approximation, where the individual contributions to the postsynaptic potential are small. The focus of this review is upon the mathematical techniques that give the time distribution of output spikes, namely stochastic differential equations and the Fokker–Planck equation. The integrate-and-fire neuron model has become established as a canonical model for the description of spiking neurons because it is capable of being analyzed mathematically while at the same time being sufficiently complex to capture many of the essential features of neural processing. A number of variations of the model are discussed, together with the relationship with the Hodgkin–Huxley neuron model and the comparison with electrophysiological data. A brief overview is given of two issues in neural information processing that the integrate-and-fire neuron model has contributed to – the irregular nature of spiking in cortical neurons and neural gain modulation.},
	language = {en},
	number = {1},
	urldate = {2023-05-11},
	journal = {Biological Cybernetics},
	author = {Burkitt, A. N.},
	month = jul,
	year = {2006},
	keywords = {Conductance models, Integrate-and-fire neuron, Neural models},
	pages = {1--19},
}

@article{cisneros_mitochondria-lysosome_2022,
	title = {Mitochondria-lysosome contact site dynamics and misregulation in neurodegenerative diseases},
	volume = {45},
	issn = {1878-108X},
	doi = {10.1016/j.tins.2022.01.005},
	abstract = {Neurons rely heavily on properly regulated mitochondrial and lysosomal homeostasis, with multiple neurodegenerative diseases linked to dysfunction in these two organelles. Interestingly, mitochondria-lysosome membrane contact sites have been identified as a key pathway mediating their crosstalk in neurons. Recent studies have further elucidated the regulation of mitochondria-lysosome contact dynamics via distinct tethering/untethering protein machinery. Moreover, this pathway has been shown to have additional functions in regulating organelle network dynamics and metabolite transfer between lysosomes and mitochondria. In this review, we highlight recent advances in the field of mitochondria-lysosome contact sites and their misregulation across multiple neurodegenerative disorders, which further underscore a potential role for this pathway in neuronal homeostasis and disease.},
	language = {eng},
	number = {4},
	journal = {Trends in Neurosciences},
	author = {Cisneros, Jasmine and Belton, Tayler B. and Shum, George C. and Molakal, Catherine G. and Wong, Yvette C.},
	month = apr,
	year = {2022},
	pmid = {35249745},
	pmcid = {PMC8930467},
	keywords = {Charcot-Marie-Tooth disease, Humans, Intracellular Membranes, Lysosomes, Mitochondria, Neurodegenerative Diseases, Neurons, Parkinson’s disease, inter-organelle contact sites, lysosomal storage disorders, lysosomes, mitochondria},
	pages = {312--322},
}

@article{doherty_mechanisms_2009,
	title = {Mechanisms of endocytosis},
	volume = {78},
	issn = {1545-4509},
	doi = {10.1146/annurev.biochem.78.081307.110540},
	abstract = {Endocytic mechanisms control the lipid and protein composition of the plasma membrane, thereby regulating how cells interact with their environments. Here, we review what is known about mammalian endocytic mechanisms, with focus on the cellular proteins that control these events. We discuss the well-studied clathrin-mediated endocytic mechanisms and dissect endocytic pathways that proceed independently of clathrin. These clathrin-independent pathways include the CLIC/GEEC endocytic pathway, arf6-dependent endocytosis, flotillin-dependent endocytosis, macropinocytosis, circular doral ruffles, phagocytosis, and trans-endocytosis. We also critically review the role of caveolae and caveolin1 in endocytosis. We highlight the roles of lipids, membrane curvature-modulating proteins, small G proteins, actin, and dynamin in endocytic pathways. We discuss the functional relevance of distinct endocytic pathways and emphasize the importance of studying these pathways to understand human disease processes.},
	language = {eng},
	journal = {Annual Review of Biochemistry},
	author = {Doherty, Gary J. and McMahon, Harvey T.},
	year = {2009},
	pmid = {19317650},
	keywords = {Animals, Caveolae, Clathrin, Endocytosis, Humans, Phagocytosis, Pinocytosis, Protein Transport},
	pages = {857--902},
}

@article{ma_review_2017,
	title = {A review for dynamics in neuron and neuronal network},
	volume = {89},
	issn = {1573-269X},
	url = {https://doi.org/10.1007/s11071-017-3565-3},
	doi = {10.1007/s11071-017-3565-3},
	abstract = {The biological Hodgkin–Huxley model and its simplified versions have confirmed its effectiveness for recognizing and understanding the electrical activities in neurons, and bifurcation analysis is often used to detect the mode transition in neuronal activities. Within the collective behaviors of neurons, neuronal network with different topology is designed to study the synchronization behavior and spatial pattern formation. In this review, the authors give careful comments for the presented neuron models and present some open problems in this field, nonlinear analysis could be effective to further discuss these problems and some results could be helpful to give possible guidance in the field of neurodynamics.},
	language = {en},
	number = {3},
	urldate = {2023-05-11},
	journal = {Nonlinear Dynamics},
	author = {Ma, Jun and Tang, Jun},
	month = aug,
	year = {2017},
	keywords = {Electromagnetic radiation, Factor of synchronization, Memristor, Model setting, Synchronization},
	pages = {1569--1578},
}

@misc{noauthor_review_nodate,
	title = {A review for dynamics in neuron and neuronal network {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/s11071-017-3565-3},
	urldate = {2023-05-11},
}

@misc{noauthor_endocytosis_nodate,
	title = {Endocytosis {\textbar} {Physiological} {Reviews}},
	url = {https://journals.physiology.org/doi/abs/10.1152/physrev.1997.77.3.759?ssource=mfc&rss=1},
	urldate = {2023-05-11},
}

@article{rahbek-clemmensen_super-resolution_2017,
	title = {Super-resolution microscopy reveals functional organization of dopamine transporters into cholesterol and neuronal activity-dependent nanodomains},
	volume = {8},
	copyright = {2017 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-017-00790-3},
	doi = {10.1038/s41467-017-00790-3},
	abstract = {Dopamine regulates reward, cognition, and locomotor functions. By mediating rapid reuptake of extracellular dopamine, the dopamine transporter is critical for spatiotemporal control of dopaminergic neurotransmission. Here, we use super-resolution imaging to show that the dopamine transporter is dynamically sequestrated into cholesterol-dependent nanodomains in the plasma membrane of presynaptic varicosities and neuronal projections of dopaminergic neurons. Stochastic optical reconstruction microscopy reveals irregular dopamine transporter nanodomains (∼70 nm mean diameter) that were highly sensitive to cholesterol depletion. Live photoactivated localization microscopy shows a similar dopamine transporter membrane organization in live heterologous cells. In neurons, dual-color dSTORM shows that tyrosine hydroxylase and vesicular monoamine transporter-2 are distinctively localized adjacent to, but not overlapping with, the dopamine transporter nanodomains. The molecular organization of the dopamine transporter in nanodomains is reversibly reduced by short-term activation of NMDA-type ionotropic glutamate receptors, implicating dopamine transporter nanodomain distribution as a potential mechanism to modulate dopaminergic neurotransmission in response to excitatory input.},
	language = {en},
	number = {1},
	urldate = {2023-05-11},
	journal = {Nature Communications},
	author = {Rahbek-Clemmensen, Troels and Lycas, Matthew D. and Erlendsson, Simon and Eriksen, Jacob and Apuschkin, Mia and Vilhardt, Frederik and Jørgensen, Trine N. and Hansen, Freja H. and Gether, Ulrik},
	month = sep,
	year = {2017},
	keywords = {Cellular neuroscience, Membrane biophysics, Super-resolution microscopy, Transporters in the nervous system},
	pages = {740},
}

@article{tafteh_single_2016,
	title = {Single molecule localization deep within thick cells; a novel super-resolution microscope},
	volume = {9},
	issn = {1864-0648},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jbio.201500140},
	doi = {10.1002/jbio.201500140},
	abstract = {A novel 3D imaging system based on single-molecule localization microscopy is presented to allow high-accuracy drift-free ({\textless}0.7 nm lateral; 2.5 nm axial) imaging many microns deep into a cell. When imaging deep within the cell, distortions of the point-spread function result in an inaccurate and very compressed Z distribution. For the system to accurately represent the position of each blink, a series of depth-dependent calibrations are required. The system and its allied methodology are applied to image the ryanodine receptor in the cardiac myocyte. Using the depth-dependent calibration, the receptors deep within the cell are spread over a Z range that is many hundreds of nanometers greater than implied by conventional analysis. We implemented a time domain filter to detect overlapping blinks that were not filtered by a stringent goodness of fit criterion. This filter enabled us to resolve the structure of the individual (30 nm square) receptors giving a result similar to that obtained with electron tomography. High-accuracy deep imaging of the ryanodine receptor in the cardiac myocyte, using single-molecule localization microscopy. Depth-dependent calibrations are performed for accurate depth localization. The optical design featuring two independent and variable focal planes allows real-time feedback for drift-free deep imaging.},
	language = {en},
	number = {1-2},
	urldate = {2023-05-11},
	journal = {Journal of Biophotonics},
	author = {Tafteh, Reza and Scriven, David R. L. and Moore, Edwin D. W. and Chou, Keng C.},
	year = {2016},
	keywords = {cardiomyocyte, drift correction, high-density localization, ryanodine receptor, single-molecule localization},
	pages = {155--160},
}

@article{cramer_contribution_1946,
	title = {A contribution to the theory of statistical estimation},
	volume = {1946},
	issn = {0346-1238},
	url = {https://doi.org/10.1080/03461238.1946.10419631},
	doi = {10.1080/03461238.1946.10419631},
	abstract = {1. The Estimation Problem. In problems of statistical estimation, we are concerned with certain variables assumed to be random variables having more or less unknown probability distributions. A number of observed values of these variables are given, and it is required to use these values to learn something about the unknown distributions.},
	number = {1},
	urldate = {2023-05-11},
	journal = {Scandinavian Actuarial Journal},
	author = {Cramér, Harald},
	month = jan,
	year = {1946},
	pages = {85--94},
}

@article{radhakrishna_rao_information_1945,
	title = {Information and accuracy attainable in the estimation of statistical parameters},
	volume = {37},
	issn = {0008-0659},
	url = {http://bulletin.calmathsoc.org/article.php?ID=B.1945.37.14},
	abstract = {The earliest method of estimation of statistical parameters is the method of least squares due to Markoff. A set of observations whose expectations are linear functions of a number of unknown parameters being given, the problem which Markoff posed for solution is to find out a linear function of observations whose expectation is an assigned linear function of the unknown parameters and whose variance is a minimum. There is no assumption about the distribution of the observations except that each has a finite variance.},
	number = {3},
	urldate = {2023-05-11},
	journal = {Bulletin of the Calcutta Mathematical Society},
	author = {Radhakrishna Rao, C.},
	year = {1945},
	pages = {81--91},
}

@article{stirling_cellprofiler_2021,
	title = {{CellProfiler} {Analyst} 3.0: accessible data exploration and machine learning for image analysis},
	volume = {37},
	issn = {1367-4811},
	shorttitle = {{CellProfiler} {Analyst} 3.0},
	doi = {10.1093/bioinformatics/btab634},
	abstract = {SUMMARY: Image-based experiments can yield many thousands of individual measurements describing each object of interest, such as cells in microscopy screens. CellProfiler Analyst is a free, open-source software package designed for the exploration of quantitative image-derived data and the training of machine learning classifiers with an intuitive user interface. We have now released CellProfiler Analyst 3.0, which in addition to enhanced performance adds support for neural network classifiers, identifying rare object subsets, and direct transfer of objects of interest from visualization tools into the Classifier tool for use as training data. This release also increases interoperability with the recently released CellProfiler 4, making it easier for users to detect and measure particular classes of objects in their analyses.
AVAILABILITY: CellProfiler Analyst binaries for Windows and MacOS are freely available for download at https://cellprofileranalyst.org/. Source code is implemented in Python 3 and is available at https://github.com/CellProfiler/CellProfiler-Analyst/. A sample dataset is available at https://cellprofileranalyst.org/examples, based on images freely available from the Broad Bioimage Benchmark Collection.},
	language = {eng},
	number = {21},
	journal = {Bioinformatics (Oxford, England)},
	author = {Stirling, David R. and Carpenter, Anne E. and Cimini, Beth A.},
	month = nov,
	year = {2021},
	pmid = {34478488},
	keywords = {Image Processing, Computer-Assisted, Machine Learning, Microscopy, Neural Networks, Computer, Software},
	pages = {3992--3994},
}

@article{tosi_lobster_2020,
	title = {{LOBSTER}: an environment to design bioimage analysis workflows for large and complex fluorescence microscopy data},
	volume = {36},
	issn = {1367-4811},
	shorttitle = {{LOBSTER}},
	doi = {10.1093/bioinformatics/btz945},
	abstract = {SUMMARY: Open source software such as ImageJ and CellProfiler greatly simplified the quantitative analysis of microscopy images but their applicability is limited by the size, dimensionality and complexity of the images under study. In contrast, software optimized for the needs of specific research projects can overcome these limitations, but they may be harder to find, set up and customize to different needs. Overall, the analysis of large, complex, microscopy images is hence still a critical bottleneck for many Life Scientists. We introduce LOBSTER (Little Objects Segmentation and Tracking Environment), an environment designed to help scientists design and customize image analysis workflows to accurately characterize biological objects from a broad range of fluorescence microscopy images, including large images exceeding workstation main memory. LOBSTER comes with a starting set of over 75 sample image analysis workflows and associated images stemming from state-of-the-art image-based research projects.
AVAILABILITY AND IMPLEMENTATION: LOBSTER requires MATLAB (version ≥ 2015a), MATLAB Image processing toolbox, and MATLAB statistics and machine learning toolbox. Code source, online tutorials, video demonstrations, documentation and sample images are freely available from: https://sebastients.github.io.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
	language = {eng},
	number = {8},
	journal = {Bioinformatics (Oxford, England)},
	author = {Tosi, Sébastien and Bardia, Lídia and Filgueira, Maria Jose and Calon, Alexandre and Colombelli, Julien},
	month = apr,
	year = {2020},
	pmid = {31860062},
	keywords = {Animals, Image Processing, Computer-Assisted, Microscopy, Fluorescence, Nephropidae, Software, Workflow},
	pages = {2634--2635},
}

@article{nanes_slide_2015,
	title = {Slide {Set}: {Reproducible} image analysis and batch processing with {ImageJ}},
	volume = {59},
	issn = {1940-9818},
	shorttitle = {Slide {Set}},
	doi = {10.2144/000114351},
	abstract = {Most imaging studies in the biological sciences rely on analyses that are relatively simple. However, manual repetition of analysis tasks across multiple regions in many images can complicate even the simplest analysis, making record keeping difficult, increasing the potential for error, and limiting reproducibility. While fully automated solutions are necessary for very large data sets, they are sometimes impractical for the small- and medium-sized data sets common in biology. Here we present the Slide Set plugin for ImageJ, which provides a framework for reproducible image analysis and batch processing. Slide Set organizes data into tables, associating image files with regions of interest and other relevant information. Analysis commands are automatically repeated over each image in the data set, and multiple commands can be chained together for more complex analysis tasks. All analysis parameters are saved, ensuring transparency and reproducibility. Slide Set includes a variety of built-in analysis commands and can be easily extended to automate other ImageJ plugins, reducing the manual repetition of image analysis without the set-up effort or programming expertise required for a fully automated solution.},
	language = {eng},
	number = {5},
	journal = {BioTechniques},
	author = {Nanes, Benjamin A.},
	month = nov,
	year = {2015},
	pmid = {26554504},
	pmcid = {PMC4643401},
	keywords = {Algorithms, Electronic Data Processing, Image Processing, Computer-Assisted, Reproducibility of Results, Software, Workflow, automation, image analysis, image processing, reproducibility, software},
	pages = {269--278},
}

@article{annibale_identification_2011,
	title = {Identification of clustering artifacts in photoactivated localization microscopy},
	volume = {8},
	copyright = {2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.1627},
	doi = {10.1038/nmeth.1627},
	language = {en},
	number = {7},
	urldate = {2023-05-11},
	journal = {Nature Methods},
	author = {Annibale, Paolo and Vanni, Stefano and Scarselli, Marco and Rothlisberger, Ursula and Radenovic, Aleksandra},
	month = jul,
	year = {2011},
	keywords = {Fluorescent proteins, Microscopy},
	pages = {527--528},
}

@article{gilles_tapas_2020,
	title = {{TAPAS}: {Towards} {Automated} {Processing} and {Analysis} of multi-dimensional bioimage data},
	volume = {9},
	issn = {2046-1402},
	shorttitle = {{TAPAS}},
	doi = {10.12688/f1000research.26977.2},
	abstract = {Modern microscopy is based on reproducible quantitative analysis, image data should be batch-processed by a standardized system that can be shared and easily reused by others. Furthermore, such system should require none or minimal programming from the users. We developed TAPAS (Towards an Automated Processing and Analysis System). The goal is to design an easy system for describing and exchanging processing workflows. The protocols are simple text files comprising a linear list of commands used to process and analyse the images. An extensive set of 60 modules is already available, mostly based on the tools proposed in the 3D ImageJ Suite. We propose a wizard, called TAPAS menu, to help the user design the protocol by listing the available modules and the parameters associated. Most modules will have default parameters values for most common tasks. Once the user has designed the protocol, he/she can apply the protocol to a set of images, that can be either stored locally or on a OMERO database. An extensive documentation including the list of modules, various tutorials and link to the source code is available at https://imagej.net/TAPAS.},
	language = {eng},
	journal = {F1000Research},
	author = {Gilles, Jean-François and Boudier, Thomas},
	year = {2020},
	pmid = {34567536},
	pmcid = {PMC8422341},
	keywords = {Fiji, Image Processing, Computer-Assisted, Image processing, ImageJ, OMERO, Software, Workflow, automation, image analysis},
	pages = {1278},
}

@article{allan_omero_2012,
	title = {{OMERO}: flexible, model-driven data management for experimental biology},
	volume = {9},
	issn = {1548-7105},
	shorttitle = {{OMERO}},
	doi = {10.1038/nmeth.1896},
	abstract = {Data-intensive research depends on tools that manage multidimensional, heterogeneous datasets. We built OME Remote Objects (OMERO), a software platform that enables access to and use of a wide range of biological data. OMERO uses a server-based middleware application to provide a unified interface for images, matrices and tables. OMERO's design and flexibility have enabled its use for light-microscopy, high-content-screening, electron-microscopy and even non-image-genotype data. OMERO is open-source software, available at http://openmicroscopy.org/.},
	language = {eng},
	number = {3},
	journal = {Nature Methods},
	author = {Allan, Chris and Burel, Jean-Marie and Moore, Josh and Blackburn, Colin and Linkert, Melissa and Loynton, Scott and Macdonald, Donald and Moore, William J. and Neves, Carlos and Patterson, Andrew and Porter, Michael and Tarkowska, Aleksandra and Loranger, Brian and Avondo, Jerome and Lagerstedt, Ingvar and Lianas, Luca and Leo, Simone and Hands, Katherine and Hay, Ron T. and Patwardhan, Ardan and Best, Christoph and Kleywegt, Gerard J. and Zanetti, Gianluigi and Swedlow, Jason R.},
	month = feb,
	year = {2012},
	pmid = {22373911},
	pmcid = {PMC3437820},
	keywords = {Animals, Biology, Computer Simulation, Database Management Systems, Databases, Factual, Humans, Image Interpretation, Computer-Assisted, Information Storage and Retrieval, Models, Biological, Software, User-Computer Interface},
	pages = {245--253},
}

@article{pouchin_easing_2022,
	title = {Easing batch image processing from {OMERO}: a new toolbox for {ImageJ}},
	volume = {11},
	issn = {2046-1402},
	shorttitle = {Easing batch image processing from {OMERO}},
	doi = {10.12688/f1000research.110385.2},
	abstract = {The Open Microscopy Environment Remote Objects (OMERO) is an open-source image manager used by many biologists to store, organize, view, and share microscopy images, while the open-source software ImageJ/Fiji is a very popular program used to analyse them. However, there is a lack of an easy-to-use generic tool to run a workflow on a batch of images without having to download them to local computers, and to automatically organize the results in OMERO. To offer this functionality, we have built (i) a library in Java: "Simple OMERO Client", to communicate with an OMERO database from Java software, (ii) an ImageJ/Fiji plugin to run a macro-program on a batch of images from OMERO and (iii) a new set of Macro Functions, "OMERO Macro extensions", dedicated to interact with OMERO in macro-programming. The latter is intended for developers, with additional possibilities using tag criteria, while the "Batch OMERO plugin" is more geared towards non-IT scientists and has a very easy to use interface. Each tool is illustrated with a use case.},
	language = {eng},
	journal = {F1000Research},
	author = {Pouchin, Pierre and Zoghlami, Rayan and Valarcher, Rémi and Delannoy, Maxence and Carvalho, Manon and Belle, Clémence and Mongy, Marc and Desset, Sophie and Brau, Frédéric},
	year = {2022},
	pmid = {35685190},
	pmcid = {PMC9171289},
	keywords = {Automation, Databases, Factual, Fiji, Humans, Image Analysis, Image Processing, Computer-Assisted, Image processing, ImageJ, Java, Microscopy, OMERO, Software, Workflow},
	pages = {392},
}

@article{blanc_towards_2022,
	title = {Towards {Human} in the {Loop} {Analysis} of {Complex} {Point} {Clouds}: {Advanced} {Visualizations}, {Quantifications}, and {Communication} {Features} in {Virtual} {Reality}},
	volume = {1},
	issn = {2673-7647},
	shorttitle = {Towards {Human} in the {Loop} {Analysis} of {Complex} {Point} {Clouds}},
	url = {https://www.frontiersin.org/articles/10.3389/fbinf.2021.775379},
	abstract = {Multiple fields in biological and medical research produce large amounts of point cloud data with high dimensionality and complexity. In addition, a large set of experiments generate point clouds, including segmented medical data or single-molecule localization microscopy. In the latter, individual molecules are observed within their natural cellular environment. Analyzing this type of experimental data is a complex task and presents unique challenges, where providing extra physical dimensions for visualization and analysis could be beneficial. Furthermore, whether highly noisy data comes from single-molecule recordings or segmented medical data, the necessity to guide analysis with user intervention creates both an ergonomic challenge to facilitate this interaction and a computational challenge to provide fluid interactions as information is being processed. Several applications, including our software DIVA for image stack and our platform Genuage for point clouds, have leveraged Virtual Reality (VR) to visualize and interact with data in 3D. While the visualization aspects can be made compatible with different types of data, quantifications, on the other hand, are far from being standard. In addition, complex analysis can require significant computational resources, making the real-time VR experience uncomfortable. Moreover, visualization software is mainly designed to represent a set of data points but lacks flexibility in manipulating and analyzing the data. This paper introduces new libraries to enhance the interaction and human-in-the-loop analysis of point cloud data in virtual reality and integrate them into the open-source platform Genuage. We first detail a new toolbox of communication tools that enhance user experience and improve flexibility. Then, we introduce a mapping toolbox allowing the representation of physical properties in space overlaid on a 3D mesh while maintaining a point cloud dedicated shader. We introduce later a new and programmable video capture tool in VR and desktop modes for intuitive data dissemination. Finally, we highlight the protocols that allow simultaneous analysis and fluid manipulation of data with a high refresh rate. We illustrate this principle by performing real-time inference of random walk properties of recorded trajectories with a pre-trained Graph Neural Network running in Python.},
	urldate = {2023-05-11},
	journal = {Frontiers in Bioinformatics},
	author = {Blanc, Thomas and Verdier, Hippolyte and Regnier, Louise and Planchon, Guillaume and Guérinot, Corentin and El Beheiry, Mohamed and Masson, Jean-Baptiste and Hajj, Bassam},
	year = {2022},
}

@article{spark_vlume_2020,
	title = {{vLUME}: {3D} virtual reality for single-molecule localization microscopy},
	volume = {17},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{vLUME}},
	url = {https://www.nature.com/articles/s41592-020-0962-1},
	doi = {10.1038/s41592-020-0962-1},
	abstract = {vLUME is a virtual reality software package designed to render large three-dimensional single-molecule localization microscopy datasets. vLUME features include visualization, segmentation, bespoke analysis of complex local geometries and exporting features. vLUME can perform complex analysis on real three-dimensional biological samples that would otherwise be impossible by using regular flat-screen visualization programs.},
	language = {en},
	number = {11},
	urldate = {2023-05-11},
	journal = {Nature Methods},
	author = {Spark, Alexander and Kitching, Alexandre and Esteban-Ferrer, Daniel and Handa, Anoushka and Carr, Alexander R. and Needham, Lisa-Maria and Ponjavic, Aleks and Santos, Ana Mafalda and McColl, James and Leterrier, Christophe and Davis, Simon J. and Henriques, Ricardo and Lee, Steven F.},
	month = nov,
	year = {2020},
	keywords = {Single-molecule biophysics, Software},
	pages = {1097--1099},
}

@misc{baragilly_measuring_2022,
	title = {Measuring the similarity of {SMLM}-derived point-clouds},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.09.12.507560v1},
	doi = {10.1101/2022.09.12.507560},
	abstract = {Single-molecule localisation microscopy produces data in the form of point-clouds. Here, we present a tool for assessing the similarity of two such point-clouds, which, unlike measures such as co-localisation, is insensitive to differences that are not preserved between data sets. The presented method can determine whether two point-clouds were generated from the same conditions and can identify from which of two experimental conditions an unseen point-cloud was likely derived.},
	language = {en},
	urldate = {2023-05-11},
	publisher = {bioRxiv},
	author = {Baragilly, Mohammed and Nieves, Daniel J. and Williamson, David J. and Peters, Ruby and Owen, Dylan M.},
	month = sep,
	year = {2022},
}

@misc{andronov_3d_2017,
	title = {{3D} clustering analysis of super-resolution microscopy data by {3D} {Voronoi} tessellations},
	copyright = {© 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/146456v1},
	doi = {10.1101/146456},
	abstract = {Single-molecule localization microscopy (SMLM) can play an important role in integrated structural biology approaches for example at the interface of cryo electron microscopy (cryo-EM), X-ray crystallography, NMR and fluorescence imaging to identify, localize and determine the 3D structure of cellular structures. While many tools exist for the 3D analysis and visualisation of crystal or cryo-EM structures little exists for 3D SMLM data which can provide fascinating insights but are particularly challenging to analyze in three dimensions especially in a dense cellular context. We developed 3DClusterViSu, a method based on 3D Voronoi tessellations that allows local density estimation, segmentation \& quantification of 3D SMLM data and visualization of protein clusters within a 3D tool. We show its robust performance on microtubules and histone proteins H2B and CENP-A with distinct spatial distributions. 3DClusterViSu will favor multi-scale and multi-resolution synergies to allow integrating molecular and cellular levels in the analysis of macromolecular complexes.},
	language = {en},
	urldate = {2023-05-11},
	publisher = {bioRxiv},
	author = {Andronov, Leonid and Michalon, Jonathan and Ouararhni, Khalid and Orlov, Igor and Hamiche, Ali and Vonesch, Jean-Luc and Klaholz, Bruno P.},
	month = jun,
	year = {2017},
}

@article{huijben_detecting_2021,
	title = {Detecting structural heterogeneity in single-molecule localization microscopy data},
	volume = {12},
	issn = {2041-1723},
	doi = {10.1038/s41467-021-24106-8},
	abstract = {Particle fusion for single molecule localization microscopy improves signal-to-noise ratio and overcomes underlabeling, but ignores structural heterogeneity or conformational variability. We present a-priori knowledge-free unsupervised classification of structurally different particles employing the Bhattacharya cost function as dissimilarity metric. We achieve 96\% classification accuracy on mixtures of up to four different DNA-origami structures, detect rare classes of origami occuring at 2\% rate, and capture variation in ellipticity of nuclear pore complexes.},
	language = {eng},
	number = {1},
	journal = {Nature Communications},
	author = {Huijben, Teun A. P. M. and Heydarian, Hamidreza and Auer, Alexander and Schueder, Florian and Jungmann, Ralf and Stallinga, Sjoerd and Rieger, Bernd},
	month = jun,
	year = {2021},
	pmid = {34145284},
	pmcid = {PMC8213809},
	keywords = {DNA, Nanostructures, Nuclear Pore, Nucleic Acid Conformation, Signal-To-Noise Ratio, Single Molecule Imaging},
	pages = {3791},
}

@article{cnossen_drift_2021,
	title = {Drift correction in localization microscopy using entropy minimization},
	volume = {29},
	copyright = {\&\#169; 2021 Optical Society of America},
	issn = {1094-4087},
	url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-29-18-27961},
	doi = {10.1364/OE.426620},
	abstract = {Localization microscopy offers resolutions down to a single nanometer but currently requires additional dedicated hardware or fiducial markers to reduce resolution loss from the drift of the sample. Drift estimation without fiducial markers is typically implemented using redundant cross correlation (RCC). We show that RCC has sub-optimal precision and bias, which leaves room for improvement. Here, we minimize a bound on the entropy of the obtained localizations to efficiently compute a precise drift estimate. Within practical compute-time constraints, simulations show a 5x improvement in drift estimation precision over the widely used RCC algorithm. The algorithm operates directly on fluorophore localizations and is tested on simulated and experimental datasets in 2D and 3D. An open source implementation is provided, implemented in Python and C++, and can utilize a GPU if available.},
	language = {EN},
	number = {18},
	urldate = {2023-05-10},
	journal = {Optics Express},
	author = {Cnossen, Jelmer and Cui, Tao Ju and Joo, Chirlmin and Smith, Carlas},
	month = aug,
	year = {2021},
	pages = {27961--27974},
}

@article{wang_localization_2014,
	title = {Localization events-based sample drift correction for localization microscopy with redundant cross-correlation algorithm},
	volume = {22},
	copyright = {© 2014 Optical Society of America},
	issn = {1094-4087},
	url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-22-13-15982},
	doi = {10.1364/OE.22.015982},
	abstract = {Highly accurate sample drift correction is essential in super-resolution localization microscopy to guarantee a high spatial resolution, especially when the technique is used to visualize small cell organelle. Here we present a localization events-based drift correction method using a redundant cross-correlation algorithm originally developed to correct beam-induced motion in cryo-electron microscopy. With simulated, synthesized as well as experimental data, we have demonstrated its superior precision compared to previously published localization events-based drift correction methods. The major advantage of this method is the robustness when the number of localization events is low, either because a short correction time step is required or because the imaged structure is small and sparse. This method has allowed us to improve the effective resolution when imaging Golgi apparatus in mammalian cells.},
	language = {EN},
	number = {13},
	urldate = {2023-05-10},
	journal = {Optics Express},
	author = {Wang, Yina and Schnitzbauer, Joerg and Hu, Zhe and Li, Xueming and Cheng, Yifan and Huang, Zhen-Li and Huang, Bo},
	month = jun,
	year = {2014},
	keywords = {Diode lasers, Diode pumped lasers, Fast Fourier transforms, Optical microscopy, Spatial resolution, Super resolution microscopy},
	pages = {15982--15991},
}

@article{evangelidis_joint_2018,
	title = {Joint {Alignment} of {Multiple} {Point} {Sets} with {Batch} and {Incremental} {Expectation}-{Maximization}},
	volume = {40},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2017.2717829},
	abstract = {This paper addresses the problem of registering multiple point sets. Solutions to this problem are often approximated by repeatedly solving for pairwise registration, which results in an uneven treatment of the sets forming a pair: a model set and a data set. The main drawback of this strategy is that the model set may contain noise and outliers, which negatively affects the estimation of the registration parameters. In contrast, the proposed formulation treats all the point sets on an equal footing. Indeed, all the points are drawn from a central Gaussian mixture, hence the registration is cast into a clustering problem. We formally derive batch and incremental EM algorithms that robustly estimate both the GMM parameters and the rotations and translations that optimally align the sets. Moreover, the mixture's means play the role of the registered set of points while the variances provide rich information about the contribution of each component to the alignment. We thoroughly test the proposed algorithms on simulated data and on challenging real data collected with range sensors. We compare them with several state-of-the-art algorithms, and we show their potential for surface reconstruction from depth data.},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Evangelidis, Georgios Dimitrios and Horaud, Radu},
	month = jun,
	year = {2018},
	keywords = {Algorithm design and analysis, Clustering algorithms, Iterative closest point algorithm, Mixture models, Point registration, Probabilistic logic, Sensors, Shape, expectation maximization, joint alignment, mixture models},
	pages = {1397--1410},
}

@article{chao_resolution_2009,
	title = {A resolution measure for three-dimensional microscopy},
	volume = {282},
	issn = {0030-4018},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2753980/},
	doi = {10.1016/j.optcom.2009.01.062},
	abstract = {A three-dimensional (3D) resolution measure for the conventional optical microscope is introduced which overcomes the drawbacks of the classical 3D (axial) resolution limit. Formulated within the context of a parameter estimation problem and based on the Cramer-Rao lower bound, this 3D resolution measure indicates the accuracy with which a given distance between two objects in 3D space can be determined from the acquired image. It predicts that, given enough photons from the objects of interest, arbitrarily small distances of separation can be estimated with prespecified accuracy. Using simulated images of point source pairs, we show that the maximum likelihood estimator is capable of attaining the accuracy predicted by the resolution measure. We also demonstrate how different factors, such as extraneous noise sources and the spatial orientation of the imaged object pair, can affect the accuracy with which a given distance of separation can be determined.},
	number = {9},
	urldate = {2023-05-10},
	journal = {Optics communications},
	author = {Chao, Jerry and Ram, Sripad and Abraham, Anish V. and Ward, E. Sally and Ober, Raimund J.},
	month = may,
	year = {2009},
	pmid = {20161040},
	pmcid = {PMC2753980},
	pages = {1751--1761},
}

@article{mukamel_unified_2012,
	title = {Unified {Resolution} {Bounds} for {Conventional} and {Stochastic} {Localization} {Fluorescence} {Microscopy}},
	volume = {109},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.109.168102},
	doi = {10.1103/PhysRevLett.109.168102},
	abstract = {Superresolution microscopy enables imaging in the optical far field with ∼20 nm-scale resolution. However, classical concepts of resolution using point-spread and modulation-transfer functions fail to describe the physical limits of superresolution techniques based on stochastic localization of single emitters. Prior treatments of stochastic localization microscopy have defined how accurately a single emitter’s position can be determined, but these bounds are restricted to sparse emitters, do not describe conventional microscopy, and fail to provide unified concepts of resolution for all optical methods. Here we introduce a measure of resolution, the information transfer function (ITF), that gives physical limits for conventional and stochastic localization techniques. The ITF bounds the accuracy of image determination as a function of spatial frequency and for conventional microscopy is proportional to the square of the modulation-transfer function. We use the ITF to describe how emitter density and photon counts affect imaging performance across the continuum from conventional to superresolution microscopy, without assuming emitters are sparse. This unified physical description of resolution facilitates experimental choices and designs of image reconstruction algorithms.},
	number = {16},
	urldate = {2023-05-10},
	journal = {Physical Review Letters},
	author = {Mukamel, Eran A. and Schnitzer, Mark J.},
	month = oct,
	year = {2012},
	pages = {168102},
}

@article{mortensen_optimized_2010,
	title = {Optimized localization analysis for single-molecule tracking and super-resolution microscopy},
	volume = {7},
	copyright = {2010 Nature Publishing Group},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.1447},
	doi = {10.1038/nmeth.1447},
	abstract = {A theoretical and experimental treatment of fitting methods for localizing the centers of diffraction-limited spots is presented. Use of an analytical point spread function shows that maximum likelihood fitting is superior to both unweighted and weighted least squares Gaussian fitting.},
	language = {en},
	number = {5},
	urldate = {2023-05-10},
	journal = {Nature Methods},
	author = {Mortensen, Kim I. and Churchman, L. Stirling and Spudich, James A. and Flyvbjerg, Henrik},
	month = may,
	year = {2010},
	keywords = {Super-resolution microscopy},
	pages = {377--381},
}

@article{ober_localization_2004,
	title = {Localization {Accuracy} in {Single}-{Molecule} {Microscopy}},
	volume = {86},
	issn = {0006-3495},
	url = {https://www.sciencedirect.com/science/article/pii/S0006349504741934},
	doi = {10.1016/S0006-3495(04)74193-4},
	abstract = {One of the most basic questions in single-molecule microscopy concerns the accuracy with which the location of a single molecule can be determined. Using the Fisher information matrix it is shown that the limit of the localization accuracy for a single molecule is given by λem/2πnaγAt, where λem, na, γ, A, and t denote the emission wavelength of the single molecule, the numerical aperture of the objective, the efficiency of the optical system, the emission rate of the single molecule and the acquisition time, respectively. Using Monte Carlo simulations it is shown that estimation algorithms can come close to attaining the limit given in the expression. Explicit quantitative results are also provided to show how the limit of the localization accuracy is reduced by factors such as pixelation of the detector and noise sources in the detection system. The results demonstrate what is achievable by single-molecule microscopy and provide guidelines for experimental design.},
	language = {en},
	number = {2},
	urldate = {2023-05-10},
	journal = {Biophysical Journal},
	author = {Ober, Raimund J. and Ram, Sripad and Ward, E. Sally},
	month = feb,
	year = {2004},
	pages = {1185--1200},
}

@article{anwar_caveolin-1_2015,
	title = {Caveolin-1 in {Breast} {Cancer}: {Single} {Molecule} {Regulation} of {Multiple} {Key} {Signaling} {Pathways}},
	volume = {16},
	shorttitle = {Caveolin-1 in {Breast} {Cancer}},
	doi = {10.7314/APJCP.2015.16.16.6803},
	abstract = {Caveolin-1 is a 22-kD trans-membrane protein enriched in particular plasma membrane invaginations known as caveolae. Cav-1 expression is often dysregulated in human breast cancers, being commonly upregulated in cancer cells and downregulated in stromal cells. As an intracellular scaffolding protein, Cav-1, is involved in several vital biological regulations including endocytosis, transcytosis, vesicular transport, and signaling pathways. Several pathways are modulated by Cav-1 including estrogen receptor, EGFR, Her2/neu, TGFβ, and mTOR and represent as major drivers in mammary carcinogenesis. Expression and role of Cav-1 in breast carcinogenesis is highly variable depending on the stage of tumor development as well as context of the cell. However, recent data have shown that downregulation of Cav-1 expression in stromal breast tumors is associated with frequent relapse, resistance to therapy, and poor outcome. Modification of Cav-1 expression for translational cancer therapy is particularly challenging since numerous signaling pathways might be affected. This review focuses on present understanding of Cav-1 in breast carcinogenesis and its potential role as a new biomarker for predicting therapeutic response and prognosis as well as new target for therapeutic manipulation.},
	journal = {Asian Pacific Journal of Cancer Prevention},
	author = {Anwar, Sumadi Lukman and Wahyono, Artanto and Aryandono, Teguh and Haryono, Samuel},
	month = nov,
	year = {2015},
	pages = {6803--6812},
}

@article{costello_analysing_2021,
	title = {Analysing errors in single-molecule localisation microscopy},
	volume = {134},
	issn = {1878-5875},
	doi = {10.1016/j.biocel.2021.105931},
	abstract = {In single molecule localisation microscopy (SMLM) a super-resolution image of the distribution of fluorophores in the sample is built up from the localised positions of many individual molecules. It has become widely used due to its experimental simplicity and the high resolution that can be achieved. However, the factors which limit resolution in a reconstructed image, and the artefacts which can be present, are completely different to those present in standard fluorescent microscopy techniques. Artefacts may be difficult for users to identify, particularly as they can cause images to appear falsely sharp, an effect called artificial sharpening. Here we discuss the different sources of error and bias in SMLM, and the methods available for avoiding or detecting them.},
	language = {eng},
	journal = {The International Journal of Biochemistry \& Cell Biology},
	author = {Costello, Ishan and Cox, Susan},
	month = may,
	year = {2021},
	pmid = {33609748},
	keywords = {Artifacts, Data assessment, Diagnostic Errors, Fluorescent Dyes, Image Processing, Computer-Assisted, Microscopy, Fluorescence, Single Molecule Imaging, Single-molecule localisation microscopy, Super-resolution},
	pages = {105931},
}

@incollection{kobayashi_continual_2019,
	title = {Continual {Learning} {Exploiting} {Structure} of {Fractal} {Reservoir} {Computing}},
	isbn = {9783030304928},
	abstract = {Neural network has a critical problem, called catastrophic forgetting, where memories for tasks already learned are easily overwritten with memories for a task additionally learned. This problem interferes with continual learning required for autonomous robots, which learn many tasks incrementally from daily activities. To mitigate the catastrophic forgetting, it is important for especially reservoir computing to clarify which neurons should be fired corresponding to each task, since only readout weights are updated according to the degree of firing of neurons. We therefore propose the way to design reservoir computing such that the firing neurons are clearly distinguished from others according to the task to be performed. As a key design feature, we employ fractal network, which has modularity and scalability, to be reservoir layer. In particular, its modularity is fully utilized by designing input layer. As a result, simulations of control tasks using reinforcement learning show that our design mitigates the catastrophic forgetting even when random actions from reinforcement learning prompt parameters to be overwritten. Furthermore, learning multiple tasks with a single network suggests that knowledge for the other tasks can facilitate to learn a new task, unlike the case using completely different networks.},
	author = {Kobayashi, Taisuke and Sugino, Toshiki},
	month = sep,
	year = {2019},
	doi = {10.1007/978-3-030-30493-5_4},
	pages = {35--47},
}

@article{fox-roberts_local_2017,
	title = {Local dimensionality determines imaging speed in localization microscopy},
	volume = {8},
	issn = {2041-1723},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5241698/},
	doi = {10.1038/ncomms13558},
	abstract = {Localization microscopy allows biological samples to be imaged at a length scale of tens of nanometres. Live-cell super-resolution imaging is rare, as it is generally assumed to be too slow for dynamic samples. The speed of data acquisition can be optimized by tuning the density of activated fluorophores in each time frame. Here, we show that the maximum achievable imaging speed for a particular structure varies by orders of magnitude, depending on the sample dimensionality (that is, whether the sample is more like a point, a strand or an extended structure such as a focal adhesion). If too high an excitation density is used, we demonstrate that the analysis undergoes silent failure, resulting in reconstruction artefacts. We are releasing a tool to allow users to identify areas of the image in which the activation density was too high and correct for them, in both live- and fixed-cell experiments., Localisation microscopy enables nanometre-scale imaging of biological samples, but the method is too slow to use on dynamic systems. Here, the authors develop a mathematical model that optimises the number of frames required and estimates the maximum speed for super-resolution imaging.},
	urldate = {2023-05-09},
	journal = {Nature Communications},
	author = {Fox-Roberts, Patrick and Marsh, Richard and Pfisterer, Karin and Jayo, Asier and Parsons, Maddy and Cox, Susan},
	month = jan,
	year = {2017},
	pmid = {28079054},
	pmcid = {PMC5241698},
	pages = {13558},
}

@article{wang_joint_2022,
	title = {Joint registration of multiple point clouds for fast particle fusion in localization microscopy},
	volume = {38},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9191212/},
	doi = {10.1093/bioinformatics/btac320},
	abstract = {Summary
We present a fast particle fusion method for particles imaged with single-molecule localization microscopy. The state-of-the-art approach based on all-to-all registration has proven to work well but its computational cost scales unfavorably with the number of particles N, namely as N2. Our method overcomes this problem and achieves a linear scaling of computational cost with N by making use of the Joint Registration of Multiple Point Clouds (JRMPC) method. Straightforward application of JRMPC fails as mostly locally optimal solutions are found. These usually contain several overlapping clusters that each consist of well-aligned particles, but that have different poses. We solve this issue by repeated runs of JRMPC for different initial conditions, followed by a classification step to identify the clusters, and a connection step to link the different clusters obtained for different initializations. In this way a single well-aligned structure is obtained containing the majority of the particles.

Results
We achieve reconstructions of experimental DNA-origami datasets consisting of close to 400 particles within only 10 min on a CPU, with an image resolution of 3.2 nm. In addition, we show artifact-free reconstructions of symmetric structures without making any use of the symmetry. We also demonstrate that the method works well for poor data with a low density of labeling and for 3D data.

Availability and implementation
The code is available for download from https://github.com/wexw/Joint-Registration-of-Multiple-Point-Clouds-for-Fast-Particle-Fusion-in-Localization-Microscopy.

Supplementary information

 are available at Bioinformatics online.},
	number = {12},
	urldate = {2023-05-09},
	journal = {Bioinformatics},
	author = {Wang, Wenxiu and Heydarian, Hamidreza and Huijben, Teun A P M and Stallinga, Sjoerd and Rieger, Bernd},
	month = may,
	year = {2022},
	pmid = {35552632},
	pmcid = {PMC9191212},
	pages = {3281--3287},
}

@article{hermon_time-correlated_2020,
	title = {Time-correlated single molecule localization microscopy enhances resolution and fidelity},
	volume = {10},
	issn = {2045-2322},
	url = {https://doi.org/10.1038/s41598-020-72812-y},
	doi = {10.1038/s41598-020-72812-y},
	abstract = {Single-molecule-localization-microscopy (SMLM) enables superresolution imaging of biological samples down to {\textasciitilde} 10–20 nm and in single molecule detail. However, common SMLM reconstruction largely disregards information embedded in the entire intensity trajectories of individual emitters. Here, we develop and demonstrate an approach, termed time-correlated-SMLM (tcSMLM), that uses such information for enhancing SMLM reconstruction. Specifically, tcSMLM is shown to increase the spatial resolution and fidelity of SMLM reconstruction of both simulated and experimental data; esp. upon acquisition under stringent conditions of low SNR, high acquisition rate and high density of emitters. We further provide detailed guidelines and optimization procedures for effectively applying tcSMLM to data of choice. Importantly, our approach can be readily added in tandem to multiple SMLM and related superresolution reconstruction algorithms. Thus, we expect that our approach will become an effective and readily accessible tool for enhancing SMLM and superresolution imaging.},
	language = {en},
	number = {1},
	urldate = {2023-05-09},
	journal = {Scientific Reports},
	author = {Hermon, Kobi and Schidorsky, Shachar and Razvag, Yair and Yakovian, Oren and Sherman, Eilon},
	month = oct,
	year = {2020},
	pages = {16212},
}

@article{heydarian_3d_2021,
	title = {{3D} particle averaging and detection of macromolecular symmetry in localization microscopy},
	volume = {12},
	issn = {2041-1723},
	doi = {10.1038/s41467-021-22006-5},
	abstract = {Single molecule localization microscopy offers in principle resolution down to the molecular level, but in practice this is limited primarily by incomplete fluorescent labeling of the structure. This missing information can be completed by merging information from many structurally identical particles. In this work, we present an approach for 3D single particle analysis in localization microscopy which hugely increases signal-to-noise ratio and resolution and enables determining the symmetry groups of macromolecular complexes. Our method does not require a structural template, and handles anisotropic localization uncertainties. We demonstrate 3D reconstructions of DNA-origami tetrahedrons, Nup96 and Nup107 subcomplexes of the nuclear pore complex acquired using multiple single molecule localization microscopy techniques, with their structural symmetry deducted from the data.},
	language = {eng},
	number = {1},
	journal = {Nature Communications},
	author = {Heydarian, Hamidreza and Joosten, Maarten and Przybylski, Adrian and Schueder, Florian and Jungmann, Ralf and Werkhoven, Ben van and Keller-Findeisen, Jan and Ries, Jonas and Stallinga, Sjoerd and Bates, Mark and Rieger, Bernd},
	month = may,
	year = {2021},
	pmid = {33990554},
	pmcid = {PMC8121824},
	keywords = {Algorithms, Cell Line, Computer Simulation, DNA, Humans, Imaging, Three-Dimensional, Macromolecular Substances, Molecular Conformation, Nuclear Pore, Nuclear Pore Complex Proteins, Signal-To-Noise Ratio, Single Molecule Imaging},
	pages = {2847},
}

@article{heydarian_template-free_2018,
	title = {Template-free {2D} particle fusion in localization microscopy},
	volume = {15},
	issn = {1548-7105},
	doi = {10.1038/s41592-018-0136-6},
	abstract = {Methods that fuse multiple localization microscopy images of a single structure can improve signal-to-noise ratio and resolution, but they generally suffer from template bias or sensitivity to registration errors. We present a template-free particle-fusion approach based on an all-to-all registration that provides robustness against individual misregistrations and underlabeling. We achieved 3.3-nm Fourier ring correlation (FRC) image resolution by fusing 383 DNA origami nanostructures with 80\% labeling density, and 5.0-nm resolution for structures with 30\% labeling density.},
	language = {eng},
	number = {10},
	journal = {Nature Methods},
	author = {Heydarian, Hamidreza and Schueder, Florian and Strauss, Maximilian T. and van Werkhoven, Ben and Fazel, Mohamadreza and Lidke, Keith A. and Jungmann, Ralf and Stallinga, Sjoerd and Rieger, Bernd},
	month = oct,
	year = {2018},
	pmid = {30224671},
	keywords = {DNA, Humans, Image Processing, Computer-Assisted, Microscopy, Fluorescence, Nanostructures, Signal-To-Noise Ratio, Single Molecule Imaging},
	pages = {781--784},
}

@article{endesfelder_simple_2014,
	title = {A simple method to estimate the average localization precision of a single-molecule localization microscopy experiment},
	volume = {141},
	issn = {1432-119X},
	url = {https://doi.org/10.1007/s00418-014-1192-3},
	doi = {10.1007/s00418-014-1192-3},
	abstract = {The localization precision is a crucial and important parameter for single-molecule localization microscopy (SMLM) and directly influences the achievable spatial resolution. It primarily depends on experimental imaging conditions and the registration potency of the algorithm used. We propose a new and simple routine to estimate the average experimental localization precision in SMLM, based on the nearest neighbor analysis. By exploring different experimental and simulated targets, we show that this approach can be generally used for any 2D or 3D SMLM data and that reliable values for the localization precision σSMLM are obtained. Knowing σSMLM is a prerequisite for consistent visualization or any quantitative structural analysis, e.g., cluster analysis or colocalization studies.},
	language = {en},
	number = {6},
	urldate = {2023-05-09},
	journal = {Histochemistry and Cell Biology},
	author = {Endesfelder, Ulrike and Malkusch, Sebastian and Fricke, Franziska and Heilemann, Mike},
	month = jun,
	year = {2014},
	keywords = {Fluorescence microscopy, Localization precision, Resolution, Single-molecule fluorescence, Single-molecule localization microscopy},
	pages = {629--638},
}

@article{gao_detector_2021,
	title = {{DETECTOR}: structural information guided artifact detection for super-resolution fluorescence microscopy image},
	volume = {12},
	issn = {2156-7085},
	shorttitle = {{DETECTOR}},
	doi = {10.1364/BOE.431798},
	abstract = {Super-resolution fluorescence microscopy, with a spatial resolution beyond the diffraction limit of light, has become an indispensable tool to observe subcellular structures at a nanoscale level. To verify that the super-resolution images reflect the underlying structures of samples, the development of robust and reliable artifact detection methods has received widespread attention. However, the existing artifact detection methods are prone to report false alert artifacts because it relies on absolute intensity mismatch between the wide-field image and resolution rescaled super-resolution image. To solve this problem, we proposed DETECTOR, a structural information-guided artifact detection method for super-resolution images. It detects artifacts by computing the structural dissimilarity between the wide-field image and the resolution rescaled super-resolution image. To focus on structural similarity, we introduce a weight mask to weaken the influence of strong autofluorescence background and proposed a structural similarity index for super-resolution images, named MASK-SSIM. Simulations and experimental results demonstrated that compared with the state-of-the-art methods, DETECTOR has advantages in detecting structural artifacts in super-resolution images. It is especially suitable for wide-field images with strong autofluorescence background and super-resolution images of single molecule localization microscopy (SMLM). DETECTOR has extreme sensitivity to the weak signal region. Moreover, DETECTOR can guide data collection and parameter tuning during image reconstruction.},
	language = {eng},
	number = {9},
	journal = {Biomedical Optics Express},
	author = {Gao, Shan and Xu, Fan and Li, Hongjia and Xue, Fudong and Zhang, Mingshu and Xu, Pingyong and Zhang, Fa},
	month = sep,
	year = {2021},
	pmid = {34692213},
	pmcid = {PMC8515955},
	pages = {5751--5769},
}

@article{nozaki_dynamic_2017,
	title = {Dynamic {Organization} of {Chromatin} {Domains} {Revealed} by {Super}-{Resolution} {Live}-{Cell} {Imaging}},
	volume = {67},
	issn = {10972765},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1097276517304458},
	doi = {10.1016/j.molcel.2017.06.018},
	language = {en},
	number = {2},
	urldate = {2023-05-09},
	journal = {Molecular Cell},
	author = {Nozaki, Tadasu and Imai, Ryosuke and Tanbo, Mai and Nagashima, Ryosuke and Tamura, Sachiko and Tani, Tomomi and Joti, Yasumasa and Tomita, Masaru and Hibino, Kayo and Kanemaki, Masato T. and Wendt, Kerstin S. and Okada, Yasushi and Nagai, Takeharu and Maeshima, Kazuhiro},
	month = jul,
	year = {2017},
	pages = {282--293.e7},
}

@article{escoufier_traitement_1973,
	title = {Le {Traitement} des {Variables} {Vectorielles}},
	volume = {29},
	issn = {0006-341X},
	url = {https://www.jstor.org/stable/2529140},
	doi = {10.2307/2529140},
	abstract = {Multivariate statistical techniques are based upon the Hilbert space Structure of the set of random variables with finite variance, and are therefore generalizable to any set having such a structure. In Particular, since certain applications lead to families of vector random variables we are led to the problem of finding the Hilbert space which permits the above generalization to families of vector variables. The inner product which is used possesses theoretical and practical properties which are discussed. An illustrative example is given.},
	number = {4},
	urldate = {2023-05-09},
	journal = {Biometrics},
	author = {Escoufier, Yves},
	year = {1973},
	pages = {751--760},
}

@article{pageon_clus-doc_2016,
	title = {Clus-{DoC}: a combined cluster detection and colocalization analysis for single-molecule localization microscopy data},
	volume = {27},
	issn = {1059-1524},
	shorttitle = {Clus-{DoC}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5221594/},
	doi = {10.1091/mbc.E16-07-0478},
	abstract = {Despite the increasingly widespread use of single-molecule localization microscopy (SMLM) in biology, the extent to which the spatial organization of proteins influences signaling is not easy to quantify. Clus-DoC is a novel analysis method that combines cluster detection and colocalization analysis for SMLM data., Advances in fluorescence microscopy are providing increasing evidence that the spatial organization of proteins in cell membranes may facilitate signal initiation and integration for appropriate cellular responses. Our understanding of how changes in spatial organization are linked to function has been hampered by the inability to directly measure signaling activity or protein association at the level of individual proteins in intact cells. Here we solve this measurement challenge by developing Clus-DoC, an analysis strategy that quantifies both the spatial distribution of a protein and its colocalization status. We apply this approach to the triggering of the T-cell receptor during T-cell activation, as well as to the functionality of focal adhesions in fibroblasts, thereby demonstrating an experimental and analytical workflow that can be used to quantify signaling activity and protein colocalization at the level of individual proteins.},
	number = {22},
	urldate = {2023-05-02},
	journal = {Molecular Biology of the Cell},
	author = {Pageon, Sophie V. and Nicovich, Philip R. and Mollazade, Mahdie and Tabarin, Thibault and Gaus, Katharina},
	month = nov,
	year = {2016},
	pmid = {27582387},
	pmcid = {PMC5221594},
	pages = {3627--3636},
}

@article{ries_smap_2020,
	title = {{SMAP}: a modular super-resolution microscopy analysis platform for {SMLM} data},
	volume = {17},
	copyright = {2020 Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{SMAP}},
	url = {https://www.nature.com/articles/s41592-020-0938-1},
	doi = {10.1038/s41592-020-0938-1},
	language = {en},
	number = {9},
	urldate = {2023-05-01},
	journal = {Nature Methods},
	author = {Ries, Jonas},
	month = sep,
	year = {2020},
	keywords = {Software, Super-resolution microscopy},
	pages = {870--872},
}

@article{murray_taxonomy_2017,
	title = {A taxonomy of visualization tasks for the analysis of biological pathway data},
	volume = {18},
	copyright = {2017 The Author(s)},
	issn = {1471-2105},
	url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-1443-5},
	doi = {10.1186/s12859-016-1443-5},
	abstract = {Understanding complicated networks of interactions and chemical components is essential to solving contemporary problems in modern biology, especially in domains such as cancer and systems research. In these domains, biological pathway data is used to represent chains of interactions that occur within a given biological process. Visual representations can help researchers understand, interact with, and reason about these complex pathways in a number of ways. At the same time, these datasets offer unique challenges for visualization, due to their complexity and heterogeneity. Here, we present taxonomy of tasks that are regularly performed by researchers who work with biological pathway data. The generation of these tasks was done in conjunction with interviews with several domain experts in biology. These tasks require further classification than is provided by existing taxonomies. We also examine existing visualization techniques that support each task, and we discuss gaps in the existing visualization space revealed by our taxonomy. Our taxonomy is designed to support the development and design of future biological pathway visualization applications. We conclude by suggesting future research directions based on our taxonomy and motivated by the comments received by our domain experts.},
	language = {en},
	number = {2},
	urldate = {2023-05-01},
	journal = {BMC Bioinformatics},
	author = {Murray, Paul and McGee, Fintan and Forbes, Angus G.},
	month = feb,
	year = {2017},
	pages = {1--13},
}

@article{marin_pymevisualize_2021,
	title = {{PYMEVisualize}: an open-source tool for exploring {3D} super-resolution data},
	volume = {18},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{PYMEVisualize}},
	url = {https://www.nature.com/articles/s41592-021-01165-9},
	doi = {10.1038/s41592-021-01165-9},
	language = {en},
	number = {6},
	urldate = {2023-05-01},
	journal = {Nature Methods},
	author = {Marin, Zach and Graff, Michael and Barentine, Andrew E. S. and Soeller, Christian and Chung, Kenny Kwok Hin and Fuentes, Lukas A. and Baddeley, David},
	month = jun,
	year = {2021},
	keywords = {Software, Super-resolution microscopy},
	pages = {582--584},
}

@incollection{gudmundsson_geometric_2008,
	address = {Boston, MA},
	title = {Geometric {Spanners}},
	isbn = {9780387301624},
	url = {https://doi.org/10.1007/978-0-387-30162-4_167},
	language = {en},
	urldate = {2023-04-28},
	booktitle = {Encyclopedia of {Algorithms}},
	publisher = {Springer US},
	author = {Gudmundsson, Joachim and Narasimhan, Giri and Smid, Michiel},
	editor = {Kao, Ming-Yang},
	year = {2008},
	doi = {10.1007/978-0-387-30162-4_167},
	pages = {360--364},
}

@article{ritchie_detection_2005,
	title = {Detection of {Non}-{Brownian} {Diffusion} in the {Cell} {Membrane} in {Single} {Molecule} {Tracking}},
	volume = {88},
	issn = {0006-3495},
	url = {https://www.sciencedirect.com/science/article/pii/S0006349505732860},
	doi = {10.1529/biophysj.104.054106},
	abstract = {Molecules undergo non-Brownian diffusion in the plasma membrane, but the mechanism behind this anomalous diffusion is controversial. To characterize the anomalous diffusion in the complex system of the plasma membrane and to understand its underlying mechanism, single-molecule/particle methods that allow researchers to avoid ensemble averaging have turned out to be highly effective. However, the intrinsic problems of time-averaging (resolution) and the frequency of the observations have not been explored. These would not matter for the observations of simple Brownian particles, but they do strongly affect the observation of molecules undergoing anomalous diffusion. We examined these effects on the apparent motion of molecules undergoing simple, totally confined, or hop diffusion, using Monte Carlo simulations of particles undergoing short-term confined diffusion within a compartment and long-term hop diffusion between these compartments, explicitly including the effects of time-averaging during a single frame of the camera (exposure time) and the frequency of observations (frame rate). The intricate relationships of these time-related experimental parameters with the intrinsic diffusion parameters have been clarified, which indicated that by systematically varying the frame time and rate, the anomalous diffusion can be clearly detected and characterized. Based on these results, single-particle tracking of transferrin receptor in the plasma membrane of live PtK2 cells were carried out, varying the frame time between 0.025 and 33ms (0.03–40kHz), which revealed the hop diffusion of the receptor between 47-nm (average) compartments with an average residency time of 1.7ms, with the aid of single fluorescent-molecule video imaging.},
	language = {en},
	number = {3},
	urldate = {2023-04-28},
	journal = {Biophysical Journal},
	author = {Ritchie, Ken and Shan, Xiao-Yuan and Kondo, Junko and Iwasawa, Kokoro and Fujiwara, Takahiro and Kusumi, Akihiro},
	month = mar,
	year = {2005},
	pages = {2266--2277},
}

@article{adler_replicate-based_2008,
	title = {Replicate-based noise corrected correlation for accurate measurements of colocalization},
	volume = {230},
	issn = {1365-2818},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2818.2008.01967.x},
	doi = {10.1111/j.1365-2818.2008.01967.x},
	abstract = {It is widely recognized that the accuracy of colocalization measurements is dependent upon the quality of the source images. We demonstrate that, as the image quality increases, the measured colocalization, using the Pearson and Spearman rank correlation coefficients, approaches the true colocalization asymptotically. This means that in practice it is difficult to obtain images of sufficient quality for accurate measurements. We introduce the replicate-based noise corrected correlation (RBNCC) which aligns the measured colocalization with the true colocalization: a noise measurement is made for each fluorophore from a pair of replicate images, the two noise measurements are combined to generate a correction factor which is applied to the measured colocalization between the two fluorophores. In consequence, accurate measurements can be obtained even with noisy images, making RBNCC especially attractive for live imaging. Even with images of apparently good quality we found an average discrepancy of about 20\% between the measured and corrected colocalization. A case is made for using the Spearman rank coefficient instead of the Pearson coefficient to measure colocalization.},
	language = {en},
	number = {1},
	urldate = {2023-04-20},
	journal = {Journal of Microscopy},
	author = {Adler, J. and Pagakis, S. N. and Parmryd, I.},
	year = {2008},
	keywords = {Correlation, colocalization, confocal microscopy, image analysis, noise, quantification, ranking},
	pages = {121--133},
}

@article{willems_coordinate-based_2022,
	title = {A coordinate-based co-localization index to quantify and visualize spatial associations in single-molecule localization microscopy},
	volume = {12},
	copyright = {2022 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-022-08746-4},
	doi = {10.1038/s41598-022-08746-4},
	abstract = {Visualizing the subcellular distribution of proteins and determining whether specific proteins co-localize is one of the main strategies in determining the organization and potential interactions of protein complexes in biological samples. The development of super-resolution microscopy techniques such as single-molecule localization microscopy (SMLM) has tremendously increased the ability to resolve protein distribution at nanometer resolution. As super-resolution imaging techniques are becoming instrumental in revealing novel biological insights, new quantitative approaches that exploit the unique nature of SMLM datasets are required. Here, we present a new, local density-based algorithm to quantify co-localization in dual-color SMLM datasets. We show that this method is broadly applicable and only requires molecular coordinates and their localization precision as inputs. Using simulated point patterns, we show that this method robustly measures the co-localization in dual-color SMLM datasets, independent of localization density, but with high sensitivity towards local enrichments. We further validated our method using SMLM imaging of the microtubule network in epithelial cells and used it to study the spatial association between proteins at neuronal synapses. Together, we present a simple and easy-to-use, but powerful method to analyze the spatial association of molecules in dual-color SMLM datasets.},
	language = {en},
	number = {1},
	urldate = {2023-04-20},
	journal = {Scientific Reports},
	author = {Willems, Jelmer and MacGillavry, Harold D.},
	month = mar,
	year = {2022},
	keywords = {Fluorescence imaging, Super-resolution microscopy},
	pages = {4676},
}

@article{herce_new_2013,
	title = {New image colocalization coefficient for fluorescence microscopy to quantify (bio-)molecular interactions},
	volume = {249},
	issn = {1365-2818},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jmi.12008},
	doi = {10.1111/jmi.12008},
	abstract = {The spatial relationship, or degree of colocalization, between two or more types of molecules in live cells is commonly detected using fluorescence microscopy. This spatial distribution can be used to estimate the interaction between fluorescently labelled molecules. These interactions are usually quantified by analysing the correlation and/or the overlap between images, using the Pearson's and Manders’ coefficients, respectively. However, the correlation and overlap coefficients are parameters not designed to quantify molecular interactions. Here we propose a new colocalization coefficient specifically designed to quantify the interactions between molecules. In well-defined thermodynamic ensembles, this coefficient can in principle be used to calculate relevant statistical thermodynamic quantities such as binding free energies.},
	language = {en},
	number = {3},
	urldate = {2023-04-20},
	journal = {Journal of Microscopy},
	author = {Herce, H.d. and Casas-Delucchi, C.s. and Cardoso, M.c.},
	year = {2013},
	keywords = {Biomolecules, Colocalization, Confocal Microscopy, Fluorescent Microscopy, High resolution microscopy, Molecular Interactions},
	pages = {184--194},
}

@article{arnold_verifying_2020,
	title = {Verifying molecular clusters by 2-color localization microscopy and significance testing},
	volume = {10},
	copyright = {2020 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-60976-6},
	doi = {10.1038/s41598-020-60976-6},
	abstract = {While single-molecule localization microscopy (SMLM) offers the invaluable prospect to visualize cellular structures below the diffraction limit of light microscopy, its potential has not yet been fully capitalized due to its inherent susceptibility to blinking artifacts. Particularly, overcounting of single molecule localizations has impeded a reliable and sensitive detection of biomolecular nanoclusters. Here we introduce a 2-Color Localization microscopy And Significance Testing Approach (2-CLASTA), providing a parameter-free statistical framework for the qualitative analysis of two-dimensional SMLM data via significance testing methods. 2-CLASTA yields p-values for the null hypothesis of random biomolecular distributions, independent of the blinking behavior of the chosen fluorescent labels. The method is parameter-free and does not require any additional measurements nor grouping of localizations. We validated the method both by computer simulations as well as experimentally, using protein concatemers as a mimicry of biomolecular clustering. As the new approach is not affected by overcounting artifacts, it is able to detect biomolecular clustering of various shapes at high sensitivity down to a level of dimers.},
	language = {en},
	number = {1},
	urldate = {2023-04-20},
	journal = {Scientific Reports},
	author = {Arnold, Andreas M. and Schneider, Magdalena C. and Hüsson, Christoph and Sablatnig, Robert and Brameshuber, Mario and Baumgart, Florian and Schütz, Gerhard J.},
	month = mar,
	year = {2020},
	keywords = {Biophysics, Nanoscale biophysics, Single-molecule biophysics},
	pages = {4230},
}

@article{verzelli_unbiased_2022,
	title = {Unbiased choice of global clustering parameters for single-molecule localization microscopy},
	volume = {12},
	copyright = {2022 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-022-27074-1},
	doi = {10.1038/s41598-022-27074-1},
	abstract = {Single-molecule localization microscopy resolves objects below the diffraction limit of light via sparse, stochastic detection of target molecules. Single molecules appear as clustered detection events after image reconstruction. However, identification of clusters of localizations is often complicated by the spatial proximity of target molecules and by background noise. Clustering results of existing algorithms often depend on user-generated training data or user-selected parameters, which can lead to unintentional clustering errors. Here we suggest an unbiased algorithm (FINDER) based on adaptive global parameter selection and demonstrate that the algorithm is robust to noise inclusion and target molecule density. We benchmarked FINDER against the most common density based clustering algorithms in test scenarios based on experimental datasets. We show that FINDER can keep the number of false positive inclusions low while also maintaining a low number of false negative detections in densely populated regions.},
	language = {en},
	number = {1},
	urldate = {2023-04-19},
	journal = {Scientific Reports},
	author = {Verzelli, Pietro and Nold, Andreas and Sun, Chao and Heilemann, Mike and Schuman, Erin M. and Tchumatchenko, Tatjana},
	month = dec,
	year = {2022},
	keywords = {Computational biology and bioinformatics, Functional clustering, Image processing, Statistical methods},
	pages = {22561},
}

@article{ejdrup_density-based_2022,
	title = {A density-based enrichment measure for assessing colocalization in single-molecule localization microscopy data},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-32064-y},
	doi = {10.1038/s41467-022-32064-y},
	abstract = {Dual-color single-molecule localization microscopy (SMLM) provides unprecedented possibilities for detailed studies of colocalization of different molecular species in a cell. However, the informational richness of the data is not fully exploited by current analysis tools that often reduce colocalization to a single value. Here, we describe a tool specifically designed for determination of co-localization in both 2D and 3D from SMLM data. The approach uses a function that describes the relative enrichment of one molecular species on the density distribution of a reference species. The function reframes the question of colocalization by providing a density-context relevant to multiple biological questions. Moreover, the function visualize enrichment (i.e. colocalization) directly in the images for easy interpretation. We demonstrate the approach’s functionality on both simulated data and cultured neurons, and compare it to current alternative measures. The method is available in a Python function for easy and parameter-free implementation.},
	language = {en},
	number = {1},
	urldate = {2023-04-19},
	journal = {Nature Communications},
	author = {Ejdrup, Aske L. and Lycas, Matthew D. and Lorenzen, Niels and Konomi, Ainoa and Herborg, Freja and Madsen, Kenneth L. and Gether, Ulrik},
	month = jul,
	year = {2022},
	keywords = {Software, Super-resolution microscopy},
	pages = {4388},
}

@article{ankerst_optics_1999,
	title = {{OPTICS}: ordering points to identify the clustering structure},
	volume = {28},
	issn = {0163-5808},
	shorttitle = {{OPTICS}},
	url = {https://dl.acm.org/doi/10.1145/304181.304187},
	doi = {10.1145/304181.304187},
	abstract = {Cluster analysis is a primary method for database mining. It is either used as a stand-alone tool to get insight into the distribution of a data set, e.g. to focus further analysis and data processing, or as a preprocessing step for other algorithms operating on the detected clusters. Almost all of the well-known clustering algorithms require input parameters which are hard to determine but have a significant influence on the clustering result. Furthermore, for many real-data sets there does not even exist a global parameter setting for which the result of the clustering algorithm describes the intrinsic clustering structure accurately. We introduce a new algorithm for the purpose of cluster analysis which does 
              not 
              produce a clustering of a data set explicitly; but instead creates an augmented 
              ordering 
              of the database representing its density-based clustering structure. This cluster-ordering contains information which is equivalent to the density-based clusterings corresponding to a broad range of parameter settings. It is a versatile basis for both automatic and interactive cluster analysis. We show how to automatically and efficiently extract not only 'traditional' clustering information (e.g. representative points, arbitrary shaped clusters), but also the intrinsic clustering structure. For medium sized data sets, the cluster-ordering can be represented graphically and for very large data sets, we introduce an appropriate visualization technique. Both are suitable for interactive exploration of the intrinsic clustering structure offering additional insights into the distribution and correlation of the data.},
	language = {en},
	number = {2},
	urldate = {2023-04-19},
	journal = {ACM SIGMOD Record},
	author = {Ankerst, Mihael and Breunig, Markus M. and Kriegel, Hans-Peter and Sander, Jörg},
	month = jun,
	year = {1999},
	pages = {49--60},
}

@inproceedings{ester_density-based_1996,
	address = {Portland, Oregon},
	series = {{KDD}'96},
	title = {A density-based algorithm for discovering clusters in large spatial databases with noise},
	abstract = {Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLAR-ANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.},
	urldate = {2023-04-19},
	booktitle = {Proceedings of the {Second} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {AAAI Press},
	author = {Ester, Martin and Kriegel, Hans-Peter and Sander, Jörg and Xu, Xiaowei},
	month = aug,
	year = {1996},
	keywords = {arbitrary shape of clusters, clustering algorithms, efficiency on large spatial databases, handling nlj4-275oise},
	pages = {226--231},
}

@article{campello_hierarchical_2015,
	title = {Hierarchical {Density} {Estimates} for {Data} {Clustering}, {Visualization}, and {Outlier} {Detection}},
	volume = {10},
	issn = {1556-4681},
	url = {https://doi.org/10.1145/2733381},
	doi = {10.1145/2733381},
	abstract = {An integrated framework for density-based cluster analysis, outlier detection, and data visualization is introduced in this article. The main module consists of an algorithm to compute hierarchical estimates of the level sets of a density, following Hartigan’s classic model of density-contour clusters and trees. Such an algorithm generalizes and improves existing density-based clustering techniques with respect to different aspects. It provides as a result a complete clustering hierarchy composed of all possible density-based clusters following the nonparametric model adopted, for an infinite range of density thresholds. The resulting hierarchy can be easily processed so as to provide multiple ways for data visualization and exploration. It can also be further postprocessed so that: (i) a normalized score of “outlierness” can be assigned to each data object, which unifies both the global and local perspectives of outliers into a single definition; and (ii) a “flat” (i.e., nonhierarchical) clustering solution composed of clusters extracted from local cuts through the cluster tree (possibly corresponding to different density thresholds) can be obtained, either in an unsupervised or in a semisupervised way. In the unsupervised scenario, the algorithm corresponding to this postprocessing module provides a global, optimal solution to the formal problem of maximizing the overall stability of the extracted clusters. If partially labeled objects or instance-level constraints are provided by the user, the algorithm can solve the problem by considering both constraints violations/satisfactions and cluster stability criteria. An asymptotic complexity analysis, both in terms of running time and memory space, is described. Experiments are reported that involve a variety of synthetic and real datasets, including comparisons with state-of-the-art, density-based clustering and (global and local) outlier detection methods.},
	number = {1},
	urldate = {2023-04-19},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Campello, Ricardo J. G. B. and Moulavi, Davoud and Zimek, Arthur and Sander, Jörg},
	month = jul,
	year = {2015},
	keywords = {Density-based clustering, data visualization, global/local outliers, hierarchical and nonhierarchical clustering, outlier detection, unsupervised and semisupervised clustering},
	pages = {5:1--5:51},
}

@article{schubert_dbscan_2017,
	title = {{DBSCAN} {Revisited}, {Revisited}: {Why} and {How} {You} {Should} ({Still}) {Use} {DBSCAN}},
	volume = {42},
	issn = {0362-5915},
	shorttitle = {{DBSCAN} {Revisited}, {Revisited}},
	url = {https://doi.org/10.1145/3068335},
	doi = {10.1145/3068335},
	abstract = {At SIGMOD 2015, an article was presented with the title “DBSCAN Revisited: Mis-Claim, Un-Fixability, and Approximation” that won the conference’s best paper award. In this technical correspondence, we want to point out some inaccuracies in the way DBSCAN was represented, and why the criticism should have been directed at the assumption about the performance of spatial index structures such as R-trees and not at an algorithm that can use such indexes. We will also discuss the relationship of DBSCAN performance and the indexability of the dataset, and discuss some heuristics for choosing appropriate DBSCAN parameters. Some indicators of bad parameters will be proposed to help guide future users of this algorithm in choosing parameters such as to obtain both meaningful results and good performance. In new experiments, we show that the new SIGMOD 2015 methods do not appear to offer practical benefits if the DBSCAN parameters are well chosen and thus they are primarily of theoretical interest. In conclusion, the original DBSCAN algorithm with effective indexes and reasonably chosen parameter values performs competitively compared to the method proposed by Gan and Tao.},
	number = {3},
	urldate = {2023-04-19},
	journal = {ACM Transactions on Database Systems},
	author = {Schubert, Erich and Sander, Jörg and Ester, Martin and Kriegel, Hans Peter and Xu, Xiaowei},
	month = jul,
	year = {2017},
	keywords = {DBSCAN, density-based clustering, range-search complexity},
	pages = {19:1--19:21},
}

@article{malkusch_coordinate-based_2012,
	title = {Coordinate-based colocalization analysis of single-molecule localization microscopy data},
	volume = {137},
	issn = {1432-119X},
	doi = {10.1007/s00418-011-0880-5},
	abstract = {Colocalization of differently labeled biomolecules is a valuable tool in fluorescence microscopy and can provide information on biomolecular interactions. With the advent of super-resolution microscopy, colocalization analysis is getting closer to molecular resolution, bridging the gap to other technologies such as fluorescence resonance energy transfer. Among these novel microscopic techniques, single-molecule localization-based super-resolution methods offer the advantage of providing single-molecule coordinates that, rather than intensity information, can be used for colocalization analysis. This requires adapting the existing mathematical algorithms for localization microscopy data. Here, we introduce an algorithm for coordinate-based colocalization analysis which is suited for single-molecule super-resolution data. In addition, we present an experimental configuration for simultaneous dual-color imaging together with a robust approach to correct for optical aberrations with an accuracy of a few nanometers. We demonstrate the potential of our approach for cellular structures and for two proteins binding actin filaments.},
	language = {eng},
	number = {1},
	journal = {Histochemistry and Cell Biology},
	author = {Malkusch, Sebastian and Endesfelder, Ulrike and Mondry, Justine and Gelléri, Márton and Verveer, Peter J. and Heilemann, Mike},
	month = jan,
	year = {2012},
	pmid = {22086768},
	keywords = {Algorithms, Cytoskeletal Proteins, HeLa Cells, Humans, Lasers, Microscopy, Fluorescence, Neurofibromin 2},
	pages = {1--10},
}

@article{guo_visualizing_2018,
	title = {Visualizing {Intracellular} {Organelle} and {Cytoskeletal} {Interactions} at {Nanoscale} {Resolution} on {Millisecond} {Timescales}},
	volume = {175},
	issn = {0092-8674},
	url = {https://www.sciencedirect.com/science/article/pii/S0092867418313084},
	doi = {10.1016/j.cell.2018.09.057},
	abstract = {In eukaryotic cells, organelles and the cytoskeleton undergo highly dynamic yet organized interactions capable of orchestrating complex cellular functions. Visualizing these interactions requires noninvasive, long-duration imaging of the intracellular environment at high spatiotemporal resolution and low background. To achieve these normally opposing goals, we developed grazing incidence structured illumination microscopy (GI-SIM) that is capable of imaging dynamic events near the basal cell cortex at 97-nm resolution and 266 frames/s over thousands of time points. We employed multi-color GI-SIM to characterize the fast dynamic interactions of diverse organelles and the cytoskeleton, shedding new light on the complex behaviors of these structures. Precise measurements of microtubule growth or shrinkage events helped distinguish among models of microtubule dynamic instability. Analysis of endoplasmic reticulum (ER) interactions with other organelles or microtubules uncovered new ER remodeling mechanisms, such as hitchhiking of the ER on motile organelles. Finally, ER-mitochondria contact sites were found to promote both mitochondrial fission and fusion.},
	language = {en},
	number = {5},
	urldate = {2023-04-18},
	journal = {Cell},
	author = {Guo, Yuting and Li, Di and Zhang, Siwei and Yang, Yanrui and Liu, Jia-Jia and Wang, Xinyu and Liu, Chong and Milkie, Daniel E. and Moore, Regan P. and Tulu, U. Serdar and Kiehart, Daniel P. and Hu, Junjie and Lippincott-Schwartz, Jennifer and Betzig, Eric and Li, Dong},
	month = nov,
	year = {2018},
	keywords = {GI-SIM, endoplasmic reticulum, high-speed imaging, membrane contact, microtubule dynamic instability, mitochondrial fission and fusion, organelle hitchhiking, super-resolution},
	pages = {1430--1442.e17},
}

@article{datta_fluorescence_2020,
	title = {Fluorescence lifetime imaging microscopy: fundamentals and advances in instrumentation, analysis, and applications},
	volume = {25},
	issn = {1083-3668, 1560-2281},
	shorttitle = {Fluorescence lifetime imaging microscopy},
	url = {https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-25/issue-7/071203/Fluorescence-lifetime-imaging-microscopy--fundamentals-and-advances-in-instrumentation/10.1117/1.JBO.25.7.071203.full},
	doi = {10.1117/1.JBO.25.7.071203},
	abstract = {Significance: Fluorescence lifetime imaging microscopy (FLIM) is a powerful technique to distinguish the unique molecular environment of fluorophores. FLIM measures the time a fluorophore remains in an excited state before emitting a photon, and detects molecular variations of fluorophores that are not apparent with spectral techniques alone. FLIM is sensitive to multiple biomedical processes including disease progression and drug efficacy. Aim: We provide an overview of FLIM principles, instrumentation, and analysis while highlighting the latest developments and biological applications. Approach: This review covers FLIM principles and theory, including advantages over intensity-based fluorescence measurements. Fundamentals of FLIM instrumentation in time- and frequency-domains are summarized, along with recent developments. Image segmentation and analysis strategies that quantify spatial and molecular features of cellular heterogeneity are reviewed. Finally, representative applications are provided including high-resolution FLIM of cell- and organelle-level molecular changes, use of exogenous and endogenous fluorophores, and imaging protein-protein interactions with Förster resonance energy transfer (FRET). Advantages and limitations of FLIM are also discussed. Conclusions: FLIM is advantageous for probing molecular environments of fluorophores to inform on fluorophore behavior that cannot be elucidated with intensity measurements alone. Development of FLIM technologies, analysis, and applications will further advance biological research and clinical assessments.},
	number = {7},
	urldate = {2023-04-18},
	journal = {Journal of Biomedical Optics},
	author = {Datta, Rupsa and Heaster, Tiffany M. and Sharick, Joe T. and Gillette, Amani A. and Skala, Melissa C.},
	month = may,
	year = {2020},
	pages = {071203},
}

@article{sage_super-resolution_2019,
	title = {Super-resolution fight club: assessment of {2D} and {3D} single-molecule localization microscopy software},
	volume = {16},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {Super-resolution fight club},
	url = {https://www.nature.com/articles/s41592-019-0364-4},
	doi = {10.1038/s41592-019-0364-4},
	abstract = {With the widespread uptake of two-dimensional (2D) and three-dimensional (3D) single-molecule localization microscopy (SMLM), a large set of different data analysis packages have been developed to generate super-resolution images. In a large community effort, we designed a competition to extensively characterize and rank the performance of 2D and 3D SMLM software packages. We generated realistic simulated datasets for popular imaging modalities—2D, astigmatic 3D, biplane 3D and double-helix 3D—and evaluated 36 participant packages against these data. This provides the first broad assessment of 3D SMLM software and provides a holistic view of how the latest 2D and 3D SMLM packages perform in realistic conditions. This resource allows researchers to identify optimal analytical software for their experiments, allows 3D SMLM software developers to benchmark new software against the current state of the art, and provides insight into the current limits of the field.},
	language = {en},
	number = {5},
	urldate = {2023-04-18},
	journal = {Nature Methods},
	author = {Sage, Daniel and Pham, Thanh-An and Babcock, Hazen and Lukes, Tomas and Pengo, Thomas and Chao, Jerry and Velmurugan, Ramraj and Herbert, Alex and Agrawal, Anurag and Colabrese, Silvia and Wheeler, Ann and Archetti, Anna and Rieger, Bernd and Ober, Raimund and Hagen, Guy M. and Sibarita, Jean-Baptiste and Ries, Jonas and Henriques, Ricardo and Unser, Michael and Holden, Seamus},
	month = may,
	year = {2019},
	keywords = {Software, Super-resolution microscopy},
	pages = {387--395},
}

@article{thevathasan_nuclear_2019,
	title = {Nuclear pores as versatile reference standards for quantitative superresolution microscopy},
	volume = {16},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-019-0574-9},
	doi = {10.1038/s41592-019-0574-9},
	abstract = {Quantitative fluorescence and superresolution microscopy are often limited by insufficient data quality or artifacts. In this context, it is essential to have biologically relevant control samples to benchmark and optimize the quality of microscopes, labels and imaging conditions. Here, we exploit the stereotypic arrangement of proteins in the nuclear pore complex as in situ reference structures to characterize the performance of a variety of microscopy modalities. We created four genome edited cell lines in which we endogenously labeled the nucleoporin Nup96 with mEGFP, SNAP-tag, HaloTag or the photoconvertible fluorescent protein mMaple. We demonstrate their use (1) as three-dimensional resolution standards for calibration and quality control, (2) to quantify absolute labeling efficiencies and (3) as precise reference standards for molecular counting. These cell lines will enable the broader community to assess the quality of their microscopes and labels, and to perform quantitative, absolute measurements.},
	language = {en},
	number = {10},
	urldate = {2023-04-18},
	journal = {Nature Methods},
	author = {Thevathasan, Jervis Vermal and Kahnwald, Maurice and Cieśliński, Konstanty and Hoess, Philipp and Peneti, Sudheer Kumar and Reitberger, Manuel and Heid, Daniel and Kasuba, Krishna Chaitanya and Hoerner, Sarah Janice and Li, Yiming and Wu, Yu-Le and Mund, Markus and Matti, Ulf and Pereira, Pedro Matos and Henriques, Ricardo and Nijmeijer, Bianca and Kueblbeck, Moritz and Sabinina, Vilma Jimenez and Ellenberg, Jan and Ries, Jonas},
	month = oct,
	year = {2019},
	keywords = {Confocal microscopy, Microscopy, Super-resolution microscopy, Wide-field fluorescence microscopy},
	pages = {1045--1053},
}

@article{fei_quantitative_2017,
	title = {Quantitative analysis of multilayer organization of proteins and {RNA} in nuclear speckles at super resolution},
	volume = {130},
	issn = {0021-9533},
	url = {https://doi.org/10.1242/jcs.206854},
	doi = {10.1242/jcs.206854},
	abstract = {Nuclear speckles are self-assembled organelles composed of RNAs and proteins. They are proposed to act as structural domains that control distinct steps in gene expression, including transcription, splicing and mRNA export. Earlier studies identified differential localization of a few components within the speckles. It was speculated that the spatial organization of speckle components might contribute directly to the order of operations that coordinate distinct processes. Here, by performing multi-color structured illumination microscopy, we characterized the multilayer organization of speckles at a higher resolution. We found that SON and SC35 (also known as SRSF2) localize to the central region of the speckle, whereas MALAT1 and small nuclear (sn)RNAs are enriched at the speckle periphery. Coarse-grained simulations indicate that the non-random organization arises due to the interplay between favorable sequence-encoded intermolecular interactions of speckle-resident proteins and RNAs. Finally, we observe positive correlation between the total amount of RNA present within a speckle and the speckle size. These results imply that speckle size may be regulated to accommodate RNA accumulation and processing. Accumulation of RNA from various actively transcribed speckle-associated genes could contribute to the observed speckle size variations within a single cell.},
	number = {24},
	urldate = {2023-04-18},
	journal = {Journal of Cell Science},
	author = {Fei, Jingyi and Jadaliha, Mahdieh and Harmon, Tyler S. and Li, Isaac T. S. and Hua, Boyang and Hao, Qinyu and Holehouse, Alex S. and Reyer, Matthew and Sun, Qinyu and Freier, Susan M. and Pappu, Rohit V. and Prasanth, Kannanganattu V. and Ha, Taekjip},
	month = dec,
	year = {2017},
	pages = {4180--4192},
}

@article{horl_bigstitcher_2019,
	title = {{BigStitcher}: reconstructing high-resolution image datasets of cleared and expanded samples},
	volume = {16},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{BigStitcher}},
	url = {https://www.nature.com/articles/s41592-019-0501-0},
	doi = {10.1038/s41592-019-0501-0},
	abstract = {Light-sheet imaging of cleared and expanded samples creates terabyte-sized datasets that consist of many unaligned three-dimensional image tiles, which must be reconstructed before analysis. We developed the BigStitcher software to address this challenge. BigStitcher enables interactive visualization, fast and precise alignment, spatially resolved quality estimation, real-time fusion and deconvolution of dual-illumination, multitile, multiview datasets. The software also compensates for optical effects, thereby improving accuracy and enabling subsequent biological analysis.},
	language = {en},
	number = {9},
	urldate = {2023-04-18},
	journal = {Nature Methods},
	author = {Hörl, David and Rojas Rusak, Fabio and Preusser, Friedrich and Tillberg, Paul and Randel, Nadine and Chhetri, Raghav K. and Cardona, Albert and Keller, Philipp J. and Harz, Hartmann and Leonhardt, Heinrich and Treier, Mathias and Preibisch, Stephan},
	month = sep,
	year = {2019},
	keywords = {Image processing, Light-sheet microscopy, Software},
	pages = {870--874},
}

@article{belthangady_applications_2019,
	title = {Applications, promises, and pitfalls of deep learning for fluorescence image reconstruction},
	volume = {16},
	copyright = {2019 Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-019-0458-z},
	doi = {10.1038/s41592-019-0458-z},
	abstract = {Deep learning is becoming an increasingly important tool for image reconstruction in fluorescence microscopy. We review state-of-the-art applications such as image restoration and super-resolution imaging, and discuss how the latest deep learning research could be applied to other image reconstruction tasks. Despite its successes, deep learning also poses substantial challenges and has limits. We discuss key questions, including how to obtain training data, whether discovery of unknown structures is possible, and the danger of inferring unsubstantiated image details.},
	language = {en},
	number = {12},
	urldate = {2023-04-18},
	journal = {Nature Methods},
	author = {Belthangady, Chinmay and Royer, Loic A.},
	month = dec,
	year = {2019},
	keywords = {Confocal microscopy, Fluorescence imaging, Wide-field fluorescence microscopy},
	pages = {1215--1225},
}

@article{nir_walking_2018,
	title = {Walking along chromosomes with super-resolution imaging, contact maps, and integrative modeling},
	volume = {14},
	issn = {1553-7404},
	url = {https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1007872},
	doi = {10.1371/journal.pgen.1007872},
	abstract = {Chromosome organization is crucial for genome function. Here, we present a method for visualizing chromosomal DNA at super-resolution and then integrating Hi-C data to produce three-dimensional models of chromosome organization. Using the super-resolution microscopy methods of OligoSTORM and OligoDNA-PAINT, we trace 8 megabases of human chromosome 19, visualizing structures ranging in size from a few kilobases to over a megabase. Focusing on chromosomal regions that contribute to compartments, we discover distinct structures that, in spite of considerable variability, can predict whether such regions correspond to active (A-type) or inactive (B-type) compartments. Imaging through the depths of entire nuclei, we capture pairs of homologous regions in diploid cells, obtaining evidence that maternal and paternal homologous regions can be differentially organized. Finally, using restraint-based modeling to integrate imaging and Hi-C data, we implement a method–integrative modeling of genomic regions (IMGR)–to increase the genomic resolution of our traces to 10 kb.},
	language = {en},
	number = {12},
	urldate = {2023-04-18},
	journal = {PLOS Genetics},
	author = {Nir, Guy and Farabella, Irene and Estrada, Cynthia Pérez and Ebeling, Carl G. and Beliveau, Brian J. and Sasaki, Hiroshi M. and Lee, S. Dean and Nguyen, Son C. and McCole, Ruth B. and Chattoraj, Shyamtanu and Erceg, Jelena and Abed, Jumana AlHaj and Martins, Nuno M. C. and Nguyen, Huy Q. and Hannan, Mohammed A. and Russell, Sheikh and Durand, Neva C. and Rao, Suhas S. P. and Kishi, Jocelyn Y. and Soler-Vila, Paula and Pierro, Michele Di and Onuchic, José N. and Callahan, Steven P. and Schreiner, John M. and Stuckey, Jeff A. and Yin, Peng and Aiden, Erez Lieberman and Marti-Renom, Marc A. and Wu, C.-ting},
	month = dec,
	year = {2018},
	keywords = {Chromosome mapping, Chromosome structure and function, Chromosome walking, Genomics, Homologous chromosomes, Imaging techniques, Invertebrate genomics, Structural genomics},
	pages = {e1007872},
}

@article{hansel_advances_2020,
	title = {Advances in high-resolution microscopy for the study of intracellular interactions with biomaterials},
	volume = {226},
	issn = {0142-9612},
	url = {https://www.sciencedirect.com/science/article/pii/S0142961219305058},
	doi = {10.1016/j.biomaterials.2019.119406},
	abstract = {The study of sophisticated biomaterials and their cellular targets requires visualization methods with exquisite spatial and temporal resolution to discern cell organelles and molecular events. Monitoring cell-material interactions at high resolution is key for the continued development and optimization of biomaterials, for monitoring cell uptake of cargo, and for understanding the cell response to extracellular cues. This review evaluates the advantages and disadvantages of different forms of electron microscopy and super-resolution microscopy in elucidating how biomaterial surface chemistry and topography can affect intracellular events at the nanoscale.},
	language = {en},
	urldate = {2023-04-18},
	journal = {Biomaterials},
	author = {Hansel, Catherine S. and Holme, Margaret N. and Gopal, Sahana and Stevens, Molly M.},
	month = jan,
	year = {2020},
	keywords = {Cell-material interactions, Electron microscopy, Super-resolution microscopy},
	pages = {119406},
}

@article{Poljsak2011,
	title = {Strategies for reducing or preventing the generation of oxidative stress},
	volume = {2011},
	issn = {19420900},
	doi = {10.1155/2011/194586},
	abstract = {The reduction of oxidative stress could be achieved in three levels: by lowering exposure to environmental pollutants with oxidizing properties, by increasing levels of endogenous and exogenous antioxidants, or by lowering the generation of oxidative stress by stabilizing mitochondrial energy production and efficiency. Endogenous oxidative stress could be influenced in two ways: by prevention of ROS formation or by quenching of ROS with antioxidants. However, the results of epidemiological studies where people were treated with synthetic antioxidants are inconclusive and contradictory. Recent evidence suggests that antioxidant supplements (although highly recommended by the pharmaceutical industry and taken by many individuals) do not offer sufficient protection against oxidative stress, oxidative damage or increase the lifespan. The key to the future success of decreasing oxidative-stress-induced damage should thus be the suppression of oxidative damage without disrupting the wellintegrated antioxidant defense network. Approach to neutralize free radicals with antioxidants should be changed into prevention of free radical formation. Thus, this paper addresses oxidative stress and strategies to reduce it with the focus on nutritional and psychosocial interventions of oxidative stress prevention, that is, methods to stabilize mitochondria structure and energy efficiency, or approaches which would increase endogenous antioxidative protection and repair systems. Copyright © 2011 B. Poljsak.},
	number = {1},
	journal = {Oxidative Medicine and Cellular Longevity},
	author = {Poljsak, B.},
	year = {2011},
	pmid = {22191011},
	keywords = {★},
	pages = {1},
}

@article{martins_contacts_2018,
	title = {Contacts in {Death}: {The} {Role} of the {ER}-{Mitochondria} {Axis} in {Acetic} {Acid}-{Induced} {Apoptosis} in {Yeast}},
	volume = {1},
	issn = {0022-2836},
	url = {https://www.sciencedirect.com/science/article/pii/S0022283618309331?dgcid=raven_sd_aip_email},
	doi = {10.1016/J.JMB.2018.11.002},
	abstract = {Endoplasmic reticulum-mitochondria contact sites (ER-MCS) have been a subject of increasing scientific interest since the discovery that these structures are disrupted in several pathologies. Due to the emerging data that correlates ER-MCS function to known events of the apoptotic program, we aimed to dissect this interplay using our well-established model of acetic acid-induced apoptosis in Saccharomyces cerevisiae. Until recently, the only known tethering complex between ER and mitochondria in this organism was the ER-mitochondria encounter structure (ERMES). Following our results from a screening designed to identify genes whose deletion rendered cells with an altered sensitivity to acetic acid, we hypothesized that the ERMES complex could be involved in cell death mediated by this stressor. Herein we demonstrate that single ablation of the ERMES components Mdm10p, Mdm12p and Mdm34p increases the resistance of S. cerevisiae to acetic acid-induced apoptosis, which is associated with a prominent delay in the appearance of several apoptotic markers. Moreover, abrogation of Mdm10p or Mdm34p abolished cytochrome c release from mitochondria. Since these two proteins are embedded in the mitochondrial outer membrane, we propose that the ERMES complex plays a part in cytochrome c release, a key event of the apoptotic cascade. In all, these findings will aid in targeted therapies for diseases where apoptosis is disrupted, as well as assist in the development of acetic acid-resistant strains for industrial processes.},
	number = {1},
	urldate = {2018-11-09},
	journal = {Journal of Molecular Biology},
	author = {Martins, Vítor M. and Fernandes, Tânia R. and Afonso, Catarina B. and Lopes, Diana and Domingues, Maria R.M. and Côrte-Real, Manuela and Sousa, Maria J.},
	month = nov,
	year = {2018},
	note = {Publisher: Academic Press},
	pages = {1},
}

@misc{xu_isotropic_2020,
	title = {Isotropic {3D} electron microscopy reference library of whole cells and tissues},
	abstract = {Understanding cellular architecture is essential for understanding biology. Electron microscopy (EM) uniquely visualizes cellular structure with nanometer resolution. However, traditional methods, such as thin-section EM or EM tomography, have limitations inasmuch as they only visualize a single slice or a relatively small volume of the cell, respectively. Here, we overcome these limitations by imaging whole cells and tissues with enhanced Focus Ion Beam Scanning Electron Microscopy (FIB-SEM) in high resolution with month-long acquisition duration. We use this approach to generate reference 3D image datasets at 4-nm isotropic voxels for ten different examples, including cultured cells (cancer, macrophages, and T-cells) as well as tissues (mouse pancreatic islets and the Drosophila fan-shaped body). We open access to all datasets in OpenOrganelle , an interactive web platform that allows accessing both the original 3D EM data, and subsequent organelle segmentation. Together, these data will serve as a reference library to explore comprehensive quantification of whole cells and their constituents, thus addressing questions related to cell identities, cell morphologies, cell-cell interactions, as well as intracellular organelle organization and structure.},
	author = {Xu, Shan and Pang, Song and Shtengel, Gleb and Müller, Andreas and Ritter, Alex and {Hoffman} and Takemura, Shin-ya and Lu, Zhiyuan and Pasolli, H and Iyer, Nirmala and Chung, Jeeyun and Bennett, Davis and Weigel, Aubrey and Walther, Tobias and Farese, Robert and Engelenburg, Schuyler and Mellman, Ira and Solimena, Michele and Hess, Harald},
	month = nov,
	year = {2020},
	doi = {10.1101/2020.11.13.382457},
}

@misc{lin_pytorch_2021,
	title = {{PyTorch} {Connectomics}: {A} {Scalable} and {Flexible} {Segmentation} {Framework} for {EM} {Connectomics}},
	shorttitle = {{PyTorch} {Connectomics}},
	url = {http://arxiv.org/abs/2112.05754},
	doi = {10.48550/arXiv.2112.05754},
	abstract = {We present PyTorch Connectomics (PyTC), an open-source deep-learning framework for the semantic and instance segmentation of volumetric microscopy images, built upon PyTorch. We demonstrate the effectiveness of PyTC in the field of connectomics, which aims to segment and reconstruct neurons, synapses, and other organelles like mitochondria at nanometer resolution for understanding neuronal communication, metabolism, and development in animal brains. PyTC is a scalable and flexible toolbox that tackles datasets at different scales and supports multi-task and semi-supervised learning to better exploit expensive expert annotations and the vast amount of unlabeled data during training. Those functionalities can be easily realized in PyTC by changing the configuration options without coding and adapted to other 2D and 3D segmentation tasks for different tissues and imaging modalities. Quantitatively, our framework achieves the best performance in the CREMI challenge for synaptic cleft segmentation (outperforms existing best result by relatively 6.1\${\textbackslash}\%\$) and competitive performance on mitochondria and neuronal nuclei segmentation. Code and tutorials are publicly available at https://connectomics.readthedocs.io.},
	urldate = {2023-04-18},
	publisher = {arXiv},
	author = {Lin, Zudi and Wei, Donglai and Lichtman, Jeff and Pfister, Hanspeter},
	month = dec,
	year = {2021},
	note = {arXiv:2112.05754 [cs, eess, q-bio]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Quantitative Biology - Quantitative Methods},
}

@article{siemons_axial_2022,
	title = {Axial accuracy in localization microscopy with {3D} point spread function engineering},
	volume = {30},
	copyright = {© 2022 Optica Publishing Group},
	issn = {1094-4087},
	url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-30-16-28290},
	doi = {10.1364/OE.461750},
	abstract = {Single-molecule localization microscopy has developed into a widely used technique to overcome the diffraction limit and enables 3D localization of single-emitters with nanometer precision. A widely used method to enable 3D encoding is to use a cylindrical lens or a phase mask to engineer the point spread function (PSF). The performance of these PSFs is often assessed by comparing the precision they achieve, ignoring accuracy. Nonetheless, accurate localization is required in many applications, such as multi-plane imaging, measuring and modelling of physical processes based on volumetric data, and 3D particle averaging. However, there are PSF model mismatches in the localization schemes due to how reference PSFs are obtained, look-up-tables are created, or spots are fitted. Currently there is little insight in how these model mismatches give rise to systematic axial localization errors, how large these errors are, and how to mitigate them. In this theoretical and simulation work we use a vector PSF model, which incorporates super-critical angle fluorescence (SAF) and the appropriate aplanatic correction factor, to analyze the errors in z-localization. We introduce theory for defining the focal plane in SAF conditions and analyze the predicted axial errors for an astigmatic PSF, double-helix PSF, and saddle-point PSF. These simulations indicate that the absolute axial biases can be as large as 140 nm, 250 nm, and 120 nm for the astigmatic, saddle-point, and double-helix PSF respectively, with relative errors of more than 50\%. Finally, we discuss potential experimental methods to verify these findings and propose a workflow to mitigate these effects.},
	language = {EN},
	number = {16},
	urldate = {2023-04-18},
	journal = {Optics Express},
	author = {Siemons, Marijn E. and Kapitein, Lukas C. and Stallinga, Sjoerd},
	month = aug,
	year = {2022},
	keywords = {Cylindrical lenses, Diffraction limit, Fresnel reflection, Phase retrieval, Refractive index, Three dimensional microscopy},
	pages = {28290--28300},
}

@article{coles_characterisation_2016,
	title = {Characterisation of the effects of optical aberrations in single molecule techniques},
	volume = {7},
	copyright = {© 2016 Optical Society of America},
	issn = {2156-7085},
	url = {https://opg.optica.org/boe/abstract.cfm?uri=boe-7-5-1755},
	doi = {10.1364/BOE.7.001755},
	abstract = {Optical aberrations degrade image quality in fluorescence microscopy, including for single-molecule based techniques. These depend on post-processing to localize individual molecules in an image series. Using simulated data, we show the impact of optical aberrations on localization success, accuracy and precision. The peak intensity and the proportion of successful localizations strongly reduces when the aberration strength is greater than 1.0 rad RMS, while the precision of each of those localisations is halved. The number of false-positive localisations exceeded 10\% of the number of true-positive localisations at an aberration strength of only {\textasciitilde}0.6 rad RMS when using the ThunderSTORM package, but at greater than 1.0 rad RMS with the Radial Symmetry package. In the presence of coma, the localization error reaches 100 nm at {\textasciitilde}0.6 rad RMS of aberration strength. The impact of noise and of astigmatism for axial resolution are also considered. Understanding the effect of aberrations is crucial when deciding whether the addition of adaptive optics to a single-molecule microscope could significantly increase the information obtainable from an image series.},
	language = {EN},
	number = {5},
	urldate = {2023-04-18},
	journal = {Biomedical Optics Express},
	author = {Coles, Benjamin C. and Webb, Stephen E. D. and Schwartz, Noah and Rolfe, Daniel J. and Martin-Fernandez, Marisa and Schiavo, Valentina Lo},
	month = may,
	year = {2016},
	keywords = {Adaptive optics, Image quality, Imaging techniques, Laser guide stars, Optical aberrations, Three dimensional imaging},
	pages = {1755--1767},
}

@article{jensen_correction_2022,
	title = {Correction of multiple-blinking artifacts in photoactivated localization microscopy},
	volume = {19},
	issn = {1548-7105},
	doi = {10.1038/s41592-022-01463-w},
	abstract = {Photoactivated localization microscopy (PALM) produces an array of localization coordinates by means of photoactivatable fluorescent proteins. However, observations are subject to fluorophore multiple blinking and each protein is included in the dataset an unknown number of times at different positions, due to localization error. This causes artificial clustering to be observed in the data. We present a 'model-based correction' (MBC) workflow using calibration-free estimation of blinking dynamics and model-based clustering to produce a corrected set of localization coordinates representing the true underlying fluorophore locations with enhanced localization precision, outperforming the state of the art. The corrected data can be reliably tested for spatial randomness or analyzed by other clustering approaches, and descriptors such as the absolute number of fluorophores per cluster are now quantifiable, which we validate with simulated data and experimental data with known ground truth. Using MBC, we confirm that the adapter protein, the linker for activation of T cells, is clustered at the T cell immunological synapse.},
	language = {eng},
	number = {5},
	journal = {Nature Methods},
	author = {Jensen, Louis G. and Hoh, Tjun Yee and Williamson, David J. and Griffié, Juliette and Sage, Daniel and Rubin-Delanchy, Patrick and Owen, Dylan M.},
	month = may,
	year = {2022},
	pmid = {35545712},
	pages = {594--602},
}

@misc{dawoud_edge-based_2022,
	title = {Edge-{Based} {Self}-{Supervision} for {Semi}-{Supervised} {Few}-{Shot} {Microscopy} {Image} {Cell} {Segmentation}},
	url = {http://arxiv.org/abs/2208.02105},
	doi = {10.48550/arXiv.2208.02105},
	abstract = {Deep neural networks currently deliver promising results for microscopy image cell segmentation, but they require large-scale labelled databases, which is a costly and time-consuming process. In this work, we relax the labelling requirement by combining self-supervised with semi-supervised learning. We propose the prediction of edge-based maps for self-supervising the training of the unlabelled images, which is combined with the supervised training of a small number of labelled images for learning the segmentation task. In our experiments, we evaluate on a few-shot microscopy image cell segmentation benchmark and show that only a small number of annotated images, e.g. 10\% of the original training set, is enough for our approach to reach similar performance as with the fully annotated databases on 1- to 10-shots. Our code and trained models is made publicly available},
	urldate = {2023-04-18},
	publisher = {arXiv},
	author = {Dawoud, Youssef and Ernst, Katharina and Carneiro, Gustavo and Belagiannis, Vasileios},
	month = aug,
	year = {2022},
	note = {arXiv:2208.02105 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{he_effects_2022,
	title = {Effects of optical aberrations on localization of {MINFLUX} super-resolution microscopy},
	volume = {30},
	copyright = {© 2022 Optica Publishing Group},
	issn = {1094-4087},
	url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-30-26-46849},
	doi = {10.1364/OE.475425},
	abstract = {A novel super-resolution imaging technique based on the minimum photon flux (MINFLUX), can achieve nanometer-scale localization precision and sub-5-nm imaging. However, aberrations can affect the localization performance and degrade the quality of reconstructed images. In this study, we analyze the effects of different low-order aberrations on the MINFLUX system through both theoretical limits and Monte Carlo methods. We report that 1) defocus and spherical aberration have little effect on 2D localization performance, whereas astigmatism and coma have significant negative effects; 2) system aberrations that can be measured in advance cause changes primarily in the magnitude and angular uniformity of localization precision, whereas sample-induced aberrations that cannot be a priori introduce large biases and reduce localization accuracy.},
	language = {EN},
	number = {26},
	urldate = {2023-04-18},
	journal = {Optics Express},
	author = {He, Chenying and Zhan, Zhengyi and Li, Chuankang and Sun, Xiaofan and Liu, Yong and Kuang, Cuifang and Liu, Xu},
	month = dec,
	year = {2022},
	keywords = {Chromatic aberrations, High numerical aperture optics, Image quality, Optical aberrations, Optical standards, Spherical aberrations},
	pages = {46849--46860},
}

@misc{noauthor_effects_nodate,
	title = {Effects of optical aberrations on localization of {MINFLUX} super-resolution microscopy},
	url = {https://opg.optica.org/oe/fulltext.cfm?uri=oe-30-26-46849&id=522826},
	urldate = {2023-04-18},
}

@article{wester_robust_2021,
	title = {Robust, fiducial-free drift correction for super-resolution imaging},
	volume = {11},
	copyright = {2021 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-02850-7},
	doi = {10.1038/s41598-021-02850-7},
	abstract = {We describe a robust, fiducial-free method of drift correction for use in single molecule localization-based super-resolution methods. The method combines periodic 3D registration of the sample using brightfield images with a fast post-processing algorithm that corrects residual registration errors and drift between registration events. The method is robust to low numbers of collected localizations, requires no specialized hardware, and provides stability and drift correction for an indefinite time period.},
	language = {en},
	number = {1},
	urldate = {2023-04-18},
	journal = {Scientific Reports},
	author = {Wester, Michael J. and Schodt, David J. and Mazloom-Farsibaf, Hanieh and Fazel, Mohamadreza and Pallikkuth, Sandeep and Lidke, Keith A.},
	month = dec,
	year = {2021},
	keywords = {Nanoscale biophysics, Single-molecule biophysics, Super-resolution microscopy},
	pages = {23672},
}

@misc{noauthor_reassessing_nodate,
	title = {Reassessing the {Revolution}’s {Resolutions} {\textbar} {bioRxiv}},
	url = {https://www.biorxiv.org/content/10.1101/224402v1},
	urldate = {2023-04-18},
}

@article{tawn_modelling_1990,
	title = {Modelling multivariate extreme value distributions},
	volume = {77},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/77.2.245},
	doi = {10.1093/biomet/77.2.245},
	abstract = {Multivariate extreme value distributions arise as the limiting joint distribution of normalized componentwise maxima/minima. No parametric family exists for the dependence between the margins. This paper extends to more than two variables the models and results for the bivariate case obtained by Tawn (1988). Two new families of physically motivated parametric models for the dependence structure are presented and are illustrated with an application to trivariate extreme sea level data.},
	number = {2},
	urldate = {2023-04-17},
	journal = {Biometrika},
	author = {TAWN, JONATHAN A.},
	month = jun,
	year = {1990},
	pages = {245--253},
}

@incollection{de_haan_basic_2006,
	address = {New York, NY},
	series = {Springer {Series} in {Operations} {Research} and {Financial} {Engineering}},
	title = {Basic {Theory}},
	isbn = {9780387344713},
	url = {https://link.springer.com/book/10.1007/0-387-34471-3},
	abstract = {In order to see the usefulness of developing multivariate extremes we start with a problem for which multivariate extreme value theory seems to be relevant.},
	language = {en},
	urldate = {2023-04-17},
	booktitle = {Extreme {Value} {Theory}: {An} {Introduction}},
	publisher = {Springer},
	editor = {de Haan, Laurens and Ferreira, Ana},
	year = {2006},
	keywords = {Finite Measure, Limit Distribution, Marginal Distribution, Random Vector, Spectral Measure},
	pages = {207--233},
}

@article{irgen-gioro_fixation_2022,
	title = {Fixation can change the appearance of phase separation in living cells},
	volume = {11},
	issn = {2050-084X},
	url = {https://elifesciences.org/articles/79903},
	doi = {10.7554/eLife.79903},
	abstract = {Fixing cells with paraformaldehyde (PFA) is an essential step in numerous biological techniques as it is thought to preserve a snapshot of biomolecular transactions in living cells. Fixed-cell imaging techniques such as immunofluorescence have been widely used to detect liquid–liquid phase separation (LLPS) in vivo. Here, we compared images, before and after fixation, of cells expressing intrinsically disordered proteins that are able to undergo LLPS. Surprisingly, we found that PFA fixation can both enhance and diminish putative LLPS behaviors. For specific proteins, fixation can even cause their droplet-like puncta to artificially appear in cells that do not have any detectable puncta in the live condition. Fixing cells in the presence of glycine, a molecule that modulates fixation rates, can reverse the fixation effect from enhancing to diminishing LLPS appearance. We further established a kinetic model of fixation in the context of dynamic protein–protein interactions. Simulations based on the model suggest that protein localization in fixed cells depends on an intricate balance of protein–protein interaction dynamics, the overall rate of fixation, and notably, the difference between fixation rates of different proteins. Consistent with simulations, live-cell single-molecule imaging experiments showed that a fast overall rate of fixation relative to protein–protein interaction dynamics can minimize fixation artifacts. Our work reveals that PFA fixation changes the appearance of LLPS from living cells, presents a caveat in studying LLPS using fixation-based methods, and suggests a mechanism underlying the fixation artifact. 
          ,  
            A typical human cell is a crowded soup of thousands of different proteins. One way that the cell organizes this complex mix of contents is by creating separate droplets within the cell, like oil in water. These droplets can form through a process known as liquid-liquid phase separation, or LLPS, where specific proteins gather in high concentrations to carry out their cellular roles. 
            The critical role of LLPS in cellular organization means that it is widely studied by biologists. To detect LLPS, researchers often subject the cells to treatments designed to hold all the proteins in place, creating a snapshot of their natural state. This process, known as fixing, allows scientists to easily label a protein with a fluorescent tag, take pictures of the cells, and look at whether the protein forms droplets in its natural state. This is often easier to do than imaging cells live, but it relies on LLPS being well-preserved upon fixation. 
            To test if this is true, Irgen-Gioro, Yoshida et al. looked at protein droplets in live cells, and then fixed the cells to check whether the appearance of the droplets had changed. The images taken showed that fixation could alter the size and number of droplets depending on the protein being studied. To explain why the effects of fixing change depending on the protein, Irgen-Gioro, Yoshida et al. hypothesized that a faster fixation – relative to how quickly proteins can bind and unbind to their droplets – can better preserve the LLPS droplets. They verified their idea using a microscopy technique in which they imaged single molecules, allowing them to see how different fixation speeds relative to protein binding affected the droplets. 
            The work of Irgen-Gioro, Yoshida et al. identifies an important caveat to using fixation for the study of LLPS in cells. Their findings suggest that researchers should be cautious when interpreting the results of such studies. Given that LLPS in cells is an area of research with a lot of interest, these results could benefit a broad range of biological and medical fields. In the future, Irgen-Gioro, Yoshida et al.’s findings could prompt scientists to develop new fixing methods that better preserve LLPS in cells.},
	language = {en},
	urldate = {2023-04-17},
	journal = {eLife},
	author = {Irgen-Gioro, Shawn and Yoshida, Shawn and Walling, Victoria and Chong, Shasha},
	month = nov,
	year = {2022},
	pages = {e79903},
}

@article{zanforlin_optical_2022,
	title = {Optical quantum super-resolution imaging and hypothesis testing},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-32977-8},
	doi = {10.1038/s41467-022-32977-8},
	abstract = {Estimating the angular separation between two incoherent thermal sources is a challenging task for direct imaging, especially at lengths within the diffraction limit. Moreover, detecting the presence of multiple sources of different brightness is an even more severe challenge. We experimentally demonstrate two tasks for super-resolution imaging based on hypothesis testing and quantum metrology techniques. We can significantly reduce the error probability for detecting a weak secondary source, even for small separations. We reduce the experimental complexity to a simple interferometer: we show (1) our set-up is optimal for the state discrimination task, and (2) if the two sources are equally bright, then this measurement can super-resolve their angular separation. Using a collection baseline of 5.3 mm, we resolve the angular separation of two sources placed 15 μm apart at a distance of 1.0 m with a 1.7\% accuracy - an almost 3-orders-of-magnitude improvement over shot-noise limited direct imaging.},
	language = {en},
	number = {1},
	urldate = {2023-04-17},
	journal = {Nature Communications},
	author = {Zanforlin, Ugo and Lupo, Cosmo and Connolly, Peter W. R. and Kok, Pieter and Buller, Gerald S. and Huang, Zixin},
	month = sep,
	year = {2022},
	keywords = {Imaging and sensing, Quantum metrology, Quantum optics},
	pages = {5373},
}

@book{stokes_effect_2009,
	address = {Cambridge},
	series = {Cambridge {Library} {Collection} - {Mathematics}},
	title = {On the {Effect} of the {Internal} {Friction} of {Fluids} on the {Motion} of {Pendulums}},
	volume = {3},
	url = {https://www.cambridge.org/core/books/mathematical-and-physical-papers/on-the-effect-of-the-internal-friction-of-fluids-on-the-motion-of-pendulums/11038EBC1E2D897D9E5B1297C9AE5D99},
	abstract = {The great importance of the results obtained by means of the pendulum has induced philosophers to devote so much attention to the subject, and to perform the experiments with such a scrupulous regard to accuracy in every particular, that pendulum observations may justly be ranked among those most distinguished by modern exactness. It is unnecessary here to enumerate the different methods which have been employed, and the several corrections which must be made, in order to deduce from the actual observations the result which would correspond to the ideal case of a simple pendulum performing indefinitely small oscillations in vacuum. There is only one of these corrections which bears on the subject of the present paper, namely, the correction usually termed the reduction to a vacuum. On account of the inconvenience and expense attending experiments in a vacuum apparatus, the observations are usually made in air, and it then becomes necessary to apply a small correction, in order to reduce the observed result to what would have been observed had the pendulum been swung in a vacuum. The most obvious effect of the air consists in a diminution of the moving force, and consequent increase in the time of vibration, arising from the buoyancy of the fluid. The correction for buoyancy is easily calculated from the first principles of hydrostatics, and formed for a considerable time the only correction which it was thought necessary to make for reduction to a vacuum.},
	urldate = {2023-02-14},
	publisher = {Cambridge University Press},
	editor = {Stokes, George Gabriel},
	year = {2009},
	doi = {10.1017/CBO9780511702266.002},
}

@phdthesis{martos_statistical_2015,
	title = {Statistical {Distances} and {Probability} {Metrics} for {Multivariate} {Data}, {Ensembles} and {Probability} {Distributions}},
	school = {Universidad Carlos III de Madrid},
	author = {Martos, Gabriel and Mu˜, Alberto Mu˜noz and Garc´ia, Mu˜noz and Garc´ia, Garc´},
	year = {2015},
	keywords = {Distance measures, Mahalanobis distance, Multivariate data, Probability distribution},
}

@article{hyun_recent_2023,
	title = {Recent development of computational cluster analysis methods for single-molecule localization microscopy images},
	volume = {21},
	issn = {2001-0370},
	url = {https://www.sciencedirect.com/science/article/pii/S2001037023000077},
	doi = {10.1016/j.csbj.2023.01.006},
	abstract = {With the development of super-resolution imaging techniques, it is crucial to understand protein structure at the nanoscale in terms of clustering and organization in a cell. However, cluster analysis from single-molecule localization microscopy (SMLM) images remains challenging because the classical computational cluster analysis methods developed for conventional microscopy images do not apply to pointillism SMLM data, necessitating the development of distinct methods for cluster analysis from SMLM images. In this review, we discuss the development of computational cluster analysis methods for SMLM images by categorizing them into classical and machine-learning-based methods. Finally, we address possible future directions for machine learning-based cluster analysis methods for SMLM data.},
	language = {en},
	urldate = {2023-04-17},
	journal = {Computational and Structural Biotechnology Journal},
	author = {Hyun, Yoonsuk and Kim, Doory},
	month = jan,
	year = {2023},
	keywords = {Cluster analysis, Machine learning, Single-molecule localization microscopy, Super-resolution fluorescence microscopy},
	pages = {879--888},
}

@article{wu_quantitative_2020,
	title = {Quantitative {Data} {Analysis} in {Single}-{Molecule} {Localization} {Microscopy}},
	volume = {30},
	issn = {0962-8924},
	url = {https://www.sciencedirect.com/science/article/pii/S096289242030146X},
	doi = {10.1016/j.tcb.2020.07.005},
	abstract = {Super-resolution microscopy, and specifically single-molecule localization microscopy (SMLM), is becoming a transformative technology for cell biology, as it allows the study of cellular structures with nanometer resolution. Here, we review a wide range of data analyses approaches for SMLM that extract quantitative information about the distribution, size, shape, spatial organization, and stoichiometry of macromolecular complexes to guide biological interpretation. We present a case study using the nuclear pore complex as an example that highlights the power of combining complementary approaches by identifying its symmetry, ringlike structure, and protein copy number. In face of recent technical and computational advances, this review serves as a guideline for selecting appropriate analysis tools and controls to exploit the potential of SMLM for a wide range of biological questions.},
	language = {en},
	number = {11},
	urldate = {2023-04-17},
	journal = {Trends in Cell Biology},
	author = {Wu, Yu-Le and Tschanz, Aline and Krupnik, Leonard and Ries, Jonas},
	month = nov,
	year = {2020},
	keywords = {coordinate-based data, nuclear pore complex, quantitative analysis, single-molecule localization microscopy, super-resolution microscopy},
	pages = {837--851},
}

@article{Helmuth2010,
	title = {Beyond co-localization: {Inferring} spatial interactions between sub-cellular structures from microscopy images},
	volume = {11},
	issn = {14712105},
	doi = {10.1186/1471-2105-11-372},
	abstract = {BACKGROUND: Sub-cellular structures interact in numerous direct and indirect ways in order to fulfill cellular functions. While direct molecular interactions crucially depend on spatial proximity, other interactions typically result in spatial correlations between the interacting structures. Such correlations are the target of microscopy-based co-localization analysis, which can provide hints of potential interactions. Two complementary approaches to co-localization analysis can be distinguished: intensity correlation methods capitalize on pattern discovery, whereas object-based methods emphasize detection power. RESULTS: We first reinvestigate the classical co-localization measure in the context of spatial point pattern analysis. This allows us to unravel the set of implicit assumptions inherent to this measure and to identify potential confounding factors commonly ignored. We generalize object-based co-localization analysis to a statistical framework involving spatial point processes. In this framework, interactions are understood as position co-dependencies in the observed localization patterns. The framework is based on a model of effective pairwise interaction potentials and the specification of a null hypothesis for the expected pattern in the absence of interaction. Inferred interaction potentials thus reflect all significant effects that are not explained by the null hypothesis. Our model enables the use of a wealth of well-known statistical methods for analyzing experimental data, as demonstrated on synthetic data and in a case study considering virus entry into live cells. We show that the classical co-localization measure typically under-exploits the information contained in our data. CONCLUSIONS: We establish a connection between co-localization and spatial interaction of sub-cellular structures by formulating the object-based interaction analysis problem in a spatial statistics framework based on nearest-neighbor distance distributions. We provide generic procedures for inferring interaction strengths and quantifying their relative statistical significance from sets of discrete objects as provided by image analysis methods. Within our framework, an interaction potential can either refer to a phenomenological or a mechanistic model of a physico-chemical interaction process. This increased flexibility in designing and testing different hypothetical interaction models can be used to quantify the parameters of a specific interaction model or may catalyze the discovery of functional relations.},
	journal = {BMC Bioinformatics},
	author = {Helmuth, Jo A. and Paul, Grégory and Sbalzarini, Ivo F.},
	year = {2010},
	pages = {1--12},
}

@article{carlini_correction_2015,
	title = {Correction of a {Depth}-{Dependent} {Lateral} {Distortion} in {3D} {Super}-{Resolution} {Imaging}},
	volume = {10},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4658163/},
	doi = {10.1371/journal.pone.0142949},
	abstract = {Three-dimensional (3D) localization-based super-resolution microscopy (SR) requires correction of aberrations to accurately represent 3D structure. Here we show how a depth-dependent lateral shift in the apparent position of a fluorescent point source, which we term `wobble`, results in warped 3D SR images and provide a software tool to correct this distortion. This system-specific, lateral shift is typically {\textgreater} 80 nm across an axial range of {\textasciitilde} 1 μm. A theoretical analysis based on phase retrieval data from our microscope suggests that the wobble is caused by non-rotationally symmetric phase and amplitude aberrations in the microscope’s pupil function. We then apply our correction to the bacterial cytoskeletal protein FtsZ in live bacteria and demonstrate that the corrected data more accurately represent the true shape of this vertically-oriented ring-like structure. We also include this correction method in a registration procedure for dual-color, 3D SR data and show that it improves target registration error (TRE) at the axial limits over an imaging depth of 1 μm, yielding TRE values of {\textless} 20 nm. This work highlights the importance of correcting aberrations in 3D SR to achieve high fidelity between the measurements and the sample.},
	number = {11},
	urldate = {2021-05-16},
	journal = {PLoS ONE},
	author = {Carlini, Lina and Holden, Seamus J. and Douglass, Kyle M. and Manley, Suliana},
	month = nov,
	year = {2015},
	pmid = {26600467},
	pmcid = {PMC4658163},
	pages = {e0142949},
}

@article{faklaris_quality_2022,
	title = {Quality assessment in light microscopy for routine use through simple tools and robust metrics},
	volume = {221},
	issn = {0021-9525},
	url = {https://doi.org/10.1083/jcb.202107093},
	doi = {10.1083/jcb.202107093},
	abstract = {Although there is a need to demonstrate reproducibility in light microscopy acquisitions, the lack of standardized guidelines monitoring microscope health status over time has so far impaired the widespread use of quality control (QC) measurements. As scientists from 10 imaging core facilities who encounter various types of projects, we provide affordable hardware and open source software tools, rigorous protocols, and define reference values to assess QC metrics for the most common fluorescence light microscopy modalities. Seven protocols specify metrics on the microscope resolution, field illumination flatness, chromatic aberrations, illumination power stability, stage drift, positioning repeatability, and spatial-temporal noise of camera sensors. We designed the MetroloJ\_QC ImageJ/Fiji Java plugin to incorporate the metrics and automate analysis. Measurements allow us to propose an extensive characterization of the QC procedures that can be used by any seasoned microscope user, from research biologists with a specialized interest in fluorescence light microscopy through to core facility staff, to ensure reproducible and quantifiable microscopy results.},
	number = {11},
	urldate = {2023-04-17},
	journal = {Journal of Cell Biology},
	author = {Faklaris, Orestis and Bancel-Vallée, Leslie and Dauphin, Aurélien and Monterroso, Baptiste and Frère, Perrine and Geny, David and Manoliu, Tudor and de Rossi, Sylvain and Cordelières, Fabrice P. and Schapman, Damien and Nitschke, Roland and Cau, Julien and Guilbert, Thomas},
	month = sep,
	year = {2022},
	pages = {e202107093},
}

@article{cardoen_ergo_2020,
	title = {{ERGO}: {Efficient} {Recurrent} {Graph} {Optimized} {Emitter} {Density} {Estimation} in {Single} {Molecule} {Localization} {Microscopy}},
	volume = {39},
	issn = {1558-254X},
	shorttitle = {{ERGO}},
	doi = {10.1109/TMI.2019.2962361},
	abstract = {Single molecule localization microscopy (SMLM) allows unprecedented insight into the three-dimensional organization of proteins at the nanometer scale. The combination of minimal invasive cell imaging with high resolution positions SMLM at the forefront of scientific discovery in cancer, infectious, and degenerative diseases. By stochastic temporal and spatial separation of light emissions from fluorescent labelled proteins, SMLM is capable of nanometer scale reconstruction of cellular structures. Precise localization of proteins in 3D astigmatic SMLM is dependent on parameter sensitive preprocessing steps to select regions of interest. With SMLM acquisition highly variable over time, it is non-trivial to find an optimal static parameter configuration. The high emitter density required for reconstruction of complex protein structures can compromise accuracy and introduce artifacts. To address these problems, we introduce two modular auto-tuning pre-processing methods: adaptive signal detection and learned recurrent signal density estimation that can leverage the information stored in the sequence of frames that compose the SMLM acquisition process. We show empirically that our contributions improve accuracy, precision and recall with respect to the state of the art. Both modules auto-tune their hyper-parameters to reduce the parameter space for practitioners, improve robustness and reproducibility, and are validated on a reference in silico dataset. Adaptive signal detection and density prediction can offer a practitioner, in addition to informed localization, a tool to tune acquisition parameters ensuring improved reconstruction of the underlying protein complex. We illustrate the challenges faced by practitioners in applying SMLM algorithms on real world data markedly different from the data used in development and show how ERGO can be run on new datasets without retraining while motivating the need for robust transfer learning in SMLM.},
	number = {6},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Cardoen, Ben and Yedder, Hanene Ben and Sharma, Anmol and Chou, Keng C and Nabi, Ivan Robert and Hamarneh, Ghassan},
	month = jun,
	year = {2020},
	keywords = {Estimation, Image reconstruction, Labeling, Microscopy, Proteins, Single molecule localization microscopy, Three-dimensional displays, Two dimensional displays, astigmatism, dSTORM, deep learning, density estimation, recurrent network, signal detection},
	pages = {1942--1956},
}

@article{cardoen_specht_2022,
	title = {{SPECHT}: {Self}-tuning {Plausibility} based object detection {Enables} quantification of {Conflict} in {Heterogeneous} multi-scale microscopy},
	volume = {17},
	issn = {1932-6203},
	shorttitle = {{SPECHT}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0276726},
	doi = {10.1371/journal.pone.0276726},
	abstract = {Identification of small objects in fluorescence microscopy is a non-trivial task burdened by parameter-sensitive algorithms, for which there is a clear need for an approach that adapts dynamically to changing imaging conditions. Here, we introduce an adaptive object detection method that, given a microscopy image and an image level label, uses kurtosis-based matching of the distribution of the image differential to express operator intent in terms of recall or precision. We show how a theoretical upper bound of the statistical distance in feature space enables application of belief theory to obtain statistical support for each detected object, capturing those aspects of the image that support the label, and to what extent. We validate our method on 2 datasets: distinguishing sub-diffraction limit caveolae and scaffold by stimulated emission depletion (STED) super-resolution microscopy; and detecting amyloid-β deposits in confocal microscopy retinal cross-sections of neuropathologically confirmed Alzheimer’s disease donor tissue. Our results are consistent with biological ground truth and with previous subcellular object classification results, and add insight into more nuanced class transition dynamics. We illustrate the novel application of belief theory to object detection in heterogeneous microscopy datasets and the quantification of conflict of evidence in a joint belief function. By applying our method successfully to diffraction-limited confocal imaging of tissue sections and super-resolution microscopy of subcellular structures, we demonstrate multi-scale applicability.},
	language = {en},
	number = {12},
	urldate = {2023-04-17},
	journal = {PLOS ONE},
	author = {Cardoen, Ben and Wong, Timothy and Alan, Parsa and Lee, Sieun and Matsubara, Joanne Aiko and Nabi, Ivan Robert and Hamarneh, Ghassan},
	month = dec,
	year = {2022},
	keywords = {Alzheimer's disease, Background signal noise, Coated pits, Confocal microscopy, Fluorescence imaging, Fluorescence microscopy, Gaussian noise, Imaging techniques},
	pages = {e0276726},
}

@article{lee_unraveling_2017,
	title = {Unraveling the {Thousand} {Word} {Picture}: {An} {Introduction} to {Super}-{Resolution} {Data} {Analysis}},
	volume = {117},
	issn = {0009-2665},
	shorttitle = {Unraveling the {Thousand} {Word} {Picture}},
	url = {https://doi.org/10.1021/acs.chemrev.6b00729},
	doi = {10.1021/acs.chemrev.6b00729},
	abstract = {Super-resolution microscopy provides direct insight into fundamental biological processes occurring at length scales smaller than light’s diffraction limit. The analysis of data at such scales has brought statistical and machine learning methods into the mainstream. Here we provide a survey of data analysis methods starting from an overview of basic statistical techniques underlying the analysis of super-resolution and, more broadly, imaging data. We subsequently break down the analysis of super-resolution data into four problems: the localization problem, the counting problem, the linking problem, and what we’ve termed the interpretation problem.},
	number = {11},
	urldate = {2023-04-17},
	journal = {Chemical Reviews},
	author = {Lee, Antony and Tsekouras, Konstantinos and Calderon, Christopher and Bustamante, Carlos and Pressé, Steve},
	month = jun,
	year = {2017},
	pages = {7276--7330},
}

@article{qian_single_1991,
	title = {Single particle tracking. {Analysis} of diffusion and flow in two-dimensional systems},
	volume = {60},
	issn = {0006-3495},
	doi = {10.1016/S0006-3495(91)82125-7},
	abstract = {Analysis of the trajectories of small particles at high spatial and temporal resolution using video enhanced contrast microscopy provides a powerful approach to characterizing the mechanisms of particle motion in living cells and in other systems. We present here the theoretical basis for the analysis of these trajectories for particles undergoing random diffusion and/or systematic transport at uniform velocity in two-dimensional systems. The single particle tracking method, based on observations of the trajectories of individual particles, is compared with methods that characterize the motions of a large collection of particles such as fluorescence photobleaching recovery. Determination of diffusion coefficients or transport velocities either from correlation of positions or of velocities of the particles is discussed. A result of practical importance is an analysis of the dependence of the expected statistical uncertainty of these determinations on the number of position measurements. This provides a way of judging the accuracy of the diffusion coefficients and transport velocities obtained using this approach.},
	language = {eng},
	number = {4},
	journal = {Biophysical Journal},
	author = {Qian, H. and Sheetz, M. P. and Elson, E. L.},
	month = oct,
	year = {1991},
	pmid = {1742458},
	pmcid = {PMC1260142},
	keywords = {Diffusion, Kinetics, Mathematics, Membrane Proteins, Models, Biological, Probability},
	pages = {910--921},
}

@article{wofgang_uber_1925,
	title = {Über den {Zusammenhang} des {Abschlusses} der {Elektronengruppen} im {Atom} mit der {Komplexstruktur} der {Spektren} {\textbar} {SpringerLink}},
	volume = {229},
	url = {https://link.springer.com/article/10.1007/BF02980631},
	urldate = {2023-02-14},
	journal = {Einf\{{\textbackslash}"u\}hr. Orig},
	author = {Wofgang, Pauli},
	year = {1925},
	pages = {765--783},
}

@article{lu_advances_2021,
	title = {Advances in the study of organelle interactions and their role in neurodegenerative diseases enabled by super-resolution microscopy},
	volume = {159},
	issn = {1095-953X},
	doi = {10.1016/j.nbd.2021.105475},
	abstract = {From the first illustrations of neuronal morphology by Ramón y Cajal to the recent three-dimensional reconstruction of synaptic connections, the development of modern neuroscience has greatly benefited from breakthroughs in imaging technology. This also applies specifically to the study of neurodegenerative diseases. Much of the research into these diseases relies on the direct visualisation of intracellular structures and their dynamics in degenerating neural cells, which cannot be fully resolved by diffraction-limited microscopes. Progress in the field has therefore been closely linked to the development of super-resolution imaging methods. Their application has greatly advanced our understanding of disease mechanisms, ranging from the structural progression of protein aggregates to defects in organelle morphology. Recent super-resolution studies have specifically implicated the disruption of inter-organelle interactions in multiple neurodegenerative diseases. In this article, we describe some of the key super-resolution techniques that have contributed to this field. We then discuss work to visualise changes in the structure and dynamics of organelles and associated dysfunctions. Finally, we consider what future developments in imaging technology may further our knowledge of these processes.},
	language = {eng},
	journal = {Neurobiology of Disease},
	author = {Lu, Meng and Ward, Edward and van Tartwijk, Francesca W. and Kaminski, Clemens F.},
	month = nov,
	year = {2021},
	pmid = {34390833},
	keywords = {Animals, Humans, Imaging, Three-Dimensional, Microscopy, Confocal, Microscopy, Fluorescence, Neurodegenerative Diseases, Neurons, Organelles, Single Molecule Imaging},
	pages = {105475},
}

@article{sbalzarini_seeing_2016,
	title = {Seeing {Is} {Believing}: {Quantifying} {Is} {Convincing}: {Computational} {Image} {Analysis} in {Biology}},
	volume = {219},
	issn = {0301-5556},
	shorttitle = {Seeing {Is} {Believing}},
	doi = {10.1007/978-3-319-28549-8_1},
	abstract = {Imaging is center stage in biology. Advances in microscopy and labeling techniques have enabled unprecedented observations and continue to inspire new developments. Efficient and accurate quantification and computational analysis of the acquired images, however, are becoming the bottleneck. We review different paradigms of computational image analysis for intracellular, single-cell, and tissue-level imaging, providing pointers to the specialized literature and listing available software tools. We place particular emphasis on clear categorization of image-analysis frameworks and on identifying current trends and challenges in the field. We further outline some of the methodological advances that are required in order to use images as quantitative scientific measurements.},
	language = {eng},
	journal = {Advances in Anatomy, Embryology, and Cell Biology},
	author = {Sbalzarini, Ivo F.},
	year = {2016},
	pmid = {27207361},
	keywords = {Animals, Humans, Image Processing, Computer-Assisted, Machine Learning, Mathematical Computing, Microscopy, Fluorescence, Single-Cell Analysis, Software, Staining and Labeling},
	pages = {1--39},
}

@article{chen_quantitative_2020,
	title = {Quantitative analysis of interactive behavior of mitochondria and lysosomes using structured illumination microscopy},
	volume = {250},
	issn = {0142-9612},
	url = {https://www.sciencedirect.com/science/article/pii/S0142961220303057},
	doi = {10.1016/j.biomaterials.2020.120059},
	abstract = {Super-resolution optical microscopy has extended the spatial resolution of cell biology from the cellular level to the nanoscale, enabling the observation of the interactive behavior of single mitochondria and lysosomes. Quantitative parametrization of interactions between mitochondria and lysosomes under super-resolution optical microscopy, however, is currently unavailable, which has severely limited our understanding of the molecular machinery underlying mitochondrial functionality. Here, we introduce an M-value to quantitatively investigate mitochondria and lysosome contact (MLC) and mitophagy under structured illumination microscopy. We found that the M-value for an MLC is typically less than 0.4, whereas in mitophagy it ranges from 0.5 to 1.0. This system permits further investigation of the detailed molecular mechanism governing the interactive behavior of mitochondria and lysosomes.},
	language = {en},
	urldate = {2023-04-17},
	journal = {Biomaterials},
	author = {Chen, Qixin and Shao, Xintian and Hao, Mingang and Fang, Hongbao and Guan, Ruilin and Tian, Zhiqi and Li, Miaoling and Wang, Chenran and Ji, Liangnian and Chao, Hui and Guan, Jun-Lin and Diao, Jiajie},
	month = aug,
	year = {2020},
	keywords = {Lysosome, Membrane fusion, Mitochondria, Mitophagy, Super-resolution imaging},
	pages = {120059},
}

@article{ma_simple_2017,
	title = {A {Simple} {Marker}-{Assisted} {3D} {Nanometer} {Drift} {Correction} {Method} for {Superresolution} {Microscopy}},
	volume = {112},
	issn = {0006-3495},
	url = {https://www.sciencedirect.com/science/article/pii/S0006349517304411},
	doi = {10.1016/j.bpj.2017.04.025},
	abstract = {High-precision fluorescence microscopy such as superresolution imaging or single-particle tracking often requires an online drift correction method to maintain the stability of the three-dimensional (3D) position of the sample at a nanometer precision throughout the entire data acquisition process. Current online drift correction methods require modification of the existing two-dimensional (2D) fluorescence microscope with additional optics and detectors, which can be cumbersome and limit its use in many biological laboratories. Here we report a simple marker-assisted online drift correction method in which all 3D positions can be derived from fiducial markers on the coverslip of the sample on a standard 2D fluorescence microscope without additional optical components. We validate this method by tracking the long-term 3D stability of single-molecule localization microscopy at a precision of {\textless}2 and 5 nm in the lateral and axial dimension, respectively. We then provide three examples to evaluate the performance of the marker-assisted drift correction method. Finally, we give an example of a biological application of superresolution imaging of spatiotemporal alteration for a DNA replication structure with both low-abundance newly synthesized DNAs at the early onset of DNA synthesis and gradually condensed DNA structures during DNA replication. Using an isogenic breast cancer progression cell line model that recapitulates normal-like, precancerous, and tumorigenic stages, we characterize a distinction in the DNA replication process in normal, precancerous, and tumorigenic cells.},
	language = {en},
	number = {10},
	urldate = {2023-04-17},
	journal = {Biophysical Journal},
	author = {Ma, Hongqiang and Xu, Jianquan and Jin, Jingyi and Huang, Yi and Liu, Yang},
	month = may,
	year = {2017},
	pages = {2196--2208},
}

@article{rodriguez-sevilla_multichannel_2022,
	title = {Multichannel {Fluorescence} {Microscopy}: {Advantages} of {Going} beyond a {Single} {Emission}},
	volume = {2},
	issn = {2699-9307},
	shorttitle = {Multichannel {Fluorescence} {Microscopy}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/anbr.202100084},
	doi = {10.1002/anbr.202100084},
	abstract = {Fluorescent microscopy has enabled the study of intracellular processes and revealed the most intricate details of the subcellular structure. This has benefitted not only the basic biological science, but also has had an impact in numerous biomedical applications. Basic fluorescent sensing techniques use the change in the absolute emission of a fluorescent sensor. This entails some disadvantages as the signal might be influenced by factors not directly related to the process under study (e.g., fluctuations in the excitation source). To overcome these drawbacks, one can use multiple emissions of a single or various fluorophores. There are numerous examples of multichannel fluorescence microscopy techniques that have given rise to numerous ratiometric methods and multiplexing assays. Herein, how the use of multiple emission channels has impacted fluorescence microscopy in terms of speed, sensitivity, and resolution is reviewed. Using recent examples, how the easy implementation of multichannel detection can overcome current limitations of the main used fluorescence techniques and promote the development of novel microscopy methods is shown.},
	language = {en},
	number = {5},
	urldate = {2023-04-17},
	journal = {Advanced NanoBiomed Research},
	author = {Rodríguez-Sevilla, Paloma and Thompson, Sebastian A. and Jaque, Daniel},
	year = {2022},
	keywords = {biomedical applications, fluorescence microscopy, intracellular sensing, multichannel, multiplexing, ratiometric sensing},
	pages = {2100084},
}

@misc{noauthor_mf_nodate,
	title = {{MF} {Reconstruction} and {Diag} {DOT}\_TMI\_rev\_1},
	url = {https://www.overleaf.com/project/61533eb1fe2c89a32248a1be},
	abstract = {An online LaTeX editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2023-04-03},
}

@article{lu_ernet_2023,
	title = {{ERnet}: a tool for the semantic segmentation and quantitative analysis of endoplasmic reticulum topology},
	copyright = {2023 The Author(s) under exclusive license to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{ERnet}},
	url = {https://www.nature.com/articles/s41592-023-01815-0},
	doi = {10.1038/s41592-023-01815-0},
	abstract = {The ability to quantify structural changes of the endoplasmic reticulum (ER) is crucial for understanding the structure and function of this organelle. However, the rapid movement and complex topology of ER networks make this challenging. Here, we construct a state-of-the-art semantic segmentation method that we call ERnet for the automatic classification of sheet and tubular ER domains inside individual cells. Data are skeletonized and represented by connectivity graphs, enabling precise and efficient quantification of network connectivity. ERnet generates metrics on topology and integrity of ER structures and quantifies structural change in response to genetic or metabolic manipulation. We validate ERnet using data obtained by various ER-imaging methods from different cell types as well as ground truth images of synthetic ER structures. ERnet can be deployed in an automatic high-throughput and unbiased fashion and identifies subtle changes in ER phenotypes that may inform on disease progression and response to therapy.},
	language = {en},
	urldate = {2023-03-31},
	journal = {Nature Methods},
	author = {Lu, Meng and Christensen, Charles N. and Weber, Jana M. and Konno, Tasuku and Läubli, Nino F. and Scherer, Katharina M. and Avezov, Edward and Lio, Pietro and Lapkin, Alexei A. and Kaminski Schierle, Gabriele S. and Kaminski, Clemens F.},
	month = mar,
	year = {2023},
	keywords = {Fluorescence imaging, Machine learning, Organelles, Software, Super-resolution microscopy},
	pages = {1--11},
}

@article{cambria_survey_2023,
	title = {A survey on {XAI} and natural language explanations},
	volume = {60},
	issn = {0306-4573},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457322002126},
	doi = {10.1016/j.ipm.2022.103111},
	abstract = {The field of explainable artificial intelligence (XAI) is gaining increasing importance in recent years. As a consequence, several surveys have been published to explore the current state of the art on this topic. One aspect that seems to be overlooked by these works is the applied presentation methods and, specifically, the role of natural language in generating the final explanations. This survey reviews 70 XAI papers published between 2006 and 2021 and evaluates their readiness with respect to natural language explanations. Thus, together with a set of hierarchical criteria, we define a multi-criteria decision-making model. Finally, we conclude that only a handful of recent XAI works either considered natural language explanations to approach final users (see, e.g.,(Bennetot et al., 2021)) or implemented a method capable of generating such explanations.},
	language = {en},
	number = {1},
	urldate = {2023-03-28},
	journal = {Information Processing \& Management},
	author = {Cambria, Erik and Malandri, Lorenzo and Mercorio, Fabio and Mezzanzanica, Mario and Nobani, Navid},
	month = jan,
	year = {2023},
	keywords = {Explainable AI, Natural language explanations, Presentation methods},
	pages = {103111},
}

@misc{geiger_inducing_2022,
	title = {Inducing {Causal} {Structure} for {Interpretable} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2112.00826},
	doi = {10.48550/arXiv.2112.00826},
	abstract = {In many areas, we have well-founded insights about causal structure that would be useful to bring into our trained models while still allowing them to learn in a data-driven fashion. To achieve this, we present the new method of interchange intervention training (IIT). In IIT, we (1) align variables in a causal model (e.g., a deterministic program or Bayesian network) with representations in a neural model and (2) train the neural model to match the counterfactual behavior of the causal model on a base input when aligned representations in both models are set to be the value they would be for a source input. IIT is fully differentiable, flexibly combines with other objectives, and guarantees that the target causal model is a causal abstraction of the neural model when its loss is zero. We evaluate IIT on a structural vision task (MNIST-PVR), a navigational language task (ReaSCAN), and a natural language inference task (MQNLI). We compare IIT against multi-task training objectives and data augmentation. In all our experiments, IIT achieves the best results and produces neural models that are more interpretable in the sense that they more successfully realize the target causal model.},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Geiger, Atticus and Wu, Zhengxuan and Lu, Hanson and Rozner, Josh and Kreiss, Elisa and Icard, Thomas and Goodman, Noah D. and Potts, Christopher},
	month = jul,
	year = {2022},
	note = {arXiv:2112.00826 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{liu_one_2023,
	title = {One {Model} to {Synthesize} {Them} {All}: {Multi}-contrast {Multi}-scale {Transformer} for {Missing} {Data} {Imputation}},
	issn = {1558-254X},
	shorttitle = {One {Model} to {Synthesize} {Them} {All}},
	doi = {10.1109/TMI.2023.3261707},
	abstract = {Multi-contrast magnetic resonance imaging (MRI) is widely used in clinical practice as each contrast provides complementary information. However, the availability of each imaging contrast may vary amongst patients, which poses challenges to radiologists and automated image analysis algorithms. A general approach for tackling this problem is missing data imputation, which aims to synthesize the missing contrasts from existing ones. While several convolutional neural networks (CNN) based algorithms have been proposed, they suffer from the fundamental limitations of CNN models, such as the requirement for fixed numbers of input and output channels, the inability to capture long-range dependencies, and the lack of interpretability. In this work, we formulate missing data imputation as a sequence-to-sequence learning problem and propose a multi-contrast multi-scale Transformer (MMT), which can take any subset of input contrasts and synthesize those that are missing. MMT consists of a multi-scale Transformer encoder that builds hierarchical representations of inputs combined with a multi-scale Transformer decoder that generates the outputs in a coarse-to-fine fashion. The proposedmulti-contrast Swin Transformer blocks can efficiently capture intra- and inter-contrast dependencies for accurate image synthesis. Moreover, MMT is inherently interpretable as it allows us to understand the importance of each input contrast in different regions by analyzing the in-built attention maps of Transformer blocks in the decoder. Extensive experiments on two large-scale multi-contrast MRI datasets demonstrate that MMT outperforms the state-of-the-art methods quantitatively and qualitatively.},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Liu, Jiang and Pasumarthi, Srivathsa and Duffy, Ben and Gong, Enhao and Datta, Keshav and Zaharchuk, Greg},
	year = {2023},
	keywords = {Convolutional neural networks, Data models, Decoding, Deep Learning, Generative adversarial networks, Image Synthesis, Image synthesis, Magnetic resonance imaging, Missing Data Imputation, Multi-contrast MRI, Transformers, Vision Transformer},
	pages = {1--1},
}

@book{yerxa_learning_2023,
	title = {Learning {Efficient} {Coding} of {Natural} {Images} with {Maximum} {Manifold} {Capacity} {Representations}},
	abstract = {Self-supervised Learning (SSL) provides a strategy for constructing useful representations of images without relying on hand-assigned labels. Many such methods aim to map distinct views of the same scene or object to nearby points in the representation space, while employing some constraint to prevent representational collapse. Here we recast the problem in terms of efficient coding by adopting manifold capacity, a measure that quantifies the quality of a representation based on the number of linearly separable object manifolds it can support, as the efficiency metric to optimize. Specifically, we adapt the manifold capacity for use as an objective function in a contrastive learning framework, yielding a Maximum Manifold Capacity Representation (MMCR). We apply this method to unlabeled images, each augmented by a set of basic transformations, and find that it learns meaningful features using the standard linear evaluation protocol. Specifically, we find that MMCRs support performance on object recognition comparable to or surpassing that of recently developed SSL frameworks, while providing more robustness to adversarial attacks. Empirical analyses reveal differences between MMCRs and representations learned by other SSL frameworks, and suggest a mechanism by which manifold compression gives rise to class separability.},
	author = {Yerxa, Thomas and Kuang, Yilun and Simoncelli, Eero and Chung, Sueyeon},
	month = mar,
	year = {2023},
	doi = {10.48550/arXiv.2303.03307},
}

@book{zador_toward_2022,
	title = {Toward {Next}-{Generation} {Artificial} {Intelligence}: {Catalyzing} the {NeuroAI} {Revolution}},
	shorttitle = {Toward {Next}-{Generation} {Artificial} {Intelligence}},
	abstract = {Neuroscience has long been an important driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI.},
	author = {Zador, Anthony and Richards, Blake and Ölveczky, Bence and Escola, Sean and Bengio, Yoshua and Boahen, Kwabena and Botvinick, Matthew and Chklovskii, Dmitri and Churchland, Anne and Clopath, Claudia and DiCarlo, James and Ganguli, Surya and Hawkins, Jeff and Koerding, Konrad and Koulakov, Alexei and LeCun, Yann and Lillicrap, Timothy and Marblestone, Adam and Olshausen, Bruno and Tsao, Doris},
	month = oct,
	year = {2022},
}

@article{gentilhomme_towards_2023,
	title = {Towards smart pruning: {ViNet}, a deep-learning approach for grapevine structure estimation},
	volume = {207},
	issn = {0168-1699},
	shorttitle = {Towards smart pruning},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169923001242},
	doi = {10.1016/j.compag.2023.107736},
	abstract = {Image and video tools for analyzing crop scenes and plants are essential for applying precision agriculture to crop maintenance, harvesting, or pruning. In this paper, we are interested in vine pruning, a task that requires a precise understanding of the vine structure with branch type identification, orientations, and node locations. However, estimating such a structure is highly challenging, given the large variety in grapevine appearances, lighting conditions, viewpoint, the interweaving of branches, occlusions, and the level of details needed. To address these challenges, we propose ViNet: a deep-learning approach for estimating the structure of grapevine, which comprises two main steps: The first one detects nodes and identifies the branch types of the plant, as well as the spatial relation between them, whilst the second one uses the extracted nodes and branches to build a graph, out of which the structure of the grapevine is inferred. In doing so, we make four main contributions: (i) we put forward for the first time a method for automatic segmentation and extraction of the grapevine structure from images; (ii) we propose a novel approach leveraging the powerful stacked hourglass network to infer node location, branch types and the spatial relationships between them; (iii) we propose a novel shortest path weighted graph optimization step to extract connections between nodes and infer the structure, allowing to address the problem of having an unknown number of branches in the tree; (iv) we publicly release a dataset of more than 1500 grapevine images fully annotated with the structure information. Extensive experiments on this dataset demonstrate the efficiency of our approach at predicting the structure of a grapevine, achieving a precision and recall for node prediction of 95\% and 90\%, respectively, as well as ablation studies validating our design choices.},
	language = {en},
	urldate = {2023-03-20},
	journal = {Computers and Electronics in Agriculture},
	author = {Gentilhomme, Theophile and Villamizar, Michael and Corre, Jerome and Odobez, Jean-Marc},
	month = apr,
	year = {2023},
	keywords = {Convolutional network, Deep learning, Grapevine pruning, Plant skeleton, Precision viticulture, Vineyard},
	pages = {107736},
}

@book{lochocki_early_2023,
	title = {Early detection of {Alzheimer}’s disease in the human retina: insights of 7 years research},
	shorttitle = {Early detection of {Alzheimer}’s disease in the human retina},
	author = {Lochocki, Benjamin and den Haan, Jurre and Hart de Ruyter, Frederique and Kroon, Maurice and Kemper, E. and Teunissen, Charlotte and Berckel, Bert and van de Kreeke, Aleid and Scheltens, Philip and Hoozemans, Jeroen and Verbraak, Frank and Bouwman, Femke and Boer, Johannes},
	month = mar,
	year = {2023},
	doi = {10.1117/12.2648950},
}

@incollection{verachtert_impact_2023,
	title = {The {Impact} of a {Popularity} {Punishing} {Hyperparameter} on {ItemKNN} {Recommendation} {Performance}},
	isbn = {9783031282379},
	abstract = {Collaborative filtering techniques have a tendency to amplify popularity biases present in the training data if no countermeasures are taken. The ItemKNN algorithm with conditional probability-inspired similarity function has a hyperparameter {\textbackslash}({\textbackslash}alpha {\textbackslash}) that allows one to counteract this popularity bias. In this work, we perform a deep dive into the effects of this hyperparameter in both online and offline experiments, with regard to both accuracy metrics and equality of exposure. Our experiments show that the hyperparameter can indeed counteract popularity bias in a dataset. We also find that there exists a trade-off between countering popularity bias and the quality of the recommendations: Reducing popularity bias too much results in a decrease in click-through rate, but some counteracting of popularity bias is required for optimal online performance.KeywordsRecommendation systemsAB testNearest neighbour},
	author = {Verachtert, Robin and Craps, Jeroen and Michiels, Lien and Goethals, Bart},
	month = mar,
	year = {2023},
	doi = {10.1007/978-3-031-28238-6_56},
	pages = {646--654},
}

@book{dalmaz_one_2022,
	title = {One {Model} to {Unite} {Them} {All}: {Personalized} {Federated} {Learning} of {Multi}-{Contrast} {MRI} {Synthesis}},
	shorttitle = {One {Model} to {Unite} {Them} {All}},
	abstract = {Learning-based MRI translation involves a synthesis model that maps a source-contrast onto a target-contrast image. Multi-institutional collaborations are key to training synthesis models across broad datasets, yet centralized training involves privacy risks. Federated learning (FL) is a collaboration framework that instead adopts decentralized training to avoid sharing imaging data and mitigate privacy concerns. However, FL-trained models can be impaired by the inherent heterogeneity in the distribution of imaging data. On the one hand, implicit shifts in image distribution are evident across sites, even for a common translation task with fixed source-target configuration. Conversely, explicit shifts arise within and across sites when diverse translation tasks with varying source-target configurations are prescribed. To improve reliability against domain shifts, here we introduce the first personalized FL method for MRI Synthesis (pFLSynth). pFLSynth is based on an adversarial model equipped with a mapper that produces latents specific to individual sites and source-target contrasts. It leverages novel personalization blocks that adaptively tune the statistics and weighting of feature maps across the generator based on these latents. To further promote site-specificity, partial model aggregation is employed over downstream layers of the generator while upstream layers are retained locally. As such, pFLSynth enables training of a unified synthesis model that can reliably generalize across multiple sites and translation tasks. Comprehensive experiments on multi-site datasets clearly demonstrate the enhanced performance of pFLSynth against prior federated methods in multi-contrast MRI synthesis.},
	author = {Dalmaz, Onat and Mirza, Usama and Elmas, Gökberk and Özbey, Muzaffer and Dar, Salman Ul Hassan and Ceyani, Emir and Avestimehr, Salman and Cukur, Tolga},
	month = jul,
	year = {2022},
	doi = {10.48550/arXiv.2207.06509},
}

@article{dalmaz_resvit_2022,
	title = {{ResViT}: {Residual} {Vision} {Transformers} for {Multimodal} {Medical} {Image} {Synthesis}},
	volume = {PP},
	shorttitle = {{ResViT}},
	doi = {10.1109/TMI.2022.3167808},
	abstract = {Generative adversarial models with convolutional neural network (CNN) backbones have recently been established as state-of-the-art in numerous medical image synthesis tasks. However, CNNs are designed to perform local processing with compact filters, and this inductive bias compromises learning of contextual features. Here, we propose a novel generative adversarial approach for medical image synthesis, ResViT, that leverages the contextual sensitivity of vision transformers along with the precision of convolution operators and realism of adversarial learning. ResViT's generator employs a central bottleneck comprising novel aggregated residual transformer (ART) blocks that synergistically combine residual convolutional and transformer modules. Residual connections in ART blocks promote diversity in captured representations, while a channel compression module distills task-relevant information. A weight sharing strategy is introduced among ART blocks to mitigate computational burden. A unified implementation is introduced to avoid the need to rebuild separate synthesis models for varying source-target modality configurations. Comprehensive demonstrations are performed for synthesizing missing sequences in multi-contrast MRI, and CT images from MRI. Our results indicate superiority of ResViT against competing CNN- and transformer-based methods in terms of qualitative observations and quantitative metrics.},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Dalmaz, Onat and Yurt, Mahmut and Cukur, Tolga},
	month = apr,
	year = {2022},
	pages = {1--1},
}

@book{cheng_combining_2023,
	title = {Combining {Pairwise} {Structural} {Similarity} and {Deep} {Learning} {Interface} {Contact} {Prediction} to {Estimate} {Protein} {Complex} {Model} {Accuracy} in {CASP15}},
	abstract = {Estimating the accuracy of quaternary structural models of protein complexes and assemblies (EMA) is important for predicting quaternary structures and applying them to studying protein function and interaction. The pairwise similarity between structural models is proven useful for estimating the quality of protein tertiary structural models, but it has been rarely applied to predicting the quality of quaternary structural models. Moreover, the pairwise similarity approach often fails when many structural models are of low quality and similar to each other. To address the gap, we developed a hybrid method (MULTICOM\_qa) combining a pairwise similarity score (PSS) and an interface contact probability score (ICPS) based on the deep learning inter-chain contact prediction for estimating protein complex model accuracy. It blindly participated in the 15th Critical Assessment of Techniques for Protein Structure Prediction (CASP15) in 2022 and ranked first out of 24 predictors in estimating the global accuracy of assembly models. The average per-target correlation coefficient between the model quality scores predicted by MULTICOM\_qa and the true quality scores of the models of CASP15 assembly targets is 0.66. The average per-target ranking loss in using the predicted quality scores to rank the models is 0.14. It was able to select good models for most targets. Moreover, several key factors (i.e., target difficulty, model sampling difficulty, skewness of model quality, and similarity between good/bad models) for EMA are identified and analayzed. The results demonstrate that combining the multi-model method (PSS) with the complementary single-model method (ICPS) is a promising approach to EMA.},
	author = {Cheng, Jianlin and Roy, Raj and Liu, Jian and Giri, Nabin and Guo, Zhiye},
	month = mar,
	year = {2023},
	doi = {10.22541/au.167872025.53516971/v1},
}

@inproceedings{kim_multi-channel_2021,
	title = {Multi-channel virtual fluorescence microscopy with a learned sensing network},
	volume = {11804},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11804/1180412/Multi-channel-virtual-fluorescence-microscopy-with-a-learned-sensing-network/10.1117/12.2594729.full},
	doi = {10.1117/12.2594729},
	abstract = {Fluorescence imaging is used throughout biological research to identify subcellular structures, detect neural activity, and differentiate cell types. Multi-channel fluorescence is a challenging subset of fluorescence imaging where multiple fluorescent modes are emitted simultaneously, allowing the detection of a multitude of elements within the specimen (for example, multiple types of neurons). In our work, we demonstrate a learned sensing approach to realize virtual multi-channel fluorescence, by jointly optimizing image illumination and a deep learning neural network that infers labels from brightfield images. We used our setup to demonstrate the influence of key design decisions, such as model architecture, choice of loss function, and amount of input images, on the final optical design. We expect that our work can provide a better understanding of building machine learning based imaging systems and demonstrate the scalability of our illumination optimization technique.},
	urldate = {2023-03-14},
	booktitle = {Emerging {Topics} in {Artificial} {Intelligence} ({ETAI}) 2021},
	publisher = {SPIE},
	author = {Kim, Kanghyun and Cooke, Colin L. and Konda, Pavan Chandra and Horstmeyer, Roarke W.},
	month = aug,
	year = {2021},
	pages = {1180412},
}

@inproceedings{ritter_optimizing_2020,
	title = {Optimizing {Particle} {Detection} by {Colocalization} {Analysis} in {Multi}-{Channel} {Fluorescence} {Microscopy} {Images}},
	doi = {10.1109/ISBI45749.2020.9098659},
	abstract = {Automatic detection of virus particles displayed as small spots in fluorescence microscopy images is an important task to elucidate infection processes. Particles are typically labeled with multiple fluorophores to acquire multi-channel images. We propose a new weakly supervised approach for automatic particle detection in the lower SNR channel of two-channel fluorescence microscopy data. A main advantage is that labeled data is not required. Instead of using labeled data, colocalization in different channels is exploited as a surrogate for ground truth using a novel measure. Our approach has been evaluated using synthetic as well as challenging live cell microscopy images of human immunodeficiency virus type 1 particles. We found, that our approach yields comparable results to a state-of-the-art supervised method, and can cope with defective fluorescent labeling as well as chromatic aberration of the microscope.},
	booktitle = {2020 {IEEE} 17th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Ritter, C. and Newrly, A. and Schifferdecker, S. and Roggenbach, I. and Müller, B. and Rohr, K.},
	month = apr,
	year = {2020},
	note = {ISSN: 1945-8452},
	keywords = {Atmospheric measurements, Channel estimation, Colocalization analysis, Labeling, Microscopy, Multi-channel microscopy images, Particle detection, Particle measurements, Signal to noise ratio, Viruses (medical)},
	pages = {882--885},
}

@article{natekin_gradient_2013,
	title = {Gradient boosting machines, a tutorial},
	volume = {7},
	issn = {1662-5218},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3885826/},
	doi = {10.3389/fnbot.2013.00021},
	abstract = {Gradient boosting machines are a family of powerful machine-learning techniques that have shown considerable success in a wide range of practical applications. They are highly customizable to the particular needs of the application, like being learned with respect to different loss functions. This article gives a tutorial introduction into the methodology of gradient boosting methods with a strong focus on machine learning aspects of modeling. A theoretical information is complemented with descriptive examples and illustrations which cover all the stages of the gradient boosting model design. Considerations on handling the model complexity are discussed. Three practical examples of gradient boosting applications are presented and comprehensively analyzed.},
	urldate = {2023-03-13},
	journal = {Frontiers in Neurorobotics},
	author = {Natekin, Alexey and Knoll, Alois},
	month = dec,
	year = {2013},
	pmid = {24409142},
	pmcid = {PMC3885826},
	pages = {21},
}

@article{shanmuganathan_cte_2017,
	title = {{CTE}: {A} {METHOD} {TO} {COMPRESSION}-{THEN}-{ENCRYPTION} {FOR} {IMAGES}},
	volume = {6},
	shorttitle = {{CTE}},
	doi = {10.5281/zenodo.809006},
	abstract = {Compression is important because it helps us to reduce the consumption of expensive resources, such as disk
space and cost for using bandwidth. Use of the right compression method and encryption technique yield more
compact and secure data that are eligible to transfer over public channel. We introduce an optimal approach to
compress and then encrypt images. The proposed method is used to increase the compression ratio for images
by segmenting an image into non-overlapping segments called edge and non-edge segments and applying
different compression depths for these segments. In an edge segment (a region that contains important
information) the compression ratio is reduced to prevent loss of information, whereas in a non-edge segment (a
smooth region which does not have important information), a high compression ratio is achieved and for
encryption, a non-linear chaotic map is used. The performance of the proposed system is quantified using the
peak signal-to-noise ratio to test the compression ratio and also the encrypted image has huge key space which
makes harder for a hacker to decrypt it using the wrong key.},
	journal = {INTERNATIONAL JOURNAL OF ENGINEERING SCIENCES \& RESEARCH TECHNOLOGY},
	author = {Shanmuganathan, Sankar},
	month = jun,
	year = {2017},
	pages = {214--224},
}

@article{shanmuganathan_zzrd_2014,
	title = {{ZZRD} and {ZZSW}: {Novel} hybrid scanning paths for squared blocks},
	volume = {9},
	shorttitle = {{ZZRD} and {ZZSW}},
	abstract = {A scan method can convert a difficult to use signal into an easy to use one by exploring source redundancies within the input signal, which could be very useful in image compression. In Joint Picture Expert Group (JPEG) image compression, encoding an image can lead to not an optimum result, if the quantized two-dimensional discrete cosine transform coefficients are not arranged in linear sufficiently. An efficient linearization scheme is necessary to keep highly redundant coefficients consecutively in one dimensional sequence space so that other techniques involved in the compression process can be expected to yield better results. In this paper, we propose two novel scanning algorithms for performing linearization where a hybrid procedure is employed by integrating a portion of Zigzag with new Raster Diagonal pattern and Saw tooth Wave pattern. The result shows proposed methods had competitive performance in comparison with the conventional Zigzag scanning scheme.
Keywords: Image compression, Linearization, Quantization, Zigzag scan.},
	journal = {International Journal of Applied Engineering Research},
	author = {Shanmuganathan, Sankar and Ls, Nagarajan},
	month = oct,
	year = {2014},
	pages = {10567--10583},
}

@article{guo_improved_2022,
	title = {Improved reverse zigzag transform and {DNA} diffusion chaotic image encryption method},
	volume = {81},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-022-12269-5},
	doi = {10.1007/s11042-022-12269-5},
	abstract = {In this paper, we propose a chaotic image encryption method based on an improved reverse Zigzag cyclic traversal algorithm combined with DNA coding. The original Zigzag algorithm cannot change all pixel positions at once due to the limitation of the traversal method, and our improved traversal method modifies the original traversal order to reverse zigzag cyclic traversal, after which the image is scrambled with a secondary chaotic sequence. Secondly, the diffusion of DNA pixels is completed after the scrambling operation on the image on the screen. Finally, as an example to further deepen the encryption effect, the image of the chaotic sequence is diffused and the final encrypted image is obtained. Experiments show that the algorithm in this paper has high security. Compared with the original algorithm, the improved reverse Zigzag algorithm has better traversal effect and higher efficiency. Meanwhile, the combination of DNA encoding makes the algorithm more resistant to attacks and can effectively resist common types of attacks.},
	language = {en},
	number = {8},
	urldate = {2023-03-11},
	journal = {Multimedia Tools and Applications},
	author = {Guo, Zhida and Sun, Peng},
	month = mar,
	year = {2022},
	keywords = {DNA operation, Diffusion operation, Hash function, Image encryption, Logistic map, Reverse zigzag traverse},
	pages = {11301--11323},
}

@article{pettine_human_2023,
	title = {Human generalization of internal representations through prototype learning with goal-directed attention},
	copyright = {2023 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-023-01543-7},
	doi = {10.1038/s41562-023-01543-7},
	abstract = {The world is overabundant with feature-rich information obscuring the latent causes of experience. How do people approximate the complexities of the external world with simplified internal representations that generalize to novel examples or situations? Theories suggest that internal representations could be determined by decision boundaries that discriminate between alternatives, or by distance measurements against prototypes and individual exemplars. Each provide advantages and drawbacks for generalization. We therefore developed theoretical models that leverage both discriminative and distance components to form internal representations via action-reward feedback. We then developed three latent-state learning tasks to test how humans use goal-oriented discrimination attention and prototypes/exemplar representations. The majority of participants attended to both goal-relevant discriminative features and the covariance of features within a prototype. A minority of participants relied only on the discriminative feature. Behaviour of all participants could be captured by parameterizing a model combining prototype representations with goal-oriented discriminative attention.},
	language = {en},
	urldate = {2023-03-10},
	journal = {Nature Human Behaviour},
	author = {Pettine, Warren Woodrich and Raman, Dhruva Venkita and Redish, A. David and Murray, John D.},
	month = mar,
	year = {2023},
	keywords = {Human behaviour, Learning algorithms},
	pages = {1--22},
}

@article{wolff_minflux_2023,
	title = {{MINFLUX} dissects the unimpeded walking of kinesin-1},
	volume = {379},
	url = {https://www.science.org/doi/10.1126/science.ade2650},
	doi = {10.1126/science.ade2650},
	abstract = {We introduce an interferometric MINFLUX microscope that records protein movements with up to 1.7 nanometer per millisecond spatiotemporal precision. Such precision has previously required attaching disproportionately large beads to the protein, but MINFLUX requires the detection of only about 20 photons from an approximately 1-nanometer-sized fluorophore. Therefore, we were able to study the stepping of the motor protein kinesin-1 on microtubules at up to physiological adenosine-5′-triphosphate (ATP) concentrations. We uncovered rotations of the stalk and the heads of load-free kinesin during stepping and showed that ATP is taken up with a single head bound to the microtubule and that ATP hydrolysis occurs when both heads are bound. Our results show that MINFLUX quantifies (sub)millisecond conformational changes of proteins with minimal disturbance.},
	number = {6636},
	urldate = {2023-03-10},
	journal = {Science},
	author = {Wolff, Jan O. and Scheiderer, Lukas and Engelhardt, Tobias and Engelhardt, Johann and Matthias, Jessica and Hell, Stefan W.},
	month = mar,
	year = {2023},
	pages = {1004--1010},
}

@article{midtvedt_single-shot_2022,
	title = {Single-shot self-supervised object detection in microscopy},
	volume = {13},
	doi = {10.1038/s41467-022-35004-y},
	abstract = {Object detection is a fundamental task in digital microscopy, where machine learning has made great strides in overcoming the limitations of classical approaches. The training of state-of-the-art machine-learning methods almost universally relies on vast amounts of labeled experimental data or the ability to numerically simulate realistic datasets. However, experimental data are often challenging to label and cannot be easily reproduced numerically. Here, we propose a deep-learning method, named LodeSTAR (Localization and detection from Symmetries, Translations And Rotations), that learns to detect microscopic objects with sub-pixel accuracy from a single unlabeled experimental image by exploiting the inherent roto-translational symmetries of this task. We demonstrate that LodeSTAR outperforms traditional methods in terms of accuracy, also when analyzing challenging experimental data containing densely packed cells or noisy backgrounds. Furthermore, by exploiting additional symmetries we show that LodeSTAR can measure other properties, e.g., vertical position and polarizability in holographic microscopy.},
	journal = {Nature Communications},
	author = {Midtvedt, Benjamin and Pineda, Jesús and Skärberg, Fredrik and Olsén, Erik and Bachimanchi, Harshith and Wesén, Emelie and Esbjörner, Elin and Selander, Erik and Höök, Fredrik and Midtvedt, Daniel and Volpe, Giovanni},
	month = dec,
	year = {2022},
}

@article{coombes_next_2023,
	title = {Next generation neural population models},
	volume = {9},
	doi = {10.3389/fams.2023.1128224},
	abstract = {Low-dimensional neural mass models are often invoked to model the coarse-grained activity of large populations of neurons and synapses and have been used to help understand the coordination of large scale brain rhythms. However, they are phenomenological in nature and, although motivated by neurobiological considerations, the absence of a direct link to an underlying biophysical reality is a weakness that means they may not be best suited to capturing some of the rich behaviors seen in real neuronal tissue. In this perspective article I discuss a simple spiking neuron network model that has recently been shown to admit to an exact mean-field description for synaptic interactions. This has many of the features of a neural mass model coupled to an additional dynamical equation that describes the evolution of population synchrony. This next generation neural mass model is ideally suited to understanding the patterns of brain activity that are ubiquitously seen in neuroimaging recordings. Here I review the mean-field equations, the way in which population synchrony, firing rate, and average voltage are intertwined, together with their application in large scale brain modeling. As well as natural extensions of this new approach to modeling the dynamics of neuronal populations I discuss some of the open mathematical challenges in developing a statistical neurodynamics that can generalize the one discussed here.},
	journal = {Frontiers in Applied Mathematics and Statistics},
	author = {Coombes, Stephen},
	month = feb,
	year = {2023},
	pages = {1128224},
}

@article{yuan_review_2017,
	title = {A review of moving object trajectory clustering algorithms},
	volume = {47},
	issn = {1573-7462},
	url = {https://doi.org/10.1007/s10462-016-9477-7},
	doi = {10.1007/s10462-016-9477-7},
	abstract = {Clustering is an efficient way to group data into different classes on basis of the internal and previously unknown schemes inherent of the data. With the development of the location based positioning devices, more and more moving objects are traced and their trajectories are recorded. Therefore, moving object trajectory clustering undoubtedly becomes the focus of the study in moving object data mining. To provide an overview, we survey and summarize the development and trend of moving object clustering and analyze typical moving object clustering algorithms presented in recent years. In this paper, we firstly summarize the strategies and implement processes of classical moving object clustering algorithms. Secondly, the measures which can determine the similarity/dissimilarity between two trajectories are discussed. Thirdly, the validation criteria are analyzed for evaluating the performance and efficiency of clustering algorithms. Finally, some application scenarios are point out for the potential application in future. It is hope that this research will serve as the steppingstone for those interested in advancing moving object mining.},
	language = {en},
	number = {1},
	urldate = {2023-03-09},
	journal = {Artificial Intelligence Review},
	author = {Yuan, Guan and Sun, Penghui and Zhao, Jie and Li, Daxing and Wang, Canwei},
	month = jan,
	year = {2017},
	keywords = {Data mining, Moving objects, Moving pattern, Similarity measure, Trajectory clustering},
	pages = {123--144},
}

@misc{alt_can_2007,
	title = {Can we {Compute} the {Similarity} {Between} {Surfaces}?},
	url = {http://arxiv.org/abs/cs/0703011},
	doi = {10.48550/arXiv.cs/0703011},
	abstract = {A suitable measure for the similarity of shapes represented by parameterized curves or surfaces is the Fr{\textbackslash}'echet distance. Whereas efficient algorithms are known for computing the Fr{\textbackslash}'echet distance of polygonal curves, the same problem for triangulated surfaces is NP-hard. Furthermore, it remained open whether it is computable at all. Here, using a discrete approximation we show that it is \{{\textbackslash}em upper semi-computable\}, i.e., there is a non-halting Turing machine which produces a monotone decreasing sequence of rationals converging to the result. It follows that the decision problem, whether the Fr{\textbackslash}'echet distance of two given surfaces lies below some specified value, is recursively enumerable. Furthermore, we show that a relaxed version of the problem, the computation of the \{{\textbackslash}em weak Fr{\textbackslash}'echet distance\} can be solved in polynomial time. For this, we give a computable characterization of the weak Fr{\textbackslash}'echet distance in a geometric data structure called the \{{\textbackslash}em free space diagram\}.},
	urldate = {2023-03-09},
	publisher = {arXiv},
	author = {Alt, Helmut and Buchin, Maike},
	month = mar,
	year = {2007},
	note = {arXiv:cs/0703011},
	keywords = {Computer Science - Computational Complexity, Computer Science - Computational Geometry, F.1.1, F.2.2},
}

@article{fu_field-dependent_2023,
	title = {Field-dependent deep learning enables high-throughput whole-cell {3D} super-resolution imaging},
	volume = {20},
	copyright = {2023 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-023-01775-5},
	doi = {10.1038/s41592-023-01775-5},
	abstract = {Single-molecule localization microscopy in a typical wide-field setup has been widely used for investigating subcellular structures with super resolution; however, field-dependent aberrations restrict the field of view (FOV) to only tens of micrometers. Here, we present a deep-learning method for precise localization of spatially variant point emitters (FD-DeepLoc) over a large FOV covering the full chip of a modern sCMOS camera. Using a graphic processing unit-based vectorial point spread function (PSF) fitter, we can fast and accurately model the spatially variant PSF of a high numerical aperture objective in the entire FOV. Combined with deformable mirror-based optimal PSF engineering, we demonstrate high-accuracy three-dimensional single-molecule localization microscopy over a volume of {\textasciitilde}180 × 180 × 5 μm3, allowing us to image mitochondria and nuclear pore complexes in entire cells in a single imaging cycle without hardware scanning; a 100-fold increase in throughput compared to the state of the art.},
	language = {en},
	number = {3},
	urldate = {2023-03-09},
	journal = {Nature Methods},
	author = {Fu, Shuang and Shi, Wei and Luo, Tingdan and He, Yingchuan and Zhou, Lulu and Yang, Jie and Yang, Zhichao and Liu, Jiadong and Liu, Xiaotian and Guo, Zhiyong and Yang, Chengyu and Liu, Chao and Huang, Zhen-li and Ries, Jonas and Zhang, Mingjie and Xi, Peng and Jin, Dayong and Li, Yiming},
	month = mar,
	year = {2023},
	keywords = {Super-resolution microscopy},
	pages = {459--468},
}

@misc{noauthor_fluorescence_nodate,
	title = {Fluorescence {Excitation} \& {Emission} {\textbar} {Emission} {Spectrums} {\textbar} {Olympus} {LS}},
	url = {https://www.olympus-lifescience.com/en/microscope-resource/primer/lightandcolor/fluoroexcitation/},
	urldate = {2023-03-07},
}

@misc{smith_disciplined_2018,
	title = {A disciplined approach to neural network hyper-parameters: {Part} 1 -- learning rate, batch size, momentum, and weight decay},
	shorttitle = {A disciplined approach to neural network hyper-parameters},
	url = {http://arxiv.org/abs/1803.09820},
	doi = {10.48550/arXiv.1803.09820},
	abstract = {Although deep learning has produced dazzling successes for applications of image, speech, and video processing in the past few years, most trainings are with suboptimal hyper-parameters, requiring unnecessarily long training times. Setting the hyper-parameters remains a black art that requires years of experience to acquire. This report proposes several efficient ways to set the hyper-parameters that significantly reduce training time and improves performance. Specifically, this report shows how to examine the training validation/test loss function for subtle clues of underfitting and overfitting and suggests guidelines for moving toward the optimal balance point. Then it discusses how to increase/decrease the learning rate/momentum to speed up training. Our experiments show that it is crucial to balance every manner of regularization for each dataset and architecture. Weight decay is used as a sample regularizer to show how its optimal value is tightly coupled with the learning rates and momentums. Files to help replicate the results reported here are available.},
	urldate = {2023-03-07},
	publisher = {arXiv},
	author = {Smith, Leslie N.},
	month = apr,
	year = {2018},
	note = {arXiv:1803.09820 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@book{aggarwal_ensure_2021,
	title = {Ensure: {Ensemble} {Stein}’s {Unbiased} {Risk} {Estimator} for {Unsupervised} {Learning}},
	volume = {2021},
	shorttitle = {Ensure},
	abstract = {Deep learning algorithms are emerging as powerful alternatives to compressed sensing methods, offering improved image quality and computational efficiency. Unfortunately, fully sampled training images may not be available or are difficult to acquire in several applications, including high-resolution and dynamic imaging. Previous studies in image reconstruction have utilized Stein's Unbiased Risk Estimator (SURE) as a mean square error (MSE) estimate for the image denoising step in an unrolled network. Unfortunately, the end-to-end training of a network using SURE remains challenging since the projected SURE loss is a poor approximation to the MSE, especially in the heavily undersampled setting. We propose an ENsemble SURE (ENSURE) approach to train a deep network only from undersampled measurements. In particular, we show that training a network using an ensemble of images, each acquired with a different sampling pattern, can closely approximate the MSE. Our preliminary experimental results show that the proposed ENSURE approach gives comparable reconstruction quality to supervised learning and a recent unsupervised learning method.},
	author = {Aggarwal, Hemant and Pramanik, Aniket and Jacob, Mathews},
	month = jun,
	year = {2021},
	doi = {10.1109/ICASSP39728.2021.9414513},
}

@article{bosquet_full_2022,
	title = {A {Full} {Data} {Augmentation} {Pipeline} for {Small} {Object} {Detection} based on {Generative} {Adversarial} {Networks}},
	volume = {133},
	doi = {10.1016/j.patcog.2022.108998},
	abstract = {Object detection accuracy on small objects, i.e., objects under 32×32 pixels, lags behind that of large ones. To address this issue, innovative architectures have been designed and new datasets have been released. Still, the number of small objects in many datasets does not suffice for training. The advent of the generative adversarial networks (GANs) opens up a new data augmentation possibility for training architectures without the costly task of annotating huge datasets for small objects. In this paper, we propose a full pipeline for data augmentation for small object detection which combines a GAN-based object generator with techniques of object segmentation, image inpainting, and image blending to achieve high-quality synthetic data. The main component of our pipeline is DS-GAN, a novel GAN-based architecture that generates realistic small objects from larger ones. Experimental results show that our overall data augmentation method improves the performance of state-of-the-art models up to 11.9\% APs@.5 on UAVDT and by 4.7\% APs@.5 on iSAID, both for the small objects subset and for a scenario where the number of training instances is limited.},
	journal = {Pattern Recognition},
	author = {Bosquet, Brais and Cores, Daniel and Seidenari, Lorenzo and Brea, Victor and Mucientes, Manuel and Bimbo, Alberto},
	month = aug,
	year = {2022},
	pages = {108998},
}

@article{moroni_multilayergraphsjl_2023,
	title = {{MultilayerGraphs}.jl: {Multilayer} {Network} {Science} in {Julia}},
	volume = {8},
	issn = {2475-9066},
	shorttitle = {{MultilayerGraphs}.jl},
	url = {https://joss.theoj.org/papers/10.21105/joss.05116},
	doi = {10.21105/joss.05116},
	abstract = {Moroni et al., (2023). MultilayerGraphs.jl: Multilayer Network Science in Julia. Journal of Open Source Software, 8(83), 5116, https://doi.org/10.21105/joss.05116},
	language = {en},
	number = {83},
	urldate = {2023-03-06},
	journal = {Journal of Open Source Software},
	author = {Moroni, Claudio and Monticone, Pietro},
	month = mar,
	year = {2023},
	pages = {5116},
}

@article{teves_dynamic_2016,
	title = {A dynamic mode of mitotic bookmarking by transcription factors},
	volume = {5},
	issn = {2050-084X},
	doi = {10.7554/eLife.22280},
	abstract = {During mitosis, transcription is shut off, chromatin condenses, and most transcription factors (TFs) are reported to be excluded from chromosomes. How do daughter cells re-establish the original transcription program? Recent discoveries that a select set of TFs remain bound on mitotic chromosomes suggest a potential mechanism for maintaining transcriptional programs through the cell cycle termed mitotic bookmarking. Here we report instead that many TFs remain associated with chromosomes in mouse embryonic stem cells, and that the exclusion previously described is largely a fixation artifact. In particular, most TFs we tested are significantly enriched on mitotic chromosomes. Studies with Sox2 reveal that this mitotic interaction is more dynamic than in interphase and is facilitated by both DNA binding and nuclear import. Furthermore, this dynamic mode results from lack of transcriptional activation rather than decreased accessibility of underlying DNA sequences in mitosis. The nature of the cross-linking artifact prompts careful re-examination of the role of TFs in mitotic bookmarking.},
	language = {eng},
	journal = {eLife},
	author = {Teves, Sheila S. and An, Luye and Hansen, Anders S. and Xie, Liangqi and Darzacq, Xavier and Tjian, Robert},
	month = nov,
	year = {2016},
	pmid = {27855781},
	pmcid = {PMC5156526},
	keywords = {Animals, Cells, Cultured, Chromosomes, Mice, Mitosis, Mouse Embryonic Stem Cells, Transcription Factors, Transcription, Genetic, cell biology, chromosomes, embryonic stem cells, genes, knock-in cells, mouse},
	pages = {e22280},
}

@book{yang_graph_2015,
	title = {Graph {Based} {Kernel} k-{Means} {Using} {Representative} {Data} {Points} as {Initial} {Centers}},
	isbn = {9783319221793},
	abstract = {The k-means algorithm is undoubtedly the most widely used data clustering algorithm due to its relative simplicity. It can only handle data that are linearly separable. A generalization of k-means is kernel k-means, which can handle data that are not linearly separable. Standard k-means and kernel k-means have the same disadvantage of being sensitive to the initial placement of the cluster centers. A novel kernel k-means algorithm is proposed in the paper. The proposed algorithm uses a graph based kernel matrix and finds k data points as initial centers for kernel k-means. Since finding the optimal data points as initial centers is an NP-hard problem, this problem is relaxed to obtain k representative data points as initial centers. Matching pursuit algorithm for multiple vectors is used to greedily find k representative data points. The proposed algorithm is tested on synthetic and real-world datasets and compared with kernel k-means algorithms using other initialization techniques. Our empirical study shows encouraging results of the proposed algorithm.},
	author = {Yang, Wuyi and Tang, L.},
	month = aug,
	year = {2015},
	doi = {10.1007/978-3-319-22180-9_29},
}

@article{ganesan_finding_2016,
	title = {Finding {Representative} {Points} in {Multivariate} {Data} {Using} {PCA}},
	abstract = {The idea of representation has been used in various fields of study from data analysis to political science. In this paper, we define representativeness and describe a method to isolate data points that can represent the entire data set. Also, we show how the minimum set of representative data points can be generated. We use data from GLOBE (a project to study the effects on Land Change based on a set of parameters that include temperature, forest cover, human population, atmospheric parameters and many other variables) to test \& validate the algorithm. Principal Component Analysis (PCA) is used to reduce the dimensions of the multivariate data set, so that the representative points can be generated efficiently and its Representativeness has been compared against Random Sampling of points from the data set.},
	author = {Ganesan, Ashwinkumar and Oates, Tim and Schmill, Matt},
	month = oct,
	year = {2016},
}

@book{lago_machado_generating_2022,
	title = {On {Generating} {Representative} {Data} for {Multiple} {Aspects} {Trajectory} {Data}},
	abstract = {Trajectory data mining and analysis tasks have been widely studied in recent years. These tasks are complex due to the large volume of data generated and its heterogeneity. A solution to minimize these problems is the summarization of these data, aiming to generate representative data. Few works in the literature address these solutions, and none were found that consider all dimensions of a trajectory (spatial, temporal and unlimited semantic aspects), analyzing the peculiarities and singularities of each aspect. This doctoral thesis proposes a method based on a spatial grid for summarizing multi-aspect trajectories, called MAT-SG. Its main contributions are: (i) segmentation of trajectories in a spatial grid according to the dispersion of points; (ii) from a set of input trajectories, a representative trajectory is generated as a sequence of representative points with representative values for each dimension, considering the particularities of each type of aspect. An example demonstrates the potential of the proposal, being evaluated the volume reduction and the accuracy of the summarization.},
	author = {Lago Machado, Vanessa and Mello, Ronaldo and Bogorny, Vania},
	month = sep,
	year = {2022},
	doi = {10.5753/sbbd_estendido.2022.21850},
}

@book{sarah_adaptive_2023,
	title = {Adaptive weighting of {Bayesian} physics informed neural networks for multitask and multiscale forward and inverse problems},
	abstract = {In this paper, we present a novel methodology for automatic adaptive weighting of Bayesian Physics-Informed Neural Networks (BPINNs), and we demonstrate that this makes it possible to robustly address multi-objective and multi-scale problems. BPINNs are a popular framework for data assimilation, combining the constraints of Uncertainty Quantification (UQ) and Partial Differential Equation (PDE). The relative weights of the BPINN target distribution terms are directly related to the inherent uncertainty in the respective learning tasks. Yet, they are usually manually set a-priori, that can lead to pathological behavior, stability concerns, and to conflicts between tasks which are obstacles that have deterred the use of BPINNs for inverse problems with multi-scale dynamics. The present weighting strategy automatically tunes the weights by considering the multi-task nature of target posterior distribution. We show that this remedies the failure modes of BPINNs and provides efficient exploration of the optimal Pareto front. This leads to better convergence and stability of BPINN training while reducing sampling bias. The determined weights moreover carry information about task uncertainties, reflecting noise levels in the data and adequacy of the PDE model. We demonstrate this in numerical experiments in Sobolev training, and compare them to analytically \${\textbackslash}epsilon\$-optimal baseline, and in a multi-scale Lokta-Volterra inverse problem. We eventually apply this framework to an inpainting task and an inverse problem, involving latent field recovery for incompressible flow in complex geometries.},
	author = {Sarah, Perez and Maddu, Suryanarayana},
	month = feb,
	year = {2023},
	doi = {10.48550/arXiv.2302.12697},
}

@article{nizam_monte_2022,
	title = {Monte {Carlo}-based data generation for efficient deep learning reconstruction of macroscopic diffuse optical tomography and topography applications},
	volume = {27},
	doi = {10.1117/1.JBO.27.8.083016},
	abstract = {Significance: Deep learning (DL) models are being increasingly developed to map sensor data to the image domain directly. However, DL methodologies are data-driven and require large and diverse data sets to provide robust and accurate image formation performances. For research modalities such as 2D/3D diffuse optical imaging, the lack of large publicly available data sets and the wide variety of instrumentation designs, data types, and applications leads to unique challenges in obtaining well-controlled data sets for training and validation. Meanwhile, great efforts over the last four decades have focused on developing accurate and computationally efficient light propagation models that are flexible enough to simulate a wide variety of experimental conditions. 

Aim: Recent developments in Monte Carlo (MC)-based modeling offer the unique advantage of simulating accurately light propagation spatially, temporally, and over an extensive range of optical parameters, including minimally to highly scattering tissue within a computationally efficient platform. Herein, we demonstrate how such MC platforms, namely "Monte Carlo eXtreme" and "Mesh-based Monte Carlo," can be leveraged to generate large and representative data sets for training the DL model efficiently.

Approach: We propose data generator pipeline strategies using these platforms and demonstrate their potential in fluorescence optical topography, fluorescence optical tomography, and single-pixel diffuse optical tomography. These applications represent a large variety in instrumentation design, sample properties, and contrast function.

Results: DL models trained using the MC-based in silico datasets, validated further with experimental data not used during training, show accurate and promising results.

Conclusion: Overall, these MC-based data generation pipelines are expected to support the development of DL models for rapid, robust, and user-friendly image formation in a wide variety of applications.},
	journal = {Journal of Biomedical Optics},
	author = {Nizam, Navid and Ochoa, Marien and Smith, Jason and Gao, Shan and Intes, Xavier},
	month = apr,
	year = {2022},
}

@article{nizam_deep_2023,
	title = {Deep {Learning} {Based} {Fusion} of {Widefield} {Diffuse} {Optical} {Tomography} and micro-{CT} {Structural} {Priors} for {Accurate} {3D} {Reconstructions}},
	doi = {10.1364/BOE.480091},
	abstract = {Widefield illumination and detection strategies leveraging structured light have enabled fast and robust probing of tissue properties over large surface areas and volumes. However, when applied to diffuse optical tomography (DOT) applications, they still require a time-consuming and expert-centric solving of an ill-posed inverse problem. Deep learning (DL) models have been recently proposed to facilitate this challenging step. Herein, we expand on a previously reported deep neural network (DNN) -based architecture (modified AUTOMAP - ModAM) for accurate and fast reconstructions of the absorption coefficient in 3D DOT based on a structured light illumination and detection scheme. Furthermore, we evaluate the improved performances when incorporating a micro-CT structural prior in the DNN-based workflow, named Z-AUTOMAP. This Z-AUTOMAP significantly improves the widefield imaging process’s spatial resolution, especially in the transverse direction. The reported DL-based strategies are validated both in silico and in experimental phantom studies using spectral micro-CT priors. Overall, this is the first successful demonstration of micro-CT and DOT fusion using deep learning, greatly enhancing the prospect of rapid data-integration strategies, often demanded in challenging pre-clinical scenarios.},
	journal = {Biomedical Optics Express},
	author = {Nizam, Navid and Ochoa, Marien and Smith, Jason and Intes, Xavier},
	month = jan,
	year = {2023},
}

@article{ilacqua_expression_2022,
	title = {Expression of {Synj2bp} in mouse liver regulates the extent of {wrappER}-mitochondria contact to maintain hepatic lipid homeostasis},
	volume = {17},
	copyright = {2022 The Author(s)},
	issn = {1745-6150},
	url = {https://biologydirect.biomedcentral.com/articles/10.1186/s13062-022-00344-8},
	doi = {10.1186/s13062-022-00344-8},
	abstract = {In mouse liver hepatocytes, nearly half of the surface area of every mitochondrion is covered by wrappER, a wrapping-type of ER that is rich in fatty acids and synthesizes lipoproteins (VLDL) (Anastasia et al. in Cell Rep 34:108873, 2021; Hurtley in Science (80- ) 372:142–143, 2021; Ilacqua et al. in J Cell Sci 135:1–11, 2021). A disruption of the ultrastructure of the wrappER-mitochondria contact results in altered fatty acid flux, leading to hepatic dyslipidemia (Anastasia et al. 2021). The molecular mechanism that regulates the extent of wrappER-mitochondria contacts is unknown. We evaluated the expression level of the mitochondrial protein Synj2bp in the liver of normal and obese (ob/ob) mice. In addition, we silenced its expression in the liver using an AAV8 vector. We coupled quantitative EM morphometric analysis to proteomics and lipid analyses on these livers. The expression level of Synj2bp in the liver positively correlates with the extent of wrappER-mitochondria contacts. A 50\% reduction in wrappER-mitochondria contacts causes hepatic dyslipidemia, characterized by a gross accumulation of lipid droplets in the liver, an increased hepatic secretion of VLDL and triglycerides, a curtailed ApoE expression, and an increased capacity of mitochondrial fatty acid respiration. Synj2bp regulates the extent of wrappER-mitochondria contacts in the liver, thus contributing to the control of hepatic lipid flux.},
	language = {en},
	number = {1},
	urldate = {2023-02-16},
	journal = {Biology Direct},
	author = {Ilacqua, Nicolò and Anastasia, Irene and Aloshyn, Danylo and Ghandehari-Alavijeh, Rana and Peluso, Emily Ann and Brearley-Sholto, Madelaine C. and Pellegrini, Leonardo V. and Raimondi, Andrea and de Aguiar Vallim, Thomas Q. and Pellegrini, Luca},
	month = dec,
	year = {2022},
	pages = {1--18},
}

@article{varga_machine_2023,
	title = {Machine learning framework to segment sarcomeric structures in {SMLM} data},
	volume = {13},
	doi = {10.1038/s41598-023-28539-7},
	abstract = {Object detection is an image analysis task with a wide range of applications, which is difficult to accomplish with traditional programming. Recent breakthroughs in machine learning have made significant progress in this area. However, these algorithms are generally compatible with traditional pixelated images and cannot be directly applied for pointillist datasets generated by single molecule localization microscopy (SMLM) methods. Here, we have improved the averaging method developed for the analysis of SMLM images of sarcomere structures based on a machine learning object detection algorithm. The ordered structure of sarcomeres allows us to determine the location of the proteins more accurately by superimposing SMLM images of identically assembled proteins. However, the area segmentation process required for averaging can be extremely time-consuming and tedious. In this work, we have automated this process. The developed algorithm not only finds the regions of interest, but also classifies the localizations and identifies the true positive ones. For training, we used simulations to generate large amounts of labelled data. After tuning the neural network’s internal parameters, it could find the localizations associated with the structures we were looking for with high accuracy. We validated our results by comparing them with previous manual evaluations. It has also been proven that the simulations can generate data of sufficient quality for training. Our method is suitable for the identification of other types of structures in SMLM data.},
	journal = {Scientific Reports},
	author = {Varga, Dániel and Szikora, Szilard and Novák, Tibor and Pap, Gergely and Leko, Gabor and Mihály, József and Erdélyi, Miklós},
	month = jan,
	year = {2023},
	pages = {1582},
}

@article{de_duve_lysosome_1963,
	title = {The {Lysosome}},
	volume = {208},
	issn = {0036-8733},
	url = {https://www.scientificamerican.com/article/the-lysosome},
	doi = {10.1038/scientificamerican0563-64},
	number = {5},
	urldate = {2023-02-13},
	journal = {Scientific American},
	author = {de Duve, Christian},
	month = may,
	year = {1963},
	pages = {64--73},
}

@article{nieves_framework_2023,
	title = {A framework for evaluating the performance of {SMLM} cluster analysis algorithms},
	volume = {20},
	copyright = {2023 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-022-01750-6},
	doi = {10.1038/s41592-022-01750-6},
	abstract = {Single-molecule localization microscopy (SMLM) generates data in the form of coordinates of localized fluorophores. Cluster analysis is an attractive route for extracting biologically meaningful information from such data and has been widely applied. Despite a range of cluster analysis algorithms, there exists no consensus framework for the evaluation of their performance. Here, we use a systematic approach based on two metrics to score the success of clustering algorithms in simulated conditions mimicking experimental data. We demonstrate the framework using seven diverse analysis algorithms: DBSCAN, ToMATo, KDE, FOCAL, CAML, ClusterViSu and SR-Tesseler. Given that the best performer depended on the underlying distribution of localizations, we demonstrate an analysis pipeline based on statistical similarity measures that enables the selection of the most appropriate algorithm, and the optimized analysis parameters for real SMLM data. We propose that these standard simulated conditions, metrics and analysis pipeline become the basis for future analysis algorithm development and evaluation.},
	language = {en},
	number = {2},
	urldate = {2023-02-12},
	journal = {Nature Methods},
	author = {Nieves, Daniel J. and Pike, Jeremy A. and Levet, Florian and Williamson, David J. and Baragilly, Mohammed and Oloketuyi, Sandra and de Marco, Ario and Griffié, Juliette and Sage, Daniel and Cohen, Edward A. K. and Sibarita, Jean-Baptiste and Heilemann, Mike and Owen, Dylan M.},
	month = feb,
	year = {2023},
	keywords = {Software, Super-resolution microscopy},
	pages = {259--267},
}

@misc{noauthor_correction_nodate,
	title = {Correction of multiple-blinking artifacts in photoactivated localization microscopy - {PubMed}},
	url = {https://pubmed.ncbi.nlm.nih.gov/35545712/},
	urldate = {2023-02-01},
}

@book{lozenski_neural_2022,
	title = {Neural fields for dynamic imaging},
	author = {Lozenski, Luke and Anastasio, Mark and Villa, Umberto},
	month = mar,
	year = {2022},
	doi = {10.1117/12.2613148},
}

@article{hagen_fluorescence_2021,
	title = {Fluorescence microscopy datasets for training deep neural networks},
	volume = {10},
	doi = {10.1093/gigascience/giab032},
	abstract = {Background: 
Fluorescence microscopy is an important technique in many areas of biological research. Two factors that limit the usefulness and performance of fluorescence microscopy are photobleaching of fluorescent probes during imaging and, when imaging live cells, phototoxicity caused by light exposure. Recently developed methods in machine learning are able to greatly improve the signal-to-noise ratio of acquired images. This allows researchers to record images with much shorter exposure times, which in turn minimizes photobleaching and phototoxicity by reducing the dose of light reaching the sample.

Findings:
To use deep learning methods, a large amount of data is needed to train the underlying convolutional neural network. One way to do this involves use of pairs of fluorescence microscopy images acquired with long and short exposure times. We provide high-quality datasets that can be used to train and evaluate deep learning methods under development.

Conclusion:
The availability of high-quality data is vital for training convolutional neural networks that are used in current machine learning approaches.},
	journal = {GigaScience},
	author = {Hagen, Guy and Bendesky, Justin and Machado, Rosa and Nguyen, Tram-Anh and Kumar, Tanmay and Ventura, Jonathan},
	month = may,
	year = {2021},
}

@article{adler_quantifying_2021,
	title = {Quantifying colocalization: {The} case for discarding the {Manders} overlap coefficient},
	volume = {99},
	issn = {1552-4930},
	shorttitle = {Quantifying colocalization},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cyto.a.24336},
	doi = {10.1002/cyto.a.24336},
	abstract = {Colocalization measurements aim to characterize the relative distribution of two molecules within a biologically relevant area. It is efficient to measure two distinct features, co-occurrence, the extent to which the molecules appear together, and correlation, how well variations in concentration of the two molecules match. The Manders overlap coefficient (MOC) appears in most colocalization software but the literature contains three interpretations of its measurements: (a) co-occurrence, (b) correlation, or (c) a combination of both. This is surprising given the simplicity of the underlying equation. Testing shows that the MOC responds both to changes in co-occurrence and to changes in correlation. Further testing reveals that different distributions of intensity (Gaussian, gamma, uniform, exponential) dramatically alter the balance between the contribution from co-occurrence and correlation. It follows that the MOC's ability to differentiate between different patterns of colocalization is very limited, since any value is compatible with widely differing combinations of co-occurrence, correlation, and intensity distribution. To characterize colocalization, we recommend reporting both co-occurrence and correlation, using coefficients specific for each attribute. Since the MOC has no clear role in the measurement of colocalization and causes considerable confusion, we conclude that it should be discarded.},
	language = {en},
	number = {9},
	urldate = {2023-01-18},
	journal = {Cytometry Part A},
	author = {Adler, Jeremy and Parmryd, Ingela},
	year = {2021},
	keywords = {MOC, co-occurrence, colocalization analysis, correlation, fluorescence, quantification},
	pages = {910--920},
}

@book{fawkes_doubly_2022,
	title = {Doubly {Robust} {Kernel} {Statistics} for {Testing} {Distributional} {Treatment} {Effects} {Even} {Under} {One} {Sided} {Overlap}},
	abstract = {As causal inference becomes more widespread the importance of having good tools to test for causal effects increases. In this work we focus on the problem of testing for causal effects that manifest in a difference in distribution for treatment and control. We build on work applying kernel methods to causality, considering the previously introduced Counterfactual Mean Embedding framework ({\textbackslash}textsc\{CfME\}). We improve on this by proposing the {\textbackslash}emph\{Doubly Robust Counterfactual Mean Embedding\} ({\textbackslash}textsc\{DR-CfME\}), which has better theoretical properties than its predecessor by leveraging semiparametric theory. This leads us to propose new kernel based test statistics for distributional effects which are based upon doubly robust estimators of treatment effects. We propose two test statistics, one which is a direct improvement on previous work and one which can be applied even when the support of the treatment arm is a subset of that of the control arm. We demonstrate the validity of our methods on simulated and real-world data, as well as giving an application in off-policy evaluation.},
	author = {Fawkes, Jake and Hu, Robert and Evans, Robin and Sejdinovic, Dino},
	month = dec,
	year = {2022},
	doi = {10.48550/arXiv.2212.04922},
}

@misc{hasani_liquid_2020,
	title = {Liquid {Time}-constant {Networks}},
	url = {http://arxiv.org/abs/2006.04439},
	doi = {10.48550/arXiv.2006.04439},
	abstract = {We introduce a new class of time-continuous recurrent neural network models. Instead of declaring a learning system's dynamics by implicit nonlinearities, we construct networks of linear first-order dynamical systems modulated via nonlinear interlinked gates. The resulting models represent dynamical systems with varying (i.e., liquid) time-constants coupled to their hidden state, with outputs being computed by numerical differential equation solvers. These neural networks exhibit stable and bounded behavior, yield superior expressivity within the family of neural ordinary differential equations, and give rise to improved performance on time-series prediction tasks. To demonstrate these properties, we first take a theoretical approach to find bounds over their dynamics and compute their expressive power by the trajectory length measure in latent trajectory space. We then conduct a series of time-series prediction experiments to manifest the approximation capability of Liquid Time-Constant Networks (LTCs) compared to classical and modern RNNs. Code and data are available at https://github.com/raminmh/liquid\_time\_constant\_networks},
	urldate = {2023-01-14},
	publisher = {arXiv},
	author = {Hasani, Ramin and Lechner, Mathias and Amini, Alexander and Rus, Daniela and Grosu, Radu},
	month = dec,
	year = {2020},
	note = {arXiv:2006.04439 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@inproceedings{metagudda_uncertainty_2023,
	address = {Singapore},
	series = {Lecture {Notes} in {Civil} {Engineering}},
	title = {Uncertainty {Quantification} of {Structures} {Using} {Belief} {Theory}},
	isbn = {9789811933714},
	doi = {10.1007/978-981-19-3371-4_23},
	abstract = {Uncertainties due to loading, material properties, lack of knowledge, and manufacturing defaults are typical among practical engineering problems. They affect the performance and safety aspects of the structures. The fundamental difficulty in reliability evaluation is quantifying the uncertainty of structural systems. There are two forms of uncertainties such as aleatory uncertainty and epistemic uncertainty. Both aleatory uncertainty and epistemic uncertainty affect structures in the real world: aleatory uncertainty (induced by innate randomness) and epistemic uncertainty (induced by deficiency of information). Aleatory uncertainties can be handled effectively using probability measures, but epistemic uncertainties are not justified precisely using probability-based theories. Many non-probabilistic reliability estimates have been proposed to account for the influence of epistemic uncertainty, including evidence theory, interval analysis, fuzzy analysis, and the posbist reliability approach. A new reliability metric, belief reliability, is created to solve the disadvantages of non-probability approaches. Belief reliability is defined as the degree of confidence in the belief dependability of a system that meets four key axioms: normalcy, duality, subadditivity, and the product axiom. The belief’s reliability combines the contribution of design margin, aleatory uncertainty, and epistemic uncertainty. Belief reliability is an effective tool to evaluate uncertainties caused due to inherent randomness of the system (irreducible uncertainties) and uncertainties caused due to lack of information (reducible uncertainties). This paper reviews the belief reliability approach adopted for uncertainty quantification in civil engineering structures.},
	language = {en},
	booktitle = {Recent {Advances} in {Materials}, {Mechanics} and {Structures}},
	publisher = {Springer Nature},
	author = {Metagudda, Sushma H. and Balu, A. S.},
	editor = {Saha, Suman and Sajith, A. S. and Sahoo, Dipti Ranjan and Sarkar, Pradip},
	year = {2023},
	keywords = {Aleatory uncertainty, Belief reliability, Chance theory, Epistemic uncertainty, Reliability metric, Uncertainty theory},
	pages = {253--263},
}

@incollection{denoeux_representations_2020,
	address = {Cham},
	title = {Representations of {Uncertainty} in {AI}: {Beyond} {Probability} and {Possibility}},
	isbn = {9783030061647},
	shorttitle = {Representations of {Uncertainty} in {AI}},
	url = {https://doi.org/10.1007/978-3-030-06164-7_4},
	abstract = {This chapter completes the survey of the existing frameworks for representing uncertain and incomplete information, started in the previous chapter of this volume. The theory of belief functions and the theory of imprecise probabilities are presented. The latter setting is mathematically more general than the former, and both include probability theory and quantitative possibility theory as particular cases. Their respective knowledge representation capabilities are highlighted.},
	language = {en},
	urldate = {2023-01-13},
	booktitle = {A {Guided} {Tour} of {Artificial} {Intelligence} {Research}: {Volume} {I}: {Knowledge} {Representation}, {Reasoning} and {Learning}},
	publisher = {Springer International Publishing},
	author = {Denœux, Thierry and Dubois, Didier and Prade, Henri},
	editor = {Marquis, Pierre and Papini, Odile and Prade, Henri},
	year = {2020},
	doi = {10.1007/978-3-030-06164-7_4},
	pages = {119--150},
}

@book{han_design_2022,
	title = {Design principles of caveolins across metazoa and beyond},
	abstract = {Caveolins are a unique family of membrane remodeling proteins essential for caveolae formation, signaling, and stress sensing in vertebrates. Caveolin-related proteins are also expressed broadly across Metazoa. However, the relationship between the structure and function of members of the protein family remains obscure. To address this fundamental question, we use AlphaFold2 as a predictive tool to investigate the structural properties of 72 representative caveolins across evolution. The results of this analysis reveal caveolins consist of six common structural elements that can be mixed and matched, uncover principles that govern their assembly into oligomeric discs, and provide evidence that the association of caveolins with membranes is one of the most ancient functions of the protein. We also identify homologs of caveolins in choanoflagellates, pointing to a pre-metazoan origin of the protein family. Together, these findings define a new structure-based framework for probing the functional roles of caveolins across evolutionary space.},
	author = {Han, Bing and Wilson, Louis and Gulsevin, Alican and Meiler, Jens and Karakas, Erkan and Kenworthy, Anne},
	month = nov,
	year = {2022},
	doi = {10.1101/2022.11.15.516482},
}

@article{singh_joint_2022,
	title = {Joint {Frequency} and {Image} {Space} {Learning} for {MRI} {Reconstruction} and {Analysis}},
	volume = {2022},
	abstract = {We propose neural network layers that explicitly combine frequency and image feature representations and show that they can be used as a versatile building block for reconstruction from frequency space data. Our work is motivated by the challenges arising in MRI acquisition where the signal is a corrupted Fourier transform of the desired image. The proposed joint learning schemes enable both correction of artifacts native to the frequency space and manipulation of image space representations to reconstruct coherent image structures at every layer of the network. This is in contrast to most current deep learning approaches for image reconstruction that treat frequency and image space features separately and often operate exclusively in one of the two spaces. We demonstrate the advantages of joint convolutional learning for a variety of tasks, including motion correction, denoising, reconstruction from undersampled acquisitions, and combined undersampling and motion correction on simulated and real world multicoil MRI data. The joint models produce consistently high quality output images across all tasks and datasets. When integrated into a state of the art unrolled optimization network with physics-inspired data consistency constraints for undersampled reconstruction, the proposed architectures significantly improve the optimization landscape, which yields an order of magnitude reduction of training time. This result suggests that joint representations are particularly well suited for MRI signals in deep learning networks. Our code and pretrained models are publicly available at https://github.com/nalinimsingh/interlacer.},
	journal = {The journal of machine learning for biomedical imaging},
	author = {Singh, Nalini and Iglesias, Juan and Adalsteinsson, Elfar and Dalca, Adrian and Golland, Polina},
	month = jun,
	year = {2022},
}

@article{lolo_caveolin-1_2022,
	title = {Caveolin-1 dolines form a distinct and rapid caveolae-independent mechanoadaptation system},
	doi = {10.1038/s41556-022-01034-3},
	abstract = {In response to different types and intensities of mechanical force, cells modulate their physical properties and adapt their plasma membrane (PM). Caveolae are PM nano-invaginations that contribute to mechanoadaptation, buffering tension changes. However, whether core caveolar proteins contribute to PM tension accommodation independently from the caveolar assembly is unknown. Here we provide experimental and computational evidence supporting that caveolin-1 confers deformability and mechanoprotection independently from caveolae, through modulation of PM curvature. Freeze-fracture electron microscopy reveals that caveolin-1 stabilizes non-caveolar invaginations—dolines—capable of responding to low-medium mechanical forces, impacting downstream mechanotransduction and conferring mechanoprotection to cells devoid of caveolae. Upon cavin-1/PTRF binding, doline size is restricted and membrane buffering is limited to relatively high forces, capable of flattening caveolae. Thus, caveolae and dolines constitute two distinct albeit complementary components of a buffering system that allows cells to adapt efficiently to a broad range of mechanical stimuli.},
	journal = {Nature Cell Biology},
	author = {Lolo, Fidel-Nicolás and Walani, Nikhil and Seemann, Eric and Zalvidea, Dobryna and Pavón, Dácil and Cojoc, Gheorghe and Zamai, Moreno and Viaris de Lesegno, Christine and Benito, Fernando and Sánchez-Álvarez, Miguel and Uriarte, Juan and Echarri, Asier and Jiménez-Carretero, Daniel and Escolano, Joan-Carles and Sánchez, Susana and Caiolfa, Valeria and Navajas, Daniel and Trepat, Xavier and Guck, Jochen and Del Pozo, Miguel},
	month = dec,
	year = {2022},
}

@inproceedings{fang_decision-making_2022,
	title = {Decision-{Making} under {Open} {World} with {Generalized} {Evidence} {Theory}},
	doi = {10.1109/ICCCBDA55098.2022.9778880},
	abstract = {As an extension of Dempster-Shafer evidence theory, Generalized evidence theory can be used in an open world where some targets are unknown. How to make a proper decision under open world is an open issue. In this paper, we propose a method under uncertain environments based on generalized evidence theory, which is used for decision making. We use K-means clustering and elbow methods based on generalized evidence theory to generate a complete discernment framework. And under the framework, a new decision-making method is proposed. After experimental verification, the newly proposed method can well solve the decision-making problem under open world.},
	booktitle = {2022 7th {International} {Conference} on {Cloud} {Computing} and {Big} {Data} {Analytics} ({ICCCBDA})},
	author = {Fang, Hao},
	month = apr,
	year = {2022},
	keywords = {Big Data, Cloud computing, Decision making, Evidence theory, K-means clustering, Machine learning, Machine learning algorithms, Target recognition, decision-making under open world, elbow method, generalized evidence theory},
	pages = {370--378},
}

@article{zhang_belief_2022,
	title = {Belief {Combination} of {Classifiers} for {Incomplete} {Data}},
	volume = {9},
	issn = {2329-9274},
	doi = {10.1109/JAS.2022.105458},
	abstract = {Data with missing values, or incomplete information, brings some challenges to the development of classification, as the incompleteness may significantly affect the performance of classifiers. In this paper, we handle missing values in both training and test sets with uncertainty and imprecision reasoning by proposing a new belief combination of classifier (BCC) method based on the evidence theory. The proposed BCC method aims to improve the classification performance of incomplete data by characterizing the uncertainty and imprecision brought by incompleteness. In BCC, different attributes are regarded as independent sources, and the collection of each attribute is considered as a subset. Then, multiple classifiers are trained with each subset independently and allow each observed attribute to provide a sub-classification result for the query pattern. Finally, these sub-classification results with different weights (discounting factors) are used to provide supplementary information to jointly determine the final classes of query patterns. The weights consist of two aspects: global and local. The global weight calculated by an optimization function is employed to represent the reliability of each classifier, and the local weight obtained by mining attribute distribution characteristics is used to quantify the importance of observed attributes to the pattern classification. Abundant comparative experiments including seven methods on twelve datasets are executed, demonstrating the out-performance of BCC over all baseline methods in terms of accuracy, precision, recall, F1 measure, with pertinent computational costs.},
	number = {4},
	journal = {IEEE/CAA Journal of Automatica Sinica},
	author = {Zhang, Zuowei and Ye, Songtao and Zhang, Yiru and Ding, Weiping and Wang, Hao},
	month = apr,
	year = {2022},
	keywords = {Classifier fusion, Cognition, Deep learning, Evidence theory, Fuses, Pattern classification, Robustness, Training, classification, evidence theory, incomplete data, missing values},
	pages = {652--667},
}

@article{zhao_complex_2021,
	title = {Complex {Network} {Modeling} of {Evidence} {Theory}},
	volume = {29},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2020.3023760},
	abstract = {Because of the advantages of graphs in visualizing the relationship between individuals, complex networks have been widely used and greatly developed. In real-world applications of Dempster–Shafer evidence theory, there are usually thousands of sensors collecting information. It is easy to be overwhelmed by the mass of information and ignore the connections between them. The rise of the semisupervised learning method graph convolutional network makes it possible to address this issue. In this article, inspired by complex network, the basic probability assignment function, the base function of evidence theory, is modeled in a novel form of the network graph. Some typical issues of evidence theory, such as conflicting evidence, multiclass evidence clustering, and computational complexity for large-scale fusion are systematically addressed in the framework of the proposed network model. What's more, a new combination rule is presented from the point view of the graph. The empirical results of experiments on real data set demonstrate the potential and feasibility of complex networks in traditional evidence theory.},
	number = {11},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Zhao, Jie and Deng, Yong},
	month = nov,
	year = {2021},
	keywords = {Complex network, Complex networks, Computational complexity, Dempster–Shafer evidence theory, Machine learning, Semisupervised learning, evidential clustering, graph convolutional network (GCN), semisupervised learning},
	pages = {3470--3480},
}

@article{cozic_non-bayesian_2011,
	title = {Non-{Bayesian} {Decision} {Theory}. {Beliefs} and {Desires} as {Reasons} for {Action}, {Martin} {Peterson}. {Theory} and {Decision} {Library}, {Springer}, 2008. ix + 170 pages.},
	volume = {27},
	issn = {0266-2671, 1474-0028},
	url = {https://www.cambridge.org/core/journals/economics-and-philosophy/article/nonbayesian-decision-theory-beliefs-and-desires-as-reasons-for-action-martin-peterson-theory-and-decision-library-springer-2008-ix-170-pages/2788E245239F3EA88AF092C03A282824},
	doi = {10.1017/S0266267110000477},
	abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0266267110000477/resource/name/firstPage-S0266267110000477a.jpg},
	language = {en},
	number = {1},
	urldate = {2023-01-05},
	journal = {Economics \& Philosophy},
	author = {Cozic, Mikaël},
	month = mar,
	year = {2011},
	pages = {53--59},
}

@incollection{balke_counterfactual_1994,
	address = {San Francisco (CA)},
	title = {Counterfactual {Probabilities}: {Computational} {Methods}, {Bounds} and {Applications}},
	isbn = {9781558603325},
	shorttitle = {Counterfactual {Probabilities}},
	url = {https://www.sciencedirect.com/science/article/pii/B9781558603325500110},
	abstract = {Evaluation of counterfactual queries (e.g., “If A were true, would C have been true?”) is important to fault diagnosis, planning, and determination of liability. In this paper we present methods for computing the probabilities of such queries using the formulation proposed in [Balke and Pearl, 1994], where the antecedent of the query is interpreted as an external action that forces the proposition A to be true. When a prior probability is available on the causal mechanisms governing the domain, counterfactual probabilities can be evaluated precisely. However, when causal knowledge is specified as conditional probabilities on the observables, only bounds can computed. This paper develops techniques for evaluating these bounds, and demonstrates their use in two applications: (1) the determination of treatment efficacy from studies in which subjects may choose their own treatment, and (2) the determination of liability in product-safety litigation.},
	language = {en},
	urldate = {2023-01-05},
	booktitle = {Uncertainty {Proceedings} 1994},
	publisher = {Morgan Kaufmann},
	author = {Balke, Alexander and Pearl, Judea},
	editor = {de Mantaras, Ramon Lopez and Poole, David},
	month = jan,
	year = {1994},
	doi = {10.1016/B978-1-55860-332-5.50011-0},
	pages = {46--54},
}

@article{pearl_algorithmization_2011,
	title = {The algorithmization of counterfactuals},
	volume = {61},
	issn = {1573-7470},
	url = {https://doi.org/10.1007/s10472-011-9247-9},
	doi = {10.1007/s10472-011-9247-9},
	abstract = {Recent advances in causal reasoning have given rise to a computation model that emulates the process by which humans generate, evaluate and distinguish counterfactual sentences. Though compatible with the “possible worlds” account, this model enjoys the advantages of representational economy, algorithmic simplicity and conceptual clarity. Using this model, the paper demonstrates the processing of counterfactual sentences on a classical example due to Ernest Adam. It then gives a panoramic view of several applications where counterfactual reasoning has benefited problem areas in the empirical sciences.},
	language = {en},
	number = {1},
	urldate = {2023-01-05},
	journal = {Annals of Mathematics and Artificial Intelligence},
	author = {Pearl, Judea},
	month = jul,
	year = {2011},
	keywords = {68T30, 68T37, Causal reasoning, Conditional logic, Counterfactuals},
	pages = {29},
}

@incollection{pearl_causation_1997,
	address = {Dordrecht},
	series = {Synthese {Library}},
	title = {Causation, {Action}, and {Counterfactuals}},
	isbn = {9789401704878},
	url = {https://doi.org/10.1007/978-94-017-0487-8_18},
	abstract = {The central aim of many empirical studies in the physical, behavioral, social, and biological sciences is the elucidation of cause-effect relationships among variables. It is through cause-effect relationships that we obtain a sense of a “deep understanding” of a given phenomenon, and it is through such relationships that we obtain a sense of being “in control,” namely, that we are able to shape the course of events by deliberate actions or policies. It is for these two reasons, understanding and control, that causal thinking is so pervasive, popping up in everything from everyday activities to high-level decision-making: For example, every car owner wonders why an engine won’t start; a cigarette smoker would like to know, given his/her specific characteristics, to what degree his/her health would be affected by refraining from further smoking; a policy maker would like to know to what degree anti-smoking advertising would reduce costs of health care; and so on. Although a plethora of data has been collected on cars and on smoking and health, the appropriate methodology for extracting answers to such questions from the data has been fiercely debated, partly because some fundamental questions of causality have not been given fully satisfactory answers.},
	language = {en},
	urldate = {2023-01-05},
	booktitle = {Logic and {Scientific} {Methods}: {Volume} {One} of the {Tenth} {International} {Congress} of {Logic}, {Methodology} and {Philosophy} of {Science}, {Florence}, {August} 1995},
	publisher = {Springer Netherlands},
	author = {Pearl, Judea},
	editor = {Dalla Chiara, Maria Luisa and Doets, Kees and Mundici, Daniele and van Benthem, Johan},
	year = {1997},
	doi = {10.1007/978-94-017-0487-8_18},
	keywords = {Causal Effect, Causal Theory, Close World, Local Surgery, Manipulate Variable},
	pages = {355--375},
}

@article{zhao_generative_2023,
	title = {Generative {Models} for {Inverse} {Imaging} {Problems}: {From} mathematical foundations to physics-driven applications},
	volume = {40},
	shorttitle = {Generative {Models} for {Inverse} {Imaging} {Problems}},
	doi = {10.1109/MSP.2022.3215282},
	abstract = {Physics-informed generative modeling for inverse problems in computational imaging is a fast-growing field encompassing a variety of methods and applications. Here, we review a few generative modeling techniques, such as variational autoencoders (VAEs) and generative adversarial networks (GANs), as well as more recent developments in score-based generative models. Through different imaging applications, we review how the generative modeling techniques are effectively combined with the physics of the imaging problem, e.g., the measurement forward model and physical properties of the target objects, to solve the inverse problems.},
	journal = {IEEE Signal Processing Magazine},
	author = {Zhao, Zhizhen and Ye, Jong Chul and Bresler, Yoram},
	month = jan,
	year = {2023},
	pages = {148--163},
}

@book{gadermayr_multiple_2022,
	title = {Multiple {Instance} {Learning} for {Digital} {Pathology}: {A} {Review} on the {State}-of-the-{Art}, {Limitations} \& {Future} {Potential}},
	shorttitle = {Multiple {Instance} {Learning} for {Digital} {Pathology}},
	abstract = {Digital whole slides images contain an enormous amount of information providing a strong motivation for the development of automated image analysis tools. Particularly deep neural networks show high potential with respect to various tasks in the field of digital pathology. However, a limitation is given by the fact that typical deep learning algorithms require (manual) annotations in addition to the large amounts of image data, to enable effective training. Multiple instance learning exhibits a powerful tool for learning deep neural networks in a scenario without fully annotated data. These methods are particularly effective in this domain, due to the fact that labels for a complete whole slide image are often captured routinely, whereas labels for patches, regions or pixels are not. This potential already resulted in a considerable number of publications, with the majority published in the last three years. Besides the availability of data and a high motivation from the medical perspective, the availability of powerful graphics processing units exhibits an accelerator in this field. In this paper, we provide an overview of widely and effectively used concepts of used deep multiple instance learning approaches, recent advances and also critically discuss remaining challenges and future potential.},
	author = {Gadermayr, Michael and Tschuchnig, Maximilian Ernst},
	month = jun,
	year = {2022},
	doi = {10.48550/arXiv.2206.04425},
}

@article{liu_classic_2008,
	title = {Classic {Works} of the {Dempster}-{Shafer} {Theory} of {Belief} {Functions}: {An} {Introduction}},
	volume = {219},
	issn = {978-3-540-25381-5},
	shorttitle = {Classic {Works} of the {Dempster}-{Shafer} {Theory} of {Belief} {Functions}},
	doi = {10.1007/978-3-540-44792-4_1},
	abstract = {In this chapter, we review the basic concepts of the theory of belief functions and sketch a brief history of its conceptual
development. We then provide an overview of the classic works and examine how they established a body of knowledge on belief
functions, transformed the theory into a computational tool for evidential reasoning in artificial intelligence, opened up
new avenues for applications, and became authoritative resources for anyone who is interested in gaining further insight into
and understanding of belief functions.},
	journal = {Studies in Fuzziness and Soft Computing},
	author = {Liu, Liping and Yager, Ronald},
	month = jan,
	year = {2008},
}

@article{yaghlane_inference_2008,
	title = {Inference in directed evidential networks based on the transferable belief model},
	volume = {48},
	doi = {10.1016/j.ijar.2008.01.002},
	abstract = {Inference algorithms in directed evidential networks (DEVN) obtain their efficiency by making use of the represented independencies between variables in the model. This can be done using the disjunctive rule of combination (DRC) and the generalized Bayesian theorem (GBT), both proposed by Smets [Ph. Smets, Belief functions: the disjunctive rule of combination and the generalized Bayesian theorem, International Journal of Approximate Reasoning 9 (1993) 1–35]. These rules make possible the use of conditional belief functions for reasoning in directed evidential networks, avoiding the computations of joint belief function on the product space. In this paper, new algorithms based on these two rules are proposed for the propagation of belief functions in singly and multiply directed evidential networks.},
	journal = {International Journal of Approximate Reasoning},
	author = {Yaghlane, Boutheina and Mellouli, Khaled},
	month = jun,
	year = {2008},
	pages = {399--418},
}

@article{jirousek_entropy_2022,
	title = {Entropy for evaluation of {Dempster}-{Shafer} belief function models},
	volume = {151},
	doi = {10.1016/j.ijar.2022.09.009},
	abstract = {Applications of Dempster-Shafer (D-S) belief functions to practical problems involve difficulties arising from their high computational complexity. One can use space-saving factored approximations such as graphical belief function models to solve them. Using an analogy with probability distributions, we represent these approximations in the form of compositional models. Since no theoretical apparatus similar to probabilistic information theory exists for D-S belief functions (e.g., dissimilarity measure analogous to the Kullback-Liebler divergence measure), the problems arise not only in connection with the design of algorithms seeking optimal approximations but also in connection with a criterion comparing two different approximations. In this respect, the application of the analogy with probability theory fails. Therefore, in this paper, we conduct some synthetic experiments and describe the results designed to reveal whether some belief function entropy definitions described in the literature can detect optimal approximations, i.e., that achieve their minimum for an optimal approximation.},
	journal = {International Journal of Approximate Reasoning},
	author = {Jirousek, Radim and Kratochvil, Vaclav and Shenoy, Prakash},
	month = sep,
	year = {2022},
}

@article{jsang_dempsters_2010,
	title = {Dempster's {Rule} as {Seen} by {Little} {Coloured} {Balls}},
	abstract = {Dempster's Rule is commonly described as an operator for fusing beliefs. While there are different possible interpretations of belief fusion, there is considerable confusion regarding the exact type of belief fusion that Dempster's rule performs. Many alternative operators for belief fusion have been proposed, where some are based on the same fundamental principle as Dempster's rule, and others have a totally different basis, such as the consensus operator. In this article we take a closer look at Dempster's rule in order to determine exactly what type of belief fusion it performs. Our conclusion is that Dempster's rule in fact represents a method for serial combination of constraints, which is not suitable for fusing different beliefs on the same frame of discernment. We conclude that the non-normalised version of Dempster's rule represents a method for multiplying orthogonal beliefs on product frames of discernment.},
	journal = {Information Fusion - INFFUS},
	author = {Jsang, Audun and Pope, Simon and Diaz, Javier and Bouchon-Meunier, Bernadette},
	month = jan,
	year = {2010},
}

@article{inglis_mathematical_1978,
	title = {A {Mathematical} {Theory} of {Evidence}},
	volume = {20},
	issn = {0040-1706, 1537-2723},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1978.10489628},
	doi = {10.1080/00401706.1978.10489628},
	abstract = {Both in science and in practical affairs we reason by combining facts only inconclusively supported by evidence. Building on an abstract understanding of this process of combination, this book constructs a new theory of epistemic probability. The theory draws on the work of A. P. Dempster but diverges from Depster's viewpoint by identifying his "lower probabilities" as epistemic probabilities and taking his rule for combining "upper and lower probabilities" as fundamental. The book opens with a critique of the well-known Bayesian theory of epistemic probability. It then proceeds to develop an alternative to the additive set functions and the rule of conditioning of the Bayesian theory: set functions that need only be what Choquet called "monotone of order of infinity." and Dempster's rule for combining such set functions. This rule, together with the idea of "weights of evidence," leads to both an extensive new theory and a better understanding of the Bayesian theory. The book concludes with a brief treatment of statistical inference and a discussion of the limitations of epistemic probability. Appendices contain mathematical proofs, which are relatively elementary and seldom depend on mathematics more advanced that the binomial theorem.},
	language = {en},
	number = {1},
	urldate = {2022-12-27},
	journal = {Technometrics},
	author = {Inglis, James},
	month = feb,
	year = {1978},
	pages = {106--106},
}

@article{schmitz_opposing_2009,
	title = {Opposing {Influences} of {Affective} {State} {Valence} on {Visual} {Cortical} {Encoding}},
	volume = {29},
	copyright = {Copyright © 2009 Society for Neuroscience 0270-6474/09/297199-09\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/29/22/7199},
	doi = {10.1523/JNEUROSCI.5387-08.2009},
	abstract = {Positive and negative emotional states are thought to have originated from fundamentally opposing approach and avoidance behaviors. Furthermore, affective valence has been hypothesized to exert opposing biases in cognitive control. Here we examined with functional magnetic resonance imaging whether the opposing influences of positive and negative states extend to perceptual encoding in the visual cortices. Based on prior behavioral research, we hypothesized that positive states would broaden and negative states would narrow visual field of view (FOV). Positive, neutral, and negative states were induced on alternating blocks. To index FOV, observers then viewed brief presentations (300 ms) of face/place concentric center/surround stimuli on interleaved blocks. Central faces were attended, rendering the place surrounds unattended. As face and place information was presented at different visual eccentricities, our physiological metric of FOV was a valence-dependent modulation of place processing in the parahippocampal place area (PPA). Consistent with our hypotheses, positive affective states increased and negative states decreased PPA response to novel places as well as adaptation to repeated places. Individual differences in self-reported positive and negative affect correlated inversely with PPA encoding of peripheral places, as well as with activation in the mesocortical prefrontal cortex and amygdala. Psychophysiological interaction analyses further demonstrated that valence-dependent responses in the PPA arose from opponent coupling with extrafoveal regions of the primary visual cortex during positive and negative states. These findings collectively suggest that affective valence differentially biases gating of early visual inputs, fundamentally altering the scope of perceptual encoding.},
	language = {en},
	number = {22},
	urldate = {2022-12-27},
	journal = {Journal of Neuroscience},
	author = {Schmitz, Taylor W. and Rosa, Eve De and Anderson, Adam K.},
	month = jun,
	year = {2009},
	pmid = {19494142},
	pages = {7199--7207},
}

@misc{cao_open-3dsim_2022,
	title = {Open-{3DSIM}: an {Open}-source three-dimensional structured illumination microscopy reconstruction platform},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {Open-{3DSIM}},
	url = {https://www.biorxiv.org/content/10.1101/2022.12.16.520543v1},
	doi = {10.1101/2022.12.16.520543},
	abstract = {With optical section and defocus removal effect, three-dimensional structured illumination microscopy (3DSIM) can get a whole sight of intracellular organelle. Here, Open-3DSIM is reported as an open-source reconstruction platform with double improvement on lateral and axial resolution. MATLAB code, ImageJ version and Exe application are provided for biologists and engineers to maximize its user-friendliness and prompt its further development. Through adaptive parameter estimation and spectrum filter optimization, we demonstrate its superior performance of artifact suppression and defocus elimination over other algorithms on various specimens, under gradient signal-to-noise levels. Moreover, with the capacity to extract the dipole orientation, Open-3DSIM paves a new avenue for interpreting the subcellular structures in six dimensions (xyzθλt).},
	language = {en},
	urldate = {2022-12-21},
	publisher = {bioRxiv},
	author = {Cao, Ruijie and Li, Yaning and Chen, Xin and Ge, Xichuan and Li, Meiqi and Guan, Meiling and Hou, Yiwei and Fu, Yunzhe and Jiang, Shan and Gao, Baoxiang and Xi, Peng},
	month = dec,
	year = {2022},
}

@misc{noauthor_categorical_nodate,
	title = {Categorical {Reparametrization} with {Gumble}-{Softmax} :: {MPG}.{PuRe}},
	url = {https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2564872},
	urldate = {2022-12-19},
}

@misc{corona-figueroa_mednerf_2022,
	title = {{MedNeRF}: {Medical} {Neural} {Radiance} {Fields} for {Reconstructing} {3D}-aware {CT}-{Projections} from a {Single} {X}-ray},
	shorttitle = {{MedNeRF}},
	url = {http://arxiv.org/abs/2202.01020},
	doi = {10.48550/arXiv.2202.01020},
	abstract = {Computed tomography (CT) is an effective medical imaging modality, widely used in the field of clinical medicine for the diagnosis of various pathologies. Advances in Multidetector CT imaging technology have enabled additional functionalities, including generation of thin slice multiplanar cross-sectional body imaging and 3D reconstructions. However, this involves patients being exposed to a considerable dose of ionising radiation. Excessive ionising radiation can lead to deterministic and harmful effects on the body. This paper proposes a Deep Learning model that learns to reconstruct CT projections from a few or even a single-view X-ray. This is based on a novel architecture that builds from neural radiance fields, which learns a continuous representation of CT scans by disentangling the shape and volumetric depth of surface and internal anatomical structures from 2D images. Our model is trained on chest and knee datasets, and we demonstrate qualitative and quantitative high-fidelity renderings and compare our approach to other recent radiance field-based methods. Our code and link to our datasets are available at https://github.com/abrilcf/mednerf},
	urldate = {2022-12-19},
	publisher = {arXiv},
	author = {Corona-Figueroa, Abril and Frawley, Jonathan and Bond-Taylor, Sam and Bethapudi, Sarath and Shum, Hubert P. H. and Willcocks, Chris G.},
	month = apr,
	year = {2022},
	note = {arXiv:2202.01020 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, I.4, J.7},
}

@misc{noauthor_multiperson_nodate,
	title = {Multiperson},
	url = {https://jiangwenpl.github.io/multiperson/},
	urldate = {2022-12-16},
}

@inproceedings{camgoz_multi-channel_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Multi-channel {Transformers} for {Multi}-articulatory {Sign} {Language} {Translation}},
	isbn = {9783030668235},
	doi = {10.1007/978-3-030-66823-5_18},
	abstract = {Sign languages use multiple asynchronous information channels (articulators), not just the hands but also the face and body, which computational approaches often ignore. In this paper we tackle the multi-articulatory sign language translation task and propose a novel multi-channel transformer architecture. The proposed architecture allows both the inter and intra contextual relationships between different sign articulators to be modelled within the transformer network itself, while also maintaining channel specific information. We evaluate our approach on the RWTH-PHOENIX-Weather-2014T dataset and report competitive translation performance. Importantly, we overcome the reliance on gloss annotations which underpin other state-of-the-art approaches, thereby removing the need for expensive curated datasets.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2020 {Workshops}},
	publisher = {Springer International Publishing},
	author = {Camgoz, Necati Cihan and Koller, Oscar and Hadfield, Simon and Bowden, Richard},
	editor = {Bartoli, Adrien and Fusiello, Andrea},
	year = {2020},
	keywords = {Multi-channel, Sequence-to-sequence, Sign language translation},
	pages = {301--319},
}

@phdthesis{villalonga_pineda_leveraging_2021,
	type = {Ph.{D}. {Thesis}},
	title = {Leveraging {Synthetic} {Data} to {Create} {Autonomous} {Driving} {Perception} {Systems}},
	copyright = {Open Access},
	url = {https://www.tdx.cat/handle/10803/671739},
	abstract = {L’anotació manual d’imatges per desenvolupar sistemes basats en visió per computador ha estat un dels punts més problemàtics des que s’utilitza aprenentatge automàtic per a això. Aquesta tesi es centra en aprofitar les dades sintètiques per alleujar el cost de les anotacions manuals en tres tasques de percepció relacionades amb l’assistència a la conducció i la conducció autònoma. En tot moment assumim l’ús de xarxes neuronals convolucionals per al desenvolupament dels nostres models profunds de percepció. La primera tasca planteja el reconeixement de senyals de trànsit, un problema de classificació d’imatges. Assumim que el nombre de classes de senyals de trànsit a reconèixer s’ha d’incrementar sense haver pogut anotar noves imatges amb què realitzar el corresponent reentrenament. Demostrem que aprofitant les dades sintètiques de les noves classes i transformant-les amb una xarxa adversària-generativa (GAN, de les seves sigles en anglès) entrenada amb les classes conegudes (sense usar mostres de les noves classes), és possible reentrenar la xarxa neuronal per classificar tots els senyals en una proporció {\textasciitilde}1/4 entre classes noves i conegudes. La segona tasca consisteix en la detecció de vehicles i vianants (objectes) en imatges. En aquest cas, assumim la recepció d’un conjunt d’imatges sense anotar. L’objectiu és anotar automàticament aquestes imatges perquè així es puguin utilitzar posteriorment en l’entrenament del detector d’objectes que desitgem. Per assolir aquest objectiu, vam partir de dades sintètiques anotades i proposem un mètode d’aprenentatge semi-supervisat basat en la idea del co-aprenentatge. A més, utilitzem una GAN per reduir la distància entre els dominis sintètic i real abans d’aplicar el co-aprenentatge. Els nostres resultats quantitatius mostren que el procediment desenvolupat permet anotar el conjunt d’imatges d’entrada amb la precisió suficient per entrenar detectors d’objectes de forma efectiva; és a dir, tan precisos com si les imatges s’haguessin anotat manualment. A la tercera tasca deixem enrere l’espai 2D de les imatges, i ens centrem en processar núvols de punts 3D provinents de sensors LiDAR. El nostre objectiu inicial era desenvolupar un detector d’objectes 3D (vehicles, vianants, ciclistes) entrenat en núvols de punts sintètics estil LiDAR. En el cas de les imatges es podia esperar el problema de canvi de domini degut a les diferències visuals entre les imatges sintètiques i reals. Però, a priori, no esperàvem el mateix en treballar amb núvols de punts LiDAR, ja que es tracta d’informació geomètrica provinent del mostreig actiu del món, sense que l’aparença visual influeixi. No obstant això, a la pràctica, hem vist que també apareixen els problemes d’adaptació de domini. Factors com els paràmetres de mostreig del LiDAR, la configuració dels sensors a bord del vehicle autònom, i l’anotació manual dels objectes 3D, indueixen diferències de domini. A la tesi demostrem aquesta observació mitjançant un exhaustiu conjunt d’experiments amb diferents bases de dades públiques i detectors 3D disponibles. Per tant, en relació amb la tercera tasca, el treball s’ha centrat finalment en el disseny d’una GAN capaç de transformar núvols de punts 3D per portar-los d’un domini a un altre, un tema relativament inexplorat.Finalment, cal esmentar que tots els conjunts de dades sintètiques usats en aquestes tres tasques han estat dissenyats i generats en el context d’aquesta tesi doctoral i es faran públics. En general, considerem que aquesta tesi presenta un avanç en el foment de la utilització de dades sintètiques per al desenvolupament de models profunds de percepció, essencials en el camp de la conducció autònoma.},
	language = {eng},
	urldate = {2022-12-15},
	school = {Universitat Autònoma de Barcelona},
	author = {Villalonga Pineda, Gabriel},
	month = feb,
	year = {2021},
	keywords = {004, Adaptació de domini, Adaptación de dominio, Autonomous driving, Computer vision, Conducció autónoma, Conducción autónoma, Domain adaptation, Tecnologies, Visión por computador},
}

@misc{kabir_what_2022,
	title = {What is a 2 simplex?},
	url = {https://dailyjustnow.com/en/what-is-a-2-simplex-79937/},
	abstract = {The triangle is the 2-simplex, a simple shape that requires two dimensions. Consider a triangle ABC, a shape in a 2-dimensional space (the plane in which the triangle resides). One can place a new point D somewhere off the plane. How many Tetrahedrons are in a 4 simplex? Either projection of the four-simplex shows three … What is a 2 simplex? Read More »},
	language = {en-US},
	urldate = {2022-12-15},
	journal = {Daily Justnow},
	author = {Kabir, Farhad},
	month = jun,
	year = {2022},
}

@article{pang_image--image_2022,
	title = {Image-to-{Image} {Translation}: {Methods} and {Applications}},
	volume = {24},
	issn = {1941-0077},
	shorttitle = {Image-to-{Image} {Translation}},
	doi = {10.1109/TMM.2021.3109419},
	abstract = {Image-to-image translation (I2I) aims to transfer images from a source domain to a target domain while preserving the content representations. I2I has drawn increasing attention and made tremendous progress in recent years because of its wide range of applications in many computer vision and image processing problems, such as image synthesis, segmentation, style transfer, restoration, and pose estimation. In this paper, we provide an overview of the I2I works developed in recent years. We will analyze the key techniques of the existing I2I works and clarify the main progress the community has made. Additionally, we will elaborate on the effect of I2I on the research and industry community and point out remaining challenges in related fields.},
	journal = {IEEE Transactions on Multimedia},
	author = {Pang, Yingxue and Lin, Jianxin and Qin, Tao and Chen, Zhibo},
	year = {2022},
	keywords = {Analytical models, Data models, Generative adversarial networks, Generators, Image-to-image translation, Measurement, PSNR, Task analysis, few-shot methods, multi-domain I2I, semi-supervised methods, supervised methods, two-domain I2I, unsupersived methods},
	pages = {3859--3881},
}

@article{hong_mitoguardin-2mediated_2022,
	title = {Mitoguardin-2–mediated lipid transfer preserves mitochondrial morphology and lipid droplet formation},
	volume = {221},
	doi = {10.1083/jcb.202207022},
	abstract = {Lipid transport proteins at membrane contacts, where organelles are closely apposed, are critical in redistributing lipids from the endoplasmic reticulum (ER), where they are made, to other cellular membranes. Such protein-mediated transfer is especially important for maintaining organelles disconnected from secretory pathways, like mitochondria. We identify mitoguardin-2, a mitochondrial protein at contacts with the ER and/or lipid droplets (LDs), as a lipid transporter. An x-ray structure shows that the C-terminal domain of mitoguardin-2 has a hydrophobic cavity that binds lipids. Mass spectrometry analysis reveals that both glycerophospholipids and free-fatty acids co-purify with mitoguardin-2 from cells, and that each mitoguardin-2 can accommodate up to two lipids. Mitoguardin-2 transfers glycerophospholipids between membranes in vitro, and this transport ability is required for roles both in mitochondrial and LD biology. While it is not established that protein-mediated transfer at contacts plays a role in LD metabolism, our findings raise the possibility that mitoguardin-2 functions in transporting fatty acids and glycerophospholipids at mitochondria-LD contacts.},
	journal = {Journal of Cell Biology},
	author = {Hong, Zhouping and Adlakha, Jyoti and Wan, Neng and Guinn, Emily and Giska, Fabian and Gupta, Kallol and Melia, Thomas and Reinisch, Karin},
	month = oct,
	year = {2022},
}

@article{nieblas_role_2022,
	title = {Role of mitochondria-associated endoplasmic reticulum membranes in insulin sensitivity, energy metabolism, and contraction of skeletal muscle},
	volume = {9},
	doi = {10.3389/fmolb.2022.959844},
	abstract = {Skeletal muscle has a critical role in the regulation of the energy balance of the organism, particularly as the principal tissue responsible for insulin-stimulated glucose disposal and as the major site of peripheral insulin resistance (IR), which has been related to accumulation of lipid intermediates, reduced oxidative capacity of mitochondria and endoplasmic reticulum (ER) stress. These organelles form contact sites, known as mitochondria-associated ER membranes (MAMs). This interconnection seems to be involved in various cellular processes, including Ca ²⁺ transport and energy metabolism; therefore, MAMs could play an important role in maintaining cellular homeostasis. Evidence suggests that alterations in MAMs may contribute to IR. However, the evidence does not refer to a specific subcellular location, which is of interest due to the fact that skeletal muscle is constituted by oxidative and glycolytic fibers as well as different mitochondrial populations that appear to respond differently to stimuli and pathological conditions. In this review, we show the available evidence of possible differential responses in the formation of MAMs in skeletal muscle as well as its role in insulin signaling and the beneficial effect it could have in the regulation of energetic metabolism and muscular contraction.},
	journal = {Frontiers in Molecular Biosciences},
	author = {Nieblas, Bianca and Pérez Treviño, Perla and Garcia, Noemi},
	month = oct,
	year = {2022},
}

@article{torres-garcia_extending_2022,
	title = {Extending resolution within a single imaging frame},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-34693-9},
	doi = {10.1038/s41467-022-34693-9},
	abstract = {The resolution of fluorescence microscopy images is limited by the physical properties of light. In the last decade, numerous super-resolution microscopy (SRM) approaches have been proposed to deal with such hindrance. Here we present Mean-Shift Super Resolution (MSSR), a new SRM algorithm based on the Mean Shift theory, which extends spatial resolution of single fluorescence images beyond the diffraction limit of light. MSSR works on low and high fluorophore densities, is not limited by the architecture of the optical setup and is applicable to single images as well as temporal series. The theoretical limit of spatial resolution, based on optimized real-world imaging conditions and analysis of temporal image stacks, has been measured to be 40 nm. Furthermore, MSSR has denoising capabilities that outperform other SRM approaches. Along with its wide accessibility, MSSR is a powerful, flexible, and generic tool for multidimensional and live cell imaging applications.},
	language = {en},
	number = {1},
	urldate = {2022-12-13},
	journal = {Nature Communications},
	author = {Torres-García, Esley and Pinto-Cámara, Raúl and Linares, Alejandro and Martínez, Damián and Abonza, Víctor and Brito-Alarcón, Eduardo and Calcines-Cruz, Carlos and Valdés-Galindo, Gustavo and Torres, David and Jabloñski, Martina and Torres-Martínez, Héctor H. and Martínez, José L. and Hernández, Haydee O. and Ocelotl-Oviedo, José P. and Garcés, Yasel and Barchi, Marco and D’Antuono, Rocco and Bošković, Ana and Dubrovsky, Joseph G. and Darszon, Alberto and Buffone, Mariano G. and Morales, Roberto Rodríguez and Rendon-Mancha, Juan Manuel and Wood, Christopher D. and Hernández-García, Armando and Krapf, Diego and Crevenna, Álvaro H. and Guerrero, Adán},
	month = dec,
	year = {2022},
	keywords = {3-D reconstruction, Confocal microscopy, Fluorescence imaging, Software, Super-resolution microscopy},
	pages = {7452},
}

@misc{noauthor_analyzing_nodate,
	title = {Analyzing {Brain} {Morphology} in {Alzheimer}’s {Disease} {Using} {Discriminative} and {Generative} {Spiral} {Networks} {\textbar} {bioRxiv}},
	url = {https://www.biorxiv.org/content/10.1101/2021.04.15.440008v1.full},
	urldate = {2022-12-10},
}

@misc{worchel_multi-view_2022,
	title = {Multi-{View} {Mesh} {Reconstruction} with {Neural} {Deferred} {Shading}},
	url = {http://arxiv.org/abs/2212.04386},
	doi = {10.48550/arXiv.2212.04386},
	abstract = {We propose an analysis-by-synthesis method for fast multi-view 3D reconstruction of opaque objects with arbitrary materials and illumination. State-of-the-art methods use both neural surface representations and neural rendering. While flexible, neural surface representations are a significant bottleneck in optimization runtime. Instead, we represent surfaces as triangle meshes and build a differentiable rendering pipeline around triangle rasterization and neural shading. The renderer is used in a gradient descent optimization where both a triangle mesh and a neural shader are jointly optimized to reproduce the multi-view images. We evaluate our method on a public 3D reconstruction dataset and show that it can match the reconstruction accuracy of traditional baselines and neural approaches while surpassing them in optimization runtime. Additionally, we investigate the shader and find that it learns an interpretable representation of appearance, enabling applications such as 3D material editing.},
	urldate = {2022-12-09},
	publisher = {arXiv},
	author = {Worchel, Markus and Diaz, Rodrigo and Hu, Weiwen and Schreer, Oliver and Feldmann, Ingo and Eisert, Peter},
	month = dec,
	year = {2022},
	note = {arXiv:2212.04386 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Machine Learning},
}

@article{kobayashi_self-supervised_2022,
	title = {Self-supervised deep learning encodes high-resolution features of protein subcellular localization},
	volume = {19},
	copyright = {2022 The Author(s)},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-022-01541-z},
	doi = {10.1038/s41592-022-01541-z},
	abstract = {Explaining the diversity and complexity of protein localization is essential to fully understand cellular architecture. Here we present cytoself, a deep-learning approach for fully self-supervised protein localization profiling and clustering. Cytoself leverages a self-supervised training scheme that does not require preexisting knowledge, categories or annotations. Training cytoself on images of 1,311 endogenously labeled proteins from the OpenCell database reveals a highly resolved protein localization atlas that recapitulates major scales of cellular organization, from coarse classes, such as nuclear and cytoplasmic, to the subtle localization signatures of individual protein complexes. We quantitatively validate cytoself’s ability to cluster proteins into organelles and protein complexes, showing that cytoself outperforms previous self-supervised approaches. Moreover, to better understand the inner workings of our model, we dissect the emergent features from which our clustering is derived, interpret them in the context of the fluorescence images, and analyze the performance contributions of each component of our approach.},
	language = {en},
	number = {8},
	urldate = {2022-12-06},
	journal = {Nature Methods},
	author = {Kobayashi, Hirofumi and Cheveralls, Keith C. and Leonetti, Manuel D. and Royer, Loic A.},
	month = aug,
	year = {2022},
	keywords = {Data mining, Machine learning},
	pages = {995--1003},
}

@book{schwartz_pip_2022,
	title = {{PIP}: {Positional}-encoding {Image} {Prior}},
	shorttitle = {{PIP}},
	abstract = {In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to map a latent space to a degraded (e.g. noisy) image but in the process learns to reconstruct the clean image. This phenomenon is attributed to CNN's internal image-prior. We revisit the DIP framework, examining it from the perspective of a neural implicit representation. Motivated by this perspective, we replace the random or learned latent with Fourier-Features (Positional Encoding). We show that thanks to the Fourier features properties, we can replace the convolution layers with simple pixel-level MLPs. We name this scheme ``Positional Encoding Image Prior" (PIP) and exhibit that it performs very similarly to DIP on various image-reconstruction tasks with much less parameters required. Additionally, we demonstrate that PIP can be easily extended to videos, where 3D-DIP struggles and suffers from instability. Code and additional examples for all tasks, including videos, are available on the project page https://nimrodshabtay.github.io/PIP/},
	author = {Schwartz, Eli},
	month = nov,
	year = {2022},
	doi = {10.48550/arXiv.2211.14298},
}

@phdthesis{song_learning_2022,
	address = {United States -- California},
	type = {Ph.{D}.},
	title = {Learning to {Generate} {Data} by {Estimating} {Gradients} of the {Data} {Distribution}},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	url = {https://www.proquest.com/docview/2734696898/abstract/37C4DB568F4841D8PQ/1},
	abstract = {Generating realistic data with complex patterns, such as images, audio, or molecular structures, often relies on expressive probabilistic models to represent and estimate high- dimensional data distributions. However, even with the power of deep neural networks, building powerful probabilistic models is non-trivial. One major challenge is the need to normalize probability distributions; that is, to ensure the total probability equals one. This necessitates summing over all possible model outputs, which quickly becomes impractical in high-dimensional spaces. In this dissertation, I propose to address this difficulty by working with data distributions through their score functions. These functions, defined as gradients of log data densities, capture information about the corresponding data distributions without requiring normalization, hence can be modeled with highly flexible deep neural networks.
This dissertation is organized into three parts. In Part I, I show how to estimate the score function from a finite dataset with expressive deep neural networks and efficient statistical methods. In Part II, I discuss several ways to generate new data samples from models of score functions, building upon ideas from homotopy methods, Markov chain Monte Carlo, diffusion processes, and differential equations. The resulting score-based generative models (also known as diffusion models) achieved record-breaking generation performance for numerous data modalities, challenging the long-standing dominance of generative adversarial networks on many tasks. Importantly, the sampling procedure of score-based generative models can be flexibly controlled for solving inverse problems, demonstrated by their superior performance on multiple tasks in medical image reconstruction. In Part III, I show how to evaluate probability values accurately with models of score functions. Taken together, score-based generative models provide a flexible, powerful and versatile solution for data generation in machine learning and many other disciplines of science and engineering.},
	language = {English},
	urldate = {2022-11-21},
	school = {Stanford University},
	author = {Song, Yang},
	year = {2022},
	keywords = {Inverse problems, Mathematics},
}

@article{nagahama_graph_2022,
	title = {Graph {Signal} {Restoration} {Using} {Nested} {Deep} {Algorithm} {Unrolling}},
	volume = {70},
	doi = {10.1109/TSP.2022.3180546},
	abstract = {Graph signal processing is a ubiquitous task in many applications such as sensor, social, transportation and brain networks, point cloud processing, and graph neural networks. Often, graph signals are corrupted in the sensing process, thus requiring restoration. In this paper, we propose two graph signal restoration methods based on deep algorithm unrolling (DAU). First, we present a graph signal denoiser by unrolling iterations of the alternating direction method of multiplier (ADMM). We then suggest a general restoration method for linear degradation by unrolling iterations of Plug-and-Play ADMM (PnP-ADMM). In the second approach, the unrolled ADMM-based denoiser is incorporated as a submodule, leading to a nested DAU structure. The parameters in the proposed denoising/restoration methods are trainable in an end-to-end manner. Our approach is interpretable and keeps the number of parameters small since we only tune graph-independent regularization parameters. We overcome two main challenges in existing graph signal restoration methods: 1) limited performance of convex optimization algorithms due to fixed parameters which are often determined manually. 2) large number of parameters of graph neural networks that result in difficulty of training. Several experiments for graph signal denoising and interpolation are performed on synthetic and real-world data. The proposed methods show performance improvements over several existing techniques in terms of root mean squared error in both tasks.},
	journal = {IEEE Transactions on Signal Processing},
	author = {Nagahama, Masatoshi and Yamada, Koki and Tanaka, Yuichi and Chan, Stanley and Eldar, Yonina},
	month = jan,
	year = {2022},
	pages = {1--16},
}

@misc{noauthor_foundations_nodate,
	title = {Foundations of {Wavelet} {Networks} and {Applications} {\textbar} {S}. {Sitharama} {Iyenga}},
	url = {https://www.taylorfrancis.com/books/mono/10.1201/9781315273679/foundations-wavelet-networks-applications-sitharama-iyengar-phoha-sitharama-iyengar},
	urldate = {2022-11-18},
}

@misc{noauthor_hamarneh_nodate,
	title = {Hamarneh {Lab} - {Publications}},
	url = {https://www.medicalimageanalysis.com/publications},
	abstract = {Publications},
	language = {en-US},
	urldate = {2022-11-17},
}

@book{hinton_opa1_2022,
	title = {{OPA1} {Downregulation} in {Skeletal} {Muscle} {Induces} {MERC} formation in an {ATF4}-{Dependent} {Manner}},
	abstract = {Mitochondria and endoplasmic reticulum (ER) contact sites (MERCs) are protein- and lipid-enriched hubs that mediate intracellular communications, contributing to the dynamic transfer of Ca2+, lipid, and other metabolites between these organelles. Defective MERCs are associated with cellular oxidative stress, neurodegenerative disease, and cardiac and skeletal muscle pathology via mechanisms that are poorly understood. We previously demonstrated that skeletal muscle-specific knockdown (KD) of the mitochondrial fusion mediator optic atrophy 1 (OPA1) induced ER stress and upregulated Mitofusin-2, a known MERC protein. In the present study, we tested the hypothesis that Opa1 downregulation in skeletal muscle cells induces MERC formation using multiple experimental models, including mice, Drosophila, and primary myotubes. Our results revealed that OPA1 deficiency increased MERC tethering and activated the integrated stress response (ISR) pathway effector, activating transcription factor 4 (ATF4). Loss of OPA1, reduced mitochondria calcium uptake and caffeine-induced calcium release by the ER, which was associated with changes in expression of mediators of calcium exchange IP3R3, GRP75, VDAC, at MERCs. Reducing Atf4 expression in Opa1-deficient muscle cells altered MERC ultrastructure changes and reestablished cytosolic calcium homeostasis. These data identify a role for ATF4 in the regulation of MERCs distance and mitochondrial calcium exchange.},
	author = {Hinton, Antentor, Jr and Katti, Prasanna and Mungai, Margaret and Hall, Duane and Koval, Olha and Shao, Jianqiang and Vue, Zer and Christensen, Trace and Lopez, Edgar and Rostami, Rahmati and Neikirk, Kit and Lam, Jacob and Alghanem, Ahmad and Ponce, Jessica and Hicsasmaz, Innes and Streeter, Jennifer and Schickling, Brandon and Bacevac, Serif and Grueter, Chad and Abel, E.},
	month = sep,
	year = {2022},
	doi = {10.1101/2022.09.12.507669},
}

@article{zou_automatic_2020,
	title = {An automatic {3D} point cloud registration algorithm based on triangle similarity ratio consistency},
	volume = {14},
	doi = {10.1049/iet-ipr.2019.1087},
	abstract = {Three‐dimensional (3D) point cloud registration is a fundamental key issue in 3D reconstruction, 3D object recognition and augmented reality. In this study, the authors propose a novel local feature descriptor called local angle statistics histogram (LASH) for efficient 3D point cloud registration. LASH forms a description of local shape geometries by encoding their properties on angles between the normal vector of the point and the vector formed by the point and other points in its local neighbourhood. In addition, they propose a 3D point cloud registration algorithm based on LASH. The registration algorithm firstly detects triangle matching points with consistent similarity ratios, and then aggregates each pair of triangular matching points into a set of matching points. They can use these matching sets to calculate multiple transformations between two point clouds. Finally, they use the error function to identify the best transformation and to achieve coarse alignment of the two point clouds. Experiments and comparisons with other global algorithms demonstrate that the proposed approach can be applied to register point clouds with considerable or limited overlaps and is robust to noise.},
	journal = {IET Image Processing},
	author = {Zou, Xuyan and He, Hanwu and Wu, Yueming and Chen, Youbin and Xu, Mingxi},
	month = dec,
	year = {2020},
}

@article{wang_storm_2022,
	title = {{STORM}: {Structure}-based {Overlap} {Matching} for {Partial} {Point} {Cloud} {Registration}},
	volume = {PP},
	shorttitle = {{STORM}},
	doi = {10.1109/TPAMI.2022.3148308},
	abstract = {Partial point cloud registration aims to transform partial scans into a common coordinate system. It is an important preprocessing step to generate complete 3D shapes. Although previous registration methods have made great progress in recent decades, traditional registration methods, such as Iterative Closest Point (ICP) and its variants, all these methods highly depend on the sufficient overlaps between two point clouds, because they cannot distinguish outlier correspondences. Note that the overlap between point clouds could always be small, which limits the application of these methods. To tackle this problem, we present a StrucTure-based OveRlap Matching (STORM) method for partial point cloud registration. In our method, an overlap prediction module with differentiable sampling is designed to detect points in overlap utilizing structure information, and facilitates exact partial correspondence generation, which is based on discriminative pointwise feature similarity. The pointwise features which contain effective structural information are extracted by graph-based methods. Experimental results and comparison with state-of-the-art methods demonstrate that STORM can achieve better performance. Moreover, most registration methods perform worse when the overlap ratio decreases, while STORM can still achieve satisfactory performance when the overlap ratio is small.},
	journal = {IEEE transactions on pattern analysis and machine intelligence},
	author = {Wang, Yujie and Yan, Chenggang and Feng, Yutong and Du, Shaoyi and Dai, Qionghai and Gao, Yue},
	month = feb,
	year = {2022},
}

@book{zhu_point_2021,
	title = {Point {Cloud} {Registration} using {Representative} {Overlapping} {Points}},
	abstract = {3D point cloud registration is a fundamental task in robotics and computer vision. Recently, many learning-based point cloud registration methods based on correspondences have emerged. However, these methods heavily rely on such correspondences and meet great challenges with partial overlap. In this paper, we propose ROPNet, a new deep learning model using Representative Overlapping Points with discriminative features for registration that transforms partial-to-partial registration into partial-to-complete registration. Specifically, we propose a context-guided module which uses an encoder to extract global features for predicting point overlap score. To better find representative overlapping points, we use the extracted global features for coarse alignment. Then, we introduce a Transformer to enrich point features and remove non-representative points based on point overlap score and feature matching. A similarity matrix is built in a partial-to-complete mode, and finally, weighted SVD is adopted to estimate a transformation matrix. Extensive experiments over ModelNet40 using noisy and partially overlapping point clouds show that the proposed method outperforms traditional and learning-based methods, achieving state-of-the-art performance. The code is available at https://github.com/zhulf0804/ROPNet.},
	author = {Zhu, Lifa and Liu, Dongrui and Lin, Changwei and Yan, Rui and Gómez-Fernández, Francisco and Yang, Ninghua and Feng, Ziyong},
	month = jul,
	year = {2021},
}

@book{lin_coarse--fine_2022,
	title = {Coarse-to-{Fine} {Point} {Cloud} {Registration} with {SE}(3)-{Equivariant} {Representations}},
	abstract = {Point cloud registration is a crucial problem in computer vision and robotics. Existing methods either rely on matching local geometric features, which are sensitive to the pose differences, or leverage global shapes and thereby lead to inconsistency when facing distribution variances such as partial overlapping. Combining the advantages of both types of methods, we adopt a coarse-to-fine pipeline that concurrently handles both issues. We first reduce the pose differences between input point clouds by aligning global features; then we match the local features to further refine the inaccurate alignments resulting from distribution variances. As global feature alignment requires the features to preserve the poses of input point clouds and local feature matching expects the features to be invariant to these poses, we propose an SE(3)-equivariant feature extractor to simultaneously generate two types of features. In this feature extractor, representations preserving the poses are first encoded by our novel SE(3)-equivariant network and then converted into pose-invariant ones by a pose-detaching module. Experiments demonstrate that our proposed method increases the recall rate by 20\% compared to state-of-the-art methods when facing both pose differences and distribution variances.},
	author = {Lin, Cheng-Wei and Chen, Tung-I and Lee, Hsin-Ying and Chen, Wen-Chin and Hsu, Winston},
	month = oct,
	year = {2022},
}

@article{arnold_fast_2022,
	title = {Fast and {Robust} {Registration} of {Partially} {Overlapping} {Point} {Clouds}},
	volume = {7},
	issn = {2377-3766},
	doi = {10.1109/LRA.2021.3137888},
	abstract = {Real-time registration of partially overlapping point clouds has emerging applications in cooperative perception for autonomous vehicles and multi-agent SLAM. The relative translation between point clouds in these applications is higher than in traditional SLAM and odometry applications, which challenges the identification of correspondences and a successful registration. In this paper, we propose a novel registration method for partially overlapping point clouds where correspondences are learned using an efficient point-wise feature encoder, and refined using a graph-based attention network. This attention network exploits geometrical relationships between key points to improve the matching in point clouds with low overlap. At inference time, the relative pose transformation is obtained by robustly fitting the correspondences through sample consensus. The evaluation is performed on the KITTI dataset and a novel synthetic dataset including low-overlapping point clouds with displacements of up to 30 m. The proposed method achieves on-par performance with state-of-the-art methods on the KITTI dataset, and outperforms existing methods for low overlapping point clouds. Additionally, the proposed method achieves significantly faster inference times, as low as 410 ms, between 5 and 35 times faster than competing methods. Our code and dataset are available at https://github.com/eduardohenriquearnold/fastreg.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Arnold, Eduardo and Mozaffari, Sajjad and Dianati, Mehrdad},
	month = apr,
	year = {2022},
	keywords = {Feature extraction, Iterative methods, Laser radar, Mapping, Point cloud compression, Real-time systems, Simultaneous localization and mapping, Three-dimensional displays, data sets for robotic vision, deep learning for visual perception, multi-robot systems, sensor fusion},
	pages = {1502--1509},
}

@misc{noauthor_point-set_nodate,
	title = {Point-set registration - {Wikipedia}},
	url = {https://en.wikipedia.org/wiki/Point-set_registration#Robust_registration},
	urldate = {2022-11-17},
}

@misc{noauthor_random_2022,
	title = {Random sample consensus},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Random_sample_consensus&oldid=1121168883},
	abstract = {Random sample consensus (RANSAC) is an iterative method to estimate parameters of a mathematical model from a set of observed data that contains outliers, when outliers are to be accorded no influence on the values of the estimates.  Therefore, it also can be interpreted as an outlier detection method. It is a non-deterministic algorithm in the sense that it produces a reasonable result only with a certain probability, with this probability increasing as more iterations are allowed.  The algorithm was first published by Fischler and Bolles at SRI International in 1981. They used RANSAC to solve the Location Determination Problem (LDP), where the goal is to determine the points in the space that project onto an image into a set of landmarks with known locations.
RANSAC uses repeated random sub-sampling.
A basic assumption is that the data consists of "inliers", i.e., data whose distribution can be explained by some set of model parameters, though may be subject to noise, and "outliers" which are data that do not fit the model.  The outliers can come, for example, from extreme values of the noise or from erroneous measurements or incorrect hypotheses about the interpretation of data.  RANSAC also assumes that, given a (usually small) set of inliers, there exists a procedure which can estimate the parameters of a model that optimally explains or fits this data.},
	language = {en},
	urldate = {2022-11-17},
	journal = {Wikipedia},
	month = nov,
	year = {2022},
	note = {Page Version ID: 1121168883},
}

@misc{poh_strong_2022,
	title = {Strong {Lensing} {Parameter} {Estimation} on {Ground}-{Based} {Imaging} {Data} {Using} {Simulation}-{Based} {Inference}},
	url = {http://arxiv.org/abs/2211.05836},
	doi = {10.48550/arXiv.2211.05836},
	abstract = {Current ground-based cosmological surveys, such as the Dark Energy Survey (DES), are predicted to discover thousands of galaxy-scale strong lenses, while future surveys, such as the Vera Rubin Observatory Legacy Survey of Space and Time (LSST) will increase that number by 1-2 orders of magnitude. The large number of strong lenses discoverable in future surveys will make strong lensing a highly competitive and complementary cosmic probe. To leverage the increased statistical power of the lenses that will be discovered through upcoming surveys, automated lens analysis techniques are necessary. We present two Simulation-Based Inference (SBI) approaches for lens parameter estimation of galaxy-galaxy lenses. We demonstrate the successful application of Neural Posterior Estimation (NPE) to automate the inference of a 12-parameter lens mass model for DES-like ground-based imaging data. We compare our NPE constraints to a Bayesian Neural Network (BNN) and find that it outperforms the BNN, producing posterior distributions that are for the most part both more accurate and more precise; in particular, several source-light model parameters are systematically biased in the BNN implementation.},
	urldate = {2022-11-15},
	publisher = {arXiv},
	author = {Poh, Jason and Samudre, Ashwin and Ćiprijanović, Aleksandra and Nord, Brian and Khullar, Gourav and Tanoglidis, Dimitrios and Frieman, Joshua A.},
	month = nov,
	year = {2022},
	note = {arXiv:2211.05836 [astro-ph]},
	keywords = {Astrophysics - Astrophysics of Galaxies, Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics},
}

@inproceedings{tayu_evasion_2016,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {On {Evasion} {Games} on {Graphs}},
	isbn = {9783319485324},
	doi = {10.1007/978-3-319-48532-4_23},
	abstract = {We consider an evasion game on a connected simple graph. We first show that the pursuit number of a graph G, the smallest k such that k pursuers win the game, is bounded above by the pathwidth of G. We next show that the pursuit number of G is two if and only if the pathwidth of G is one. We also show that for any integer \$\$\{w\}{\textbackslash}ge 2\$\$, there exists a tree T such that the pursuit number of T is three and the pathwidth of T is w.},
	language = {en},
	booktitle = {Discrete and {Computational} {Geometry} and {Graphs}},
	publisher = {Springer International Publishing},
	author = {Tayu, Satoshi and Ueno, Shuichi},
	editor = {Akiyama, Jin and Ito, Hiro and Sakai, Toshinori and Uno, Yushi},
	year = {2016},
	keywords = {Caterpillars, Evader, Evasion Game, Path Decomposition, Pathwidth},
	pages = {253--264},
}

@misc{wang_augmentation_2022,
	title = {Augmentation {Invariant} {Manifold} {Learning}},
	url = {http://arxiv.org/abs/2211.00460},
	doi = {10.48550/arXiv.2211.00460},
	abstract = {Data augmentation is a widely used technique and an essential ingredient in the recent advance in self-supervised representation learning. By preserving the similarity between augmented data, the resulting data representation can improve various downstream analyses and achieve state-of-art performance in many applications. To demystify the role of data augmentation, we develop a statistical framework on a low-dimension product manifold to theoretically understand why the unlabeled augmented data can lead to useful data representation. Under this framework, we propose a new representation learning method called augmentation invariant manifold learning and develop the corresponding loss function, which can work with a deep neural network to learn data representations. Compared with existing methods, the new data representation simultaneously exploits the manifold's geometric structure and invariant property of augmented data. Our theoretical investigation precisely characterizes how the data representation learned from augmented data can improve the \$k\$-nearest neighbor classifier in the downstream analysis, showing that a more complex data augmentation leads to more improvement in downstream analysis. Finally, numerical experiments on simulated and real datasets are presented to support the theoretical results in this paper.},
	urldate = {2022-11-14},
	publisher = {arXiv},
	author = {Wang, Shulei},
	month = nov,
	year = {2022},
	note = {arXiv:2211.00460 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Methodology},
}

@article{staudte_characterization_1971,
	title = {A {Characterization} of {Invariant} {Loss} {Functions}},
	volume = {42},
	issn = {0003-4851},
	url = {https://www.jstor.org/stable/2240032},
	abstract = {Maximally invariant loss functions are constructed in a decision theoretic framework, and sufficient conditions for their measurability are given.},
	number = {4},
	urldate = {2022-11-14},
	journal = {The Annals of Mathematical Statistics},
	author = {Staudte, Robert G.},
	year = {1971},
	pages = {1322--1327},
}

@article{noauthor_learning_2022,
	title = {Learning spatial cellular motifs predictive of the responses of patients to cancer treatments},
	copyright = {2022 Springer Nature Limited},
	issn = {2157-846X},
	url = {https://www.nature.com/articles/s41551-022-00958-3},
	doi = {10.1038/s41551-022-00958-3},
	abstract = {Graph deep learning applied to multiplexed immunofluorescence data from tumour microenvironments reveals spatial cellular structures that are indicative of cancer prognosis.},
	language = {en},
	urldate = {2022-11-14},
	journal = {Nature Biomedical Engineering},
	month = nov,
	year = {2022},
	keywords = {Biotechnology, Computational biology and bioinformatics},
	pages = {1--2},
}

@article{lin_deep_2022,
	title = {Deep hierarchical {LSTM} networks with attention for video summarization},
	volume = {97},
	issn = {0045-7906},
	url = {https://www.sciencedirect.com/science/article/pii/S0045790621005504},
	doi = {10.1016/j.compeleceng.2021.107618},
	abstract = {This paper studies the video summarization task by formulating it as a sequential decision-making process, in which the input is a sequence of video frames and the output is a subset of the original frames. Long Short-Term Memory (LSTM) is a commonly used framework of prior video summarization methods due to great temporal dependencies modeling ability. However, the frame sequence in the video summarization task is relatively long, and LSTM can only handle short video clips of up to 80 frames in length. This paper proposes a novel deep summarization framework named Deep Hierarchical LSTM Networks with Attention for Video Summarization (DHAVS) that consists of delicate feature extraction, temporal dependencies modeling, and video summary generation. Specifically, we employ 3D CNN instead of 2D CNN to extract spatial–temporal features and design an attention-based hierarchical LSTM module to capture the temporal dependencies among video frames. Additionally, we treat video summarization as an imbalanced class distribution problem and design a cost-sensitive loss function. Experimental results show that the proposed method has 0.7\% ∼ 21.3\% and 4.5\% ∼ 12.2\% improved to the conventional methods on SumMe and TVSum datasets.},
	language = {en},
	urldate = {2022-11-14},
	journal = {Computers \& Electrical Engineering},
	author = {Lin, Jingxu and Zhong, Sheng-hua and Fares, Ahmed},
	month = jan,
	year = {2022},
	keywords = {Attention mechanism, Cost-sensitive learning, LSTM, Video summarization},
	pages = {107618},
}

@book{martinez-taboada_sequential_2022,
	title = {Sequential {Decision} {Making} on {Unmatched} {Data} using {Bayesian} {Kernel} {Embeddings}},
	abstract = {The problem of sequentially maximizing the expectation of a function seeks to maximize the expected value of a function of interest without having direct control on its features. Instead, the distribution of such features depends on a given context and an action taken by an agent. In contrast to Bayesian optimization, the arguments of the function are not under agent's control, but are indirectly determined by the agent's action based on a given context. If the information of the features is to be included in the maximization problem, the full conditional distribution of such features, rather than its expectation only, needs to be accounted for. Furthermore, the function is itself unknown, only counting with noisy observations of such function, and potentially requiring the use of unmatched data sets. We propose a novel algorithm for the aforementioned problem which takes into consideration the uncertainty derived from the estimation of both the conditional distribution of the features and the unknown function, by modeling the former as a Bayesian conditional mean embedding and the latter as a Gaussian process. Our algorithm empirically outperforms the current state-of-the-art algorithm in the experiments conducted.},
	author = {Martinez-Taboada, Diego and Sejdinovic, Dino},
	month = oct,
	year = {2022},
	doi = {10.48550/arXiv.2210.13692},
}

@book{martinez-taboada_bayesian_2022,
	title = {Bayesian {Counterfactual} {Mean} {Embeddings} and {Off}-{Policy} {Evaluation}},
	abstract = {The counterfactual distribution models the effect of the treatment in the untreated group. While most of the work focuses on the expected values of the treatment effect, one may be interested in the whole counterfactual distribution or other quantities associated to it. Building on the framework of Bayesian conditional mean embeddings, we propose a Bayesian approach for modeling the counterfactual distribution, which leads to quantifying the epistemic uncertainty about the distribution. The framework naturally extends to the setting where one observes multiple treatment effects (e.g. an intermediate effect after an interim period, and an ultimate treatment effect which is of main interest) and allows for additionally modelling uncertainty about the relationship of these effects. For such goal, we present three novel Bayesian methods to estimate the expectation of the ultimate treatment effect, when only noisy samples of the dependence between intermediate and ultimate effects are provided. These methods differ on the source of uncertainty considered and allow for combining two sources of data. Moreover, we generalize these ideas to the off-policy evaluation framework, which can be seen as an extension of the counterfactual estimation problem. We empirically explore the calibration of the algorithms in two different experimental settings which require data fusion, and illustrate the value of considering the uncertainty stemming from the two sources of data.},
	author = {Martinez-Taboada, Diego and Sejdinovic, Dino},
	month = nov,
	year = {2022},
	doi = {10.48550/arXiv.2211.01518},
}

@book{jiang_teinet_2022,
	title = {{TEINet}: a deep learning framework for prediction of {TCR}-epitope binding specificity},
	shorttitle = {{TEINet}},
	abstract = {The adaptive immune response to foreign antigens is initiated by T-cell receptor (TCR) recognition on the antigens. Recent experimental advances have enabled the generation of a large amount of TCR data and their cognate antigenic targets, allowing machine learning models to predict the binding specificity of TCRs. In this work, we present TEINet, a deep learning framework that utilizes transfer learning to address this prediction problem. TEINet employs two separately trained encoders to transform TCR and epitope sequences into numerical vectors, which are subsequently fed into a fully connected neural network to predict their binding specificities. A major challenge for binding specificity prediction is the lack of a unified approach to sample negative data. Here, we first assess the current negative sampling approaches comprehensively and suggest that the Unified Epitope is the most suitable one. Subsequently, we compare TEINet with three baseline methods and observe that TEINet achieves an AUROC of 0.760, which outperforms baseline methods by 6.4-26\%. Furthermore, we investigate the impacts of the pretraining step and notice that excessive pretraining can adversely affect model performance. Our results and analysis show that TEINet can make an accurate prediction using only the TCR sequence (CDR3 β ) and the epitope sequence, providing novel insights to understand the interactions between TCRs and epitopes. TEINet is available at https://github.com/jiangdada1221/TEINet .},
	author = {Jiang, Yuepeng and Huo, Miaozhe and Li, Shuai},
	month = oct,
	year = {2022},
	doi = {10.1101/2022.10.20.513029},
}

@book{dens_interpretable_2022,
	title = {Interpretable deep learning to uncover the molecular binding patterns determining {TCR}–epitope interactions},
	abstract = {Background
The recognition of an epitope by a T-cell receptor (TCR) is crucial for eliminating pathogens and establishing immunological memory. Prediction of the binding of any TCR–epitope pair is still a challenging task, especially with novel epitopes, because the underlying patterns that drive the recognition are still largely unknown to both domain experts and machine learning models.

Results
The binding of a TCR and epitope sequence can only occur when amino acids from both sequences are in close contact with each other. We analyze the distance between interacting molecules of the TCR and epitope sequences and compare this to the amino acids that are important for TCR–epitope prediction models. Important residues are determined by using interpretable deep learning techniques or, more specifically, feature attribution extraction methods, on two state-of-the-art TCR–epitope prediction models: ImRex and TITAN. Highlighting feature attributions on the molecular complex reveals additional insights to the domain expert about why the prediction was made and can offer novel insights into the factors that determine TCR affinity on a molecular level. We also show which residues of the TCR and epitope sequences determine binding prediction for ImRex and TITAN and use those to explain model performance.

Conclusions
Extracting feature attributions is a useful way to verify your model and data for challenging problems where small hard-to-detect problems can accumulate to inaccurate results.},
	author = {Dens, Ceder and Bittremieux, Wout and Affaticati, Fabio and Laukens, Kris and Meysman, Pieter},
	month = may,
	year = {2022},
	doi = {10.1101/2022.05.02.490264},
}

@article{zhu_no-reference_2015,
	title = {No-{Reference} {Video} {Quality} {Assessment} {Based} on {Artifact} {Measurement} and {Statistical} {Analysis}},
	volume = {25},
	issn = {1558-2205},
	doi = {10.1109/TCSVT.2014.2363737},
	abstract = {A discrete cosine transform (DCT)-based no-reference video quality prediction model is proposed that measures artifacts and analyzes the statistics of compressed natural videos. The model has two stages: 1) distortion measurement and 2) nonlinear mapping. In the first stage, an unsigned ac band, three frequency bands, and two orientation bands are generated from the DCT coefficients of each decoded frame in a video sequence. Six efficient frame-level features are then extracted to quantify the distortion of natural scenes. In the second stage, each frame-level feature of all frames is transformed to a corresponding video-level feature via a temporal pooling, then a trained multilayer neural network takes all video-level features as inputs and outputs, a score as the predicted quality of the video sequence. The proposed method was tested on videos with various compression types, content, and resolution in four databases. We compared our model with a linear model, a support-vector-regression-based model, a state-of-the-art training-based model, and a four popular full-reference metrics. Detailed experimental results demonstrate that the results of the proposed method are highly correlated with the subjective assessments.},
	number = {4},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {Zhu, Kongfeng and Li, Chengqing and Asari, Vijayan and Saupe, Dietmar},
	month = apr,
	year = {2015},
	keywords = {Blocking artifact, DCT, Discrete cosine transforms, Distortion measurement, Feature extraction, H.264/AVC, H.264/Advanced Video Coding (AVC), Neural networks, Nonlinear distortion, Quality assessment, Video recording, discrete cosine transform (DCT), natural scene, no-reference (NR) measure, noreference measure, video quality assessment, video quality assessment (VQA)},
	pages = {533--546},
}

@article{kosko_bidirectional_2021,
	title = {Bidirectional {Associative} {Memories}: {Unsupervised} {Hebbian} {Learning} to {Bidirectional} {Backpropagation}},
	volume = {51},
	issn = {2168-2232},
	shorttitle = {Bidirectional {Associative} {Memories}},
	doi = {10.1109/TSMC.2020.3043249},
	abstract = {Bidirectional associative memories (BAMs) pass neural signals forward and backward through the same web of synapses. Earlier BAMs had no hidden neurons and did not use supervised learning. They tuned their synaptic weights with unsupervised Hebbian or competitive learning. Two-layer feedback BAMs always converge to fixed-point equilibria for threshold or threshold-like neurons. Every rectangular connection matrix is bidirectionally stable. These simpler BAMs extend to arbitrary hidden layers with supervised learning if the resulting bidirectional backpropagation algorithm uses the proper layer likelihood in the forward and backward directions. Bidirectional backpropagation lets users run deep classifiers and regressors in reverse as well as forward. Bidirectional training exploits pattern and synaptic information that forward-only running ignores.},
	number = {1},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
	author = {Kosko, Bart},
	month = jan,
	year = {2021},
	keywords = {Associative memory, Backpropagation, Backpropagation algorithms, Bidirectional associative memory (BAM), Hebbian learning, Neurons, Supervised learning, Synapses, Training, bidirectional backpropagation, global stability},
	pages = {103--115},
}

@misc{noauthor_dynamic_nodate,
	title = {A {Dynamic} {Growing} {Neural} {Network} for {Supervised} or {Unsupervised} {Learning} {\textbar} {IEEE} {Conference} {Publication} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/document/1712893},
	urldate = {2022-11-04},
}

@misc{noauthor_liquid_nodate,
	title = {Liquid {Neural} {Networks} {\textbar} {The} {Center} for {Brains}, {Minds} \& {Machines}},
	url = {https://cbmm.mit.edu/video/liquid-neural-networks},
	urldate = {2022-11-04},
}

@misc{noauthor_multilayer_nodate,
	title = {Multilayer networks {\textbar} {Journal} of {Complex} {Networks} {\textbar} {Oxford} {Academic}},
	url = {https://academic.oup.com/comnet/article/2/3/203/2841130?searchresult=1},
	urldate = {2022-11-04},
}

@misc{noauthor_robust_nodate,
	title = {Robust multiscale estimation of time-average variance for time series segmentation - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947322002286#fg0020},
	urldate = {2022-11-04},
}

@book{zhang_differentiable_2022,
	title = {Differentiable {Topology}-{Preserved} {Distance} {Transform} for {Pulmonary} {Airway} {Segmentation}},
	abstract = {Detailed pulmonary airway segmentation is a clinically important task for endobronchial intervention and treatment of peripheral lung cancer lesions. Convolutional Neural Networks (CNNs) are promising tools for medical image analysis but have been performing poorly for cases when there is a significantly imbalanced feature distribution, which is true for the airway data as the trachea and principal bronchi dominate most of the voxels whereas the lobar bronchi and distal segmental bronchi occupy only a small proportion. In this paper, we propose a Differentiable Topology-Preserved Distance Transform (DTPDT) framework to improve the performance of airway segmentation. A Topology-Preserved Surrogate (TPS) learning strategy is first proposed to equalize the training progress within-class distribution. Furthermore, a Convolutional Distance Transform (CDT) is designed to identify the breakage phenomenon with improved sensitivity, minimizing the variation of the distance map between the prediction and ground-truth. The proposed method is validated with the publicly available reference airway segmentation datasets.},
	author = {Zhang, Minghui and Yang, Guang-Zhong and Gu, Yun},
	month = sep,
	year = {2022},
	doi = {10.48550/arXiv.2209.08355},
}

@book{tang_adversarial_2022,
	title = {Adversarial {Transformer} for {Repairing} {Human} {Airway} {Segmentation}},
	abstract = {Discontinuity in the delineation of peripheral bronchioles hinders the potential clinical application of automated airway segmentation models. Moreover, the deployment of such models is limited by the data heterogeneity across different centres, and pathological abnormalities also make achieving accurate robust segmentation in distal small airways difficult. Meanwhile, the diagnosis and prognosis of lung diseases often rely on evaluating structural changes in those anatomical regions. To address this gap, this paper presents a patch-scale adversarial-based refinement network that takes in preliminary segmentation along with original CT images and outputs a refined mask of the airway structure. The method is validated on three different datasets encompassing healthy cases, cases with cystic fibrosis and cases with COVID-19. The results are quantitatively evaluated by seven metrics and achieved more than a 15\% rise in detected length ratio and detected branch ratio, showing promising performance compared to previously proposed models. The visual illustration also proves our refinement guided by a patch-scale discriminator and centreline objective functions is effective in detecting discontinuities and missing bronchioles. Furthermore, the generalizability of our refinement pipeline is tested on three previous models and improves their segmentation completeness significantly.},
	author = {Tang, Zeyu and Yang, Nan and Walsh, Simon and Yang, Guang},
	month = oct,
	year = {2022},
}

@misc{noauthor_evolutionary-scale_nodate,
	title = {Evolutionary-scale prediction of atomic level protein structure with a language model {\textbar} {bioRxiv}},
	url = {https://www.biorxiv.org/content/10.1101/2022.07.20.500902v2},
	urldate = {2022-11-01},
}

@article{deckers_extended_2022,
	title = {Extended liquid state machines for speech recognition},
	volume = {16},
	doi = {10.3389/fnins.2022.1023470},
	abstract = {A liquid state machine (LSM) is a biologically plausible model of a cortical microcircuit. It exists of a random, sparse reservoir of recurrently connected spiking neurons with fixed synapses and a trainable readout layer. The LSM exhibits low training complexity and enables backpropagation-free learning in a powerful, yet simple computing paradigm. In this work, the liquid state machine is enhanced by a set of bio-inspired extensions to create the extended liquid state machine (ELSM), which is evaluated on a set of speech data sets. Firstly, we ensure excitatory/inhibitory (E/I) balance to enable the LSM to operate in edge-of-chaos regime. Secondly, spike-frequency adaptation (SFA) is introduced in the LSM to improve the memory capabilities. Lastly, neuronal heterogeneity, by means of a differentiation in time constants, is introduced to extract a richer dynamical LSM response. By including E/I balance, SFA, and neuronal heterogeneity, we show that the ELSM consistently improves upon the LSM while retaining the benefits of the straightforward LSM structure and training procedure. The proposed extensions led up to an 5.2\% increase in accuracy while decreasing the number of spikes in the ELSM up to 20.2\% on benchmark speech data sets. On some benchmarks, the ELSM can even attain similar performances as the current state-of-the-art in spiking neural networks. Furthermore, we illustrate that the ELSM input-liquid and recurrent synaptic weights can be reduced to 4-bit resolution without any significant loss in classification performance. We thus show that the ELSM is a powerful, biologically plausible and hardware-friendly spiking neural network model that can attain near state-of-the-art accuracy on speech recognition benchmarks for spiking neural networks.},
	journal = {Frontiers in Neuroscience},
	author = {Deckers, Lucas and Tsang, Ing and Van Leekwijck, Werner and Latré, Steven},
	month = oct,
	year = {2022},
	pages = {1023470},
}

@misc{noauthor_vapnikchervonenkis_2022,
	title = {Vapnik–{Chervonenkis} dimension},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Vapnik%E2%80%93Chervonenkis_dimension&oldid=1107484419},
	abstract = {In Vapnik–Chervonenkis theory, the Vapnik–Chervonenkis (VC) dimension is a measure of the capacity (complexity, expressive power, richness, or flexibility) of a set of functions that can be learned by a statistical binary classification algorithm. It is defined as the cardinality of the largest set of points that the algorithm can shatter, which means the algorithm can always learn a perfect classifier for any labeling of at least one configuration of those data points. It was originally defined by Vladimir Vapnik and Alexey Chervonenkis.Informally, the capacity of a classification model is related to how complicated it can be. For example, consider the thresholding of a high-degree polynomial: if the polynomial evaluates above zero, that point is classified as positive, otherwise as negative. A high-degree polynomial can be wiggly, so it can fit a given set of training points well. But one can expect that the classifier will make errors on other points, because it is too wiggly. Such a polynomial has a high capacity. A much simpler alternative is to threshold a linear function. This function may not fit the training set well, because it has a low capacity. This notion of capacity is made rigorous below.},
	language = {en},
	urldate = {2022-10-31},
	journal = {Wikipedia},
	month = aug,
	year = {2022},
	note = {Page Version ID: 1107484419},
}

@inproceedings{ethayarajh_understanding_2022,
	title = {Understanding {Dataset} {Difficulty} with \${\textbackslash}mathcal\{{V}\}\$-{Usable} {Information}},
	url = {https://proceedings.mlr.press/v162/ethayarajh22a.html},
	abstract = {Estimating the difficulty of a dataset typically involves comparing state-of-the-art models to humans; the bigger the performance gap, the harder the dataset is said to be. However, this comparison provides little understanding of how difficult each instance in a given distribution is, or what attributes make the dataset difficult for a given model. To address these questions, we frame dataset difficulty—w.r.t. a model V{\textbackslash}mathcal\{V\}—as the lack of V{\textbackslash}mathcal\{V\}-usable information (Xu et al., 2019), where a lower value indicates a more difficult dataset for V{\textbackslash}mathcal\{V\}. We further introduce pointwise V{\textbackslash}mathcal\{V\}-information (PVI) for measuring the difficulty of individual instances w.r.t. a given distribution. While standard evaluation metrics typically only compare different models for the same dataset, V{\textbackslash}mathcal\{V\}-usable information and PVI also permit the converse: for a given model V{\textbackslash}mathcal\{V\}, we can compare different datasets, as well as different instances/slices of the same dataset. Furthermore, our framework allows for the interpretability of different input attributes via transformations of the input, which we use to discover annotation artefacts in widely-used NLP benchmarks.},
	language = {en},
	urldate = {2022-10-31},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Ethayarajh, Kawin and Choi, Yejin and Swayamdipta, Swabha},
	month = jun,
	year = {2022},
	pages = {5988--6008},
}

@article{wang_cdk5-mediated_2018,
	title = {{CDK5}-{Mediated} {Phosphorylation}-{Dependent} {Ubiquitination} and {Degradation} of {E3} {Ubiquitin} {Ligases} {GP78} {Accelerates} {Neuronal} {Death} in {Parkinson}’s {Disease}},
	volume = {55},
	issn = {1559-1182},
	url = {https://doi.org/10.1007/s12035-017-0579-2},
	doi = {10.1007/s12035-017-0579-2},
	abstract = {The molecular mechanisms responsible for the loss of dopaminergic neurons in Parkinson’s disease (PD) remain obscure. Loss of function of E3 ubiquitin ligases is associated with mitochondria dysfunction, dysfunction of protein degradation, and α-synuclein aggregation, which are major contributors to neurodegeneration in PD. Recent research has thus focused on E3 ubiquitin ligase glycoprotein 78 (GP78); however, the role of GP78 in PD pathogenesis remains unclear. Notably, cyclin-dependent kinase 5 (CDK5) controls multiple cellular events in postmitotic neurons, and CDK5 activity has been implicated in the pathogenesis of PD. Thus, we addressed the relationship between CDK5 and GP78 in MPTP-based PD models. We found that GP78 expression is decreased in MPTP-based cellular and animal PD models, and CDK5 directly phosphorylated GP78 at Ser516, which promoted the ubiquitination and degradation of GP78. Importantly, overexpression of GP78 or interference of GP78 Ser516 phosphorylation protected neurons against MPP+-induced cell death. Thus, our research reveals that the CDK5-GP78 pathway is involved in the pathogenesis of PD and could be a novel candidate drug target for the treatment of PD.},
	language = {en},
	number = {5},
	urldate = {2022-10-29},
	journal = {Molecular Neurobiology},
	author = {Wang, Qingzhi and Jiao, Fengjuan and Zhang, Pei and Yan, Jianguo and Zhang, Zheng and He, Feng and Zhang, Qian and Lv, Zexi and Peng, Xiang and Cai, Hongwei and Tian, Bo},
	month = may,
	year = {2018},
	keywords = {Cyclin-dependent kinase, Glycoprotein 78, Parkinson’s disease, Ubiquitination},
	pages = {3709--3717},
}

@article{feng_log_2013,
	title = {Log transformation: application and interpretation in biomedical research},
	volume = {32},
	issn = {1097-0258},
	shorttitle = {Log transformation},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5486},
	doi = {10.1002/sim.5486},
	abstract = {The log transformation has been widely used in biomedical research to deal with the skewed data. However, in the medical publications, we have found many misuses and misinterpretations of analysis based on log-transformed data. In this paper, we list some common scenarios of misuse and misinterpretation of log transformation in biomedical applications. We also provide both theoretical and practical justifications to support our viewpoints. Copyright © 2012 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {2},
	urldate = {2022-10-28},
	journal = {Statistics in Medicine},
	author = {Feng, Changyong and Wang, Hongyue and Lu, Naiji and Tu, Xin M.},
	year = {2013},
	keywords = {geometric mean, hypothesis testing, skewness},
	pages = {230--239},
}

@inproceedings{shao_contrastive_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Contrastive {Learning} in {Frequency} {Domain} for {Non}-{I}.{I}.{D}. {Image} {Classification}},
	isbn = {9783030678326},
	doi = {10.1007/978-3-030-67832-6_10},
	abstract = {Non-I.I.D. image classification is an important research topic for both academic and industrial communities. However, it is a very challenging task, as it violates the famous hypothesis of independent and identically distributed (I.I.D.) in conventional machine learning, and the classifier minimizing empirical errors on training images does not perform well on testing images. In this work, we propose a novel model called Contrastive Learning in Frequency Domain (CLFD) to learn invariant representations for Non-I.I.D. image classification. In CLFD, model learning includes two steps: contrastive learning in the frequency domain for pre-training, and image classification with fine-tuning. In the first pre-training step, anchor, positive and negative images are transformed by Discrete Cosine Transform (DCT) and then projected into vector space. This step is to obtain stable invariant features by minimizing the contrastive loss. In the step of image classification with fine-tuning, the features from ResNet are mapped into the label space by a simple fully connected layer, and the classification loss is utilized to fine-tune the parameters in the ResNet. Extensive experiments conducted on public NICO dataset demonstrate the effectiveness of the proposed CLFD, which outperforms the state-of-the-art methods.},
	language = {en},
	booktitle = {{MultiMedia} {Modeling}},
	publisher = {Springer International Publishing},
	author = {Shao, Huan and Yuan, Zhaoquan and Peng, Xiao and Wu, Xiao},
	editor = {Lokoč, Jakub and Skopal, Tomáš and Schoeffmann, Klaus and Mezaris, Vasileios and Li, Xirong and Vrochidis, Stefanos and Patras, Ioannis},
	year = {2021},
	keywords = {Contrastive learning, Frequency domain learning, Non-I.I.D. image classification},
	pages = {111--122},
}

@inproceedings{liu_contrastive_2021,
	title = {Contrastive {Self}-{Supervised} {Representation} {Learning} for {Sensing} {Signals} from the {Time}-{Frequency} {Perspective}},
	doi = {10.1109/ICCCN52240.2021.9522151},
	abstract = {This paper presents a contrastive self-supervised representation learning framework that is new in being designed specifically for deep learning from frequency domain data. Contrastive self-supervised representation learning trains neural networks using mostly unlabeled data. It is motivated by the need to reduce the labeling burden of deep learning. In this paper, we are specifically interested in applying this approach to physical sensing scenarios, such as those arising in Internet-of-Things (IoT) applications. Deep neural networks have been widely utilized in IoT applications, but the performance of such models largely depends on the availability of large labeled datasets, which in turn entails significant training costs. Motivated by the success of contrastive self-supervised representation learning at substantially reducing the need for labeled data (mostly in areas of computer vision and natural language processing), there is growing interest in customizing the contrastive learning framework to IoT applications. Most existing work in that space approaches the problem from a time-domain perspective. However, IoT applications often measure physical phenomena, where the underlying processes (such as acceleration, vibration, or wireless signal propagation) are fundamentally a function of signal frequencies and thus have sparser and more compact representations in the frequency domain. Recently, this observation motivated the development of Short-Time Fourier Neural Networks (STFNets) that learn directly in the frequency domain, and were shown to offer large performance gains compared to Convolutional Neural Networks (CNNs) when designing supervised learning models for IoT tasks. Hence, in this paper, we introduce an STFNet-based Contrastive Self-supervised representation Learning framework (STF-CSL). STF-CSL takes both time-domain and frequency-domain features into consideration. We build the encoder using STFNet as the fundamental building block. We also apply both time-domain data augmentation and frequency-domain data augmentation during the self-supervised training process. We evaluate the resulting performance of STF-CSL on various human activity recognition tasks. The evaluation results demonstrate that STF-CSL significantly outperforms the time-domain based self-supervised approaches thereby substantially enhancing our ability to train deep neural networks from unlabeled data in IoT contexts.},
	booktitle = {2021 {International} {Conference} on {Computer} {Communications} and {Networks} ({ICCCN})},
	author = {Liu, Dongxin and Wang, Tianshi and Liu, Shengzhong and Wang, Ruijie and Yao, Shuochao and Abdelzaher, Tarek},
	month = jul,
	year = {2021},
	note = {ISSN: 2637-9430},
	keywords = {Deep learning, Frequency Domain, IoT, Neural networks, Performance gain, Representation Learning, Self-supervision, Sensors, Time-frequency analysis, Training, Wireless sensor networks},
	pages = {1--10},
}

@misc{liu_contrastive_2022,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Contrastive {Learning} {Combining} {Frequency}-{Domain} and {Time}-{Domain} {Information} for {Intelligent} {Fault} {Diagnosis} of {Rotating} {Machinery}},
	url = {https://papers.ssrn.com/abstract=4147550},
	doi = {10.2139/ssrn.4147550},
	abstract = {Data-driven intelligent fault diagnosis requires a large amount of data. However, it is usually difficult for us to acquire adequate labeled data in the field. In addition, with mechanical failure being a small probability event, the problem of insufficient fault data is often presented, which makes it hard for intelligent diagnosis methods. In this paper, a contrastive learning model combining frequency-domain and time-domain information (CLFT) is proposed for rotating machinery fault diagnosis. This model constrains the time-domain and frequency-domain information of vibration signals at the feature level, in order to obtain more refined features for the model encoder. Based on CLFT, a fault diagnosis method applicable to the rotating machinery has been constructed, which uses the pre-trained encoder to fine-tune the downstream task. Experiments indicate that CLFT has strong cross-domain learning capabilities, and the fault diagnosis methods outperform other state-of-the-art methods and perform well in small labeled sample situations.},
	language = {en},
	urldate = {2022-10-27},
	author = {Liu, Yang and Wen, Weigang and Bai, Yihao and Meng, Qingzhou},
	month = jun,
	year = {2022},
	keywords = {Contrastive learning, Fourier transform, Intelligent fault diagnosis, Self-supervised pre-training, Time-frequency contrast},
}

@article{beaulant_endoplasmic_2022,
	title = {Endoplasmic reticulum-mitochondria miscommunication is an early and causal trigger of hepatic insulin resistance and steatosis},
	volume = {77},
	doi = {10.1016/j.jhep.2022.03.017},
	abstract = {Background \& aims
Hepatic insulin resistance in obesity and type 2 diabetes was recently associated with endoplasmic reticulum (ER)-mitochondria miscommunication. These contact sites (mitochondria-associated membranes: MAMs) are highly dynamic and involved in many functions. Up to now, it is not clear if MAM miscommunication could have a causal role in hepatic insulin resistance and steatosis. We therefore aimed to determine whether and how organelle miscommunication plays a role in the onset and progression of hepatic metabolic impairment.

Methods
We analyzed hepatic ER-mitochondria interactions and calcium exchange in diet-induced obese mice in a time-dependent and reversible manner, and investigated causality in hepatic metabolic alterations by expressing a specific organelle spacer or linker in mouse liver, using adenovirus.

Results
Disruption of ER-mitochondria interactions and calcium exchange is an early event preceding hepatic insulin resistance and steatosis in diet-induced obese mice. Interestingly, an 8-week reversal diet concomitantly reversed hepatic organelle miscommunication and insulin resistance in obese mice. Mechanistically, disrupting structural and functional ER-mitochondria interactions through the hepatic overexpression of the organelle spacer FATE1 was sufficient to impair hepatic insulin action and glucose homeostasis. In addition, FATE1-mediated organelle miscommunication disrupted lipid-related mitochondrial oxidative metabolism and induced hepatic steatosis. Conversely, reinforcement of ER-mitochondria interactions through hepatic expression of a synthetic linker prevented diet-induced glucose intolerance after 4 weeks’ overnutrition. Importantly, ER-mitochondria miscommunication was confirmed in the liver of obese patients with type-2 diabetes, and correlated with glycemia, HbA1c and HOMA-IR index.

Conclusions
ER-mitochondria miscommunication is an early causal trigger of hepatic insulin resistance and steatosis, and can be reversed by switching to a healthy diet. Thus, targeting MAMs could contribute to restoring metabolic homeostasis.

Lay summary
The literature suggests that interactions between endoplasmic reticulum (ER) and mitochondria could play a dual role in hepatic insulin resistance and steatosis during chronic obesity. The present study reappraised time-dependent regulation of hepatic ER-mitochondria interactions and calcium exchange in diet-induced obese mice and their causal role in hepatic insulin resistance and steatosis. We show that organelle miscommunication is an early causal trigger of hepatic insulin resistance and steatosis, and can be improved by nutritional strategies.},
	journal = {Journal of Hepatology},
	author = {Beaulant, Agathe and Dia, Maya and Pillot, Bruno and Chauvin, Marie-Agnes and Ji-Cao, Jingwei and Durand, Christine and Bendridi, Nadia and Chanon, Stéphanie and Vieille-Marchiset, Aurelie and Crola Da Silva, Claire and Patouraux, Stéphanie and Anty, Rodolphe and Iannelli, Antonio and Tran, Albert and Gual, Philippe and Vidal, Hubert and Gomez, Ludovic and Paillard, Melanie and Rieusset, Jennifer},
	month = mar,
	year = {2022},
}

@article{rizik_synthetic_2022,
	title = {Synthetic neuromorphic computing in living cells},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-33288-8},
	doi = {10.1038/s41467-022-33288-8},
	abstract = {Computational properties of neuronal networks have been applied to computing systems using simplified models comprising repeated connected nodes, e.g., perceptrons, with decision-making capabilities and flexible weighted links. Analogously to their revolutionary impact on computing, neuro-inspired models can transform synthetic gene circuit design in a manner that is reliable, efficient in resource utilization, and readily reconfigurable for different tasks. To this end, we introduce the perceptgene, a perceptron that computes in the logarithmic domain, which enables efficient implementation of artificial neural networks in Escherichia coli cells. We successfully modify perceptgene parameters to create devices that encode a minimum, maximum, and average of analog inputs. With these devices, we create multi-layer perceptgene circuits that compute a soft majority function, perform an analog-to-digital conversion, and implement a ternary switch. We also create a programmable perceptgene circuit whose computation can be modified from OR to AND logic using small molecule induction. Finally, we show that our approach enables circuit optimization via artificial intelligence algorithms.},
	language = {en},
	number = {1},
	urldate = {2022-10-25},
	journal = {Nature Communications},
	author = {Rizik, Luna and Danial, Loai and Habib, Mouna and Weiss, Ron and Daniel, Ramez},
	month = sep,
	year = {2022},
	keywords = {Synthetic biology},
	pages = {5602},
}

@article{kiemen_coda_2022,
	title = {{CODA}: quantitative {3D} reconstruction of large tissues at cellular resolution},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{CODA}},
	url = {https://www.nature.com/articles/s41592-022-01650-9},
	doi = {10.1038/s41592-022-01650-9},
	abstract = {A central challenge in biology is obtaining high-content, high-resolution information while analyzing tissue samples at volumes relevant to disease progression. We address this here with CODA, a method to reconstruct exceptionally large (up to multicentimeter cubed) tissues at subcellular resolution using serially sectioned hematoxylin and eosin-stained tissue sections. Here we demonstrate CODA’s ability to reconstruct three-dimensional (3D) distinct microanatomical structures in pancreas, skin, lung and liver tissues. CODA allows creation of readily quantifiable tissue volumes amenable to biological research. As a testbed, we assess the microanatomy of the human pancreas during tumorigenesis within the branching pancreatic ductal system, labeling ten distinct structures to examine heterogeneity and structural transformation during neoplastic progression. We show that pancreatic precancerous lesions develop into distinct 3D morphological phenotypes and that pancreatic cancer tends to spread far from the bulk tumor along collagen fibers that are highly aligned to the 3D curves of ductal, lobular, vascular and neural structures. Thus, CODA establishes a means to transform broadly the structural study of human diseases through exploration of exhaustively labeled 3D microarchitecture.},
	language = {en},
	urldate = {2022-10-24},
	journal = {Nature Methods},
	author = {Kiemen, Ashley L. and Braxton, Alicia M. and Grahn, Mia P. and Han, Kyu Sang and Babu, Jaanvi Mahesh and Reichel, Rebecca and Jiang, Ann C. and Kim, Bridgette and Hsu, Jocelyn and Amoa, Falone and Reddy, Sashank and Hong, Seung-Mo and Cornish, Toby C. and Thompson, Elizabeth D. and Huang, Peng and Wood, Laura D. and Hruban, Ralph H. and Wirtz, Denis and Wu, Pei-Hsun},
	month = oct,
	year = {2022},
	keywords = {Cancer imaging, Cancer microenvironment, Imaging, Machine learning},
	pages = {1--10},
}

@misc{qian_transformer_2022,
	title = {Transformer based multiple instance learning for weakly supervised histopathology image segmentation},
	url = {http://arxiv.org/abs/2205.08878},
	doi = {10.48550/arXiv.2205.08878},
	abstract = {Hispathological image segmentation algorithms play a critical role in computer aided diagnosis technology. The development of weakly supervised segmentation algorithm alleviates the problem of medical image annotation that it is time-consuming and labor-intensive. As a subset of weakly supervised learning, Multiple Instance Learning (MIL) has been proven to be effective in segmentation. However, there is a lack of related information between instances in MIL, which limits the further improvement of segmentation performance. In this paper, we propose a novel weakly supervised method for pixel-level segmentation in histopathology images, which introduces Transformer into the MIL framework to capture global or long-range dependencies. The multi-head self-attention in the Transformer establishes the relationship between instances, which solves the shortcoming that instances are independent of each other in MIL. In addition, deep supervision is introduced to overcome the limitation of annotations in weakly supervised methods and make the better utilization of hierarchical information. The state-of-the-art results on the colon cancer dataset demonstrate the superiority of the proposed method compared with other weakly supervised methods. It is worth believing that there is a potential of our approach for various applications in medical images.},
	urldate = {2022-10-24},
	publisher = {arXiv},
	author = {Qian, Ziniu and Li, Kailu and Lai, Maode and Chang, Eric I.-Chao and Wei, Bingzheng and Fan, Yubo and Xu, Yan},
	month = may,
	year = {2022},
	note = {arXiv:2205.08878 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{bathini_molecular_2022,
	title = {The {Molecular} {Mechanisms} of {Action} of {Photobiomodulation} {Against} {Neurodegenerative} {Diseases}: {A} {Systematic} {Review}},
	volume = {42},
	shorttitle = {The {Molecular} {Mechanisms} of {Action} of {Photobiomodulation} {Against} {Neurodegenerative} {Diseases}},
	doi = {10.1007/s10571-020-01016-9},
	abstract = {Neurodegenerative diseases might be slow but relentless, as we continue to fail in treating or delaying their progression. Given the complexity in the pathogenesis of these diseases, a broad-acting approach like photobiomodulation can prove promising. Photobiomodulation (PBM) uses red and infrared light for therapeutic benefits, working by stimulating growth and proliferation. The implications of photobiomodulation have been studied in several neurodegenerative disease models. It has been shown to improve cell survival, decrease apoptosis, alleviate oxidative stress, suppress inflammation, and rescue mitochondrial function. In in vivo models, it has reportedly preserved motor and cognitive skills. Beyond mitochondrial stimulation, the molecular mechanisms by which photobiomodulation protects against neurodegeneration have not been very well studied. This review has systematically been undertaken to study the effects of photobiomodulation at a molecular level and identify the different biochemical pathways and molecular changes in the process. The data showed the involvement of pathways like extracellular signal-regulated kinase (ERK), mitogen-activated protein kinase (MAPK), and protein kinase B (Akt). In addition, the expression of several genes and proteins playing different roles in the disease mechanisms was found to be influenced by PBM, such as neurotrophic factors and secretases. Studying the literature indicated that PBM can be translated to a potential therapeutic tool, acting through a spectrum of mechanisms that work together to decelerate disease progression in the organism, which is difficult to achieve through pharmacological interventions.},
	journal = {Cellular and Molecular Neurobiology},
	author = {Bathini, Mayukha and Raghushaker, Chandavalli and Mahato, Krishna K.},
	month = may,
	year = {2022},
	pages = {1--17},
}

@misc{baghal_termination_2020,
	title = {A termination criterion for stochastic gradient descent for binary classification},
	url = {http://arxiv.org/abs/2003.10312},
	doi = {10.48550/arXiv.2003.10312},
	abstract = {We propose a new, simple, and computationally inexpensive termination test for constant step-size stochastic gradient descent (SGD) applied to binary classification on the logistic and hinge loss with homogeneous linear predictors. Our theoretical results support the effectiveness of our stopping criterion when the data is Gaussian distributed. This presence of noise allows for the possibility of non-separable data. We show that our test terminates in a finite number of iterations and when the noise in the data is not too large, the expected classifier at termination nearly minimizes the probability of misclassification. Finally, numerical experiments indicate for both real and synthetic data sets that our termination test exhibits a good degree of predictability on accuracy and running time.},
	urldate = {2022-10-24},
	publisher = {arXiv},
	author = {Baghal, Sina and Paquette, Courtney and Vavasis, Stephen A.},
	month = mar,
	year = {2020},
	note = {arXiv:2003.10312 [math, stat]},
	keywords = {Mathematics - Optimization and Control, Statistics - Machine Learning},
}

@misc{noauthor_stopping_nodate,
	title = {Stopping criteria for, and strong convergence of, stochastic gradient descent on {Bottou}-{Curtis}-{Nocedal} functions {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/s10107-021-01710-6},
	urldate = {2022-10-24},
}

@book{song_new_2019,
	title = {A {New} {Recurrent} {Plug}-and-{Play} {Prior} {Based} on the {Multiple} {Self}-{Similarity} {Network}},
	abstract = {Recent work has shown the effectiveness of the plug-and-play priors (PnP) framework for regularized image reconstruction. However, the performance of PnP depends on the quality of the denoisers used as priors. In this letter, we design a novel PnP denoising prior, called multiple self-similarity net (MSSN), based on the recurrent neural network (RNN) with self-similarity matching using multi-head attention mechanism. Unlike traditional neural net denoisers, MSSN exploits different types of relationships among non-local and repeating features to remove the noise in the input image. We numerically evaluate the performance of MSSN as a module within PnP for solving magnetic resonance (MR) image reconstruction. Experimental results show the stable convergence and excellent performance of MSSN for reconstructing images from highly compressive Fourier measurements.},
	author = {Song, Guangxiao and Sun, Yu and Liu, Jiaming and Wang, Zhi-Jie and Kamilov, Ulugbek},
	month = jul,
	year = {2019},
}

@article{gan_deformation-compensated_2022,
	title = {Deformation-{Compensated} {Learning} for {Image} {Reconstruction} {Without} {Ground} {Truth}},
	volume = {PP},
	doi = {10.1109/TMI.2022.3163018},
	abstract = {Deep neural networks for medical image reconstruction are traditionally trained using high-quality ground-truth images as training targets. Recent work on Noise2Noise (N2N) has shown the potential of using multiple noisy measurements of the same object as an alternative to having a ground-truth. However, existing N2N-based methods are not suitable for learning from the measurements of an object undergoing nonrigid deformation. This paper addresses this issue by proposing the deformation-compensated learning (DeCoLearn) method for training deep reconstruction networks by compensating for object deformations. A key component of DeCoLearn is a deep registration module, which is jointly trained with the deep reconstruction network without any ground-truth supervision. We validate DeCoLearn on both simulated and experimentally collected magnetic resonance imaging (MRI) data and show that it significantly improves imaging quality.},
	journal = {IEEE transactions on medical imaging},
	author = {Gan, Weijie and Sun, Yu and Eldeniz, Cihat and Liu, Jiaming and An, Hongyu and Kamilov, Ulugbek},
	month = mar,
	year = {2022},
}

@article{leiting_multicolor_2017,
	title = {Multicolor {Single}-{Molecule} {Localization} {Super}-{Resolution} {Microscopy}},
	volume = {37},
	doi = {10.3788/AOS201737.0318010},
	abstract = {Multicolor imaging is an important extension of super-resolution microscopy, which greatly enhances the investigation ability of the relationship between localization and interaction of sub-cellular structures. Therefore, it is beneficial for researchers to go deep into understanding of complicated biological phenomena and processes in cells. Based on the special working principle of single-molecule localization super-resolution microscopy (SMLM), several characteristic multicolor imaging technologies including excitation-dependent, activation-dependent, split-dependent multicolor SMLM and so on are accomplished. In this paper, we analyze the advantages and disadvantages among six main multicolor SMLM from the views of color separation ability, spectrum cross-talk and data collection efficiency. In addition, we discuss the cell fixation method in relation to the multicolor imaging. This review may be helpful for researchers to seek suitable and reliable multicolor imaging methods to study corresponding scientific problem according to their own experimental conditions.},
	journal = {Acta Optica Sinica},
	author = {Leiting, 潘雷霆 and Fen, 胡芬 and Zhang, Xinzheng and Xu, Jingjun},
	month = mar,
	year = {2017},
	pages = {0318010},
}

@article{andronov_splitsmlm_2022,
	title = {{splitSMLM}, a spectral demixing method for high-precision multi-color localization microscopy applied to nuclear pore complexes},
	volume = {5},
	doi = {10.1038/s42003-022-04040-1},
	abstract = {Single molecule localization microscopy (SMLM) with a dichroic image splitter can provide invaluable multi-color information regarding colocalization of individual molecules, but it often suffers from technical limitations. Classical demixing algorithms tend to give suboptimal results in terms of localization precision and correction of chromatic errors. Here we present an image splitter based multi-color SMLM method (splitSMLM) that offers much improved localization precision and drift correction, compensation of chromatic distortions, and optimized performance of fluorophores in a specific buffer to equalize their reactivation rates for simultaneous imaging. A novel spectral demixing algorithm, SplitViSu, fully preserves localization precision with essentially no data loss and corrects chromatic errors at the nanometer scale. Multi-color performance is further improved by using optimized fluorophore and filter combinations. Applied to three-color imaging of the nuclear pore complex (NPC), this method provides a refined positioning of the individual NPC proteins and reveals that Pom121 clusters act as NPC deposition loci, hence illustrating strength and general applicability of the method.},
	journal = {Communications Biology},
	author = {Andronov, Leonid and Genthial, Rachel and Hentsch, Didier and Klaholz, Bruno},
	month = oct,
	year = {2022},
}

@misc{park_efficient_2022,
	title = {Efficient debiasing with contrastive weight pruning},
	url = {http://arxiv.org/abs/2210.05247},
	doi = {10.48550/arXiv.2210.05247},
	abstract = {Neural networks are often biased to spuriously correlated features that provide misleading statistical evidence that does not generalize. This raises a fundamental question: "Does an optimal unbiased functional subnetwork exist in a severely biased network? If so, how to extract such subnetwork?" While few studies have revealed the existence of such optimal subnetworks with the guidance of ground-truth unbiased samples, the way to discover the optimal subnetworks with biased training dataset is still unexplored in practice. To address this, here we first present our theoretical insight that alerts potential limitations of existing algorithms in exploring unbiased subnetworks in the presence of strong spurious correlations. We then further elucidate the importance of bias-conflicting samples on structure learning. Motivated by these observations, we propose a Debiased Contrastive Weight Pruning (DCWP) algorithm, which probes unbiased subnetworks without expensive group annotations. Experimental results demonstrate that our approach significantly outperforms state-of-the-art debiasing methods despite its considerable reduction in the number of parameters.},
	urldate = {2022-10-23},
	publisher = {arXiv},
	author = {Park, Geon Yeong and Lee, Sangmin and Lee, Sang Wan and Ye, Jong Chul},
	month = oct,
	year = {2022},
	note = {arXiv:2210.05247 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{wang_review_2016,
	title = {A review of road extraction from remote sensing images},
	volume = {3},
	issn = {2095-7564},
	url = {https://www.sciencedirect.com/science/article/pii/S2095756416301076},
	doi = {10.1016/j.jtte.2016.05.005},
	abstract = {As a significant role for traffic management, city planning, road monitoring, GPS navigation and map updating, the technology of road extraction from a remote sensing (RS) image has been a hot research topic in recent years. In this paper, after analyzing different road features and road models, the road extraction methods were classified into the classification-based methods, knowledge-based methods, mathematical morphology, active contour model, and dynamic programming. Firstly, the road features, road model, existing difficulties and interference factors for road extraction were analyzed. Secondly, the principle of road extraction, the advantages and disadvantages of various methods and research achievements were briefly highlighted. Then, the comparisons of the different road extraction algorithms were performed, including road features, test samples and shortcomings. Finally, the research results in recent years were summarized emphatically. It is obvious that only using one kind of road features is hard to get an excellent extraction effect. Hence, in order to get good results, the road extraction should combine multiple methods according to the real applications. In the future, how to realize the complete road extraction from a RS image is still an essential but challenging and important research topic.},
	language = {en},
	number = {3},
	urldate = {2022-10-20},
	journal = {Journal of Traffic and Transportation Engineering (English Edition)},
	author = {Wang, Weixing and Yang, Nan and Zhang, Yi and Wang, Fengping and Cao, Ting and Eklund, Patrik},
	month = jun,
	year = {2016},
	keywords = {Classification, Remote sensing image, Road extraction, Road feature},
	pages = {271--282},
}

@incollection{hubert_caveolae_2023,
	title = {Caveolae biogenesis and lipid sorting at the plasma membrane},
	isbn = {9780323899116},
	abstract = {The plasma membrane of many cell types, in particular, endothelia, smooth muscle cells, and adipocytes, contains numerous small invaginations termed caveolae. In nonmuscle cells, caveolae are formed by lipid-driven assembly of the integral membrane protein caveolin 1 (Cav1) and the peripherally attached protein cavin1. Accessory proteins such as Eps15 homology domain-containing 2 (EHD2) control the cell surface association of caveolae, together providing a unique invaginated membrane structure with distinct dynamics and protein and lipid compositions. These features enable caveolae to survey the plasma membrane integrity and to adjust membrane tension, and sort lipids according to the cellular requirements. Currently, characteristics of the protein and lipid interface of caveola are being unraveled, and this chapter is focused on the present knowledge of caveolae biogenesis and dynamics and describes methods that are being used to study the role of caveolae in lipid flux and lipid composition at the cell surface.},
	author = {Hubert, Madlen and Larsson, Elin and Liu, Kang-cheng and Lundmark, Richard},
	month = jan,
	year = {2023},
	doi = {10.1016/B978-0-323-89911-6.00017-0},
	pages = {219--228},
}

@book{tu_maxim_2022,
	title = {{MAXIM}: {Multi}-{Axis} {MLP} for {Image} {Processing}},
	shorttitle = {{MAXIM}},
	author = {Tu, Zhengzhong and Talebi, Hossein and Zhang, Han and Yang, Feng and Milanfar, Peyman and Bovik, Alan and Li, Yinxiao},
	month = jun,
	year = {2022},
	doi = {10.1109/CVPR52688.2022.00568},
}

@article{wenzel_er_2022,
	title = {{ER} as master regulator of membrane trafficking and organelle function},
	volume = {221},
	issn = {0021-9525},
	url = {https://doi.org/10.1083/jcb.202205135},
	doi = {10.1083/jcb.202205135},
	abstract = {The endoplasmic reticulum (ER), which occupies a large portion of the cytoplasm, is the cell’s main site for the biosynthesis of lipids and carbohydrate conjugates, and it is essential for folding, assembly, and biosynthetic transport of secreted proteins and integral membrane proteins. The discovery of abundant membrane contact sites (MCSs) between the ER and other membrane compartments has revealed that, in addition to its biosynthetic and secretory functions, the ER plays key roles in the regulation of organelle dynamics and functions. In this review, we will discuss how the ER regulates endosomes, lysosomes, autophagosomes, mitochondria, peroxisomes, and the Golgi apparatus via MCSs. Such regulation occurs via lipid and Ca2+ transfer and also via control of in trans dephosphorylation reactions and organelle motility, positioning, fusion, and fission. The diverse controls of other organelles via MCSs manifest the ER as master regulator of organelle biology.},
	number = {10},
	urldate = {2022-10-17},
	journal = {Journal of Cell Biology},
	author = {Wenzel, Eva Maria and Elfmark, Liv Anker and Stenmark, Harald and Raiborg, Camilla},
	month = sep,
	year = {2022},
	pages = {e202205135},
}

@misc{noauthor_quantitative_nodate,
	title = {Quantitative analysis of the intracellular organelle interaction using soft {X}-ray tomography {\textbar} {Request} {PDF}},
	url = {https://www.researchgate.net/publication/358556890_Quantitative_analysis_of_the_intracellular_organelle_interaction_using_soft_X-ray_tomography},
	urldate = {2022-10-12},
}

@article{zhang_vp-klnet_2022,
	title = {{VP}-{KLNet}: efficient {6D} object pose estimation with an enhanced vector-field prediction network and a keypoint localization network},
	volume = {31},
	issn = {1017-9909, 1560-229X},
	shorttitle = {{VP}-{KLNet}},
	url = {https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-31/issue-5/053026/VP-KLNet--efficient-6D-object-pose-estimation-with-an/10.1117/1.JEI.31.5.053026.full},
	doi = {10.1117/1.JEI.31.5.053026},
	abstract = {6D object pose estimation is essential for many applications with high demands in accuracy and speed. Compared with end-to-end approaches, pixel-wise voting network (PVNet), a vector-field based two-stage approach, has shown the superiority in accuracy but the inferiority in speed because of the time-consuming RANSAC-based voting strategy. To resolve this problem, we propose an efficient deep architecture that consists of an enhanced vector-field prediction network (VPNet) and a keypoint localization network (KLNet) and call it VP-KLNet. Specifically, the KLNet replaces PVNet’s time-consuming voting scheme by directly regressing 2D keypoints from the vector fields, which significantly improves the inference speed. Furthermore, to capture multiscale contextual information, we embed the pyramid pooling module between the encoder and decoder in VPNet to obtain more accurate object segmentation and vector-field prediction, with negligible speed loss. Experiments demonstrate that our method has more than 50\% improved in the running speed to the baseline method PVNet and achieves comparable accuracy with the state-of-the-art methods on the LINEMOD and occlusion LINEMOD datasets.},
	number = {5},
	urldate = {2022-10-12},
	journal = {Journal of Electronic Imaging},
	author = {Zhang, Yaoyin and Wan, Lili and Zhu, Yazhi and Xu, Wanru and Wang, Shenghui},
	month = oct,
	year = {2022},
	pages = {053026},
}

@misc{noauthor_analysis_nodate,
	title = {Analysis and {Control} of {Nonlinear} {Process} {Systems} - {PDF} {Free} {Download}},
	url = {https://epdf.pub/analysis-and-control-of-nonlinear-process-systems082b4a90df4bee9566376d35601e62018172.html},
	abstract = {Analysis and Control of Nonlinear Process SystemsK.M. Hangos J. Bokor G. SzederkényiSpringer TLFeBook Advanced Tex...},
	language = {en},
	urldate = {2022-10-12},
	journal = {epdf.pub},
}

@article{he_high-plex_2022,
	title = {High-plex imaging of {RNA} and proteins at subcellular resolution in fixed tissue by spatial molecular imaging},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/s41587-022-01483-z},
	doi = {10.1038/s41587-022-01483-z},
	abstract = {Resolving the spatial distribution of RNA and protein in tissues at subcellular resolution is a challenge in the field of spatial biology. We describe spatial molecular imaging, a system that measures RNAs and proteins in intact biological samples at subcellular resolution by performing multiple cycles of nucleic acid hybridization of fluorescent molecular barcodes. We demonstrate that spatial molecular imaging has high sensitivity (one or two copies per cell) and very low error rate (0.0092 false calls per cell) and background ({\textasciitilde}0.04 counts per cell). The imaging system generates three-dimensional, super-resolution localization of analytes at {\textasciitilde}2 million cells per sample. Cell segmentation is morphology based using antibodies, compatible with formalin-fixed, paraffin-embedded samples. We measured multiomic data (980 RNAs and 108 proteins) at subcellular resolution in formalin-fixed, paraffin-embedded tissues (nonsmall cell lung and breast cancer) and identified {\textgreater}18 distinct cell types, ten unique tumor microenvironments and 100 pairwise ligand–receptor interactions. Data on {\textgreater}800,000 single cells and {\textasciitilde}260 million transcripts can be accessed at http://nanostring.com/CosMx-dataset.},
	language = {en},
	urldate = {2022-10-12},
	journal = {Nature Biotechnology},
	author = {He, Shanshan and Bhatt, Ruchir and Brown, Carl and Brown, Emily A. and Buhr, Derek L. and Chantranuvatana, Kan and Danaher, Patrick and Dunaway, Dwayne and Garrison, Ryan G. and Geiss, Gary and Gregory, Mark T. and Hoang, Margaret L. and Khafizov, Rustem and Killingbeck, Emily E. and Kim, Dae and Kim, Tae Kyung and Kim, Youngmi and Klock, Andrew and Korukonda, Mithra and Kutchma, Alecksandr and Lewis, Zachary R. and Liang, Yan and Nelson, Jeffrey S. and Ong, Giang T. and Perillo, Evan P. and Phan, Joseph C. and Phan-Everson, Tien and Piazza, Erin and Rane, Tushar and Reitz, Zachary and Rhodes, Michael and Rosenbloom, Alyssa and Ross, David and Sato, Hiromi and Wardhani, Aster W. and Williams-Wietzikoski, Corey A. and Wu, Lidan and Beechem, Joseph M.},
	month = oct,
	year = {2022},
	keywords = {Transcriptomics},
	pages = {1--13},
}

@incollection{sanchez_what_2022,
	title = {What is {Healthy}? {Generative} {Counterfactual} {Diffusion} for {Lesion} {Localization}},
	isbn = {9783031185755},
	shorttitle = {What is {Healthy}?},
	abstract = {Reducing the requirement for densely annotated masks in medical image segmentation is important due to cost constraints. In this paper, we consider the problem of inferring pixel-level predictions of brain lesions by only using image-level labels for training. By leveraging recent advances in generative diffusion probabilistic models (DPM), we synthesize counterfactuals of “How would a patient appear if X pathology was not present?”. The difference image between the observed patient state and the healthy counterfactual can be used for inferring the location of pathology. We generate counterfactuals that correspond to the minimal change of the input such that it is transformed to healthy domain. This requires training with healthy and unhealthy data in DPMs. We improve on previous counterfactual DPMs by manipulating the generation process with implicit guidance along with attention conditioning instead of using classifiers (Code is available at https://github.com/vios-s/Diff-SCM).KeywordsGenerative modelsDiffusion probabilistic modelsCounterfactuals},
	author = {Sanchez, Pedro and Kascenas, Antanas and Liu, Xiao and O’Neil, Alison and Tsaftaris, Sotirios},
	month = oct,
	year = {2022},
	doi = {10.1007/978-3-031-18576-2_4},
	pages = {34--44},
}

@book{xu_efficient_2020,
	title = {Efficient {Neural} {Network} {Implementation} with {Quadratic} {Neuron}},
	abstract = {Previous works proved that the combination of the linear neuron network with nonlinear activation functions (e.g. ReLu) can achieve nonlinear function approximation. However, simply widening or deepening the network structure will introduce some training problems. In this work, we are aiming to build a comprehensive second-order CNN implementation framework that includes neuron/network design and system deployment optimization.},
	author = {Xu, Zirui and Xiong, Jinjun and Yu, Fuxun and Chen, Xiang},
	month = nov,
	year = {2020},
}

@article{king_volume_2022,
	title = {Volume {Segmantics}: {A} {Python} {Package} for {Semantic} {Segmentation} of {Volumetric} {Data} {Using} {Pre}-trained {PyTorch} {Deep} {Learning} {Models}},
	volume = {7},
	issn = {2475-9066},
	shorttitle = {Volume {Segmantics}},
	url = {https://joss.theoj.org/papers/10.21105/joss.04691},
	doi = {10.21105/joss.04691},
	abstract = {King et al., (2022). Volume Segmantics: A Python Package for Semantic Segmentation of Volumetric Data Using Pre-trained PyTorch Deep Learning
Models. Journal of Open Source Software, 7(78), 4691, https://doi.org/10.21105/joss.04691},
	language = {en},
	number = {78},
	urldate = {2022-10-09},
	journal = {Journal of Open Source Software},
	author = {King, Oliver N. f and Bellos, Dimitrios and Basham, Mark},
	month = oct,
	year = {2022},
	pages = {4691},
}

@article{zabeo_studying_2022,
	title = {Studying membrane modulation mechanisms by electron cryo-tomography},
	volume = {77},
	issn = {0959-440X},
	url = {https://www.sciencedirect.com/science/article/pii/S0959440X22001439},
	doi = {10.1016/j.sbi.2022.102464},
	abstract = {Membrane modulation is a key part of cellular life. Critical to processes like energy production, cell division, trafficking, migration and even pathogen entry, defects in membrane modulation are often associated with diseases. Studying the molecular mechanisms of membrane modulation is challenging due to the highly dynamic nature of the oligomeric assemblies involved, which adopt multiple conformations depending on the precise event they are participating in. With the development of electron cryo-tomography and subtomogram averaging, many of these challenges are being resolved as it is now possible to observe complex macromolecular assemblies inside a cell at nanometre to sub-nanometre resolutions. Here, we review the different ways electron cryo-tomography is being used to help uncover the molecular mechanisms used by cells to shape their membranes.},
	language = {en},
	urldate = {2022-10-09},
	journal = {Current Opinion in Structural Biology},
	author = {Zabeo, Davide and Davies, Karen M.},
	month = dec,
	year = {2022},
	pages = {102464},
}

@article{_deep_2022,
	title = {Deep {Learning}-based {Material} {Representation} and {Noniterative} {Multiscale} {Topology} {Optimization}},
	url = {https://repository.hanyang.ac.kr/handle/20.500.11754/174439},
	abstract = {For decades, topology optimization method has been actively researched and applied in various disciplines. In addition to applications in macroscopic structure design, topology optimization has been applied in material design to derive optimal microstructures. Material design via homogenization-based topology optimization has created a new design possibility for metamaterials, such as negative Poisson’s ratio. Subsequently, research has been conducted for simultaneous optimization of both macro- and microscopic structures, termed as multiscale topology optimization (MSTO), which offers the advantages of lightweight, robust, and multifunctional design. In particular, MSTO requires at least two or more variables for each material point, whereas single-scale topology optimization (SSTO) involves only a single variable. However, the increasing number of variables and homogenization equations increases the computational demand. Therefore, this thesis aims to reduce such computation burden in MSTO using emerging deep learning approaches. This study proposes a deep-learning approach for MSTO and an experimental MSTO acceleration method. 
First, a deep-learning-based MSTO method (DL-MSTO) is proposed with a material representation scheme using a generative adversarial network (GAN) and a vision transformer (ViT)-based predictor. A generator network learns the lower-dimensional representation of the microstructural manifold and provides microstructural images from the low-dimensional latent vectors. Thereafter, a ViT-based predictor is trained to predict the corresponding homogenized elasticity matrix. More specifically, the predictor network is modified based on a technique inspired by Cholesky decomposition to ensure the positive semi-definiteness. The generator and predictor networks are integrated into the MSTO process to reduce the number of variables and replace homogenization computation. 
The proposed DL-MSTO method enables a DL-based accelerating approach for the MSTO. Accordingly, a noniterative MSTO prediction method is further introduced based on implicit neural representation and graph neural networks (GNNs). A multilayer perceptron (MLP) behaves as an implicit function that maps from the spatial coordinates to the latent vector field for a given MSTO problem. In this thesis, we selected a graph to represent an MSTO problem defined in an irregular design domain. As a GNN encodes the MSTO problem into the parameters defining the MLP, the GNN-based encoder is trained to determine the optimal MLP approximator. The trained encoder and approximator predict the (near-)optimal latent vector field over the design domain without iteration. 
Comprehensively, the qualitative and quantitative evaluation using the isotropy-dominated and anisotropic microstructures datasets demonstrated the validity of the generator and predictor networks. The effectiveness and efficiency of the method were verified by comparing the benchmarks of the conventional MSTO and the proposed DL-MSTO. Furthermore, the noniterative MSTO prediction method was validated using the training dataset consisting of randomly sampled MSTO problems. Conclusively, the MSTO solution inferred from the proposed noniterative MSTO method can aid an engineer to obtain intuitive multiscale designs without solving the MSTO problem.},
	language = {ko},
	urldate = {2022-10-07},
	author = {{서민식}},
	year = {2022},
}

@article{backlund_correlations_2014,
	title = {Correlations of three-dimensional motion of chromosomal loci in yeast revealed by the double-helix point spread function microscope},
	volume = {25},
	issn = {1059-1524},
	url = {https://www.molbiolcell.org/doi/10.1091/mbc.e14-06-1127},
	doi = {10.1091/mbc.e14-06-1127},
	abstract = {Single-particle tracking has been applied to study chromatin motion in live cells, revealing a wealth of dynamical behavior of the genomic material once believed to be relatively static throughout most of the cell cycle. Here we used the dual-color three-dimensional (3D) double-helix point spread function microscope to study the correlations of movement between two fluorescently labeled gene loci on either the same or different budding yeast chromosomes. We performed fast (10 Hz) 3D tracking of the two copies of the GAL locus in diploid cells in both activating and repressive conditions. As controls, we tracked pairs of loci along the same chromosome at various separations, as well as transcriptionally orthogonal genes on different chromosomes. We found that under repressive conditions, the GAL loci exhibited significantly higher velocity cross-correlations than they did under activating conditions. This relative increase has potentially important biological implications, as it might suggest coupling via shared silencing factors or association with decoupled machinery upon activation. We also found that on the time scale studied (∼0.1–30 s), the loci moved with significantly higher subdiffusive mean square displacement exponents than previously reported, which has implications for the application of polymer theory to chromatin motion in eukaryotes.},
	number = {22},
	urldate = {2022-10-07},
	journal = {Molecular Biology of the Cell},
	author = {Backlund, Mikael P. and Joyner, Ryan and Weis, Karsten and Moerner, W. E.},
	month = nov,
	year = {2014},
	pages = {3619--3629},
}

@article{yi_madstorm_2016,
	title = {{madSTORM}: a superresolution technique for large-scale multiplexing at single-molecule accuracy},
	volume = {27},
	issn = {1059-1524},
	shorttitle = {{madSTORM}},
	url = {https://www.molbiolcell.org/doi/10.1091/mbc.e16-05-0330},
	doi = {10.1091/mbc.E16-05-0330},
	abstract = {Investigation of heterogeneous cellular structures using single-molecule localization microscopy has been limited by poorly defined localization accuracy and inadequate multiplexing capacity. Using fluorescent nanodiamonds as fiducial markers, we define and achieve localization precision required for single-molecule accuracy in dSTORM images. Coupled with this advance, our new multiplexing strategy, madSTORM, allows accurate targeting of multiple molecules using sequential binding and elution of fluorescent antibodies. madSTORM is used on an activated T-cell to localize 25 epitopes, 14 of which are on components of the same multimolecular T-cell receptor complex. We obtain an average localization precision of 2.6 nm, alignment error of 2.0 nm, and {\textless}0.01\% cross-talk. Combining these technical advances affords the ability to move beyond obtaining superresolved structures to defining spatial relationships among constituent molecules within structures. Probing the molecular topology of complex signaling cascades and other heterogeneous networks is feasible with madSTORM.},
	number = {22},
	urldate = {2022-10-07},
	journal = {Molecular Biology of the Cell},
	author = {Yi, Jason and Manna, Asit and Barr, Valarie A. and Hong, Jennifer and Neuman, Keir C. and Samelson, Lawrence E.},
	month = nov,
	year = {2016},
	pages = {3591--3600},
}

@article{huang_unsupervised_2022,
	title = {An {Unsupervised} {3D} {Image} {Registration} {Network} for {Brain} {MRI} {Deformable} {Registration}},
	volume = {2022},
	issn = {1748-670X},
	url = {https://www.hindawi.com/journals/cmmm/2022/9246378/},
	doi = {10.1155/2022/9246378},
	abstract = {In recent years, deep learning has made successful applications and remarkable achievements in the field of medical image registration, and the method of medical image registration based on deep learning has become the current research hotspot. However, the performance of convolutional neural networks may not be fully exploited due to neglect of spatial relationships between distant locations in the image and incomplete updates of network parameters. To avoid this phenomenon, MHNet, a multiscale hierarchical deformable registration network for 3D brain MR images, was proposed in this paper. This network was an unsupervised end-to-end convolutional neural network. After training, the dense displacement vector field can be predicted almost in real-time for the unseen input image pairs, which saves a lot of time compared with the traditional algorithms of independent iterative optimization for each pair of images. On the basis of the encoder-decoder structure, this network introduced the improved Inception module for multiscale feature extraction and expanding the receptive field and the hierarchical forecast structure to promote the update of the parameters of the middle layers, which achieved the best performance on the augmented public dataset compared with the existing four excellent registration methods.},
	language = {en},
	urldate = {2022-10-07},
	journal = {Computational and Mathematical Methods in Medicine},
	author = {Huang, Min and Ren, Guanyu and Zhang, Shizheng and Zheng, Qian and Niu, Huiyang},
	month = oct,
	year = {2022},
	pages = {e9246378},
}

@article{graham_detecting_2022,
	title = {Detecting molecular interactions in live-cell single-molecule imaging with proximity-assisted photoactivation ({PAPA})},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.76870},
	doi = {10.7554/eLife.76870},
	abstract = {Single-molecule imaging provides a powerful way to study biochemical processes in live cells, yet it remains challenging to track single molecules while simultaneously detecting their interactions. Here, we describe a novel property of rhodamine dyes, proximity-assisted photoactivation (PAPA), in which one fluorophore (the ‘sender’) can reactivate a second fluorophore (the ‘receiver’) from a dark state. PAPA requires proximity between the two fluorophores, yet it operates at a longer average intermolecular distance than Förster resonance energy transfer (FRET). We show that PAPA can be used in live cells both to detect protein–protein interactions and to highlight a subpopulation of labeled protein complexes in which two different labels are in proximity. In proof-of-concept experiments, PAPA detected the expected correlation between androgen receptor self-association and chromatin binding at the single-cell level. These results establish a new way in which a photophysical property of fluorophores can be harnessed to study molecular interactions in single-molecule imaging of live cells.},
	urldate = {2022-10-07},
	journal = {eLife},
	author = {Graham, Thomas GW and Ferrie, John Joseph and Dailey, Gina M and Tjian, Robert and Darzacq, Xavier},
	editor = {Xiao, Jie and Akhmanova, Anna and Gebhardt, J Christof M and Ewers, Helge},
	month = aug,
	year = {2022},
	keywords = {fluorophore photoactivation, live-cell imaging, protein–protein interactions, single-molecule fluorescence, single-particle tracking (SPT)},
	pages = {e76870},
}

@book{chung_improving_2022,
	title = {Improving {Diffusion} {Models} for {Inverse} {Problems} using {Manifold} {Constraints}},
	abstract = {Recently, diffusion models have been used to solve various inverse problems in an unsupervised manner with appropriate modifications to the sampling process. However, the current solvers, which recursively apply a reverse diffusion step followed by a measurement consistency step, often produce sub-optimal results. By studying the generative sampling path, here we show that current solvers throw the sample path off the data manifold, and hence the error accumulates. To address this, we propose an additional correction term inspired by the manifold constraint, which can be used synergistically with the previous solvers to make the iterations close to the manifold. The proposed manifold constraint is straightforward to implement within a few lines of code, yet boosts the performance by a surprisingly large margin. With extensive experiments, we show that our method is superior to the previous methods both theoretically and empirically, producing promising results in many applications such as image inpainting, colorization, and sparse-view computed tomography.},
	author = {Chung, Hyungjin and Sim, Byeongsu and Ryu, Dohoon and Ye, Jong Chul},
	month = jun,
	year = {2022},
	doi = {10.48550/arXiv.2206.00941},
}

@book{chung_diffusion_2022,
	title = {Diffusion {Posterior} {Sampling} for {General} {Noisy} {Inverse} {Problems}},
	abstract = {Diffusion models have been recently studied as powerful generative inverse problem solvers, owing to their high quality reconstructions and the ease of combining existing iterative solvers. However, most works focus on solving simple linear inverse problems in noiseless settings, which significantly under-represents the complexity of real-world problems. In this work, we extend diffusion solvers to efficiently handle general noisy (non)linear inverse problems via the Laplace approximation of the posterior sampling. Interestingly, the resulting posterior sampling scheme is a blended version of diffusion sampling with the manifold constrained gradient without a strict measurement consistency projection step, yielding a more desirable generative path in noisy settings compared to the previous studies. Our method demonstrates that diffusion models can incorporate various measurement noise statistics such as Gaussian and Poisson, and also efficiently handle noisy nonlinear inverse problems such as Fourier phase retrieval and non-uniform deblurring.},
	author = {Chung, Hyungjin and Kim, Jeongsol and Mccann, Michael and Klasky, Marc and Ye, Jong Chul},
	month = sep,
	year = {2022},
	doi = {10.48550/arXiv.2209.14687},
}

@article{wu_dipole-spread-function_2022,
	title = {Dipole-spread-function engineering for simultaneously measuring the {3D} orientations and {3D} positions of fluorescent molecules},
	volume = {9},
	copyright = {\&\#169; 2022 Optica Publishing Group},
	issn = {2334-2536},
	url = {https://opg.optica.org/optica/abstract.cfm?uri=optica-9-5-505},
	doi = {10.1364/OPTICA.451899},
	abstract = {Interactions between biomolecules are characterized by where they occur and how they are organized, e.g., the alignment of lipid molecules to form a membrane. However, spatial and angular information are mixed within the image of a fluorescent molecule–the microscope’s dipole-spread function (DSF). We demonstrate the pixOL algorithm to simultaneously optimize all pixels within a phase mask to produce an engineered Green’s tensor–the dipole extension of point-spread function engineering. The pixOL DSF achieves optimal precision to simultaneously measure the 3D orientation and 3D location of a single molecule, i.e., 4.1° orientation, 0.44 sr wobble angle, 23.2 nm lateral localization, and 19.5 nm axial localization precisions in simulations over a 700 nm depth range using 2500 detected photons. The pixOL microscope accurately and precisely resolves the 3D positions and 3D orientations of Nile red within a spherical supported lipid bilayer, resolving both membrane defects and differences in cholesterol concentration in six dimensions.},
	language = {EN},
	number = {5},
	urldate = {2022-10-04},
	journal = {Optica},
	author = {Wu, Tingting and Wu, Tingting and Lu, Jin and Lu, Jin and Lew, Matthew D. and Lew, Matthew D. and Lew, Matthew D.},
	month = may,
	year = {2022},
	pages = {505--511},
}

@article{wu_deep-smolm_2022,
	title = {Deep-{SMOLM}: deep learning resolves the {3D} orientations and {2D} positions of overlapping single molecules with optimal nanoscale resolution},
	volume = {30},
	copyright = {\&\#169; 2022 Optica Publishing Group},
	issn = {1094-4087},
	shorttitle = {Deep-{SMOLM}},
	url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-30-20-36761},
	doi = {10.1364/OE.470146},
	abstract = {Dipole-spread function (DSF) engineering reshapes the images of a microscope to maximize the sensitivity of measuring the 3D orientations of dipole-like emitters. However, severe Poisson shot noise, overlapping images, and simultaneously fitting high-dimensional information\&\#x2013;both orientation and position\&\#x2013;greatly complicates image analysis in single-molecule orientation-localization microscopy (SMOLM). Here, we report a deep-learning based estimator, termed Deep-SMOLM, that achieves superior 3D orientation and 2D position measurement precision within 3\&\#x0025; of the theoretical limit (3.8\&\#x00B0; orientation, 0.32 sr wobble angle, and 8.5 nm lateral position using 1000 detected photons). Deep-SMOLM also demonstrates state-of-art estimation performance on overlapping images of emitters, e.g., a 0.95 Jaccard index for emitters separated by 139 nm, corresponding to a 43\&\#x0025; image overlap. Deep-SMOLM accurately and precisely reconstructs 5D information of both simulated biological fibers and experimental amyloid fibrils from images containing highly overlapped DSFs at a speed {\textasciitilde}10 times faster than iterative estimators.},
	language = {EN},
	number = {20},
	urldate = {2022-10-04},
	journal = {Optics Express},
	author = {Wu, Tingting and Wu, Tingting and Lu, Peng and Lu, Peng and Lu, Peng and Rahman, Md Ashequr and Rahman, Md Ashequr and Rahman, Md Ashequr and Li, Xiao and Li, Xiao and Lew, Matthew D. and Lew, Matthew D. and Lew, Matthew D.},
	month = sep,
	year = {2022},
	pages = {36761--36773},
}

@article{eordogh_long-term_nodate,
	title = {Long-{Term}, {Single}-{Molecule} {Imaging} of {Proteins} in {Live} {Cells} with {Photoregulated} {Fluxional} {Fluorophores}},
	volume = {n/a},
	issn = {1521-3765},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/chem.202202832},
	doi = {10.1002/chem.202202832},
	abstract = {Single-molecule localization microscopy (SMLM) can reveal nanometric details of biological samples, but its high phototoxicity hampers long-term imaging in live specimens. A significant part of this phototoxicity stems from repeated irradiations that are necessary for controlled switching of fluorophores to maintain the sparse labeling of the sample. Lower phototoxicity can be obtained using fluorophores that blink spontaneously, but controlling the density of single-molecule emitters is challenging. We recently developed photoregulated fluxional fluorophores (PFFs) that combine the benefits of spontaneously blinking dyes with photocontrol of emitter density. These dyes, however, were limited to imaging acidic organelles in live cells. Here, we report a systematic study of PFFs that culminates in probes that are functional at physiological pH and operate at longer wavelengths than their predecessors. Moreover, these probes are compatible with HaloTag labeling, thus enabling timelapse, single-molecule imaging of specific protein targets for exceptionally long times.},
	language = {en},
	number = {n/a},
	urldate = {2022-10-04},
	journal = {Chemistry – A European Journal},
	author = {Eördögh, Ádám and Martin, Annabell and Rivera-Fuentes, Pablo},
	keywords = {HaloTag, Live-cell imaging, Super-resolution microscopy, fluorescent probes, photophysics},
}

@misc{noauthor_ben_depth_nodate,
	title = {Ben\_Depth},
	url = {https://www.overleaf.com/project/633c5b21dcf4131f18fb56b6},
	abstract = {An online LaTeX editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2022-10-04},
}

@article{ogata_fasting-related_2010,
	title = {Fasting-related autophagic response in slow- and fast-twitch skeletal muscle},
	volume = {394},
	issn = {0006-291X},
	url = {https://www.sciencedirect.com/science/article/pii/S0006291X10003645},
	doi = {10.1016/j.bbrc.2010.02.130},
	abstract = {This study investigated regulation of autophagy in slow-twitch soleus and fast-twitch plantaris muscles in fasting-related atrophy. Male Fischer-344 rats were subjected to fasting for 1, 2, or 3days. Greater weight loss was observed in plantaris muscle than in soleus muscle in response to fasting. Western blot analysis demonstrated that LC3-II, a marker protein for macroautophagy, was expressed at a notably higher level in plantaris than in soleus muscle, and that the expression level was fasting duration-dependent. To identify factors related to LC3-II enhancement, autophagy-related signals were examined in both types of muscle. Phosphorylated mTOR was reduced in plantaris but not in soleus muscle. FOXO3a and ER stress signals were unchanged in both muscle types during fasting. These findings suggest that preferential atrophy of fast-twitch muscle is associated with induction of autophagy during fasting and that differences in autophagy regulation are attributable to differential signal regulation in soleus and plantaris muscle.},
	language = {en},
	number = {1},
	urldate = {2022-09-30},
	journal = {Biochemical and Biophysical Research Communications},
	author = {Ogata, Tomonori and Oishi, Yasuharu and Higuchi, Mitsuru and Muraoka, Isao},
	month = mar,
	year = {2010},
	keywords = {Autophagy, LC3, Skeletal muscle, mTOR, p62},
	pages = {136--140},
}

@article{ha_unraveling_2021,
	title = {Unraveling hidden interactions in complex systems with deep learning},
	volume = {11},
	copyright = {2021 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-91878-w},
	doi = {10.1038/s41598-021-91878-w},
	abstract = {Rich phenomena from complex systems have long intrigued researchers, and yet modeling system micro-dynamics and inferring the forms of interaction remain challenging for conventional data-driven approaches, being generally established by scientists with human ingenuity. In this study, we propose AgentNet, a model-free data-driven framework consisting of deep neural networks to reveal and analyze the hidden interactions in complex systems from observed data alone. AgentNet utilizes a graph attention network with novel variable-wise attention to model the interaction between individual agents, and employs various encoders and decoders that can be selectively applied to any desired system. Our model successfully captured a wide variety of simulated complex systems, namely cellular automata (discrete), the Vicsek model (continuous), and active Ornstein–Uhlenbeck particles (non-Markovian) in which, notably, AgentNet’s visualized attention values coincided with the true variable-wise interaction strengths and exhibited collective behavior that was absent in the training data. A demonstration with empirical data from a flock of birds showed that AgentNet could identify hidden interaction ranges exhibited by real birds, which cannot be detected by conventional velocity correlation analysis. We expect our framework to open a novel path to investigating complex systems and to provide insight into general process-driven modeling.},
	language = {en},
	number = {1},
	urldate = {2022-09-29},
	journal = {Scientific Reports},
	author = {Ha, Seungwoong and Jeong, Hawoong},
	month = jun,
	year = {2021},
	pages = {1--13},
}

@misc{noauthor_unraveling_nodate,
	title = {Unraveling hidden interactions in complex systems with deep learning {\textbar} {Scientific} {Reports}},
	url = {https://www.nature.com/articles/s41598-021-91878-w},
	urldate = {2022-09-29},
}

@misc{noauthor_towards_nodate,
	title = {Towards optimal point spread function design for resolving closely spaced emitters in three dimensions},
	url = {https://opg.optica.org/oe/fulltext.cfm?uri=oe-30-20-37154&id=506531},
	urldate = {2022-09-27},
}

@article{kazemi_comparison_2022,
	title = {Comparison of dietary and physical activity behaviors in women with and without polycystic ovary syndrome: a systematic review and meta-analysis of 39 471 women},
	shorttitle = {Comparison of dietary and physical activity behaviors in women with and without polycystic ovary syndrome},
	doi = {10.1093/humupd/dmac023},
	abstract = {BACKGROUND
Lifestyle (dietary and/or physical activity [PA]) modification is recommended as first-line therapy to manage polycystic ovary syndrome (PCOS). Current recommendations are based on healthy lifestyle practices for the general public since evidence for unique lifestyle approaches in PCOS is limited and low quality.

OBJECTIVE AND RATIONALE
We aimed to synthesize evidence on dietary and PA behaviors between women with PCOS and those without PCOS. Primary outcomes were overall diet quality, total energy intake and total PA, and secondary outcomes included macronutrients, micronutrients, food groups, foods, glycemic indices, sedentary time and sitting levels. We conducted this work to identify any unique lifestyle behaviors in women with PCOS that could underlie the propensity of weight gain and obesity in PCOS and be targeted for precision nutrition and PA interventions. These findings could be used to inform future practice recommendations and research that more effectively address complications (weight gain, obesity, diabetes, infertility, cardiovascular disease and mental health) in this high-risk population.

SEARCH METHODS
Databases of MEDLINE, Web of Science, Scopus and CINAHL were searched until 15 February 2022 to identify observational studies documenting dietary and PA behaviors between women with PCOS and without PCOS (Controls). Studies on children, adolescents ({\textless}18 years), pregnant or menopausal-aged women ({\textgreater}50 years) were excluded. Data were pooled by random-effects models and expressed as (standardized) mean differences (MD) and 95\% CIs. The risk of bias was assessed by the Newcastle-Ottawa scale (NOS).

OUTCOMES
Fifty-four studies (N = 39 471 participants; [n = 8736 PCOS; 30 735 Controls]) were eligible (96\%; [52/54] NOS scores ≥ 7). Women with PCOS had higher cholesterol (MD: 12.78, 95\% CI: 1.48 to 24.08 mg/day; P = 0.03; I2 = 19\%), lower magnesium (MD: −21.46, 95\% CI: −41.03 to −1.91 mg/day; P = 0.03; I2 = 76\%), and a tendency for lower zinc (MD: −1.08, 95\% CI: −2.19 to −0.03 mg/day; P = 0.05; I2 = 96\%) intake, despite lower alcohol consumption (MD: −0.95, 95\% CI: −1.67 to 0.22 g/day; P = 0.02; I2 = 0\%) versus Controls. Also, women with PCOS had lower total PA (standardized mean difference: −0.38, 95\% CI: −0.72 to 0.03; P = 0.03; I2 = 98\%). Conversely, energy, macronutrients (carbohydrate, fat, protein, fiber), micronutrients (folic acid, iron, calcium, sodium), glycemic index and glycemic load were similar (all: P ≥ 0.06). Most eligible studies reported lower total adherence to healthy eating patterns or poorer consumption of major food groups (grains, fruits, vegetables, proteins, seeds, nuts, dairy) in women with PCOS, as described narratively since variable study methodology did not permit meta-analyses.

WIDER IMPLICATIONS
Collective evidence supports that women with PCOS have a lower overall diet quality, poorer dietary intakes (higher cholesterol, lower magnesium and zinc) and lower total PA, despite lower alcohol consumption versus those without PCOS. Considerable heterogeneity among studies reinforces the need for research to address any relative contributions of other factors (e.g. genetic, metabolic or sociodemographic) to the observed differences. These clarifications may contribute to future evidence-based guideline recommendations on monitoring and managing PCOS in the era of precision lifestyle medicine.},
	journal = {Human Reproduction Update},
	author = {Kazemi, Maryam and Kim, Joy and Wan, Cynthia and Xiong, Julia and Michalak, Julia and Xavier, Isabella and Ganga, Kiran and Tay, Chau and Grieger, Jessica and Parry, Stephen and Moran, Lisa and Lujan, Marla},
	month = may,
	year = {2022},
}

@incollection{whillier_exercise_2020,
	title = {Exercise and {Insulin} {Resistance}},
	volume = {1228},
	isbn = {9789811517914},
	abstract = {In insulin resistance, alterations occur in the signalling pathways that modulate glucose uptake into cells, especially skeletal muscle cells, resulting in impaired glucose homeostasis. Glucose uptake into cells is controlled by a number of pathways, some of which are insulin-dependent. During exercise glucose uptake can occur independently of insulin regulation, and hence research into the effects of exercise on insulin resistance must be clearly defined to reflect whether glucose uptake has been enhanced as a result of the utilisation of these insulin-independent pathways, or whether exercise directly affects insulin resistance in cells. Research into the benefits of exercise for insulin resistance is also problematic in the need to clarify whether it is the exercise itself, or the visceral fat/weight loss that has resulted from the exercise, that has led to improved insulin sensitivity. The research presents a promising picture for the benefits of exercise in insulin resistance.},
	booktitle = {Advances in experimental medicine and biology},
	author = {Whillier, Stephney},
	month = apr,
	year = {2020},
	doi = {10.1007/978-981-15-1792-1_9},
	pages = {137--150},
}

@article{suvarna_comparison_2016,
	title = {Comparison of efficacy of metformin and oral contraceptive combination of ethinyl estradiol and drospirenone in polycystic ovary syndrome},
	volume = {17},
	doi = {10.5152/jtgga.2016.16129},
	abstract = {Objective: 
The 2013 Endocrine Society guidelines state that hormonal contraceptives should be used for treating both menstrual irregularity and hirsutism in patients with polycystic ovary syndrome (PCOS). Metformin should be reserved for the treatment of women presenting with only menstrual irregularity because it has limited benefits in treating hyperandrogenism associated with PCOS. A high prevalence of insulin resistance is noted among the South Asians, and these guidelines may not hold good for this population. Thus, this study was conducted to investigate and compare the effects of metformin and an oral contraceptive containing drospirenone on menstrual pattern, body mass index, serum testosterone levels, and dehydroepiandrosterone sulfate (DHEAS) levels at baseline to 6 months of therapy in the treatment groups.

Material and methods:
This was a prospective observational study that was conducted over a year in patients visiting the Endocrinology outpatient department at a tertiary care center in a south Indian city. Forty-six subjects diagnosed with PCOS as per the Rotterdam criteria were included. They received either metformin twice daily or an oral contraceptive containing drospirenone once daily as a monthly regimen for 6 months.

Results:
Metformin regularized menstrual cycles in 72\% of patients who were followed up at 6 months. No significant difference was observed between the two treatment groups with respect to decreasing the body mass index, serum testosterone levels, and DHEAS levels (p=0.40, p=0.65, and p=0.22, respectively).

Conclusion:
Metformin is effective in regularizing menstrual cycles, decreasing body mass index, and treating hyperandrogenism in Indian women diagnosed with PCOS.},
	journal = {Journal of the Turkish German Gynecological Association},
	author = {Suvarna, Yashasvi and Maity, Nivedita and Kalra, Pramila and Shivamurthy, M},
	month = mar,
	year = {2016},
	pages = {6--9},
}

@article{hiltunen_combined_2009,
	title = {A combined reconstruction–classification method for diffuse optical tomography},
	volume = {54},
	doi = {10.1088/0031-9155/54/21/002},
	abstract = {We present a combined classification and reconstruction algorithm for diffuse optical tomography (DOT). DOT is a nonlinear ill-posed inverse problem. Therefore, some regularization is needed. We present a mixture of Gaussians prior, which regularizes the DOT reconstruction step. During each iteration, the parameters of a mixture model are estimated. These associate each reconstructed pixel with one of several classes based on the current estimate of the optical parameters. This classification is exploited to form a new prior distribution to regularize the reconstruction step and update the optical parameters. The algorithm can be described as an iteration between an optimization scheme with zeroth-order variable mean and variance Tikhonov regularization and an expectation-maximization scheme for estimation of the model parameters. We describe the algorithm in a general Bayesian framework. Results from simulated test cases and phantom measurements show that the algorithm enhances the contrast of the reconstructed images with good spatial accuracy. The probabilistic classifications of each image contain only a few misclassified pixels.},
	journal = {Physics in medicine and biology},
	author = {Hiltunen, Petri and Prince, Simon and Arridge, S},
	month = oct,
	year = {2009},
	pages = {6457--76},
}

@book{manninen_sparsity_2022,
	title = {Sparsity promoting reconstructions via hierarchical prior models in diffuse optical tomography},
	abstract = {Diffuse optical tomography (DOT) is a severely ill-posed nonlinear inverse problem that seeks to estimate optical parameters from boundary measurements. In the Bayesian framework, the ill-posedness is diminished by incorporating a priori information of the optical parameters via the prior distribution. In case the target is sparse or sharp-edged, the common choice as the prior model are non-differentiable total variation and ℓ 1 priors. Alternatively, one can hierarchically extend the variances of a Gaussian prior to obtain differentiable sparsity promoting priors. By doing this, the variances are treated as unknowns allowing the estimation to locate the discontinu-ities. In this work, we formulate hierarchical prior models for the nonlinear DOT inverse problem using exponential, standard gamma and inverse-gamma hyperpriors. Depending on the hyperprior and the hyperparameters, the hierarchical models promote different levels of sparsity and smoothness. To compute the MAP estimates, the previously proposed alternating algorithm is adapted to work with the nonlinear model. We then propose an approach based on the cumulative distribution function of the hyperpriors to select the hyperparameters. We evaluate the performance of the hyperpriors with numerical simulations and show that the hierarchical models can improve the localization, contrast and edge sharpness of the reconstructions.},
	author = {Manninen, Anssi and Mozumder, Meghdoot and Tarvainen, Tanja and Hauptmann, Andreas},
	month = sep,
	year = {2022},
	doi = {10.48550/arXiv.2209.09981},
}

@misc{noauthor_endoplasmic_nodate,
	title = {The endoplasmic reticulum adopts two distinct tubule forms},
	url = {https://www.pnas.org/doi/10.1073/pnas.2117559119},
	language = {en},
	urldate = {2022-09-21},
	doi = {10.1073/pnas.2117559119},
}

@article{gubas_er_2022,
	title = {{ER} remodeling via {ER}-phagy},
	volume = {82},
	doi = {10.1016/j.molcel.2022.02.018},
	abstract = {The endoplasmic reticulum (ER) is a hotspot for many essential cellular functions. The ER membrane is highly dynamic, which affects many cellular processes that take place within the ER. One such process is ER-phagy, a selective degradation of ER fragments (including membranes and luminal content), which serves to preserve the size of ER while adapting its morphology under basal and stress conditions. In order to be degraded, the ER undergoes selective fragmentation facilitated by specialized ER-shaping proteins that also act as ER-phagy receptors. Their ability to sense and induce membrane curvature, as well as to bridge the ER with autophagy machinery, allows for a successful ER fragmentation and delivery of these fragments to the lysosome for degradation and recycling. In this review, we provide insights into ER-phagy from the perspective of membrane remodeling. We highlight the importance of ER membrane dynamics during ER-phagy and emphasize how its dysregulation reflects on human physiology and pathology.},
	journal = {Molecular Cell},
	author = {Gubas, Andrea and Dikic, Ivan},
	month = apr,
	year = {2022},
	pages = {1492--1500},
}

@article{mochida_er_2022,
	title = {{ER} ‐phagy: selective autophagy of the endoplasmic reticulum},
	volume = {23},
	shorttitle = {{ER} ‐phagy},
	doi = {10.15252/embr.202255192},
	abstract = {Eukaryotic cells adequately control the mass and functions of organelles in various situations. Autophagy, an intracellular degradation system, largely contributes to this organelle control by degrading the excess or defective portions of organelles. The endoplasmic reticulum (ER) is an organelle with distinct structural domains associated with specific functions. The ER dynamically changes its mass, components, and shape in response to metabolic, developmental, or proteotoxic cues to maintain or regulate its functions. Therefore, elaborate mechanisms are required for proper degradation of the ER. Here, we review our current knowledge on diverse mechanisms underlying selective autophagy of the ER, which enable efficient degradation of specific ER subdomains according to different demands of cells.},
	journal = {EMBO reports},
	author = {Mochida, Keisuke and Nakatogawa, Hitoshi},
	month = jun,
	year = {2022},
}

@article{jaderberg_quantum_2022,
	title = {Quantum {Self}-{Supervised} {Learning}},
	volume = {7},
	doi = {10.1088/2058-9565/ac6825},
	abstract = {The resurgence of self-supervised learning, whereby a deep learning model generates its own supervisory signal from the data, promises a scalable way to tackle the dramatically increasing size of real-world data sets without human annotation. However, the staggering computational complexity of these methods is such that for state-of-the-art performance, classical hardware requirements represent a signiﬁcant bottleneck to further progress. Here we take the ﬁrst steps to understanding whether quantum neural networks could meet the demand for more powerful architectures and test its eﬀectiveness in proof-of-principle hybrid experiments. Interestingly, we observe a numerical advantage for the learning of visual representations using small-scale quantum neural networks over equivalently structured classical networks, even when the quantum circuits are sampled with only 100 shots. Furthermore, we apply our best quantum model to classify unseen images on the ibmq\_paris quantum computer and find that current noisy devices can already achieve equal accuracy to the equivalent classical model on downstream tasks.},
	journal = {Quantum Science and Technology},
	author = {Jaderberg, Ben and Anderson, Lewis and Xie, Weidi and Albanie, Samuel and Kiffner, Martin and Jaksch, Dieter},
	month = apr,
	year = {2022},
}

@book{feremans_pre-print_2022,
	title = {({Pre}-print) {Pattern}-{Based} {Anomaly} {Detection} in a {Network} of {Multivariate} {Time} {Series}},
	abstract = {Recent technological developments make it commonplace to have a complex system of entities such as servers or industrial devices in a network. In this context, detecting abnormal periods of operation in sensors, entities or communication has become a crucial data mining task. State-of-the-art methods based on unsupervised deep-learning methods are accurate but at the cost of significant training time and comprehension as patterns of common behaviour and relations between sensors are obscured in the multi-layer neural network. Our goal is to provide an efficient and interpretable model where patterns of common behaviour and intra-and inter-device relationships are explicit for the end-user. We capture the normal behaviour of time series using frequent and cohesive sequential patterns that compress the data best using minimum description length. For computing anomalies, we construct a pattern-based embedding of time series of different types and use an isolation forest to make predictions. Finally, we propose a method to discover similar time series based on density-based fingerprints and histograms that scale to large collections of time series. We study the properties of our method through experiments on public datasets, as well as on proprietary data provided by a telecom company, thus demonstrating its speed, scalability, interpretability and high anomaly detection performance compared to state-of-the-art methods.},
	author = {Feremans, Len and Cule, Boris and Goethals, Bart},
	month = sep,
	year = {2022},
}

@article{liu_deepcontact_2022,
	title = {{DeepContact}: {High}-throughput quantification of membrane contact sites based on electron microscopy imaging},
	volume = {221},
	shorttitle = {{DeepContact}},
	doi = {10.1083/jcb.202106190},
	abstract = {Membrane contact site (MCS)-mediated organelle interactions play essential roles in the cell. Quantitative analysis of MCSs reveals vital clues for cellular responses under various physiological and pathological conditions. However, an efficient tool is lacking. Here, we developed DeepContact, a deep-learning protocol for optimizing organelle segmentation and contact analysis based on label-free EM. DeepContact presents high efficiency and flexibility in interactive visualizations, accommodating new morphologies of organelles and recognizing contacts in versatile width ranges, which enables statistical analysis of various types of MCSs in multiple systems. DeepContact profiled previously unidentified coordinative rearrangements of MCS types in cultured cells with combined nutritional conditions. DeepContact also unveiled a subtle wave of ER–mitochondrial entanglement in Sertoli cells during the seminiferous epithelial cycle, indicating its potential in bridging MCS dynamics to physiological and pathological processes.},
	journal = {Journal of Cell Biology},
	author = {Liu, Liqing and Yang, Shuxin and Liu, Yang and Li, Xixia and Hu, Junjie and Xiao, Li and Xu, Tao},
	month = aug,
	year = {2022},
}

@article{giamogante_stable_2022,
	title = {Stable {Integration} of {Inducible} {SPLICS} {Reporters} {Enables} {Spatio}-{Temporal} {Analysis} of {Multiple} {Organelle} {Contact} {Sites} upon {Modulation} of {Cholesterol} {Traffic}},
	volume = {11},
	doi = {10.3390/cells11101643},
	abstract = {The study of organelle contact sites has received a great impulse due to increased interest in the understanding of their involvement in many disease conditions. Split-GFP-based contact sites (SPLICS) reporters emerged as essential tools to easily detect changes in a wide range of organelle contact sites in cultured cells and in vivo, e.g., in zebrafish larvae. We report here on the generation of a new vector library of SPLICS cloned into a piggyBac system for stable and inducible expression of the reporters in a cell line of interest to overcome any potential weakness due to variable protein expression in transient transfection studies. Stable HeLa cell lines expressing SPLICS between the endoplasmic reticulum (ER) and mitochondria (MT), the ER and plasma membrane (PM), peroxisomes (PO) and ER, and PO and MT, were generated and tested for their ability to express the reporters upon treatment with doxycycline. Moreover, to take advantage of these cellular models, we decided to follow the behavior of different membrane contact sites upon modulating cholesterol traffic. Interestingly, we found that the acute pharmacological inhibition of the intracellular cholesterol transporter 1 (NPC1) differently affects membrane contact sites, highlighting the importance of different interfaces for cholesterol sensing and distribution within the cell.},
	journal = {Cells},
	author = {Giamogante, Flavia and Barazzuol, Lucia and Poggio, Elena and Tromboni, Marta and Brini, Marisa and Calì, Tito},
	month = may,
	year = {2022},
	pages = {1643},
}

@article{li_graph_2022,
	title = {Graph {Signal} {Compression} by {Joint} {Quantization} and {Sampling}},
	volume = {PP},
	doi = {10.1109/TSP.2022.3205474},
	abstract = {Graph signals arise in various applications, ranging from sensor networks to social media data. The high-dimensional nature of these signals implies that they often need to be compressed in order to be stored and transmitted. The common framework for graph signal compression is based on sampling, resulting in a set of continuous-amplitude samples, which in turn have to be quantized into a finite bit representation. In this work, we study the joint design of graph signal sampling along with quantization, for graph signal compression. We focus on bandlimited graph signals, and show that the compression problem can be represented as a task-based quantization setup, in which the task is to recover the spectrum of the signal. Based on this equivalence, we propose a joint design of the sampling and recovery mechanisms for a fixed quantization mapping, and present an iterative algorithm for dividing the available bit budget among the discretized samples. Furthermore, we show how the proposed approach can be realized using graph filters combining elements corresponding the neighbouring nodes of the graph, thus facilitating distributed implementation at reduced complexity. Our numerical evaluations on both synthetic and real world data shows that the joint sampling and quantization method yields a compact finite bit representation of high-dimensional graph signals, which allows reconstruction of the original signal with accuracy within a small gap of that achievable with infinite resolution quantizers.},
	journal = {IEEE Transactions on Signal Processing},
	author = {Li, Pei and Shlezinger, Nir and Zhang, Haiyang and Wang, Baoyun and Eldar, Yonina},
	month = jan,
	year = {2022},
	pages = {1--15},
}

@article{alsnayyan_manifold_2022,
	title = {Manifold {Harmonics} and {Their} {Application} to {Computational} {Electromagnetics}},
	issn = {2379-8793},
	doi = {10.1109/JMMCT.2022.3199612},
	abstract = {The eigenfunctions of the Laplace-Beltrami operator (LBO), or manifold harmonic basis (MHB), have many applications in mathematical physics, differential geometry, machine learning, and topological data analysis. MHB allows us to associate a frequency spectrum to a function on a manifold, analogous to the Fourier decomposition. This insight can be used to build a framework for analysis. The purpose of this paper is to review and illustrate such possibilities for computational electromagnetics as well as chart a potential path forward. To this end, we introduce three features of MHB: (a) enrichment for analysis of multiply connected domains, (b) local enrichment (L-MHB) and (c) hierarchical MHB (H-MHB) for reuse of data from coarser to fine geometry discretizations. Several results highlighting the efficacy of these methods are presented.},
	journal = {IEEE Journal on Multiscale and Multiphysics Computational Techniques},
	author = {Alsnayyan, A. M. A. and Kempel, L. and Shanker, B.},
	year = {2022},
	keywords = {Faces, Harmonic analysis, Integral equations, Laplace-Beltrami operators, Localization, Manifold harmonics, Manifolds, Multi-resolution, Shape, Surface impedance, Topology},
	pages = {1--10},
}

@article{ouyang_self-supervised_2022,
	title = {Self-supervised learning of neighborhood embedding for longitudinal {MRI}},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841522002122},
	doi = {10.1016/j.media.2022.102571},
	abstract = {In recent years, several deep learning models recommend first to represent Magnetic Resonance Imaging (MRI) as latent features before performing a downstream task of interest (such as classification or regression). The performance of the downstream task generally improves when these latent representations are explicitly associated with factors of interest. For example, we derived such a representation for capturing brain aging by applying self-supervised learning to longitudinal MRIs and then used the resulting encoding to automatically identify diseases accelerating the aging of the brain. We now propose a refinement of this representation by replacing the linear modeling of brain aging with one that is consistent in local neighborhoods in the latent space. Called Longitudinal Neighborhood Embedding (LNE), we derive an encoding so that neighborhoods are age-consistent (i.e., brain MRIs of different subjects with similar brain ages are in close proximity of each other) and progression-consistent, i.e., the latent space is defined by a smooth trajectory field where each trajectory captures changes in brain ages between a pair of MRIs extracted from a longitudinal sequence. To make the problem computationally tractable, we further propose a strategy for mini-batch sampling so that the resulting local neighborhoods accurately approximate the ones that would be defined based on the whole cohort. We evaluate LNE on three different downstream tasks: (1) to predict chronological age from T1-w MRI of 274 healthy subjects participating in a study at SRI International; (2) to distinguish Normal Control (NC) from Alzheimer’s Disease (AD) and stable Mild Cognitive Impairment (sMCI) from progressive Mild Cognitive Impairment (pMCI) based on T1-w MRI of 632 participants of the Alzheimer’s Disease Neuroimaging Initiative (ADNI); and (3) to distinguish no-to-low from moderate-to-heavy alcohol drinkers based on fractional anisotropy derived from diffusion tensor MRIs of 764 adolescents recruited by the National Consortium on Alcohol and NeuroDevelopment in Adolescence (NCANDA). Across the three data sets, the visualization of the smooth trajectory vector fields and superior accuracy on downstream tasks demonstrate the strength of the proposed method over existing self-supervised methods in extracting information related to brain aging, which could help study the impact of substance use and neurodegenerative disorders. The code is available at https://github.com/ouyangjiahong/longitudinal-neighbourhood-embedding.},
	language = {en},
	urldate = {2022-09-11},
	journal = {Medical Image Analysis},
	author = {Ouyang, Jiahong and Zhao, Qingyu and Adeli, Ehsan and Zaharchuk, Greg and Pohl, Kilian M.},
	month = aug,
	year = {2022},
	keywords = {Classification, Contrastive learning, Longitudinal brain MRI, Self-supervised learning},
	pages = {102571},
}

@article{greenberg_what_2022,
	title = {What {Collapsed} in 1177?},
	volume = {10},
	issn = {2166-3556},
	url = {https://muse.jhu.edu/article/855782},
	number = {2},
	urldate = {2022-09-10},
	journal = {Journal of Eastern Mediterranean Archaeology and Heritage Studies},
	author = {Greenberg, Raphael},
	year = {2022},
	pages = {191--193},
}

@article{alexiou_dietary_2022,
	title = {Dietary {Alterations} in {Impaired} {Mitochondrial} {Dynamics} {Due} to {Neurodegeneration}},
	volume = {14},
	doi = {10.3389/fnagi.2022.893018},
	abstract = {Alzheimer's disease is still an incurable disease with significant social and economic impact globally. Nevertheless, newly FDA-approved drugs and non-pharmacological techniques may offer efficient disease treatments. Furthermore, it is widely accepted that early diagnosis or even prognosis of Alzheimer's disease using advanced computational tools could offer a compelling alternative way of management. In addition, several studies have presented an insight into the role of mitochondrial dynamics in Alzheimer's development. In combination with diverse dietary and obesity-related diseases, mitochondrial bioenergetics may be linked to neurodegeneration. Considering the probabilistic expectations of Alzheimer's disease development or progression due to specific risk factors or biomarkers, we designed a Bayesian model to formulate the impact of diet-induced obesity with an impaired mitochondrial function and altered behavior. The applied probabilities are based on clinical trials globally and are continuously subject to updating and redefinition. The proposed multiparametric model combines various data types based on uniform probabilities. The program simulates all the variables with a uniform distribution in a sample of 1000 patients. First, the program initializes the variable age (30-95) and the four different diet types ('HFO\_diet', 'Starvation', 'HL\_diet', 'CR') along with the factors that are related to prodromal or mixed AD (ATP, MFN1, MFN2, DRP1, FIS1, Diabetes, Oxidative\_Stress, Hypertension, Obesity, Depression, and Physical\_activity). Besides the known proteins related to mitochondrial dynamics, our model includes risk factors like Age, Hypertension, Oxidative Stress, Obesity, Depression, and Physical Activity, which are associated with Prodromal Alzheimer's. The outcome is the disease progression probability corresponding to a random individual ID related to diet choices and mitochondrial dynamics parameters. The proposed model and the programming code are adjustable to different parameters and values. The program is coded and executed in Python and is fully and freely available for research purposes and testing the correlation between diet type and AD progression regarding various risk factors and biomarkers.},
	journal = {Frontiers in Aging Neuroscience},
	author = {Alexiou, Athanasios and Ashraf, Ghulam and Chatzichronis, Stylianos and Kamal, Mohammad and Ganash, Magdah and Firdousi, Gazala},
	month = jun,
	year = {2022},
}

@article{li_control_2014,
	title = {Control of obesity and glucose intolerance via building neural stem cells in the hypothalamus☆},
	volume = {3},
	doi = {10.1016/j.molmet.2014.01.012},
	abstract = {Neural stem cells (NSCs) were recently revealed to exist in the hypothalamus of adult mice. Here, following our observation showing that a partial loss of hypothalamic NSCs caused weight gain and glucose intolerance, we studied if NSCs-based cell therapy could be developed to control these disorders. While hypothalamus-implanted NSCs failed to survive in mice with obesity, NF-κB inhibition induced survival and neurogenesis of these cells, leading to effects in counteracting obesity and glucose intolerance. To generate an alternative cell source, we revealed that iPS-derived NSCs were converted into htNSCs by neuropeptide treatment. Of note, obesity condition potentiated the transfer of carotid artery-injected NSCs into the hypothalamus. These iPS-derived cells when engineered with NF-κB inhibition were also effective in reducing obesity and glucose intolerance, and neurogenesis towards POMCergic and GABAergic lineages was accountable. In conclusion, building NSCs in the hypothalamus represents a strategy for controlling obesity and glucose disorders.},
	journal = {Molecular metabolism},
	author = {li, Juxue and Tang, Yizhe and Purkayastha, Sudarshana and Yan, Jingqi and Cai, Dongsheng},
	month = jun,
	year = {2014},
	pages = {313--24},
}

@article{maimaris_regulation_2021,
	title = {Regulation of {ER} {Composition} and {Extent}, and {Putative} {Action} in {Protein} {Networks} by {ER}/{NE} {Protein} {TMEM147}},
	volume = {22},
	doi = {10.3390/ijms221910231},
	abstract = {Nuclear envelope (NE) and endoplasmic reticulum (ER) collaborate to control a multitude of nuclear and cytoplasmic actions. In this context, the transmembrane protein TMEM147 localizes to both NE and ER, and through direct and indirect interactions regulates processes as varied as production and transport of multipass membrane proteins, neuronal signaling, nuclear-shape, lamina and chromatin dynamics and cholesterol synthesis. Aiming to delineate the emerging multifunctionality of TMEM147 more comprehensively, we set as objectives, first, to assess potentially more fundamental effects of TMEM147 on the ER and, second, to identify significantly TMEM147-associated cell-wide protein networks and pathways. Quantifying curved and flat ER markers RTN4 and CLIMP63/CKAP4, respectively, we found that TMEM147 silencing causes area and intensity increases for both RTN4 and CLIMP63, and the ER in general, with a profound shift toward flat areas, concurrent with reduction in DNA condensation. Protein network and pathway analyses based on comprehensive compilation of TMEM147 interactors, targets and co-factors then served to manifest novel and established roles for TMEM147. Thus, algorithmically simplified significant pathways reflect TMEM147 function in ribosome binding, oxidoreductase activity, G protein-coupled receptor activity and transmembrane transport, while analysis of protein factors and networks identifies hub proteins and corresponding pathways as potential targets of TMEM147 action and of future functional studies.},
	journal = {International Journal of Molecular Sciences},
	author = {Maimaris, Giannis and Christodoulou, Andri and Santama, Niovi and Lederer, Carsten},
	month = sep,
	year = {2021},
	pages = {10231},
}

@incollection{amari_information_1997,
	address = {Boston, MA},
	series = {Operations {Research}/{Computer} {Science} {Interfaces} {Series}},
	title = {Information {Geometry} of {Neural} {Networks} — {An} {Overview} —},
	isbn = {9781461560999},
	url = {https://doi.org/10.1007/978-1-4615-6099-9_2},
	abstract = {The set of all the neural networks of a fixed architecture forms a geometrical manifold where the modifable connection weights play the role of coordinates. It is important to study all such networks as a whole rather than the behavior of each network in order to understand the capability of information processing of neural networks. What is the natural geometry to be introduced in the manifold of neural networks? Information geometry gives an answer, giving the Riemannian metric and a dual pair of affine connections. An overview is given to information geometry of neural networks.},
	language = {en},
	urldate = {2022-09-07},
	booktitle = {Mathematics of {Neural} {Networks}: {Models}, {Algorithms} and {Applications}},
	publisher = {Springer US},
	author = {Amari, Shun-ichi},
	editor = {Ellacott, Stephen W. and Mason, John C. and Anderson, Iain J.},
	year = {1997},
	doi = {10.1007/978-1-4615-6099-9_2},
	keywords = {Fisher Information, Fisher Information Matrix, Hide Unit, Information Geometry, Neural Network},
	pages = {15--23},
}

@article{guo_statistical_2022,
	title = {Statistical shape analysis of brain arterial networks ({BAN})},
	volume = {16},
	issn = {1932-6157, 1941-7330},
	url = {https://projecteuclid.org/journals/annals-of-applied-statistics/volume-16/issue-2/Statistical-shape-analysis-of-brain-arterial-networks-BAN/10.1214/21-AOAS1536.full},
	doi = {10.1214/21-AOAS1536},
	abstract = {The arterial networks in the human brain, termed brain arterial networks or BANs, are complex arrangements of individual arteries, branching patterns, and interconnectivity. BANs play an essential role in characterizing and understanding brain physiology, and one would like tools for statistically analyzing the shapes of BANs. These tools include quantifying shape differences, comparing populations of subjects, and studying the effects of covariates on these shapes. This paper mathematically represents and statistically analyzes BAN shapes as elastic shape graphs. Each elastic shape graph consists of nodes, or points in 3D, connected by 3D curves, or edges, with arbitrary shapes. We develop a mathematical representation, a Riemannian metric and other geometrical tools, such as computations of geodesics, means, covariances, and PCA, for helping analyze BANs as elastic graphs. We apply this analysis to BANs after dividing them into four components—top, bottom, left, and right. The framework is then used to generate shape summaries of BANs from 92 subjects and study the effects of age and gender on shapes of BAN components. While gender effects require further investigation, we conclude that age has a clear, quantifiable effect on BAN shapes. Specifically, we find an increased variance in BAN shapes as age increases.},
	number = {2},
	urldate = {2022-09-07},
	journal = {The Annals of Applied Statistics},
	author = {Guo, Xiaoyang and Bal, Aditi Basu and Needham, Tom and Srivastava, Anuj},
	month = jun,
	year = {2022},
	keywords = {Graph matching, brain artery network, graph shape PCA, statistical shape analysis},
	pages = {1130--1150},
}

@book{guo_quotient_2019,
	title = {A {Quotient} {Space} {Formulation} for {Statistical} {Analysis} of {Graphical} {Data}},
	abstract = {Complex analyses involving multiple, dependent random quantities often lead to graphical models: a set of nodes denoting variables of interest, and corresponding edges denoting statistical interactions between nodes. To develop statistical analyses for graphical data, one needs mathematical representations and metrics for matching and comparing graphs, and other geometrical tools, such as geodesics, means, and covariances, on representation spaces of graphs. This paper utilizes a quotient structure to develop efficient algorithms for computing these quantities, leading to useful statistical tools, including principal component analysis, linear dimension reduction, and analytical statistical modeling. The efficacy of this framework is demonstrated using datasets taken from several problem areas, including alphabets, video summaries, social networks, and biochemical structures.},
	author = {Guo, Xiaoyang and Srivastava, Anuj and Sarkar, Sudeep},
	month = sep,
	year = {2019},
}

@misc{oh_towards_2022,
	title = {Towards {Reverse}-{Engineering} {Black}-{Box} {Neural} {Networks}, {ICLR}'18},
	copyright = {MIT},
	url = {https://github.com/coallaoh/WhitenBlackBox},
	abstract = {Towards Reverse-Engineering Black-Box Neural Networks, ICLR'18},
	urldate = {2022-09-07},
	author = {Oh, Seong Joon},
	month = sep,
	year = {2022},
	note = {original-date: 2017-12-01T15:35:47Z},
	keywords = {blackbox, iclr, neural-network, reverse-engineering},
}

@article{cao_auto-denseunet_2022,
	title = {Auto-{DenseUNet}: {Searchable} neural network architecture for mass segmentation in {3D} automated breast ultrasound},
	issn = {1361-8415},
	shorttitle = {Auto-{DenseUNet}},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841522002250},
	doi = {10.1016/j.media.2022.102589},
	abstract = {Accurate segmentation of breast mass in 3D automated breast ultrasound (ABUS) plays an important role in breast cancer analysis. Deep convolutional networks have become a promising approach in segmenting ABUS images. However, designing an effective network architecture is time-consuming, and highly relies on specialist’s experience and prior knowledge. To address this issue, we introduce a searchable segmentation network (denoted as Auto-DenseUNet) based on the neural architecture search (NAS) to search the optimal architecture automatically for the ABUS mass segmentation task. Concretely, a novel search space is designed based on a densely connected structure to enhance the gradient and information flows throughout the network. Then, to encourage multiscale information fusion, a set of searchable multiscale aggregation nodes between the down-sampling and up-sampling parts of the network are further designed. Thus, all the operators within the dense connection structure or between any two aggregation nodes can be searched to find the optimal structure. Finally, a novel decoupled search training strategy during architecture search is also introduced to alleviate the memory limitation caused by continuous relaxation in NAS. The proposed Auto-DeseUNet method has been evaluated on our ABUS dataset with 170 volumes (from 107 patients), including 120 training volumes and 50 testing volumes split at patient level. Experimental results on testing volumes show that our searched architecture performed better than several human-designed segmentation models on the 3D ABUS mass segmentation task, indicating the effectiveness of our proposed method.},
	language = {en},
	urldate = {2022-09-07},
	journal = {Medical Image Analysis},
	author = {Cao, Xuyang and Chen, Houjin and Li, Yanfeng and Peng, Yahui and Zhou, Yue and Cheng, Lin and Liu, Tianming and Shen, Dinggang},
	month = aug,
	year = {2022},
	keywords = {ABUS image, Breast mass segmentation, Deep learning, Neural architecture search},
	pages = {102589},
}

@misc{noauthor_sciencedirectcom_nodate,
	title = {{ScienceDirect}.com {\textbar} {Science}, health and medical journals, full text articles and books.},
	url = {https://www-sciencedirect-com.proxy.lib.sfu.ca/?ref=pdf_download&fr=RR-11&rr=7470d6e8edfec650},
	urldate = {2022-09-07},
}

@article{purcell_life_1977,
	title = {Life at low {Reynolds} number},
	volume = {45},
	issn = {0002-9505},
	url = {https://aapt.scitation.org/doi/10.1119/1.10903},
	doi = {10.1119/1.10903},
	number = {1},
	urldate = {2022-09-06},
	journal = {American Journal of Physics},
	author = {Purcell, E. M.},
	month = jan,
	year = {1977},
	pages = {3--11},
}

@article{janota_shielding_2022,
	title = {Shielding of actin by the endoplasmic reticulum impacts nuclear positioning},
	volume = {13},
	doi = {10.1038/s41467-022-30388-3},
	abstract = {Nuclear position is central to cell polarization, and its disruption is associated with various pathologies. The nucleus is moved away from the leading edge of migrating cells through its connection to moving dorsal actin cables, and the absence of connections to immobile ventral stress fibers. It is unclear how these asymmetric nucleo-cytoskeleton connections are established. Here, using an in vitro wound assay, we find that remodeling of endoplasmic reticulum (ER) impacts nuclear positioning through the formation of a barrier that shields immobile ventral stress fibers. The remodeling of ER and perinuclear ER accumulation is mediated by the ER shaping protein Climp-63. Furthermore, ectopic recruitment of the ER to stress fibers restores nuclear positioning in the absence of Climp-63. Our findings suggest that the ER mediates asymmetric nucleo-cytoskeleton connections to position the nucleus.},
	journal = {Nature Communications},
	author = {Janota, Cátia and Pinto, Andreia and Pezzarossa, Anna and Machado, Pedro and Costa, Judite and Campinho, Pedro and Franco, Claudio and Gomes, Edgar},
	month = may,
	year = {2022},
}

@misc{noauthor_general_2022,
	title = {General {Algebraic} {Modeling} {System}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=General_Algebraic_Modeling_System&oldid=1102089328},
	abstract = {The General Algebraic Modeling System (GAMS) is a high-level modeling system for mathematical optimization. GAMS is designed for modeling and solving linear, nonlinear, and mixed-integer optimization problems. The system is tailored for complex, large-scale modeling applications and allows the user to build large maintainable models that can be adapted to new situations. The system is available for use on various computer platforms. Models are portable from one platform to another.
GAMS was the first algebraic modeling language (AML) and is formally similar to commonly used fourth-generation programming languages. GAMS contains an integrated development environment (IDE) and is connected to a group of third-party optimization solvers. Among these solvers are BARON, COIN-OR solvers, CONOPT, CPLEX, DICOPT, MOSEK, SNOPT, SULUM, and XPRESS.
GAMS allows the users to implement a sort of hybrid algorithm combining different solvers. Models are described in concise, human-readable algebraic statements. GAMS is among the most popular input formats for the NEOS Server. Although initially designed for applications related to economics and management science, it has a community of users from various backgrounds of engineering and science.},
	language = {en},
	urldate = {2022-09-05},
	journal = {Wikipedia},
	month = aug,
	year = {2022},
	note = {Page Version ID: 1102089328},
}

@misc{obara_motion_2022,
	title = {Motion of single molecular tethers reveals dynamic subdomains at {ER}-mitochondria contact sites},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.09.03.505525v1},
	doi = {10.1101/2022.09.03.505525},
	abstract = {To coordinate cellular physiology, eukaryotic cells rely on the inter-organelle transfer of molecules at specialized organelle-organelle contact sites. Endoplasmic reticulum-mitochondria contact sites (ERMCSs) are particularly vital communication hubs, playing key roles in the exchange of signaling molecules, lipids, and metabolites. ERMCSs are maintained by interactions between complementary tethering molecules on the surface of each organelle. However, due to the extreme sensitivity of these membrane interfaces to experimental perturbation, a clear understanding of their nanoscale structure and regulation is still lacking. Here, we combine 3D electron microscopy with high-speed molecular tracking of a model organelle tether, VAPB, to map the structure and diffusion landscape of ERMCSs. From EM reconstructions, we identified subdomains within the contact site where ER membranes dramatically deform to match local mitochondrial curvature. In parallel live cell experiments, we observed that the VAPB tethers that mediate this interface were not immobile, but rather highly dynamic, entering and leaving the site in seconds. These subdomains enlarged during nutrient stress, indicating ERMCSs can readily remodel under different physiological conditions. An ALS-associated mutation in VAPB altered the normal fluidity of contact sites, likely perturbing effective communication across the contact site and preventing remodeling. These results establish high speed single molecule imaging as a new tool for mapping the structure of contact site interfaces and suggest that the diffusion landscape of VAPB is a crucial component of ERMCS homeostasis.},
	language = {en},
	urldate = {2022-09-05},
	publisher = {bioRxiv},
	author = {Obara, Christopher J. and Nixon-Abell, Jonathon and Moore, Andrew S. and Riccio, Federica and Hoffman, David P. and Shtengel, Gleb and Xu, C. Shan and Schaefer, Kathy and Pasolli, H. Amalia and Masson, Jean-Baptiste and Hess, Harald F. and Calderon, Christopher P. and Blackstone, Craig and Lippincott-Schwartz, Jennifer},
	month = sep,
	year = {2022},
}

@article{pourshafie_altered_2022,
	title = {Altered {SYNJ2BP}-mediated mitochondrial-{ER} contacts in motor neuron disease},
	volume = {172},
	doi = {10.1016/j.nbd.2022.105832},
	abstract = {Synaptojanin 2 binding protein (SYNJ2BP) is an outer mitochondrial membrane protein with a cytosolic PDZ domain that functions as a cellular signaling hub. Few studies have evaluated its role in disease. Here we use induced pluripotent stem cell (iPSC)-derived motor neurons and post-mortem tissue from patients with two hereditary motor neuron diseases, spinal and bulbar muscular atrophy (SBMA) and amyotrophic lateral sclerosis type 4 (ALS4), and show that SYNJ2BP expression is increased in diseased motor neurons. Similarly, we show that SYNJ2BP expression increases in iPSC-derived motor neurons undergoing stress. Using proteomic analysis, we found that elevated SYNJ2BP alters the cellular distribution of mitochondria and increases mitochondrial-ER membrane contact sites. Furthermore, decreasing SYNJ2BP levels improves mitochondrial oxidative function in the diseased motor neurons. Together, our observations offer new insight into the molecular pathology of motor neuron disease and the role of SYNJ2BP in mitochondrial dysfunction.},
	journal = {Neurobiology of Disease},
	author = {Pourshafie, Naemeh and Masati, Ester and Lopez, Amber and Bunker, Eric and Snyder, Allison and Edwards, Nancy and Winkelsas, Audrey and Fischbeck, Kenneth and Grunseich, Christopher},
	month = jul,
	year = {2022},
	pages = {105832},
}

@article{fages-lartaud_mcherry_2022,
	title = {{mCherry} contains a fluorescent protein isoform that interferes with its reporter function},
	volume = {10},
	doi = {10.3389/fbioe.2022.892138},
	abstract = {Fluorescent proteins are essential reporters in cell and molecular biology. Here, we found that red-fluorescent proteins possess an alternative translation initiation site that produces a short functional protein isoform in both prokaryotes and eukaryotes. The short isoform creates significant background fluorescence that biases the outcome of expression studies. In this study, we identified the short protein isoform, traced its origin, and determined the extent of the issue within the family of red fluorescent protein. Our analysis showed that the short isoform defect of the red fluorescent protein family may affect the interpretation of many published studies. We provided a re-engineered mCherry variant that lacks background expression as an improved tool for imaging and protein expression studies.},
	journal = {Frontiers in Bioengineering and Biotechnology},
	author = {Fages-Lartaud, Maxime and Tietze, Lisa and Elie, Florence and Lale, Rahmi and Hohmann-Marriott, Martin},
	month = aug,
	year = {2022},
	pages = {892138},
}

@book{scarlett_theoretical_2022,
	title = {Theoretical {Perspectives} on {Deep} {Learning} {Methods} in {Inverse} {Problems}},
	abstract = {In recent years, there have been significant advances in the use of deep learning methods in inverse problems such as denoising, compressive sensing, inpainting, and super-resolution. While this line of works has predominantly been driven by practical algorithms and experiments, it has also given rise to a variety of intriguing theoretical problems. In this paper, we survey some of the prominent theoretical developments in this line of works, focusing in particular on generative priors, untrained neural network priors, and unfolding algorithms. In addition to summarizing existing results in these topics, we highlight several ongoing challenges and open problems.},
	author = {Scarlett, Jonathan and Heckel, Reinhard and Rodrigues, M.R.D. and Hand, Paul and Eldar, Yonina},
	month = jun,
	year = {2022},
}

@article{hoffmann_robustness_2021,
	title = {A robustness measure for singular point and index estimation in discretized orientation and vector fields},
	volume = {20},
	doi = {10.1002/pamm.202000261},
	abstract = {The identification of singular points or topological defects in discretized vector fields occurs in diverse areas ranging from the polarization of the cosmic microwave background to liquid crystals to fingerprint recognition and bio‐medical imaging. Due to their discrete nature, defects and their topological charge cannot depend continuously on each single vector, but they discontinuously change as soon as a vector changes by more than a threshold. Considering this threshold of admissible change at the level of vectors, we develop a robustness measure for discrete defect estimators. Here, we compare different template paths for defect estimation in discretized vector or orientation fields. Sampling prototypical vector field patterns around defects shows that the robustness increases with the length of template path, but less so in the presence of noise on the vectors. We therefore find an optimal trade‐off between resolution and robustness against noise for relatively small templates, except for the “single pixel” defect analysis, which cannot exclude zero robustness. The presented robustness measure paves the way for uncertainty quantification of defects in discretized vector fields.},
	journal = {PAMM},
	author = {Hoffmann, Karl and Sbalzarini, Ivo},
	month = jan,
	year = {2021},
}

@misc{noauthor_geometric_nodate,
	title = {Geometric and {Shape} {Modeling}},
	url = {https://www.sci.utah.edu/sci-software/geometric-and-shape-modeling.html},
	urldate = {2022-09-01},
}

@misc{wong_cil13717_nodate,
	title = {{CIL}:13717, {Homo} sapiens, endothelial cell. {CIL}. {Dataset}},
	shorttitle = {{CIL}},
	url = {http://cellimagelibrary.org/images/13717},
	abstract = {"YFP-WT PINK1 (green) shows mitochondrial localization in HeLa cells following treatment with the mitochondrial depolarizing agent CCCP (carbonyl cyanide m-chlorophenyl hydrazone). When fixed cells are unpermeabilized (not treated with...},
	language = {nl},
	urldate = {2022-08-31},
	author = {Wong, Willy W.},
}

@article{noauthor_integrating_2021,
	title = {Integrating engineered point spread functions into the phasor-based single-molecule localization microscopy framework},
	volume = {193},
	issn = {1046-2023},
	url = {https://www.sciencedirect.com/science/article/pii/S1046202320301250},
	doi = {10.1016/j.ymeth.2020.07.010},
	abstract = {In single-molecule localization microscopy (SMLM), the use of engineered point spread functions (PSFs) provides access to three-dimensional localizati…},
	language = {en},
	urldate = {2022-08-31},
	journal = {Methods},
	month = sep,
	year = {2021},
	pages = {107--115},
}

@article{sinko_polarization_2017,
	title = {Polarization sensitive localization based super-resolution microscopy with a birefringent wedge},
	volume = {5},
	issn = {2050-6120},
	url = {https://doi.org/10.1088/2050-6120/aa6260},
	doi = {10.1088/2050-6120/aa6260},
	abstract = {A practical method has been presented for polarization sensitive localization based super-resolution microscopy using a birefringent dual wedge. The measurement of the polarization degree at the single molecule level can reveal the chemical and physical properties of the local environment of the fluorescent dye molecule and can hence provide information about the sub-diffraction sized structure of biological samples. Polarization sensitive STORM imaging of the F-Actins proved correlation between the orientation of fluorescent dipoles and the axis of the fibril.},
	language = {en},
	number = {1},
	urldate = {2022-08-31},
	journal = {Methods and Applications in Fluorescence},
	author = {Sinkó, József and Gajdos, Tamás and Czvik, Elvira and Szabó, Gábor and Erdélyi, Miklós},
	month = mar,
	year = {2017},
	pages = {017001},
}

@article{valades_cruz_quantitative_2016,
	title = {Quantitative nanoscale imaging of orientational order in biological filaments by polarized superresolution microscopy},
	volume = {113},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.1516811113},
	doi = {10.1073/pnas.1516811113},
	number = {7},
	urldate = {2022-08-31},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Valades Cruz, Cesar Augusto and Shaban, Haitham Ahmed and Kress, Alla and Bertaux, Nicolas and Monneret, Serge and Mavrakis, Manos and Savatier, Julien and Brasselet, Sophie},
	month = feb,
	year = {2016},
	pages = {E820--E828},
}

@inproceedings{rimoli_super_2019,
	title = {Super resolution polarized imaging of the organization of actin filaments in cells ({Conference} {Presentation})},
	volume = {10884},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10884/108840G/Super-resolution-polarized-imaging-of-the-organization-of-actin-filaments/10.1117/12.2509679.full},
	doi = {10.1117/12.2509679},
	abstract = {The way cells organize actin filaments at the nanoscale and its relation to biomechanical functions still raises many open questions. Polarized fluorescence microscopies (PFM), which quantify fluorophores orientations based on their coupling to excitation or detection light polarization, provide a quantitative approach to this question. These methods, because they are ensemble imaging techniques, are however vulnerable to important sources of bias such as the possible mixture of different overlapping structures, or the overestimation of orientational disorder when fluorophores are not rigidly attached to the structure of interest. To circumvent such biases, we propose in this work a single molecule based polarized detection together with direct stochastic optical reconstruction microscopy (dSTORM), a method called polarized-dSTORM. We developed a technique based on four polarization projections of STORM images (4Polar-dSTORM) to retrieve, without ambiguity, both averaged orientation and angular fluctuations extent (wobbling) for each single molecule. This approach exhibits strong advantages as compared to previously developed two-polarization projections which required, among others limitations, to suppose identical wobbling for all molecules. We analyzed the effect of tilted illumination and of the detection aperture, to reduce the sensitivity of the method to off-plane 3D-orientation biases that can occur under high numerical aperture conditions. Taking these parameters into account is crucial for a non-biased, quantitative reporter of the orientational behavior of the target protein. We demonstrate the capacity of the method to report the nanoscale organization of actin filaments in cell stress fibers, and study its spatial perturbation when the cell mechanical nature is affected.},
	urldate = {2022-08-31},
	booktitle = {Single {Molecule} {Spectroscopy} and {Superresolution} {Imaging} {XII}},
	publisher = {SPIE},
	author = {Rimoli, Caio Vaz and Cruz, Cesar Augusto Valades and Mavrakis, Manos and Brasselet, Sophie},
	month = mar,
	year = {2019},
	pages = {108840G},
}

@article{shaban_polarized_2017,
	title = {Polarized super-resolution structural imaging inside amyloid fibrils using {Thioflavine} {T}},
	volume = {7},
	copyright = {2017 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-017-12864-9},
	doi = {10.1038/s41598-017-12864-9},
	abstract = {Thioflavin T (ThT) is standardly used as a fluorescent marker to detect aggregation of amyloid fibrils by conventional fluorescence microscopy, including polarization resolved imaging that brings information on the orientational order of the fibrils. These techniques are however diffraction limited and cannot provide fine structural details at the fibrils scales of 10–100 nm, which lie beyond the diffraction limit. In this work, we evaluate the capacity of ThT to photoswitch when bound to insulin amyloids by adjusting the redox properties of its environment. We demonstrate that on-off duty cycles, intensity and photostability of the ThT fluorescence emission under adequate buffer conditions permit stochastic super-resolution imaging with a localization precision close to 20 nm. We show moreover that signal to noise conditions allow polarized orientational imaging of single ThT molecules, which reveals ultra-structure signatures related to protofilaments twisting within amyloid fibrils.},
	language = {en},
	number = {1},
	urldate = {2022-08-31},
	journal = {Scientific Reports},
	author = {Shaban, Haitham A. and Valades-Cruz, Cesar A. and Savatier, Julien and Brasselet, Sophie},
	month = oct,
	year = {2017},
	keywords = {Polarization microscopy, Single-molecule biophysics, Super-resolution microscopy},
	pages = {12482},
}

@article{yang_organelle_2022,
	title = {Organelle {Interaction} and {Drug} {Discovery}: {Towards} {Correlative} {Nanoscopy} and {Molecular} {Dynamics} {Simulation}},
	volume = {13},
	issn = {1663-9812},
	shorttitle = {Organelle {Interaction} and {Drug} {Discovery}},
	doi = {10.3389/fphar.2022.935898},
	abstract = {The inter-organelle interactions, including the cytomembrane, endoplasmic reticulum, mitochondrion, lysosome, dictyosome, and nucleus, play the important roles in maintaining the normal function and homeostasis of cells. Organelle dysfunction can lead to a range of diseases (e.g., Alzheimer's disease (AD), Parkinson's disease (PD), and cancer), and provide a new perspective for drug discovery. With the development of imaging techniques and functional fluorescent probes, a variety of algorithms and strategies have been developed for the ever-improving estimation of subcellular structures, organelle interaction, and organelle-related drug discovery with accounting for the dynamic structures of organelles, such as the nanoscopy technology and molecular dynamics (MD) simulations. Accordingly, this work summarizes a series of state-of-the-art examples of the recent progress in this rapidly changing field and uncovering the drug screening based on the structures and interactions of organelles. Finally, we propose the future outlook for exciting applications of organelle-related drug discovery, with the cooperation of nanoscopy and MD simulations.},
	language = {eng},
	journal = {Frontiers in Pharmacology},
	author = {Yang, Zhiwei and Zhang, Zichen and Zhao, Yizhen and Ye, Qiushi and Li, Xuhua and Meng, Lingjie and Long, Jiangang and Zhang, Shengli and Zhang, Lei},
	year = {2022},
	pmid = {35795548},
	pmcid = {PMC9251060},
	keywords = {drug discovery, molecular dynamics simulation, nanoscopy, organelle interaction, subcellular structure},
	pages = {935898},
}

@article{campen_exact_2010,
	title = {Exact and {Robust} ({Self}-){Intersections} for {Polygonal} {Meshes}},
	volume = {29},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2009.01609.x},
	doi = {10.1111/j.1467-8659.2009.01609.x},
	abstract = {We present a new technique to implement operators that modify the topology of polygonal meshes at intersections and self-intersections. Depending on the modification strategy, this effectively results in operators for Boolean combinations or for the construction of outer hulls that are suited for mesh repair tasks and accurate mesh-based front tracking of deformable materials that split and merge. By combining an adaptive octree with nested binary space partitions (BSP), we can guarantee exactness (= correctness) and robustness (= completeness) of the algorithm while still achieving higher performance and less memory consumption than previous approaches. The efficiency and scalability in terms of runtime and memory is obtained by an operation localization scheme. We restrict the essential computations to those cells in the adaptive octree where intersections actually occur. Within those critical cells, we convert the input geometry into a plane-based BSP-representation which allows us to perform all computations exactly even with fixed precision arithmetics. We carefully analyze the precision requirements of the involved geometric data and predicates in order to guarantee correctness and show how minimal input mesh quantization can be used to safely rely on computations with standard floating point numbers. We properly evaluate our method with respect to precision, robustness, and efficiency.},
	language = {en},
	number = {2},
	urldate = {2022-08-28},
	journal = {Computer Graphics Forum},
	author = {Campen, Marcel and Kobbelt, Leif},
	year = {2010},
	keywords = {Computational, Computer, Geometry, Graphics, I.3.5:, Modeling, Object, and},
	pages = {397--406},
}

@misc{matthaeus_molecular_2022,
	title = {The molecular organization of flat and curved caveolae indicates bendable structural units at the plasma membrane},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This article is a US Government work. It is not subject to copyright under 17 USC 105 and is also made available for use under a CC0 license},
	url = {https://www.biorxiv.org/content/10.1101/2022.03.31.486578v1},
	doi = {10.1101/2022.03.31.486578},
	abstract = {Caveolae are small coated inner plasma membrane invaginations found in many cell types. Their diverse functions span from endocytosis to signaling, regulating key cellular processes including lipid uptake, pathogen entry, and membrane tension. Caveolae undergo shape changes from flat to curved. It is unclear which proteins regulate this process. To address this gap, we studied the shapes of caveolae with platinum replica electron microscopy in six common cell types. Next, we developed a correlative multi-color stimulated emission depletion (STED) fluorescence and platinum replica EM imaging (CLEM) method to image caveolae-associated proteins at caveolae of different shapes at the nanoscale. Caveolins and cavins were found at all caveolae, independent of their curvature. EHD2, a classic caveolar neck protein, was strongly detected at both curved and flat caveolae. Both pacsin2 and the regulator EHBP1 were found only at a subset of caveolae. Pacsin2 was localized primarily to areas surrounding flat caveolae, whereas EHBP1 was mostly detected at spheres. Contrary to classic models, dynamin was absent from caveolae and localized only to clathrin-coated structures. Cells lacking dynamin showed no substantial changes to caveolae, suggesting that dynamin is not directly involved in caveolae curvature. Together, we provide a mechanistic map for the molecular control of caveolae shape by eight of the major caveolae-associated coat and regulatory proteins. We propose a model where caveolins, cavins, and EHD2 assemble as a cohesive structural unit regulated by more intermittent associations with pacsin2 and EHBP1. These complexes can flatten and curve, capturing membrane to enable lipid traffic and changes to the surface area of the cell.},
	language = {en},
	urldate = {2022-08-27},
	publisher = {bioRxiv},
	author = {Matthaeus, Claudia and Sochacki, Kem A. and Dickey, Andrea and Puchkov, Dmytro and Haucke, Volker and Lehmann, Martin and Taraska, Justin W.},
	month = mar,
	year = {2022},
}

@article{jimenez_about_2020,
	title = {About samples, giving examples: {Optimized} {Single} {Molecule} {Localization} {Microscopy}},
	volume = {174},
	issn = {1095-9130},
	shorttitle = {About samples, giving examples},
	doi = {10.1016/j.ymeth.2019.05.008},
	abstract = {Super-resolution microscopy has profoundly transformed how we study the architecture of cells, revealing unknown structures and refining our view of cellular assemblies. Among the various techniques, the resolution of Single Molecule Localization Microscopy (SMLM) can reach the size of macromolecular complexes and offer key insights on their nanoscale arrangement in situ. SMLM is thus a demanding technique and taking advantage of its full potential requires specifically optimized procedures. Here we describe how we perform the successive steps of an SMLM workflow, focusing on single-color Stochastic Optical Reconstruction Microscopy (STORM) as well as multicolor DNA Points Accumulation for imaging in Nanoscale Topography (DNA-PAINT) of fixed samples. We provide detailed procedures for careful sample fixation and immunostaining of typical cellular structures: cytoskeleton, clathrin-coated pits, and organelles. We then offer guidelines for optimal imaging and processing of SMLM data in order to optimize reconstruction quality and avoid the generation of artifacts. We hope that the tips and tricks we discovered over the years and detail here will be useful for researchers looking to make the best possible SMLM images, a pre-requisite for meaningful biological discovery.},
	language = {eng},
	journal = {Methods (San Diego, Calif.)},
	author = {Jimenez, Angélique and Friedl, Karoline and Leterrier, Christophe},
	month = mar,
	year = {2020},
	pmid = {31078795},
	keywords = {Animals, Cell Line, Chlorocebus aethiops, Color, Cytoskeleton, DNA, DNA-PAINT, Fluorescent Dyes, Humans, Image Processing, Computer-Assisted, Imaging, Three-Dimensional, Immunohistochemistry, Macromolecular Substances, Microscopy, Fluorescence, Nanotechnology, SMLM, STORM, Single Molecule Imaging, Super-resolution microscopy},
	pages = {100--114},
}

@article{lucic_hierarchical_2016,
	title = {Hierarchical detection and analysis of macromolecular complexes in cryo-electron tomograms using {Pyto} software},
	volume = {196},
	issn = {1095-8657},
	doi = {10.1016/j.jsb.2016.10.004},
	abstract = {Molecular complexes, arguably the basic units carrying cellular function, can be visualized directly in their native environment by cryo-electron tomography. Here we describe a procedure for the detection of small, pleomorphic membrane-bound molecular complexes in cryo-tomograms by a hierarchical connectivity segmentation. Validation on phantom and real data showed above 90\% true positive rates. This segmentation procedure is implemented in the Pyto software package, together with methods for quantitative characterization and classification of complexes detected by our segmentation procedure and for statistical analysis between experimental conditions. Therefore, the methods presented provide a means for the detection and quantitative interpretation of structures captured in cryo-electron tomograms, as well as for the elucidation of their cellular function.},
	language = {eng},
	number = {3},
	journal = {Journal of Structural Biology},
	author = {Lučić, Vladan and Fernández-Busnadiego, Rubén and Laugks, Ulrike and Baumeister, Wolfgang},
	month = dec,
	year = {2016},
	pmid = {27742578},
	keywords = {Algorithms, Cryo, Cryoelectron Microscopy, Electron Microscope Tomography, Electron tomography, Image Processing, Computer-Assisted, Image processing, Imaging, Three-Dimensional, Macromolecular Substances, Segmentation, Software, Synapses},
	pages = {503--514},
}

@article{liddle_dstorm_2020,
	title = {{dSTORM} microscopy evidences in {HeLa} cells clustered and scattered γ{H2AX} nanofoci sensitive to {ATM}, {DNA}-{PK}, and {ATR} kinase inhibitors},
	volume = {473},
	issn = {1573-4919},
	doi = {10.1007/s11010-020-03809-4},
	abstract = {In response to DNA double-strand breaks (DSB), histone H2AX is phosphorylated around the lesion by a feed forward signal amplification loop, originating γH2AX foci detectable by immunofluorescence and confocal microscopy as elliptical areas of uniform intensity. We exploited the significant increase in resolution ({\textasciitilde} × 10) provided by single-molecule localization microscopy (SMLM) to investigate at nanometer scale the distribution of γH2AX signals either endogenous (controls) or induced by the radiomimetic bleomycin (BLEO) in HeLa cells. In both conditions, clustered substructures (nanofoci) confined to γH2AX foci and scattered nanofoci throughout the remnant nuclear area were detected. SR-Tesseler software (Voronoï tessellation-based segmentation) was combined with a custom Python script to first separate clustered nanofoci inside γH2AX foci from scattered nanofoci, and then to perform a cluster analysis upon each nanofoci type. Compared to controls, γH2AX foci in BLEO-treated nuclei presented on average larger areas (0.41 versus 0.19 µm2), more nanofoci per focus (22.7 versus 13.2) and comparable nanofoci densities ({\textasciitilde} 60 nanofoci/µm2). Scattered γH2AX nanofoci were equally present ({\textasciitilde} 3 nanofoci/µm2), suggesting an endogenous origin. BLEO-treated cells were challenged with specific inhibitors of canonical H2AX kinases, namely: KU-55933, VE-821 and NU-7026 for ATM, ATR and DNA-PK, respectively. Under treatment with pooled inhibitors, clustered nanofoci vanished from super-resolution images while scattered nanofoci decreased ({\textasciitilde} 50\%) in density. Residual scattered nanofoci could reflect, among other alternatives, H2AX phosphorylation mediated by VRK1, a recently described non-canonical H2AX kinase. In addition to H2AX findings, an analytical approach to quantify clusters of highly differing density from SMLM data is put forward.},
	language = {eng},
	number = {1-2},
	journal = {Molecular and Cellular Biochemistry},
	author = {Liddle, Pablo and Jara-Wilde, Jorge and Lafon-Hughes, Laura and Castro, Iván and Härtel, Steffen and Folle, Gustavo},
	month = oct,
	year = {2020},
	pmid = {32638256},
	keywords = {ATM/ATR/DNA-PK inhibitors, Ataxia Telangiectasia Mutated Proteins, DNA damage, DNA-Activated Protein Kinase, HeLa Cells, Histones, Humans, Microscopy, Confocal, Neoplasm Proteins, Protein Kinase Inhibitors, SMLM microscopy, Voronoï tessellation, γH2AX nanofoci},
	pages = {77--91},
}

@article{neufeldt_membrane_2022,
	title = {Membrane architects: how positive-strand {RNA} viruses restructure the cell},
	volume = {103},
	shorttitle = {Membrane architects},
	doi = {10.1099/jgv.0.001773},
	abstract = {Virus infection is a process that requires combined contributions from both virus and host factors. For this process to be efficient within the crowded host environment, viruses have evolved ways to manipulate and reorganize host structures to produce cellular microenvironments. Positive-strand RNA virus replication and assembly occurs in association with cytoplasmic membranes, causing a reorganization of these membranes to create microenvironments that support viral processes. Similarities between virus-induced membrane domains and cellular organelles have led to the description of these structures as virus replication organelles (vRO). Electron microscopy analysis of vROs in positive-strand RNA virus infected cells has revealed surprising morphological similarities between genetically diverse virus species. For all positive-strand RNA viruses, vROs can be categorized into two groups: those that make invaginations into the cellular membranes (In-vRO), and those that cause the production of protrusions from cellular membranes (Pr-vRO), most often in the form of double membrane vesicles (DMVs). In this review, we will discuss the current knowledge on the structure and biogenesis of these two different vRO classes as well as comparing morphology and function of vROs between various positive-strand RNA viruses. Finally, we will discuss recent studies describing pharmaceutical intervention in vRO formation as an avenue to control virus infection.},
	journal = {Journal of General Virology},
	author = {Neufeldt, Christopher and Cortese, Mirko},
	month = aug,
	year = {2022},
}

@incollection{ochoa_neural_2022,
	title = {Neural {Architecture} {Search}: {A} {Visual} {Analysis}},
	isbn = {9783031147135},
	shorttitle = {Neural {Architecture} {Search}},
	abstract = {Neural architecture search (NAS) refers to the use of search heuristics to optimise the topology of deep neural networks. NAS algorithms have produced topologies that outperform human-designed ones. However, contrasting alternative NAS methods is difficult. To address this, several tabular NAS benchmarks have been proposed that exhaustively evaluate all architectures in a given search space. We conduct a thorough fitness landscape analysis of a popular tabular, cell-based NAS benchmark. Our results indicate that NAS landscapes are multi-modal, but have a relatively low number of local optima, from which it is not hard to escape. We confirm that reducing the noise in estimating performance reduces the number of local optima. We hypothesise that local-search based NAS methods are likely to be competitive, which we confirm by implementing a landscape-aware iterated local search algorithm that can outperform more elaborate evolutionary and reinforcement learning NAS methods.},
	author = {Ochoa, Gabriela and Veerapen, Nadarajen},
	month = aug,
	year = {2022},
	doi = {10.1007/978-3-031-14714-2_42},
	pages = {603--615},
}

@article{dorn_predicting_2022,
	title = {Predicting {Mitochondrial} {Dynamic} {Behavior} in {Genetically} {Defined} {Neurodegenerative} {Diseases}},
	volume = {11},
	doi = {10.3390/cells11061049},
	abstract = {Mitochondrial dynamics encompass mitochondrial fusion, fission, and movement. Mitochondrial fission and fusion are seemingly ubiquitous, whereas mitochondrial movement is especially important for organelle transport through neuronal axons. Here, we review the roles of different mitochondrial dynamic processes in mitochondrial quantity and quality control, emphasizing their impact on the neurological system in Charcot–Marie–Tooth disease type 2A, amyotrophic lateral sclerosis, Friedrich’s ataxia, dominant optic atrophy, and Alzheimer’s, Huntington’s, and Parkinson’s diseases. In addition to mechanisms and concepts, we explore in detail different technical approaches for measuring mitochondrial dynamic dysfunction in vitro, describe how results from tissue culture studies may be applied to a better understanding of mitochondrial dysdynamism in human neurodegenerative diseases, and suggest how this experimental platform can be used to evaluate candidate therapeutics in different diseases or in individual patients sharing the same clinical diagnosis.},
	journal = {Cells},
	author = {Dorn, Gerald and Dang, Xiawei},
	month = mar,
	year = {2022},
	pages = {1049},
}

@article{de_fauw_clinically_2018,
	title = {Clinically applicable deep learning for diagnosis and referral in retinal disease},
	volume = {24},
	copyright = {2018 The Author(s)},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-018-0107-6},
	doi = {10.1038/s41591-018-0107-6},
	abstract = {The volume and complexity of diagnostic imaging is increasing at a pace faster than the availability of human expertise to interpret it. Artificial intelligence has shown great promise in classifying two-dimensional photographs of some common diseases and typically relies on databases of millions of annotated images. Until now, the challenge of reaching the performance of expert clinicians in a real-world clinical pathway with three-dimensional diagnostic scans has remained unsolved. Here, we apply a novel deep learning architecture to a clinically heterogeneous set of three-dimensional optical coherence tomography scans from patients referred to a major eye hospital. We demonstrate performance in making a referral recommendation that reaches or exceeds that of experts on a range of sight-threatening retinal diseases after training on only 14,884 scans. Moreover, we demonstrate that the tissue segmentations produced by our architecture act as a device-independent representation; referral accuracy is maintained when using tissue segmentations from a different type of device. Our work removes previous barriers to wider clinical use without prohibitive training data requirements across multiple pathologies in a real-world setting.},
	language = {en},
	number = {9},
	urldate = {2022-08-18},
	journal = {Nature Medicine},
	author = {De Fauw, Jeffrey and Ledsam, Joseph R. and Romera-Paredes, Bernardino and Nikolov, Stanislav and Tomasev, Nenad and Blackwell, Sam and Askham, Harry and Glorot, Xavier and O’Donoghue, Brendan and Visentin, Daniel and van den  Driessche, George and Lakshminarayanan, Balaji and Meyer, Clemens and Mackinder, Faith and Bouton, Simon and Ayoub, Kareem and Chopra, Reena and King, Dominic and Karthikesalingam, Alan and Hughes, Cían O. and Raine, Rosalind and Hughes, Julian and Sim, Dawn A. and Egan, Catherine and Tufail, Adnan and Montgomery, Hugh and Hassabis, Demis and Rees, Geraint and Back, Trevor and Khaw, Peng T. and Suleyman, Mustafa and Cornebise, Julien and Keane, Pearse A. and Ronneberger, Olaf},
	month = sep,
	year = {2018},
	keywords = {Diagnosis, Eye manifestations, Machine learning, Three-dimensional imaging},
	pages = {1342--1350},
}

@book{nakhli_ccrl_2022,
	title = {{CCRL}: {Contrastive} {Cell} {Representation} {Learning}},
	shorttitle = {{CCRL}},
	abstract = {Cell identification within the H\&E slides is an essential prerequisite that can pave the way towards further pathology analyses including tissue classification, cancer grading, and phenotype prediction. However, performing such a task using deep learning techniques requires a large cell-level annotated dataset. Although previous studies have investigated the performance of contrastive self-supervised methods in tissue classification, the utility of this class of algorithms in cell identification and clustering is still unknown. In this work, we investigated the utility of Self-Supervised Learning (SSL) in cell clustering by proposing the Contrastive Cell Representation Learning (CCRL) model. Through comprehensive comparisons, we show that this model can outperform all currently available cell clustering models by a large margin across two datasets from different tissue types. More interestingly, the results show that our proposed model worked well with a few number of cell categories while the utility of SSL models has been mainly shown in the context of natural image datasets with large numbers of classes (e.g., ImageNet). The unsupervised representation learning approach proposed in this research eliminates the time-consuming step of data annotation in cell classification tasks, which enables us to train our model on a much larger dataset compared to previous methods. Therefore, considering the promising outcome, this approach can open a new avenue to automatic cell representation learning.},
	author = {Nakhli, Ramin and Darbandsari, Amirali and Farahani, Hossein and Bashashati, Ali},
	month = aug,
	year = {2022},
	doi = {10.48550/arXiv.2208.06445},
}

@book{kaku_intermediate_2021,
	title = {Intermediate {Layers} {Matter} in {Momentum} {Contrastive} {Self} {Supervised} {Learning}},
	abstract = {We show that bringing intermediate layers' representations of two augmented versions of an image closer together in self-supervised learning helps to improve the momentum contrastive (MoCo) method. To this end, in addition to the contrastive loss, we minimize the mean squared error between the intermediate layer representations or make their cross-correlation matrix closer to an identity matrix. Both loss objectives either outperform standard MoCo, or achieve similar performances on three diverse medical imaging datasets: NIH-Chest Xrays, Breast Cancer Histopathology, and Diabetic Retinopathy. The gains of the improved MoCo are especially large in a low-labeled data regime (e.g. 1\% labeled data) with an average gain of 5\% across three datasets. We analyze the models trained using our novel approach via feature similarity analysis and layer-wise probing. Our analysis reveals that models trained via our approach have higher feature reuse compared to a standard MoCo and learn informative features earlier in the network. Finally, by comparing the output probability distribution of models fine-tuned on small versus large labeled data, we conclude that our proposed method of pre-training leads to lower Kolmogorov-Smirnov distance, as compared to a standard MoCo. This provides additional evidence that our proposed method learns more informative features in the pre-training phase which could be leveraged in a low-labeled data regime.},
	author = {Kaku, Aakash and Upadhya, Sahana and Razavian, Narges},
	month = oct,
	year = {2021},
}

@article{murphy_self-supervised_2022,
	title = {Self-supervised learning of cell type specificity from immunohistochemical images},
	volume = {38},
	issn = {1367-4803},
	url = {https://doi.org/10.1093/bioinformatics/btac263},
	doi = {10.1093/bioinformatics/btac263},
	abstract = {Advances in bioimaging now permit in situ proteomic characterization of cell–cell interactions in complex tissues, with important applications across a spectrum of biological problems from development to disease. These methods depend on selection of antibodies targeting proteins that are expressed specifically in particular cell types. Candidate marker proteins are often identified from single-cell transcriptomic data, with variable rates of success, in part due to divergence between expression levels of proteins and the genes that encode them. In principle, marker identification could be improved by using existing databases of immunohistochemistry for thousands of antibodies in human tissue, such as the Human Protein Atlas. However, these data lack detailed annotations of the types of cells in each image.We develop a method to predict cell type specificity of protein markers from unlabeled images. We train a convolutional neural network with a self-supervised objective to generate embeddings of the images. Using non-linear dimensionality reduction, we observe that the model clusters images according to cell types and anatomical regions for which the stained proteins are specific. We then use estimates of cell type specificity derived from an independent single-cell transcriptomics dataset to train an image classifier, without requiring any human labelling of images. Our scheme demonstrates superior classification of known proteomic markers in kidney compared to selection via single-cell transcriptomics.Code and trained model are available at www.github.com/murphy17/HPA-SimCLR.Supplementary data are available at Bioinformatics online.},
	number = {Supplement\_1},
	urldate = {2022-08-17},
	journal = {Bioinformatics},
	author = {Murphy, Michael and Jegelka, Stefanie and Fraenkel, Ernest},
	month = jul,
	year = {2022},
	pages = {i395--i403},
}

@article{wu_dynamorph_2022,
	title = {{DynaMorph}: self-supervised learning of morphodynamic states of live cells},
	volume = {33},
	issn = {1059-1524},
	shorttitle = {{DynaMorph}},
	url = {https://www.molbiolcell.org/doi/10.1091/mbc.E21-11-0561},
	doi = {10.1091/mbc.E21-11-0561},
	abstract = {A cell’s shape and motion represent fundamental aspects of cell identity and can be highly predictive of function and pathology. However, automated analysis of the morphodynamic states remains challenging for most cell types, especially primary human cells where genetic labeling may not be feasible. To enable automated and quantitative analysis of morphodynamic states, we developed DynaMorph—a computational framework that combines quantitative live cell imaging with self-supervised learning. To demonstrate the robustness and utility of this approach, we used DynaMorph to annotate morphodynamic states observed with label-free measurements of optical density and anisotropy of live microglia isolated from human brain tissue. These cells show complex behavior and have varied responses to disease-relevant perturbations. DynaMorph generates quantitative morphodynamic representations that can be used to compare the effects of the perturbations. Using DynaMorph, we identify distinct morphodynamic states of microglia polarization and detect rare transition events between states. The concepts and the methods presented here can facilitate automated discovery of functional states of diverse cellular systems.},
	number = {6},
	urldate = {2022-08-17},
	journal = {Molecular Biology of the Cell},
	author = {Wu, Zhenqin and Chhun, Bryant B. and Popova, Galina and Guo, Syuan-Ming and Kim, Chang N. and Yeh, Li-Hao and Nowakowski, Tomasz and Zou, James and Mehta, Shalin B.},
	month = may,
	year = {2022},
	pages = {ar59},
}

@article{mascolini_exploiting_2022,
	title = {Exploiting generative self-supervised learning for the assessment of biological images with lack of annotations},
	volume = {23},
	copyright = {2022 The Author(s)},
	issn = {1471-2105},
	url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-022-04845-1},
	doi = {10.1186/s12859-022-04845-1},
	abstract = {Computer-aided analysis of biological images typically requires extensive training on large-scale annotated datasets, which is not viable in many situations. In this paper, we present Generative Adversarial Network Discriminator Learner (GAN-DL), a novel self-supervised learning paradigm based on the StyleGAN2 architecture, which we employ for self-supervised image representation learning in the case of fluorescent biological images. We show that Wasserstein Generative Adversarial Networks enable high-throughput compound screening based on raw images. We demonstrate this by classifying active and inactive compounds tested for the inhibition of SARS-CoV-2 infection in two different cell models: the primary human renal cortical epithelial cells (HRCE) and the African green monkey kidney epithelial cells (VERO). In contrast to previous methods, our deep learning-based approach does not require any annotation, and can also be used to solve subtle tasks it was not specifically trained on, in a self-supervised manner. For example, it can effectively derive a dose-response curve for the tested treatments. Our code and embeddings are available at https://gitlab.com/AlesioRFM/gan-dl StyleGAN2 is available at https://github.com/NVlabs/stylegan2 .},
	language = {en},
	number = {1},
	urldate = {2022-08-17},
	journal = {BMC Bioinformatics},
	author = {Mascolini, Alessio and Cardamone, Dario and Ponzio, Francesco and Di Cataldo, Santa and Ficarra, Elisa},
	month = dec,
	year = {2022},
	pages = {1--17},
}

@article{zhang_mitophagy_2021,
	title = {Mitophagy in neurological disorders},
	volume = {18},
	doi = {10.1186/s12974-021-02334-5},
	abstract = {Selective autophagy is an evolutionarily conserved mechanism that removes excess protein aggregates and damaged intracellular components. Most eukaryotic cells, including neurons, rely on proficient mitophagy responses to fine-tune the mitochondrial number and preserve energy metabolism. In some circumstances (such as the presence of pathogenic protein oligopolymers and protein mutations), dysfunctional mitophagy leads to nerve degeneration, with age-dependent intracellular accumulation of protein aggregates and dysfunctional organelles, leading to neurodegenerative disease. However, when pathogenic protein oligopolymers, protein mutations, stress, or injury are present, mitophagy prevents the accumulation of damaged mitochondria. Accordingly, mitophagy mediates neuroprotective effects in some forms of neurodegenerative disease (e.g., Alzheimer's disease, Parkinson’s disease, Huntington's disease, and Amyotrophic lateral sclerosis) and acute brain damage (e.g., stroke, hypoxic–ischemic brain injury, epilepsy, and traumatic brain injury). The complex interplay between mitophagy and neurological disorders suggests that targeting mitophagy might be applicable for the treatment of neurodegenerative diseases and acute brain injury. However, due to the complexity of the mitophagy mechanism, mitophagy can be both harmful and beneficial, and future efforts should focus on maximizing its benefits. Here, we discuss the impact of mitophagy on neurological disorders, emphasizing the contrast between the positive and negative effects of mitophagy.},
	journal = {Journal of Neuroinflammation},
	author = {Zhang, Lijun and Dai, Lei and Li, Deyuan},
	month = dec,
	year = {2021},
}

@article{tricoli_reciprocity_2017,
	title = {Reciprocity relation for the vector radiative transport equation and its application to diffuse optical tomography with polarized light},
	volume = {42},
	copyright = {\&\#169; 2017 Optical Society of America},
	issn = {1539-4794},
	url = {https://opg.optica.org/ol/abstract.cfm?uri=ol-42-2-362},
	doi = {10.1364/OL.42.000362},
	abstract = {We derive a reciprocity relation for the 3D vector radiative transport equation that describes propagation of polarized light in multiple-scattering media. We then show how this result, together with translational invariance of a plane-parallel sample, can be used to efficiently compute the sensitivity kernel of diffuse optical tomography by Monte Carlo simulations. Numerical examples of polarization-selective sensitivity kernels are given.},
	language = {EN},
	number = {2},
	urldate = {2022-08-15},
	journal = {Optics Letters},
	author = {Tricoli, Ugo and Macdonald, Callum M. and Silva, Anabela Da and Markel, Vadim A.},
	month = jan,
	year = {2017},
	pages = {362--365},
}

@article{hernandez-alvarez_mitochondrial_2021,
	title = {Mitochondrial {Dynamics} and {Liver} {Cancer}},
	volume = {13},
	doi = {10.3390/cancers13112571},
	abstract = {Hepatocellular carcinoma (HCC) is the most prevalent primary liver cancer. Due to its rising incidence and limited therapeutic options, HCC has become a leading cause of cancer-related death worldwide, accounting for 85\% of all deaths due to primary liver cancers. Standard therapy for advanced-stage HCC is based on anti-angiogenic drugs such as sorafenib and, more recently, lenvatinib and regorafenib as a second line of treatment. The identification of novel therapeutic strategies is urgently required. Mitochondrial dynamics describes a group of processes that includes the movement of mitochondria along the cytoskeleton, the regulation of mitochondrial morphology and distribution, and connectivity mediated by tethering and fusion/fission events. In recent years, mitochondrial dynamic processes have emerged as key processes in the maintenance of liver mitochondrial homeostasis. In addition, some data are accumulating on the role played by mitochondrial dynamics during cancer development, and specifically on how such dynamics act directly on tumor cells or indirectly on cells responsible for tumor aggression and defense. Here, we review the data that suggest mitochondrial dynamics to be involved in the development of liver tumors.},
	journal = {Cancers},
	author = {Hernández-Alvarez, María and Zorzano, Antonio},
	month = may,
	year = {2021},
	pages = {2571},
}

@article{gonzalez_glucose_2022,
	title = {Glucose metabolism and {AD}: evidence for a potential diabetes type 3},
	volume = {14},
	shorttitle = {Glucose metabolism and {AD}},
	doi = {10.1186/s13195-022-00996-8},
	abstract = {Background
Alzheimer’s disease is the most prevalent cause of dementia in the elderly. Neuronal death and synaptic dysfunctions are considered the main hallmarks of this disease. The latter could be directly associated to an impaired metabolism. In particular, glucose metabolism impairment has demonstrated to be a key regulatory element in the onset and progression of AD, which is why nowadays AD is considered the type 3 diabetes.

Methods
We provide a thread regarding the influence of glucose metabolism in AD from three different perspectives: (i) as a regulator of the energy source, (ii) through several metabolic alterations, such as insulin resistance, that modify peripheral signaling pathways that influence activation of the immune system (e.g., insulin resistance, diabetes, etc.), and (iii) as modulators of various key post-translational modifications for protein aggregation, for example, influence on tau hyperphosphorylation and other important modifications, which determine its self-aggregating behavior and hence Alzheimer’s pathogenesis.

Conclusions
In this revision, we observed a 3 edge-action in which glucose metabolism impairment is acting in the progression of AD: as blockade of energy source (e.g., mitochondrial dysfunction), through metabolic dysregulation and post-translational modifications in key proteins, such as tau. Therefore, the latter would sustain the current hypothesis that AD is, in fact, the novel diabetes type 3.},
	journal = {Alzheimer's Research \& Therapy},
	author = {Gonzalez, Andrea and Calfio, Camila and Churruca, Macarena and Maccioni, Ricardo},
	month = apr,
	year = {2022},
}

@inproceedings{khoo_whats_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {What’s {Next}? {Predicting} {Hamiltonian} {Dynamics} from {Discrete} {Observations} of a {Vector} {Field}},
	isbn = {9783031124266},
	shorttitle = {What’s {Next}?},
	doi = {10.1007/978-3-031-12426-6_27},
	abstract = {We present several methods for predicting the dynamics of Hamiltonian systems from discrete observation of their vector field. Each method is either informed or uninformed of the Hamiltonian property. We empirically and comparatively evaluate the methods and observe that information that the system is Hamiltonian can be effectively informed, and that different methods strike different trade-offs between efficiency and effectiveness for different dynamical systems.},
	language = {en},
	booktitle = {Database and {Expert} {Systems} {Applications}},
	publisher = {Springer International Publishing},
	author = {Khoo, Zi-Yu and Zhang, Delong and Bressan, Stéphane},
	editor = {Strauss, Christine and Cuzzocrea, Alfredo and Kotsis, Gabriele and Tjoa, A. Min and Khalil, Ismail},
	year = {2022},
	keywords = {Data analysis, Inductive bias, Learning bias, Physics-informed neural network, Trajectory prediction},
	pages = {297--302},
}

@article{li_reference-guided_2022,
	title = {Reference-{Guided} {Landmark} {Image} {Inpainting} with {Deep} {Feature} {Matching}},
	issn = {1558-2205},
	doi = {10.1109/TCSVT.2022.3193893},
	abstract = {Despite impressive progress made by recent image inpainting methods, they often fail to predict the original content when the corrupted region contains unique structures, especially for landmark images. Applying similar images as a reference is helpful but introduces a style gap of textures, resulting in color misalignment. To this end, we propose a style-robust approach for reference-guided landmark image inpainting, taking advantage of both the representation power of learned deep features and the structural prior from the reference image. By matching deep features, our approach builds style-robust nearest-neighbor mapping vector fields between the corrupted and reference images, in which the loss of information due to corruption leads to mismatched mapping vectors. To correct these mismatched mapping vectors based on the relationship between the uncorrupted and corrupted regions, we introduce mutual nearest neighbors as reliable anchors and interpolate around these anchors progressively. Finally, based on the corrected mapping vector fields, we propose a two-step warping strategy to complete the corrupted image, utilizing the reference image as a structural “blueprint”, avoiding the style misalignment problem. Extensive experiments show that our approach effectively and robustly assists image inpainting methods in restoring unique structures in the corrupted image.},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {Li, Jiacheng and Xiong, Zhiwei and Liu, Dong},
	year = {2022},
	keywords = {Boolean functions, Correlation, Data structures, Feature extraction, Image Inpainting, Image Restoration, Image Synthesis, Image color analysis, Image restoration, Task analysis},
	pages = {1--1},
}

@article{ullah_robust_2022,
	title = {A {Robust} {Convolutional} {Neural} {Network} for {6D} {Object} {Pose} {Estimation} from {RGB} {Image} with {Distance} {Regularization} {Voting} {Loss}},
	volume = {2022},
	issn = {1058-9244},
	url = {https://www.hindawi.com/journals/sp/2022/2037141/},
	doi = {10.1155/2022/2037141},
	abstract = {Six-degree (6D) pose estimation of objects is important for robot manipulation but at the same time challenging when dealing with occluded and textureless objects. To overcome this challenge, the proposed method presents an end-to-end robust network for real-time 6D pose estimation of rigid objects using the RGB image. In this proposed method, a fully convolutional network with a features pyramid is developed that effectively boosts the accuracy of pixelwise labeling and direction unit vector field that take part in the voting process for object keypoints estimation. The network further takes into account measuring the distance between pixel and keypoint, which aims to help select accurate hypotheses in the RANSAC process. This avoids hypothesis deviations caused by the errors due to direction unit vectors in cases of distant pixels from keypoints. A vectorial distance regularization loss function is used to help Perspective-n-Point find 2D-3D correspondences between 3D object keypoints and their estimated corresponding 2D counterparts. Experiments are performed on widely used LINEMOD and occlusion LINEMOD datasets with ADD (-S) and 2D projection evaluation metrics. The results show that our method improves pose estimation performance compared to the state-of-the-art while still achieving real-time efficiency.},
	language = {en},
	urldate = {2022-08-12},
	journal = {Scientific Programming},
	author = {Ullah, Faheem and Wei, Wu and Daradkeh, Yousef Ibrahim and Javed, Muhammad and Rabbi, Ihsan and Al Juaid, Hanan},
	month = aug,
	year = {2022},
	pages = {e2037141},
}

@misc{noauthor_vector_2019,
	title = {Vector {Field} {Neural} {Networks}},
	url = {https://deepai.org/publication/vector-field-neural-networks},
	abstract = {05/16/19 - This work begins by establishing a mathematical formalization between
different geometrical interpretations of Neural Networks, pr...},
	urldate = {2022-08-12},
	journal = {DeepAI},
	month = may,
	year = {2019},
}

@book{dasoulas_lipschitz_2021,
	title = {Lipschitz {Normalization} for {Self}-{Attention} {Layers} with {Application} to {Graph} {Neural} {Networks}},
	abstract = {Attention based neural networks are state of the art in a large range of applications. However, their performance tends to degrade when the number of layers increases. In this work, we show that enforcing Lipschitz continuity by normalizing the attention scores can significantly improve the performance of deep attention models. First, we show that, for deep graph attention networks (GAT), gradient explosion appears during training, leading to poor performance of gradient-based training algorithms. To address this issue, we derive a theoretical analysis of the Lipschitz continuity of attention modules and introduce LipschitzNorm, a simple and parameter-free normalization for self-attention mechanisms that enforces the model to be Lipschitz continuous. We then apply Lips-chitzNorm to GAT and Graph Transformers and show that their performance is substantially improved in the deep setting (10 to 30 layers). More specifically, we show that a deep GAT model with LipschitzNorm achieves state of the art results for node label prediction tasks that exhibit long-range dependencies, while showing consistent improvements over their unnormalized counterparts in benchmark node classification tasks.},
	author = {Dasoulas, George and Scaman, Kevin and Virmaux, Aladin},
	month = sep,
	year = {2021},
}

@article{yao_learning_2021,
	title = {Learning {Deep} {Lucas}-{Kanade} {Siamese} {Network} for {Visual} {Tracking}},
	volume = {PP},
	doi = {10.1109/TIP.2021.3076272},
	abstract = {In most recent years, Siamese trackers have drawn great attention because of their well-balanced accuracy and efficiency. Although these approaches have achieved great success, the discriminative power of the conventional Siamese trackers is still limited by the insufficient template-candidate representation. Most of the existing approaches take non-aligned features to learn a similarity function for template-candidate matching, while the target object's geometrical transformation is seldom explored. To address this problem, we propose a novel Siamese tracking framework, which enables to dynamically transform the template-candidate features to a more discriminative viewpoint for similarity matching. Specifically, we reformulate the template-candidate matching problem of the conventional Siamese tracker from the perspective of Lucas-Kanade (LK) image alignment approach. A Lucas-Kanade network (LKNet) is proposed and incorporated to the Siamese architecture to learn aligned feature representations in data-driven trainable manner, which is able to enhance the model adaptability in challenging scenarios. Within this framework, we propose two Siamese trackers named LK-Siam and LK-SiamRPN to validate the effectiveness. Extensive experiments conducted on the prevalent datasets show that the proposed method is more competitive over a number of state-of-the-art methods.},
	journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
	author = {Yao, Siyuan and Han, Xiaoguang and Zhang, Hua and Wang, Xiao and Cao, Xiaochun},
	month = may,
	year = {2021},
}

@article{yao_robust_2021,
	title = {Robust {Online} {Tracking} via {Contrastive} {Spatio}-{Temporal} {Aware} {Network}},
	volume = {PP},
	doi = {10.1109/TIP.2021.3050314},
	abstract = {Existing tracking-by-detection approaches using deep features have achieved promising results in recent years. However, these methods mainly exploit feature representations learned from individual static frames, thus paying little attention to the temporal smoothness between frames. This easily leads trackers to drift in the presence of large appearance variations and occlusions. To address this issue, we propose a two-stream network to learn discriminative spatio-temporal feature representations to represent the target objects. The proposed network consists of a Spatial ConvNet module and a Temporal ConvNet module. Specifically, the Spatial ConvNet adopts 2D convolutions to encode the target-specific appearance in static frames, while the Temporal ConvNet models the temporal appearance variations using 3D convolutions and learns consistent temporal patterns in a short video clip. Then we propose a proposal refinement module to adjust the predicted bounding box, which can make the target localizing outputs to be more consistent in video sequences. In addition, to improve the model adaptation during online update, we propose a contrastive online hard example mining (OHEM) strategy, which selects hard negative samples and enforces them to be embedded in a more discriminative feature space. Extensive experiments conducted on the OTB, Temple Color and VOT benchmarks demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods.},
	journal = {IEEE Transactions on Image Processing},
	author = {Yao, Siyuan and Zhang, Hua and Ren, Wenqi and Ma, Chao and Han, Xiaoguang and Cao, Xiaochun},
	month = jan,
	year = {2021},
	pages = {1--1},
}

@article{hu_real-time_2018,
	title = {Real-time video fire smoke detection by utilizing spatial-temporal {ConvNet} features},
	volume = {77},
	doi = {10.1007/s11042-018-5978-5},
	abstract = {Fire is one of the most dangerous disasters threatening human life and property globally. In order to reduce fire losses, researches on video analysis for early smoke detection have become particularly significant. However, it is still a challenging task to extract stable features for smoke recognition, largely due to its variations in color, shapes and texture. Classical convolutional neural networks can automatically learn feature representations of appearance from a single frame but fail to capture motion information between frames. For addressing this issue, in this paper, we propose a spatial-temporal based convolutional neural network for video smoke detection, and for real-time detection, propose an enhanced architecture, which utilizes a multitask learning strategy to jointly recognize smoke and estimate optical flow, capturing intra-frame appearance features and inter-frame motion features simultaneously. The effectiveness and efficiency of our proposed method is validated by experiments carried out on our self-created dataset, which achieves 97.0\% detection rate and 3.5\% false alarm rate with processing time of 5ms per frame, obviously outperforming existing methods.},
	journal = {Multimedia Tools and Applications},
	author = {Hu, Yaocong and Lu, Xiaobo},
	month = nov,
	year = {2018},
}

@article{riegler_octnet_2016,
	title = {{OctNet}: {Learning} {Deep} {3D} {Representations} at {High} {Resolutions}},
	shorttitle = {{OctNet}},
	abstract = {We present OctNet, a representation for deep learning with sparse 3D data. In contrast to existing models, our representation enables 3D convolutional networks which are both deep and high resolution. Towards this goal, we exploit the sparsity in the input data to hierarchically partition the space using a set of unbalanced octrees where each leaf node stores a pooled feature representation. This allows to focus memory allocation and computation to the relevant dense regions and enables deeper networks without compromising resolution. We demonstrate the utility of our OctNet representation by analyzing the impact of resolution on several 3D tasks including 3D object classification, orientation estimation and point cloud labeling.},
	author = {Riegler, Gernot and Ulusoy, Ali and Geiger, Andreas},
	month = nov,
	year = {2016},
}

@book{choy_4d_2019,
	title = {{4D} {Spatio}-{Temporal} {ConvNets}: {Minkowski} {Convolutional} {Neural} {Networks}},
	shorttitle = {{4D} {Spatio}-{Temporal} {ConvNets}},
	author = {Choy, Chris and Gwak, JunYoung and Savarese, Silvio},
	month = jun,
	year = {2019},
	doi = {10.1109/CVPR.2019.00319},
}

@misc{simonyan_deep_2014,
	title = {Deep {Inside} {Convolutional} {Networks}: {Visualising} {Image} {Classification} {Models} and {Saliency} {Maps}},
	shorttitle = {Deep {Inside} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1312.6034},
	doi = {10.48550/arXiv.1312.6034},
	abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].},
	urldate = {2022-08-08},
	publisher = {arXiv},
	author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	month = apr,
	year = {2014},
	note = {arXiv:1312.6034 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{noauthor_xai_2022,
	title = {{XAI} {Examples}},
	copyright = {BSD-3-Clause},
	url = {https://github.com/viadee/xai_examples},
	abstract = {Things that call for explanations...},
	urldate = {2022-08-08},
	publisher = {viadee IT-Unternehmensberatung AG},
	month = jan,
	year = {2022},
	note = {original-date: 2019-03-04T09:55:38Z},
	keywords = {explainable-ai, machine-learning},
}

@book{barredo_arrieta_explainable_2019,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, {Taxonomies}, {Opportunities} and {Challenges} toward {Responsible} {AI}},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	abstract = {In the last years, Artificial Intelligence (AI) has achieved a notable momentum that may deliver the best of expectations over many application sectors across the field. For this to occur, the entire community stands in front of the barrier of explainability, an inherent problem of AI techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI. Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is acknowledged as a crucial feature for the practical deployment of AI models. This overview examines the existing literature in the field of XAI, including a prospect toward what is yet to be reached. We summarize previous efforts to define explainability in Machine Learning, establishing a novel definition that covers prior conceptual propositions with a major focus on the audience for which explainability is sought. We then propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at Deep Learning methods for which a second taxonomy is built. This literature analysis serves as the background for a series of challenges faced by XAI, such as the crossroads between data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to XAI with a reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.},
	author = {Barredo Arrieta, Alejandro and Diaz Rodriguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado González, Alberto and García, Salvador and Gil-López, Sergio and Molina, Daniel and Benjamins, V. Richard and Chatila, Raja and Herrera, Francisco},
	month = oct,
	year = {2019},
}

@misc{rames_multiplexed_2022,
	title = {Multiplexed and millimeter-scale superresolution imaging of cells and tissue sections via prism-illumination and microfluidics-enhanced {DNA}-{PAINT}},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.08.07.503091v1},
	doi = {10.1101/2022.08.07.503091},
	abstract = {Superresolution microscopy (SRM) has become an enabling tool for biomedical research. A major limitation of SRM, however, is the small field-of-view (FOV), typically {\textasciitilde}50μm x 50μm and up to {\textasciitilde}200μm x 200μm in recent attempts, hampering its use in imaging large cell populations or clinical tissues. Here we report PRism-Illumination and Microfluidics-Enhanced DNA-PAINT (PRIME-PAINT) for efficient, multiplexed SRM across millimeter-scale FOVs. Unlike existing SRM, PRIME-PAINT uses prism-type illumination for robust DNA-PAINT with single FOVs up to {\textasciitilde}0.5mm x 0.5mm. Through stitching, imaging {\textgreater}1 mm2 FOVs can be completed in as little as an hour per target. The on-stage microfluidics not only facilitates multiplexing but enhances image quality, particularly for tissue sections. We demonstrate the utility of PRIME-PAINT by analyzing {\textasciitilde}106 caveolae structures in {\textasciitilde}1,000 cells and imaging entire pancreatic cancer lesions from patient tissue biopsies. Thus, we expect PRIME-PAINT to be useful toward building multiscale, Google-Earth-like views of biological systems.},
	language = {en},
	urldate = {2022-08-08},
	publisher = {bioRxiv},
	author = {Rames, Matthew J. and Kenison, John and Heineck, Daniel and Civitci, Fehmi and Szczepaniak, Malwina and Tao, Kai and Zheng, Ting and Shangguan, Julia and Esener, Sadik and Nan, Xiaolin},
	month = aug,
	year = {2022},
}

@article{qiu_light-activated_2022,
	title = {Light-activated mitochondrial fission through optogenetic control of mitochondria-lysosome contacts},
	volume = {13},
	doi = {10.1038/s41467-022-31970-5},
	abstract = {Mitochondria are highly dynamic organelles whose fragmentation by fission is critical to their functional integrity and cellular homeostasis. Here, we develop a method via optogenetic control of mitochondria–lysosome contacts (MLCs) to induce mitochondrial fission with spatiotemporal accuracy. MLCs can be achieved by blue-light-induced association of mitochondria and lysosomes through various photoactivatable dimerizers. Real-time optogenetic induction of mitochondrial fission is tracked in living cells to measure the fission rate. The optogenetic method partially restores the mitochondrial functions of SLC25A46−/− cells, which display defects in mitochondrial fission and hyperfused mitochondria. The optogenetic MLCs system thus provides a platform for studying mitochondrial fission and treating mitochondrial diseases. Existing methods can lack spatiotemporal accuracy to manipulate dynamic mitochondrial behaviour in live cells. Here the authors report an optogenetic method to control mitochondria-lysosome contacts and induce mitochondrial fission; they use photoactivatable dimerizers including CRY2/CIB and SspB/iLID.},
	journal = {Nature Communications},
	author = {Qiu, Kangqiang and Zou, Weiwei and Fang, Hongbao and Hao, Mingang and Mehta, Kritika and Tian, Zhiqi and Guan, Jun-Lin and Zhang, Kai and Huang, Taosheng and Diao, Jiajie},
	month = jul,
	year = {2022},
	pages = {4303},
}

@misc{noauthor_statistical_nodate,
	title = {Statistical shape analysis of brain arterial networks ({BAN})},
	url = {https://projecteuclid.org/journals/annals-of-applied-statistics/volume-16/issue-2/Statistical-shape-analysis-of-brain-arterial-networks-BAN/10.1214/21-AOAS1536.short},
	urldate = {2022-08-02},
}

@book{moon_difficulty-aware_2022,
	title = {Difficulty-{Aware} {Simulator} for {Open} {Set} {Recognition}},
	abstract = {Open set recognition (OSR) assumes unknown instances appear out of the blue at the inference time. The main challenge of OSR is that the response of models for unknowns is totally unpredictable. Furthermore, the diversity of open set makes it harder since instances have different difficulty levels. Therefore, we present a novel framework, DIfficulty-Aware Simulator (DIAS), that generates fakes with diverse difficulty levels to simulate the real world. We first investigate fakes from generative adversarial network (GAN) in the classifier's viewpoint and observe that these are not severely challenging. This leads us to define the criteria for difficulty by regarding samples generated with GANs having moderate-difficulty. To produce hard-difficulty examples, we introduce Copycat, imitating the behavior of the classifier. Furthermore, moderate- and easy-difficulty samples are also yielded by our modified GAN and Copycat, respectively. As a result, DIAS outperforms state-of-the-art methods with both metrics of AUROC and F-score. Our code is available at https://github.com/wjun0830/Difficulty-Aware-Simulator.},
	author = {Moon, Won Jun and Park, Junho and Seong, Hyun and Cho, Cheol-Ho and Heo, Jae-Pil},
	month = jul,
	year = {2022},
	doi = {10.48550/arXiv.2207.10024},
}

@book{moon_tailoring_2022,
	title = {Tailoring {Self}-{Supervision} for {Supervised} {Learning}},
	abstract = {Recently, it is shown that deploying a proper self-supervision is a prospective way to enhance the performance of supervised learning. Yet, the benefits of self-supervision are not fully exploited as previous pretext tasks are specialized for unsupervised representation learning. To this end, we begin by presenting three desirable properties for such auxiliary tasks to assist the supervised objective. First, the tasks need to guide the model to learn rich features. Second, the transformations involved in the self-supervision should not significantly alter the training distribution. Third, the tasks are preferred to be light and generic for high applicability to prior arts. Subsequently, to show how existing pretext tasks can fulfill these and be tailored for supervised learning, we propose a simple auxiliary self-supervision task, predicting localizable rotation (LoRot). Our exhaustive experiments validate the merits of LoRot as a pretext task tailored for supervised learning in terms of robustness and generalization capability. Our code is available at https://github.com/wjun0830/Localizable-Rotation.},
	author = {Moon, Won Jun and Kim, Ji-Hwan and Heo, Jae-Pil},
	month = jul,
	year = {2022},
	doi = {10.48550/arXiv.2207.10023},
}

@book{paredes-valles_self-supervised_2021,
	title = {Self-{Supervised} {Learning} of {Event}-{Based} {Optical} {Flow} with {Spiking} {Neural} {Networks}},
	abstract = {Neuromorphic sensing and computing hold a promise for highly energy-efficient and high-bandwidth-sensor processing. A major challenge for neuromorphic computing is that learning algorithms for traditional artificial neural networks (ANNs) do not transfer directly to spiking neural networks (SNNs) due to the discrete spikes and more complex neuronal dynamics. As a consequence, SNNs have not yet been successfully applied to complex, large-scale tasks. In this article, we focus on the self-supervised learning problem of optical flow estimation from event-based camera inputs, and investigate the changes that are necessary to the state-of-the-art ANN training pipeline in order to successfully tackle it with SNNs. More specifically, we first modify the input event representation to encode a much smaller time slice with minimal explicit temporal information. Consequently, we make the network's neuronal dynamics and recurrent connections responsible for integrating information over time. Moreover, we reformulate the self-supervised loss function for event-based optical flow to improve its convexity. We perform experiments with various types of recurrent ANNs and SNNs using the proposed pipeline. Concerning SNNs, we investigate the effects of elements such as parameter initialization and optimization, surrogate gradient shape, and adaptive neuronal mechanisms. We find that initialization and surrogate gradient width play a crucial part in enabling learning with sparse inputs, while the inclusion of adaptivity and learnable neuronal parameters can improve performance. We show that the performance of the proposed ANNs and SNNs are on par with that of the current state-of-the-art ANNs trained in a self-supervised manner.},
	author = {Paredes-Vallés, Federico and Hagenaars, Jesse and Croon, Guido},
	month = jun,
	year = {2021},
}

@article{li_kernel_2022,
	title = {Kernel {Dependence} {Regularizers} and {Gaussian} {Processes} with {Applications} to {Algorithmic} {Fairness}},
	doi = {10.1016/j.patcog.2022.108922},
	abstract = {Current adoption of machine learning in industrial, societal and economical activities has raised concerns about the fairness, equity and ethics of automated decisions. Predictive models are often developed using biased datasets and thus retain or even exacerbate biases in their decisions and recommendations. Removing the sensitive covariates, such as gender or race, is insufficient to remedy this issue since the biases may be retained due to other related covariates. We present a regularization approach to this problem that trades off predictive accuracy of the learned models (with respect to biased labels) for the fairness in terms of statistical parity, i.e. independence of the decisions from the sensitive covariates. In particular, we consider a general framework of regularized empirical risk minimization over reproducing kernel Hilbert spaces and impose an additional regularizer of dependence between predictors and sensitive covariates using kernel-based measures of dependence, namely the Hilbert-Schmidt Independence Criterion (HSIC) and its normalized version. This approach leads to a closed-form solution in the case of squared loss, i.e. ridge regression. We also provide statistical consistency results for both risk and fairness bound for our approach. Moreover, we show that the dependence regularizer has an interpretation as modifying the corresponding Gaussian process (GP) prior. As a consequence, a GP model with a prior that encourages fairness to sensitive variables can be derived, allowing principled hyperparameter selection and studying of the relative relevance of covariates under fairness constraints. Experimental results in synthetic examples and in real problems of income and crime prediction illustrate the potential of the approach to improve fairness of automated decisions.},
	journal = {Pattern Recognition},
	author = {Li, Zhu and Pérez-Suay, Adrián and Camps-Valls, Gustau and Sejdinovic, Dino},
	month = jul,
	year = {2022},
	pages = {108922},
}

@book{quan_amplification_2022,
	title = {On the amplification of security and privacy risks by post-hoc explanations in machine learning models},
	abstract = {A variety of explanation methods have been proposed in recent years to help users gain insights into the results returned by neural networks, which are otherwise complex and opaque black-boxes. However, explanations give rise to potential side-channels that can be leveraged by an adversary for mounting attacks on the system. In particular, post-hoc explanation methods that highlight input dimensions according to their importance or relevance to the result also leak information that weakens security and privacy. In this work, we perform the first systematic characterization of the privacy and security risks arising from various popular explanation techniques. First, we propose novel explanation-guided black-box evasion attacks that lead to 10 times reduction in query count for the same success rate. We show that the adversarial advantage from explanations can be quantified as a reduction in the total variance of the estimated gradient. Second, we revisit the membership information leaked by common explanations. Contrary to observations in prior studies, via our modified attacks we show significant leakage of membership information (above 100\% improvement over prior results), even in a much stricter black-box setting. Finally, we study explanation-guided model extraction attacks and demonstrate adversarial gains through a large reduction in query count.},
	author = {Quan, Pengrui and Chakraborty, Supriyo and Jeyakumar, Jeya Vikranth and Srivastava, Mani},
	month = jun,
	year = {2022},
	doi = {10.48550/arXiv.2206.14004},
}

@book{yang_omnixai_2022,
	title = {{OmniXAI}: {A} {Library} for {Explainable} {AI}},
	shorttitle = {{OmniXAI}},
	abstract = {We introduce OmniXAI, an open-source Python library of eXplainable AI (XAI), which offers omni-way explainable AI capabilities and various interpretable machine learning techniques to address the pain points of understanding and interpreting the decisions made by machine learning (ML) in practice. OmniXAI aims to be a one-stop comprehensive library that makes explainable AI easy for data scientists, ML researchers and practitioners who need explanation for various types of data, models and explanation methods at different stages of ML process (data exploration, feature engineering, model development, evaluation, and decision-making, etc). In particular, our library includes a rich family of explanation methods integrated in a unified interface, which supports multiple data types (tabular data, images, texts, time-series), multiple types of ML models (traditional ML in Scikit-learn and deep learning models in PyTorch/TensorFlow), and a range of diverse explanation methods including "model-specific" and "model-agnostic" ones (such as feature-attribution explanation, counterfactual explanation, gradient-based explanation, etc). For practitioners, the library provides an easy-to-use unified interface to generate the explanations for their applications by only writing a few lines of codes, and also a GUI dashboard for visualization of different explanations for more insights about decisions. In this technical report, we present OmniXAI's design principles, system architectures, and major functionalities, and also demonstrate several example use cases across different types of data, tasks, and models.},
	author = {Yang, Wenzhuo and Le, Hung and Savarese, Silvio and Hoi, Steven},
	month = jun,
	year = {2022},
}

@book{alikhademi_can_2021,
	title = {Can {Explainable} {AI} {Explain} {Unfairness}? {A} {Framework} for {Evaluating} {Explainable} {AI}},
	shorttitle = {Can {Explainable} {AI} {Explain} {Unfairness}?},
	abstract = {Many ML models are opaque to humans, producing decisions too complex for humans to easily understand. In response, explainable artificial intelligence (XAI) tools that analyze the inner workings of a model have been created. Despite these tools' strength in translating model behavior, critiques have raised concerns about the impact of XAI tools as a tool for `fairwashing` by misleading users into trusting biased or incorrect models. In this paper, we created a framework for evaluating explainable AI tools with respect to their capabilities for detecting and addressing issues of bias and fairness as well as their capacity to communicate these results to their users clearly. We found that despite their capabilities in simplifying and explaining model behavior, many prominent XAI tools lack features that could be critical in detecting bias. Developers can use our framework to suggest modifications needed in their toolkits to reduce issues likes fairwashing.},
	author = {Alikhademi, Kiana and Richardson, Brianna and Drobina, Emma and Gilbert, Juan},
	month = jun,
	year = {2021},
}

@inproceedings{ehsan_human-centered_2022,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '22},
	title = {Human-{Centered} {Explainable} {AI} ({HCXAI}): {Beyond} {Opening} the {Black}-{Box} of {AI}},
	isbn = {9781450391566},
	shorttitle = {Human-{Centered} {Explainable} {AI} ({HCXAI})},
	url = {https://doi.org/10.1145/3491101.3503727},
	doi = {10.1145/3491101.3503727},
	abstract = {Explainability of AI systems is crucial to hold them accountable because they are increasingly becoming consequential in our lives by powering high-stakes decisions in domains like healthcare and law. When it comes to Explainable AI (XAI), understanding who interacts with the black-box of AI is just as important as “opening” it, if not more. Yet the discourse of XAI has been predominantly centered around the black-box, suffering from deficiencies in meeting user needs and exacerbating issues of algorithmic opacity. To address these issues, researchers have called for human-centered approaches to XAI. In this second CHI workshop on Human-centered XAI (HCXAI), we build on the success of the first installment from CHI 2021 to expand the conversation around XAI. We chart the domain and shape the HCXAI discourse with reflective discussions from diverse stakeholders. The goal of the second installment is to go beyond the black box and examine how human-centered perspectives in XAI can be operationalized at the conceptual, methodological, and technical levels. Encouraging holistic (historical, sociological, and technical) approaches, we put an emphasis on “operationalizing”, aiming to produce actionable frameworks, transferable evaluation methods, concrete design guidelines, and articulate a coordinated research agenda for XAI.},
	urldate = {2022-07-29},
	booktitle = {Extended {Abstracts} of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ehsan, Upol and Wintersberger, Philipp and Liao, Q. Vera and Watkins, Elizabeth Anne and Manger, Carina and Daumé III, Hal and Riener, Andreas and Riedl, Mark O},
	month = apr,
	year = {2022},
	keywords = {Algorithmic Fairness, Artificial Intelligence, Explainable Artificial Intelligence, Interpretability, Interpretable Machine Learning, Responsible AI, Trust in Automation},
	pages = {1--7},
}

@article{wright_fever_2020,
	title = {Fever and {Fever} of {Unknown} {Origin} ({FUO}): review, recent advances, and lingering dogma},
	volume = {7},
	shorttitle = {Fever and {Fever} of {Unknown} {Origin} ({FUO})},
	doi = {10.1093/ofid/ofaa132},
	abstract = {Fever has preoccupied physicians since the earliest days of clinical medicine. It has been the subject of scrutiny in recent decades. Historical convention has mostly determined that 37.0°C (98.6°F) should be regarded as normal body temperature, and more modern evidence suggests fever is a complex physiological response involving the innate immune system and should not be characterized merely as a temperature above this threshold. Fever of unknown origin (FUO) was first defined in 1961 by Petersdorf and Beeson and continues to be a clinical challenge for physicians. Although clinicians may have some understandings of the history of clinical thermometry, how average body temperatures were established, thermoregulation, and pathophysiology of fever, new concepts are emerging. While FUO subgroups and etiologic classifications have remained unchanged since 1991 revisions, the spectrum of diseases, clinical approach to diagnosis and management are changing. This review considers how newer data should influence both definitions and lingering dogmatic principles. Despite recent advances and newer imaging techniques such as 18FDG-PET, clinical judgment remains an essential component of care.},
	journal = {Open Forum Infectious Diseases},
	author = {Wright, William and Auwaerter, Paul},
	month = may,
	year = {2020},
}

@incollection{yunlong_generator_2021,
	title = {Generator {Versus} {Segmentor}: {Pseudo}-healthy {Synthesis}},
	isbn = {9783030872304},
	shorttitle = {Generator {Versus} {Segmentor}},
	abstract = {This paper investigates the problem of pseudo-healthy synthesis that is defined as synthesizing a subject-specific pathology-free image from a pathological one. Recent approaches based on Generative Adversarial Network (GAN) have been developed for this task. However, these methods will inevitably fall into the trade-off between preserving the subject-specific identity and generating healthy-like appearances. To overcome this challenge, we propose a novel adversarial training regime, Generator versus Segmentor (GVS), to alleviate this trade-off by a divide-and-conquer strategy. We further consider the deteriorating generalization performance of the segmentor throughout the training and develop a pixel-wise weighted loss by muting the well-transformed pixels to promote it. Moreover, we propose a new metric to measure how healthy the synthetic images look. The qualitative and quantitative experiments on the public dataset BraTS demonstrate that the proposed method outperforms the existing methods. Besides, we also certify the effectiveness of our method on datasets LiTS. Our implementation and pre-trained networks are publicly available at https://github.com/Au3C2/Generator-Versus-Segmentor.},
	author = {Yunlong, Zhang and Li, Chenxin and Lin, Xin and Sun, Liyan and Zhuang, Yihong and Huang, Yue and Ding, Xinghao and Liu, Xiaoqing and Yu, Yizhou},
	month = sep,
	year = {2021},
	doi = {10.1007/978-3-030-87231-1_15},
	pages = {150--160},
}

@article{noauthor_mapping_2022,
	title = {Mapping molecular complexes with super-resolution microscopy and single-particle analysis},
	volume = {12},
	doi = {10.1098/rsob.220079},
	abstract = {Understanding the structure of supramolecular complexes provides insight into their functional capabilities and how they can be modulated in the context of disease. Super-resolution microscopy (SRM) excels in performing this task by resolving ultrastructural details at the nanoscale with molecular specificity. However, technical limitations, such as underlabelling, preclude its ability to provide complete structures. Single-particle analysis (SPA) overcomes this limitation by combining information from multiple images of identical structures and producing an averaged model, effectively enhancing the resolution and coverage of image reconstructions. This review highlights important studies using SRM–SPA, demonstrating how it broadens our knowledge by elucidating features of key biological structures with unprecedented detail.},
	journal = {Open Biology},
	month = jul,
	year = {2022},
}

@article{lanoye_using_2021,
	title = {Using measured resting metabolic rate to derive calorie prescriptions in a behavioral weight loss program},
	volume = {7},
	doi = {10.1002/osp4.489},
	abstract = {Objective
Within behavioral weight loss (BWL) programs, using measured resting metabolic rate (RMR) is a more accurate—yet costlier—alternative to the standard method of assigning calorie prescriptions using baseline weight. This investigation aimed to assess differences between calorie goals prescribed using each method including demographic predictors and associations with weight loss.

Methods
This is an ancillary study to a trial comparing approaches to motivational enhancement in a 6‐month BWL program designed for emerging adults age 18‐25 (N=308). RMR was measured at baseline and used to derive calorie prescriptions; standard calorie goals were retrospectively assigned for the purpose of these analyses.

Results
Standard calorie prescriptions were significantly higher than those derived from RMR. Sex and race were significant predictors of calorie prescription discrepancies: using the standard method, women and Black participants were assigned higher calorie goals than their RMR would indicate. Calorie goal discrepancy did not predict 6‐month weight change.

Conclusions
Differences in calorie prescriptions between approaches were significant; however, it remains to be determined whether measuring RMR is worth the cost, time, and participant burden. It may be the case that this consideration has greater impact for certain subgroups—namely, women and Black participants.
This article is protected by copyright. All rights reserved.},
	journal = {Obesity Science \& Practice},
	author = {Lanoye, Autumn and Evans, Ronald and Leahey, Tricia and LaRose, Jessica},
	month = feb,
	year = {2021},
}

@article{fanelli_depression_2022,
	title = {Depression, antidepressants, and insulin resistance: which link?},
	volume = {60},
	shorttitle = {Depression, antidepressants, and insulin resistance},
	doi = {10.1016/j.euroneuro.2022.04.011},
	abstract = {Major depressive disorder (MDD) and diseases linked to insulin resistance (IR), including obesity, type 2 diabetes mellitus (T2DM), and metabolic syndrome, are among the leading causes of disability worldwide, and their incidence continues to grow to epidemic proportions. A number of epidemiological studies have shown that the risk of IR-related diseases is higher among patients with MDD and, in turn, T2DM and obesity have up to 4-fold higher risk of MDD. MDD has also been linked to a reduction in life expectancy of up to 14 years, and IR-related somatic diseases may account for this significantly. Also, the comorbidity of depression with T2DM results in a 54\% higher mortality, and IR-related comorbidities in MDD have been associated with higher depression severity, chronicity, and worse treatment outcomes (Hamer et al., 2019; Semenkovich et al., 2015). These observations call for urgent action by …},
	journal = {European Neuropsychopharmacology},
	author = {Fanelli, Giuseppe and Serretti, Alessandro},
	month = jul,
	year = {2022},
	pages = {4--6},
}

@article{mejhert_understanding_2022,
	title = {Understanding the complexity of insulin resistance},
	volume = {18},
	doi = {10.1038/s41574-022-00648-9},
	abstract = {Nelson and colleagues compare whole body, skeletal muscle and white adipose tissue insulin resistance in inbred mouse strains fed a chow or a Western diet. They report large strain-related differences in diet-induced effects on weight gain and insulin action, and demonstrate that tissue-specific insulin sensitivity can be disentangled from systemic insulin resistance.},
	journal = {Nature Reviews Endocrinology},
	author = {Mejhert, Niklas and Rydén, Mikael},
	month = feb,
	year = {2022},
	pages = {1--2},
}

@article{carmichael_is_2022,
	title = {Is vascular insulin resistance an early step in diet-induced whole-body insulin resistance?},
	volume = {12},
	doi = {10.1038/s41387-022-00209-z},
	abstract = {There is increasing evidence that skeletal muscle microvascular (capillary) blood flow plays an important role in glucose metabolism by increasing the delivery of glucose and insulin to the myocytes. This process is impaired in insulin-resistant individuals. Studies suggest that in diet-induced insulin-resistant rodents, insulin-mediated skeletal muscle microvascular blood flow is impaired post-short-term high fat feeding, and this occurs before the development of myocyte or whole-body insulin resistance. These data suggest that impaired skeletal muscle microvascular blood flow is an early vascular step before the onset of insulin resistance. However, evidence of this is still lacking in humans. In this review, we summarise what is known about short-term high-calorie and/or high-fat feeding in humans. We also explore selected animal studies to identify potential mechanisms. We discuss future directions aimed at better understanding the ‘early’ vascular mechanisms that lead to insulin resistance as this will provide the opportunity for much earlier screening and timing of intervention to assist in preventing type 2 diabetes.},
	journal = {Nutrition \& Diabetes},
	author = {Carmichael, Lauren and Keske, Michelle and Betik, Andrew and Parker, Lewan and Brayner, Barbara and Roberts-Thomson, Katherine and Wadley, Glenn and Hamilton, David and Kaur, Gunveen},
	month = jun,
	year = {2022},
	pages = {31},
}

@article{noauthor_plant_2021,
	title = {Plant cytoskeletons and the endoplasmic reticulum network organization},
	volume = {264},
	issn = {0176-1617},
	url = {https://www.sciencedirect.com/science/article/pii/S0176161721001127},
	doi = {10.1016/j.jplph.2021.153473},
	abstract = {Plant endoplasmic reticulum (ER) remodelling is likely to be important for its function in targeted protein secretion, organelle interaction and signa…},
	language = {en},
	urldate = {2022-07-27},
	journal = {Journal of Plant Physiology},
	month = sep,
	year = {2021},
	pages = {153473},
}

@article{noauthor_mobile_2021,
	title = {Mobile late endosomes modulate peripheral endoplasmic reticulum network architecture},
	volume = {22},
	issn = {1469-221X},
	url = {https://www.embopress.org/doi/full/10.15252/embr.202050815},
	doi = {10.15252/embr.202050815},
	abstract = {Abstract The endoplasmic reticulum (ER) is the largest organelle contacting virtually every other organelle for information exchange and control of processes such as transport, fusion, and fission. Here, we studied the role of the other organelles on ER network architecture in the cell periphery. We show that the co-migration of the ER with other organelles, called ER hitchhiking facilitated by late endosomes and lysosomes is a major mechanism controlling ER network architecture. When hitchhiking occurs, emerging ER structures may fuse with the existing ER tubules to alter the local ER architecture. This couples late endosomal/lysosomal positioning and mobility to ER network architecture. Conditions restricting late endosomal movement?including cell starvation?or the depletion of tether proteins that link the ER to late endosomes reduce ER dynamics and limit the complexity of the peripheral ER network architecture. This indicates that among many factors, the ER is controlled by late endosomal movement resulting in an alteration of the ER network architecture.},
	number = {3},
	urldate = {2022-07-27},
	journal = {EMBO reports},
	month = mar,
	year = {2021},
	keywords = {endoplasmic reticulum, late endosomes, membrane contact sites, organelle hitchhiking, starvation},
	pages = {e50815},
}

@article{thamer_high_2009,
	title = {High {Baseline} {Vitamin} {C} {Levels} {Do} {Not} {Prevent} a {Positive} {Outcome} of a {Lifestyle} {Intervention}},
	volume = {32},
	doi = {10.2337/dc09-0965},
	abstract = {Reactive oxygen species (ROS) generated by oxidative stress induced by physical activity are important mediators responsible for adaptive processes in skeletal muscle (1). ROS induce the production of myokines (muscle-derived cytokines) that mediate systemic metabolic effects (1) and induce an increase in the expression of genes involved in mitochondrial biogenesis (2). Therefore, the oxidative stress induced by exercise may play an important role in the cellular responses occurring within skeletal muscle after training.

Supplementation with the antioxidant vitamin C pharmacologically inhibits positive effects of exercise on the parameters of glucose metabolism (3). However, these data conflict with the finding that high levels of vitamin C also reduce the risk of type 2 diabetes (4). Therefore, we …},
	journal = {Diabetes care},
	author = {Thamer, Claus and Machicao, Fausto and Stefan, Norbert and Fritsche, Andreas and Häring, Hans-Ulrich},
	month = oct,
	year = {2009},
	pages = {e112},
}

@misc{noauthor_alexander_nodate,
	title = {Alexander {Schmeding}},
	url = {https://www.researchgate.net/profile/Alexander-Schmeding},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2022-07-27},
	journal = {ResearchGate},
}

@misc{noauthor_balancing_nodate,
	title = {Balancing energy and protein homeostasis at {ER}-mitochondria contact sites},
	url = {https://www.science.org/doi/full/10.1126/scisignal.abm7524?casa_token=5-DnvYx2-8IAAAAA%3AGDpyUc_Vir0-UFxbEd22iU216hTCGXuMIhApPKCu713In46KaDVm2wNoNGd0eu9HAFjamHslqejtgxQ},
	urldate = {2022-07-27},
}

@article{miskei_fuzziness_2017,
	title = {Fuzziness enables context dependence of protein interactions},
	volume = {591},
	copyright = {© 2017 Federation of European Biochemical Societies},
	issn = {1873-3468},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/1873-3468.12762},
	doi = {10.1002/1873-3468.12762},
	abstract = {Proteins may undergo adaptive structural transitions to accommodate to their cellular milieu and respond to external signals. Modulation of conformational ensembles can rewire the intra- or intermolecular interaction networks and shift between different functional states. Adaptive conformational transitions are associated with protein fuzziness, which enables (a) rewiring interaction networks via alternative motifs, (b) new functional features via allosteric motifs, (c) functional switches upon post-translational modifications, or (d) regulation of higher-order organizations. We propose that all these context-dependent functional changes are intertwined with structural multiplicity or dynamic disorder in protein assemblies and can only be described by stochastic structure–function relationships.},
	language = {en},
	number = {17},
	urldate = {2022-07-27},
	journal = {FEBS Letters},
	author = {Miskei, Marton and Gregus, Andrea and Sharma, Rashmi and Duro, Norbert and Zsolyomi, Fruzsina and Fuxreiter, Monika},
	year = {2017},
	keywords = {fuzzy complex, intrinsically disordered proteins, protein interactions},
	pages = {2682--2695},
}

@misc{celledoni_deep_2022,
	title = {Deep learning of diffeomorphisms for optimal reparametrizations of shapes},
	url = {http://arxiv.org/abs/2207.11141},
	doi = {10.48550/arXiv.2207.11141},
	abstract = {In shape analysis, one of the fundamental problems is to align curves or surfaces before computing a (geodesic) distance between these shapes. To find the optimal reparametrization realizing this alignment is a computationally demanding task which leads to an optimization problem on the diffeomorphism group. In this paper, we construct approximations of orientation-preserving diffeomorphisms by composition of elementary diffeomorphisms to solve the approximation problem. We propose a practical algorithm implemented in PyTorch which is applicable both to unparametrized curves and surfaces. We derive universal approximation results and obtain bounds for the Lipschitz constant of the obtained compositions of diffeomorphisms.},
	urldate = {2022-07-27},
	publisher = {arXiv},
	author = {Celledoni, Elena and Glöckner, Helge and Riseth, Jørgen and Schmeding, Alexander},
	month = jul,
	year = {2022},
	note = {arXiv:2207.11141 [cs, math]},
	keywords = {65K10, 58D05, 46T10, Computer Science - Machine Learning, Mathematics - Differential Geometry, Mathematics - Optimization and Control},
}

@misc{lavinas_component-wise_2022,
	title = {Component-wise {Analysis} of {Automatically} {Designed} {Multiobjective} {Algorithms} on {Constrained} {Problems}},
	url = {http://arxiv.org/abs/2203.13447},
	doi = {10.48550/arXiv.2203.13447},
	abstract = {The performance of multiobjective algorithms varies across problems, making it hard to develop new algorithms or apply existing ones to new problems. To simplify the development and application of new multiobjective algorithms, there has been an increasing interest in their automatic design from component parts. These automatically designed metaheuristics can outperform their human-developed counterparts. However, it is still uncertain what are the most influential components leading to their performance improvement. This study introduces a new methodology to investigate the effects of the final configuration of an automatically designed algorithm. We apply this methodology to a well-performing Multiobjective Evolutionary Algorithm Based on Decomposition (MOEA/D) designed by the irace package on nine constrained problems. We then contrast the impact of the algorithm components in terms of their Search Trajectory Networks (STNs), the diversity of the population, and the hypervolume. Our results indicate that the most influential components were the restart and update strategies, with higher increments in performance and more distinct metric values. Also, their relative influence depends on the problem difficulty: not using the restart strategy was more influential in problems where MOEA/D performs better; while the update strategy was more influential in problems where MOEA/D performs the worst.},
	urldate = {2022-07-25},
	publisher = {arXiv},
	author = {Lavinas, Yuri and Ladeira, Marcelo and Ochoa, Gabriela and Aranha, Claus},
	month = jul,
	year = {2022},
	note = {arXiv:2203.13447 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@misc{bezanson_julia_2015,
	title = {Julia: {A} {Fresh} {Approach} to {Numerical} {Computing}},
	shorttitle = {Julia},
	url = {http://arxiv.org/abs/1411.1607},
	doi = {10.48550/arXiv.1411.1607},
	abstract = {Bridging cultures that have often been distant, Julia combines expertise from the diverse fields of computer science and computational science to create a new approach to numerical computing. Julia is designed to be easy and fast. Julia questions notions generally held as "laws of nature" by practitioners of numerical computing: 1. High-level dynamic programs have to be slow. 2. One must prototype in one language and then rewrite in another language for speed or deployment, and 3. There are parts of a system for the programmer, and other parts best left untouched as they are built by the experts. We introduce the Julia programming language and its design --- a dance between specialization and abstraction. Specialization allows for custom treatment. Multiple dispatch, a technique from computer science, picks the right algorithm for the right circumstance. Abstraction, what good computation is really about, recognizes what remains the same after differences are stripped away. Abstractions in mathematics are captured as code through another technique from computer science, generic programming. Julia shows that one can have machine performance without sacrificing human convenience.},
	urldate = {2022-07-24},
	publisher = {arXiv},
	author = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B.},
	month = jul,
	year = {2015},
	note = {arXiv:1411.1607 [cs]},
	keywords = {Computer Science - Mathematical Software},
}

@book{mao_beyond_2022,
	title = {Beyond single receptive field: {A} receptive field fusion-and-stratification network for airborne laser scanning point cloud classification},
	shorttitle = {Beyond single receptive field},
	abstract = {The classification of airborne laser scanning (ALS) point clouds is a critical task of remote sensing and photogrammetry fields. Although recent deep learning-based methods have achieved satisfactory performance, they have ignored the unicity of the receptive field, which makes the ALS point cloud classification remain challenging for the distinguishment of the areas with complex structures and extreme scale variations. In this article, for the objective of configuring multi-receptive field features, we propose a novel receptive field fusion-and-stratification network (RFFS-Net). With a novel dilated graph convolution (DGConv) and its extension annular dilated convolution (ADConv) as basic building blocks, the receptive field fusion process is implemented with the dilated and annular graph fusion (DAGFusion) module, which obtains multi-receptive field feature representation through capturing dilated and annular graphs with various receptive regions. The stratification of the receptive fields with point sets of different resolutions as the calculation bases is performed with Multi-level Decoders nested in RFFS-Net and driven by the multi-level receptive field aggregation loss (MRFALoss) to drive the network to learn in the direction of the supervision labels with different resolutions. With receptive field fusion-and-stratification, RFFS-Net is more adaptable to the classification of regions with complex structures and extreme scale variations in large-scale ALS point clouds. Evaluated on the ISPRS Vaihingen 3D dataset, our RFFS-Net significantly outperforms the baseline approach by 5.3\% on mF1 and 5.4\% on mIoU, accomplishing an overall accuracy of 82.1\%, an mF1 of 71.6\%, and an mIoU of 58.2\%. Furthermore, experiments on the LASDU dataset and the 2019 IEEE-GRSS Data Fusion Contest dataset show that RFFS-Net achieves a new state-of-the-art classification performance.},
	author = {Mao, Yongqiang and Chen, Kaiqiang and Wenhui, Diao and Sun, Xian and Lu, Xiaonan and Fu, Kun and Weinmann, Martin},
	month = jul,
	year = {2022},
}

@article{thi_predicting_2022,
	title = {Predicting compound-protein interaction using hierarchical graph convolutional networks},
	volume = {17},
	doi = {10.1371/journal.pone.0258628},
	abstract = {Motivation
Convolutional neural networks have enabled unprecedented breakthroughs in a variety of computer vision tasks. They have also drawn much attention from other domains, including drug discovery and drug development. In this study, we develop a computational method based on convolutional neural networks to tackle a fundamental question in drug discovery and development, i.e. the prediction of compound-protein interactions based on compound structure and protein sequence. We propose a hierarchical graph convolutional network (HGCN) to encode small molecules. The HGCN aggregates a molecule embedding from substructure embeddings, which are synthesized from atom embeddings. As small molecules usually share substructures, computing a molecule embedding from those common substructures allows us to learn better generic models. We then combined the HGCN with a one-dimensional convolutional network to construct a complete model for predicting compound-protein interactions. Furthermore we apply an explanation technique, Grad-CAM, to visualize the contribution of each amino acid into the prediction.

Results
Experiments using different datasets show the improvement of our model compared to other GCN-based methods and a sequence based method, DeepDTA, in predicting compound-protein interactions. Each prediction made by the model is also explainable and can be used to identify critical residues mediating the interaction.},
	journal = {PLOS ONE},
	author = {Thi, Danh and Rivière, Emmanuel and Meysman, Pieter and Laukens, Kris},
	month = jul,
	year = {2022},
	pages = {e0258628},
}

@book{wiedeman_decorrelative_2022,
	title = {Decorrelative {Network} {Architecture} for {Robust} {Electrocardiogram} {Classification}},
	abstract = {Artificial intelligence has made great progresses in medical data analysis, but the lack of robustness and interpretability has kept these methods from being widely deployed. In particular, data-driven models are vulnerable to adversarial attacks, which are small, targeted perturbations that dramatically degrade model performance. As a recent example, while deep learning has shown impressive performance in electrocardiogram (ECG) classification, Han et al. crafted realistic perturbations that fooled the network 74\% of the time [2020]. Current adversarial defense paradigms are computationally intensive and impractical for many high dimensional problems. Previous research indicates that a network vulnerability is related to the features learned during training. We propose a novel approach based on ensemble decorrelation and Fourier partitioning for training parallel network arms into a decorrelated architecture to learn complementary features, significantly reducing the chance of a perturbation fooling all arms of the deep learning model. We test our approach in ECG classification, demonstrating a much-improved 77.2\% chance of at least one correct network arm on the strongest adversarial attack tested, in contrast to a 21.7\% chance from a comparable ensemble. Our approach does not require expensive optimization with adversarial samples, and thus can be scaled to large problems. These methods can easily be applied to other tasks for improved network robustness.},
	author = {Wiedeman, Christopher and Wang, Ge},
	month = jul,
	year = {2022},
	doi = {10.48550/arXiv.2207.09031},
}

@article{killackey_mitochondrial_2022,
	title = {Mitochondrial protein import stress regulates the {LC3} lipidation step of mitophagy through {NLRX1} and {RRBP1}},
	doi = {10.1016/j.molcel.2022.06.004},
	abstract = {Protein import into mitochondria is a highly regulated process, yet how cells clear mitochondria undergoing dysfunctional protein import remains poorly characterized. Here we showed that mitochondrial protein import stress (MPIS) triggers localized LC3 lipidation. This arm of the mitophagy pathway occurs through the Nod-like receptor (NLR) protein NLRX1 while, surprisingly, without the engagement of the canonical mitophagy protein PINK1. Mitochondrial depolarization, which itself induces MPIS, also required NLRX1 for LC3 lipidation. While normally targeted to the mitochondrial matrix, cytosol-retained NLRX1 recruited RRBP1, a ribosome-binding transmembrane protein of the endoplasmic reticulum, which relocated to the mitochondrial vicinity during MPIS, and the NLRX1/RRBP1 complex in turn controlled the recruitment and lipidation of LC3. Furthermore, NLRX1 controlled skeletal muscle mitophagy in vivo and regulated endurance capacity during exercise. Thus, localization and lipidation of LC3 at the site of mitophagosome formation is a regulated step of mitophagy controlled by NLRX1/RRBP1 in response to MPIS.},
	journal = {Molecular Cell},
	author = {Killackey, Samuel and Bi, Yuntian and Soares, Fraser and Hammi, Ikram and Winsor, Nathaniel and Abdul-Sater, Ali and Romero-Gallo, Judith and Arnoult, Damien and Girardin, Stephen},
	month = jun,
	year = {2022},
}

@article{edwards_developing_2022,
	title = {The {Developing} {Human} {Connectome} {Project} {Neonatal} {Data} {Release}},
	volume = {16},
	doi = {10.3389/fnins.2022.886772},
	abstract = {The Developing Human Connectome Project has created a large open science resource which provides researchers with data for investigating typical and atypical brain development across the perinatal period. It has collected 1228 multimodal magnetic resonance imaging (MRI) brain datasets from 1173 fetal and/or neonatal participants, together with collateral demographic, clinical, family, neurocognitive and genomic data from 1173 participants, together with collateral demographic, clinical, family, neurocognitive and genomic data. All subjects were studied in utero and/or soon after birth on a single MRI scanner using specially developed scanning sequences which included novel motion-tolerant imaging methods. Imaging data are complemented by rich demographic, clinical, neurodevelopmental, and genomic information. The project is now releasing a large set of neonatal data; fetal data will be described and released separately. This release includes scans from 783 infants of whom: 583 were healthy infants born at term; as well as preterm infants; and infants at high risk of atypical neurocognitive development. Many infants were imaged more than once to provide longitudinal data, and the total number of datasets being released is 887. We now describe the dHCP image acquisition and processing protocols, summarize the available imaging and collateral data, and provide information on how the data can be accessed.},
	journal = {Frontiers in Neuroscience},
	author = {Edwards, David and Rueckert, Daniel and Smith, Stephen and Seada, Samy and Alansary, Amir and Almalbis, Jennifer and Allsop, Joanna and Andersson, Jesper and Arichi, Tomoki and Arulkumaran, Sophie and Bastiani, Matteo and Batalle, Dafnis and Baxter, Luke and Bozek, Jelena and Braithwaite, Eleanor and Brandon, Jacqueline and Carney, Olivia and Chew, Andrew and Christiaens, Daan and Hajnal, Joseph},
	month = may,
	year = {2022},
}

@misc{chundawat_zero-shot_2022,
	title = {Zero-{Shot} {Machine} {Unlearning}},
	url = {http://arxiv.org/abs/2201.05629},
	doi = {10.48550/arXiv.2201.05629},
	abstract = {Modern privacy regulations grant citizens the right to be forgotten by products, services and companies. In case of machine learning (ML) applications, this necessitates deletion of data not only from storage archives but also from ML models. Due to an increasing need for regulatory compliance required for ML applications, machine unlearning is becoming an emerging research problem. The right to be forgotten requests come in the form of removal of a certain set or class of data from the already trained ML model. Practical considerations preclude retraining of the model from scratch minus the deleted data. The few existing studies use either the whole training data, or a subset of training data, or some metadata stored during training to update the model weights for unlearning. However, strict regulatory compliance requires time-bound deletion of data. Thus, in many cases, no data related to the training process or training samples may be accessible even for the unlearning purpose. We therefore ask the question: is it possible to achieve unlearning with zero training samples? In this paper, we introduce the novel problem of zero-shot machine unlearning that caters for the extreme but practical scenario where zero original data samples are available for use. We then propose two novel solutions for zero-shot machine unlearning based on (a) error minimizing-maximizing noise and (b) gated knowledge transfer. These methods remove the information of the forget data from the model while maintaining the model efficacy on the retain data. The zero-shot approach offers good protection against the model inversion attacks and membership inference attacks. We introduce a new evaluation metric, Anamnesis Index (AIN) to effectively measure the quality of the unlearning method. The experiments show promising results for unlearning in deep learning models on benchmark vision data-sets.},
	urldate = {2022-07-16},
	publisher = {arXiv},
	author = {Chundawat, Vikram S. and Tarun, Ayush K. and Mandal, Murari and Kankanhalli, Mohan},
	month = jul,
	year = {2022},
	note = {arXiv:2201.05629 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{grafton_deep_nodate,
	title = {Deep learning detects cardiotoxicity in a high-content screen with induced pluripotent stem cell-derived cardiomyocytes},
	volume = {10},
	issn = {2050-084X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8367386/},
	doi = {10.7554/eLife.68714},
	abstract = {Drug-induced cardiotoxicity and hepatotoxicity are major causes of drug attrition. To decrease late-stage drug attrition, pharmaceutical and biotechnology industries need to establish biologically relevant models that use phenotypic screening to detect drug-induced toxicity in vitro. In this study, we sought to rapidly detect patterns of cardiotoxicity using high-content image analysis with deep learning and induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs). We screened a library of 1280 bioactive compounds and identified those with potential cardiotoxic liabilities in iPSC-CMs using a single-parameter score based on deep learning. Compounds demonstrating cardiotoxicity in iPSC-CMs included DNA intercalators, ion channel blockers, epidermal growth factor receptor, cyclin-dependent kinase, and multi-kinase inhibitors. We also screened a diverse library of molecules with unknown targets and identified chemical frameworks that show cardiotoxic signal in iPSC-CMs. By using this screening approach during target discovery and lead optimization, we can de-risk early-stage drug discovery. We show that the broad applicability of combining deep learning with iPSC technology is an effective way to interrogate cellular phenotypes and identify drugs that may protect against diseased phenotypes and deleterious mutations.},
	urldate = {2022-07-13},
	journal = {eLife},
	author = {Grafton, Francis and Ho, Jaclyn and Ranjbarvaziri, Sara and Farshidfar, Farshad and Budan, Anastasiia and Steltzer, Stephanie and Maddah, Mahnaz and Loewke, Kevin E and Green, Kristina and Patel, Snahel and Hoey, Tim and Mandegar, Mohammad Ali},
	pmid = {34338636},
	pmcid = {PMC8367386},
	pages = {e68714},
}

@article{balasubramaniam_tutorial_2022,
	title = {Tutorial on the {Use} of {Deep} {Learning} in {Diffuse} {Optical} {Tomography}},
	volume = {11},
	doi = {10.3390/electronics11030305},
	abstract = {Diffuse optical tomography using deep learning is an emerging technology that has found impressive medical diagnostic applications. However, creating an optical imaging system that uses visible and near-infrared (NIR) light is not straightforward due to photon absorption and multi-scattering by tissues. The high distortion levels caused due to these effects make the image reconstruction incredibly challenging. To overcome these challenges, various techniques have been proposed in the past, with varying success. One of the most successful techniques is the application of deep learning algorithms in diffuse optical tomography. This article discusses the current state-of-the-art diffuse optical tomography systems and comprehensively reviews the deep learning algorithms used in image reconstruction. This article attempts to provide researchers with the necessary background and tools to implement deep learning methods to solve diffuse optical tomography.},
	journal = {Electronics},
	author = {Balasubramaniam, Ganesh Muthukumaran and Wiesel, Ben and Biton, Netanel and Kumar, Rajnish and Kupferman, Judy and Arnon, Shlomi},
	month = jan,
	year = {2022},
	pages = {305},
}

@book{wilmott_mathematics_1995,
	title = {The mathematics of financial derivatives: a student introduction},
	shorttitle = {The mathematics of financial derivatives},
	publisher = {Cambridge university press},
	author = {Wilmott, Paul and Howson, Susan and Howison, Sam and Dewynne, Jeff},
	year = {1995},
}

@article{altieri_mitochondrial_2019,
	title = {Mitochondrial dynamics and metastasis},
	volume = {76},
	doi = {10.1007/s00018-018-2961-2},
	abstract = {Changes in cellular metabolism are now a recognized hallmark of cancer. Although this process is ripe with therapeutic potential in the clinic, its complexity and extraordinary plasticity have systematically defied dogmas and oversimplifications. Perhaps, best exemplifying this intricacy is the role of mitochondria in cancer, which in just a few years has gone from largely unnoticed to pivotal disease driver. The underlying mechanisms are only beginning to emerge. However, there is now clear evidence linking the dynamic nature of mitochondria to the machinery of tumor cell motility and metastatic spreading. These studies may open fresh therapeutic options for patients with disseminated cancer, currently an incurable and mostly lethal condition.},
	journal = {Cellular and Molecular Life Sciences},
	author = {Altieri, Dario},
	month = mar,
	year = {2019},
}

@article{norambuena_novel_2019,
	title = {A {Novel} {Communication} {Pathway} {Between} {Lysosomes} and {Mitochondria} {Is} {Disrupted} in {Alzheimer}’s {Disease}},
	volume = {2},
	doi = {10.1177/2515256419865859},
	abstract = {A growing body of evidence supports the idea that organelles talk to each other. This communication is characterized by either physical interactions, functional associations mediated by signaling molecules, or both. This flow of information allows the orchestration of proper cellular metabolic responses to the ever-changing extracellular environment. Mitochondria, the cell’s principle metabolic factories, have emerged as a major player that not only influence the functions of other organelles, such as the endoplasmic reticulum, nuclei, and lysosomes, but as recently shown by our group, mitochondria also receive functionally critical information from lysosomes. This process was found to be mediated by the lysosome-associated mechanistic target of rapamycin complex 1, another major regulator of cellular metabolism. As discussed here, disruption of this lysosome-to-mitochondria signaling pathway may underlie the early pathogenesis of Alzheimer’s disease.},
	journal = {Contact},
	author = {Norambuena, Andrés and Bloom, George},
	month = jan,
	year = {2019},
	pages = {251525641986585},
}

@article{anderson_dysregulation_2018,
	title = {Dysregulation of mitochondrial dynamics proteins are a targetable feature of human tumors},
	volume = {9},
	doi = {10.1038/s41467-018-04033-x},
	abstract = {Altered mitochondrial dynamics can broadly impact tumor cell physiology. Using genetic and pharmacological profiling of cancer cell lines and human tumors, we here establish that perturbations to the mitochondrial dynamics network also result in specific therapeutic vulnerabilities. In particular, through distinct mechanisms, tumors with increased mitochondrial fragmentation or connectivity are hypersensitive to SMAC mimetics, a class of compounds that induce apoptosis through inhibition of IAPs and for which robust sensitivity biomarkers remain to be identified. Further, because driver oncogenes exert dominant control over mitochondrial dynamics, oncogene-targeted therapies can be used to sensitize tumors to SMAC mimetics via their effects on fission/fusion dynamics. Collectively, these data demonstrate that perturbations to the mitochondrial dynamics network induce targetable vulnerabilities across diverse human tumors and, more broadly, suggest that the altered structures, activities, and trafficking of cellular organelles may facilitate additional cancer therapeutic opportunities.},
	journal = {Nature Communications},
	author = {Anderson, Gray and Wardell, Suzanne and Cakir, Merve and Yip, Catherine and Ahn, Yeong-ran and Ali, Moiez and Yllanes, Alexander and Chao, Christina and Mcdonnell, Donald and Wood, Kris},
	month = apr,
	year = {2018},
}

@book{raykov_introduction_2008,
	address = {New York},
	title = {An {Introduction} to {Applied} {Multivariate} {Analysis}},
	isbn = {9780429235078},
	abstract = {This comprehensive text introduces readers to the most commonly used multivariate techniques at an introductory, non-technical level. By focusing on the fundamentals, readers are better prepared for more advanced applied pursuits, particularly on topics that are most critical to the behavioral, social, and educational sciences. Analogies betwe},
	publisher = {Routledge},
	author = {Raykov, Tenko and Marcoulides, George A.},
	month = mar,
	year = {2008},
	doi = {10.4324/9780203809532},
}

@article{meli_scoring_2022,
	title = {Scoring {Functions} for {Protein}-{Ligand} {Binding} {Affinity} {Prediction} {Using} {Structure}-based {Deep} {Learning}: {A} {Review}},
	volume = {2},
	issn = {2673-7647},
	shorttitle = {Scoring {Functions} for {Protein}-{Ligand} {Binding} {Affinity} {Prediction} {Using} {Structure}-based {Deep} {Learning}},
	url = {https://www.frontiersin.org/article/10.3389/fbinf.2022.885983},
	abstract = {The rapid and accurate in silico prediction of protein-ligand binding free energies or binding affinities has the potential to transform drug discovery. In recent years, there has been a rapid growth of interest in deep learning methods for the prediction of protein-ligand binding affinities based on the structural information of protein-ligand complexes. These structure-based scoring functions often obtain better results than classical scoring functions when applied within their applicability domain. Here we review structure-based scoring functions for binding affinity prediction based on deep learning, focussing on different types of architectures, featurization strategies, data sets, methods for training and evaluation, and the role of explainable artificial intelligence in building useful models for real drug-discovery applications.},
	urldate = {2022-06-19},
	journal = {Frontiers in Bioinformatics},
	author = {Meli, Rocco and Morris, Garrett M. and Biggin, Philip C.},
	year = {2022},
}

@article{andreatta_how_2021,
	title = {How neurons adjust to diurnality},
	volume = {10},
	doi = {10.7554/eLife.74704},
	abstract = {Being active during the day requires a slow-closing ion channel that dampens the activity of neurons in a specific area of the brain.},
	journal = {eLife},
	author = {Andreatta, Gabriele and Allen, Charles},
	month = nov,
	year = {2021},
}

@article{perez-nieves_neural_2021,
	title = {Neural heterogeneity promotes robust learning},
	volume = {12},
	doi = {10.1038/s41467-021-26022-3},
	abstract = {The brain is a hugely diverse, heterogeneous structure. Whether or not heterogeneity at the neural level plays a functional role remains unclear, and has been relatively little explored in models which are often highly homogeneous. We compared the performance of spiking neural networks trained to carry out tasks of real-world difficulty, with varying degrees of heterogeneity, and found that heterogeneity substantially improved task performance. Learning with heterogeneity was more stable and robust, particularly for tasks with a rich temporal structure. In addition, the distribution of neuronal parameters in the trained networks is similar to those observed experimentally. We suggest that the heterogeneity observed in the brain may be more than just the byproduct of noisy processes, but rather may serve an active and important role in allowing animals to learn in changing environments. The authors show that heterogeneity in spiking neural networks improves accuracy and robustness of prediction for complex information processing tasks, results in optimal parameter distribution similar to experimental data and is metabolically efficient for learning tasks at varying timescales.},
	journal = {Nature Communications},
	author = {Perez-Nieves, Nicolas and Leung, Vincent and Dragotti, Pier and Goodman, Dan},
	month = oct,
	year = {2021},
	pages = {5791},
}

@misc{taylor_accelerating_2022,
	title = {Accelerating spiking neural network training},
	url = {http://arxiv.org/abs/2205.15286},
	doi = {10.48550/arXiv.2205.15286},
	abstract = {Spiking neural networks (SNN) are a type of artificial network inspired by the use of action potentials in the brain. There is a growing interest in emulating these networks on neuromorphic computers due to their improved energy consumption and speed, which are the main scaling issues of their counterpart the artificial neural network (ANN). Significant progress has been made in directly training SNNs to perform on par with ANNs in terms of accuracy. These methods are however slow due to their sequential nature, leading to long training times. We propose a new technique for directly training single-spike-per-neuron SNNs which eliminates all sequential computation and relies exclusively on vectorised operations. We demonstrate over a \${\textbackslash}times 10\$ speedup in training with robust classification performance on real datasets of low to medium spatio-temporal complexity (Fashion-MNIST and Neuromophic-MNIST). Our proposed solution manages to solve certain tasks with over a \$95.68 {\textbackslash}\%\$ reduction in spike counts relative to a conventionally trained SNN, which could significantly reduce energy requirements when deployed on neuromorphic computers.},
	urldate = {2022-06-19},
	publisher = {arXiv},
	author = {Taylor, Luke and King, Andrew and Harper, Nicol},
	month = may,
	year = {2022},
	note = {arXiv:2205.15286 [cs]},
	keywords = {Computer Science - Neural and Evolutionary Computing},
}

@article{nunes_spiking_2022,
	title = {Spiking {Neural} {Networks}: {A} {Survey}},
	volume = {10},
	shorttitle = {Spiking {Neural} {Networks}},
	abstract = {The field of Deep Learning (DL) has seen a remarkable series of developments with increasingly accurate
and robust algorithms. However, the increase in performance has been accompanied by an increase in
the parameters, complexity, and training time of the models, which means that we are rapidly reaching
a point where DL may no longer be feasible. On the other hand, some specific applications need to be
carefully considered when developing DL models due to hardware limitations or power requirements. In
this context, there is a growing interest in efficient DL algorithms, with Spiking Neural Networks (SNNs)
being one of the most promising paradigms. Due to the inherent asynchrony and sparseness of spike trains,
these types of networks have the potential to reduce power consumption while maintaining relatively good
performance. This is attractive for efficient DL and if successful, could replace traditional Artificial Neural
Networks (ANNs) in many applications. However, despite significant progress, the performance of SNNs
on benchmark datasets is often lower than that of traditional ANNs. Moreover, due to the non-differentiable
nature of their activation functions, it is difficult to train SNNs with direct backpropagation, so appropriate
training strategies must be found. Nevertheless, significant efforts have been made to develop competitive
models. This survey covers the main ideas behind SNNs and reviews recent trends in learning rules and
network architectures, with a particular focus on biologically inspired strategies. It also provides some
practical considerations of state-of-the-art SNNs and discusses relevant research opportunities.},
	journal = {IEEE Access},
	author = {Nunes, João and Carvalho, Marcelo and Carneiro, Diogo and Cardoso, Jaime},
	month = jun,
	year = {2022},
}

@book{pinkard_visual_2022,
	title = {A visual introduction to information theory},
	abstract = {Though originally developed for communications engineering, information theory contains mathematical tools with numerous applications in science and engineering. These tools can be used to characterize the fundamental limits of data compression and transmission in the presence of noise. Here, we present a practical guide to key concepts in information theory, focusing on intuitions and providing visual explanations wherever possible. Our presentation assumes only a familiarity with basic probability theory.},
	author = {Pinkard, Henry and Waller, Laura},
	month = jun,
	year = {2022},
	doi = {10.48550/arXiv.2206.07867},
}

@article{metzner_dynamics_2022,
	title = {Dynamics and {Information} {Import} in {Recurrent} {Neural} {Networks}},
	volume = {16},
	issn = {1662-5188},
	url = {https://www.frontiersin.org/article/10.3389/fncom.2022.876315},
	abstract = {Recurrent neural networks (RNNs) are complex dynamical systems, capable of ongoing activity without any driving input. The long-term behavior of free-running RNNs, described by periodic, chaotic and fixed point attractors, is controlled by the statistics of the neural connection weights, such as the density d of non-zero connections, or the balance b between excitatory and inhibitory connections. However, for information processing purposes, RNNs need to receive external input signals, and it is not clear which of the dynamical regimes is optimal for this information import. We use both the average correlations C and the mutual information I between the momentary input vector and the next system state vector as quantitative measures of information import and analyze their dependence on the balance and density of the network. Remarkably, both resulting phase diagrams C(b, d) and I(b, d) are highly consistent, pointing to a link between the dynamical systems and the information-processing approach to complex systems. Information import is maximal not at the “edge of chaos,” which is optimally suited for computation, but surprisingly in the low-density chaotic regime and at the border between the chaotic and fixed point regime. Moreover, we find a completely new type of resonance phenomenon, which we call “Import Resonance” (IR), where the information import shows a maximum, i.e., a peak-like dependence on the coupling strength between the RNN and its external input. IR complements previously found Recurrence Resonance (RR), where correlation and mutual information of successive system states peak for a certain amplitude of noise added to the system. Both IR and RR can be exploited to optimize information processing in artificial neural networks and might also play a crucial role in biological neural systems.},
	urldate = {2022-06-18},
	journal = {Frontiers in Computational Neuroscience},
	author = {Metzner, Claus and Krauss, Patrick},
	year = {2022},
}

@misc{noauthor_learning_nodate,
	title = {Learning {Disentangled} {Representations} in the {Imaging} {Domain} - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841522001633},
	urldate = {2022-06-18},
}

@article{sarrami-foroushani_-silico_2021,
	title = {In-silico trial of intracranial flow diverters replicates and expands insights from conventional clinical trials},
	volume = {12},
	doi = {10.1038/s41467-021-23998-w},
	abstract = {The cost of clinical trials is ever-increasing. In-silico trials rely on virtual populations and interventions simulated using patient-specific models and may offer a solution to lower these costs. We present the flow diverter performance assessment (FD-PASS) in-silico trial, which models the treatment of intracranial aneurysms in 164 virtual patients with 82 distinct anatomies with a flow-diverting stent, using computational fluid dynamics to quantify post-treatment flow reduction. The predicted FD-PASS flow-diversion success rates replicate the values previously reported in three clinical trials. The in-silico approach allows broader investigation of factors associated with insufficient flow reduction than feasible in a conventional trial. Our findings demonstrate that in-silico trials of endovascular medical devices can: (i) replicate findings of conventional clinical trials, and (ii) perform virtual experiments and sub-group analyses that are difficult or impossible in conventional trials to discover new insights on treatment failure, e.g. in the presence of side-branches or hypertension.},
	journal = {Nature Communications},
	author = {Sarrami-Foroushani, Ali and Lassila, Toni and MacRaild, Michael and Asquith, Josh and Roes, Kit and Byrne, James and Frangi, Alejandro},
	month = jun,
	year = {2021},
}

@article{viceconti_silico_2020,
	title = {In {Silico} {Trials}: {Verification}, {Validation} {And} {Uncertainty} {Quantification} {Of} {Predictive} {Models} {Used} {In} {The} {Regulatory} {Evaluation} {Of} {Biomedical} {Products}},
	volume = {185},
	shorttitle = {In {Silico} {Trials}},
	doi = {10.1016/j.ymeth.2020.01.011},
	abstract = {Historically, the evidences of safety and efficacy that companies provide to regulatory agencies as support to the request for marketing authorization of a new medical product have been produced experimentally, either in vitro or in vivo. More recently, regulatory agencies started receiving and accepting evidences obtained in silico, i.e. through modelling and simulation. However, before any method (experimental or computational) can be acceptable for regulatory submission, the method itself must be considered "qualified" by the regulatory agency. This involves the assessment of the overall "credibility" that such a method has in providing specific evidence for a given regulatory procedure. In this paper, we describe a methodological framework for the credibility assessment of computational models built using mechanistic knowledge of physical and chemical phenomena, in addition to available biological and physiological knowledge; these are sometimes referred to as "biophysical" models. Using guiding examples, we explore the definition of the context of use, the risk analysis for the definition of the acceptability thresholds, and the various steps of a comprehensive verification, validation and uncertainty quantification process, to conclude with considerations on the credibility of a prediction for a specific context of use. While this paper does not provide a guideline for the formal qualification process, which only the regulatory agencies can provide, we expect it to help researchers to better appreciate the extent of scrutiny required, which should be considered early on in the development/use of any (new) in silico evidence.},
	journal = {Methods},
	author = {Viceconti, Marco and Pappalardo, Francesco and Rodriguez, Blanca and Horner, Marc and Bischoff, Jeff and Tshinanu, Flora},
	month = jan,
	year = {2020},
}

@article{ahmed_computing_2014,
	title = {Computing with {Spiking} {Neuron} {Networks} {A} {Review}},
	volume = {6},
	abstract = {Spiking Neuron Networks (SNNs) are often referred to as the third generation of neural networks. Highly inspired from natural computing in the brain and recent advances in neurosciences, they derive their strength and interest from an accurate modeling of synaptic interactions between neurons, taking into account the time of spike firing. SNNs overcome the computational power of neural networks made of threshold or sigmoidal units. Based on dynamic event-driven processing, they open up new horizons for developing models with an exponential capacity of memorizing and a strong ability to fast adaptation. Today, the main challenge is to discover efficient learning rules that might take advantage of the specific features of SNNs while keeping the nice properties (general-purpose, easy-to-use, available simulators, etc.) of traditional connectionist models. This paper presents the history of the "spiking neuron", summarizes the most currently-in-use models of neurons and synaptic plasticity, the computational power of SNNs is addressed and the problem of learning in networks of spiking neurons is tackled.},
	journal = {International Journal of Advances in Soft Computing and Its Applications},
	author = {Ahmed, Falah and Yusob, Bariah and Hamed, Haza Nuzly Abdull},
	month = mar,
	year = {2014},
	pages = {1--21},
}

@misc{noauthor_multiple_nodate,
	title = {Multiple {Correlation} {\textbar} {Real} {Statistics} {Using} {Excel}},
	url = {https://www.real-statistics.com/correlation/multiple-correlation/},
	urldate = {2022-06-16},
}

@article{abend_computational_2022,
	title = {Computational modeling of threat learning reveals links with anxiety and neuroanatomy in humans},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.66169},
	doi = {10.7554/eLife.66169},
	abstract = {Influential theories implicate variations in the mechanisms supporting threat learning in the severity of anxiety symptoms. We use computational models of associative learning in conjunction with structural imaging to explicate links among the mechanisms underlying threat learning, their neuroanatomical substrates, and anxiety severity in humans. We recorded skin-conductance data during a threat-learning task from individuals with and without anxiety disorders (N=251; 8-50 years; 116 females). Reinforcement-learning model variants quantified processes hypothesized to relate to anxiety: threat conditioning, threat generalization, safety learning, and threat extinction. We identified the best-fitting models for these processes and tested associations among latent learning parameters, whole-brain anatomy, and anxiety severity. Results indicate that greater anxiety severity related specifically to slower safety learning and slower extinction of response to safe stimuli. Nucleus accumbens gray-matter volume moderated learning-anxiety associations. Using a modeling approach, we identify computational mechanisms linking threat learning and anxiety severity and their neuroanatomical substrates.},
	urldate = {2022-06-16},
	journal = {eLife},
	author = {Abend, Rany and Burk, Diana and Ruiz, Sonia G and Gold, Andrea L and Napoli, Julia L and Britton, Jennifer C and Michalska, Kalina J and Shechner, Tomer and Winkler, Anderson M and Leibenluft, Ellen and Pine, Daniel S and Averbeck, Bruno B},
	editor = {Shackman, Alexander and Frank, Michael J and Bach, Dominick},
	month = apr,
	year = {2022},
	keywords = {anxiety, computational modeling, fear, learning, neuroanatomy},
	pages = {e66169},
}

@book{ferrari_robust_2008,
	title = {A robust fault detection and isolation scheme for a class of uncertain input-output discrete-time nonlinear systems},
	abstract = {This paper extends very recent results on discrete- time nonlinear fault detection and isolation to the case of discrete-time nonlinear systems with unstructured modeling uncertainty and partial state measurement. The fault diagnosis architecture consists of a fault detection and approximation estimator and a bank of fault isolation estimators, each corresponding to a particular type of fault. A time-varying threshold that guarantees no false-positive alarms and fault detectability conditions are derived analytically. For the fault isolation scheme, we design adaptive residual thresholds associated with each isolation estimator and obtain sufficient conditions for fault isolability. To illustrate the theoretical results, a simulation example based on a input-output discrete-time version of the three-tank benchmark problem is presented.},
	author = {Ferrari, Riccardo and Parisini, Thomas and Polycarpou, Marios},
	month = jul,
	year = {2008},
	doi = {10.1109/ACC.2008.4586918},
}

@book{panagi_decentralized_2008,
	title = {Decentralized adaptive approximation based control of a class of large-scale systems},
	abstract = {This paper considers the design of a decentralized adaptive approximation based control scheme for a class of interconnected nonlinear systems. Linearly parameterized neural networks are used to adaptively approximate the unknown dynamics of each subsystem and the unknown interconnections. The feedback control and adaptation laws are based only on local measurements of the state. A dead-zone modification is used to address the issues of stability and robustness in the presence of residual approximation errors. A simulation example is used to illustrate the proposed control design methodology.},
	author = {Panagi, Panagiotis and Polycarpou, Marios},
	month = jul,
	year = {2008},
	doi = {10.1109/ACC.2008.4587151},
}

@article{canuto_absolute_1998,
	title = {Absolute and {Relative} {Cut}-{Off} in {Adaptive} {Approximation} {By} {Wavelets}},
	volume = {178},
	doi = {10.1007/BF02505900},
	abstract = {Given the wavelet expansion of a function v, a non-linear adaptive approximation of v is obtained by neglecting those coefficients whose size drops below a certain threshold. We propose several ways to define the threshold: all are based on the characterization of the local regularity of v (in a Sobolev or Besov scale) in terms of summability of properly defined subsets of its coefficients. A-priori estimates of the approximation error are derived. For the Haar system, the asymptotic behavior of both the approximation error and the number of survived coefficients is thoroughly investigated for a class of functions having Holder-type singularities. Corresponding author: Claudio Canuto Dipartimento di Matematica, Politecnico di Torino Corso Duca degli Abruzzi, 24 I-10129 TORINO Italy phone: +39 11 564 7543 fax: +39 11 564 7599 email: ccanuto@polito.it 1 Introduction Wavelets have proven a powerful tool in signal processing and related topics (see [11], [16], [30]). For instance, the i...},
	journal = {Annali di Matematica Pura ed Applicata},
	author = {Canuto, Claudio and Tabacco, Anita},
	month = jun,
	year = {1998},
}

@book{biglari_towards_2022,
	title = {Towards {Real}-time {Adaptive} {Approximation}},
	abstract = {Cyber-physical systems (CPS) are real-time systems that operate in dynamic and non-deterministic environments. Models are often used for control and prediction, however do not reason on the trade-off between real-time constraints and uncertainty. This paper presents a conceptual model to reason on adaptive approximation in such systems. Furthermore, we envision a framework to allow the adaptivity of models, balancing between uncertainty and the real-time behavior of the system.},
	author = {Biglari, Raheleh and Mertens, Joost and Denil, Joachim},
	month = jun,
	year = {2022},
}

@book{paul_efficient_2022,
	title = {Efficient {Per}-{Shot} {Convex} {Hull} {Prediction} {By} {Recurrent} {Learning}},
	abstract = {Adaptive video streaming relies on the construction of efficient bitrate ladders to deliver the best possible visual quality to viewers under bandwidth constraints. The traditional method of content dependent bitrate ladder selection requires a video shot to be pre-encoded with multiple encoding parameters to find the optimal operating points given by the convex hull of the resulting rate-quality curves. However, this pre-encoding step is equivalent to an exhaustive search process over the space of possible encoding parameters, which causes significant overhead in terms of both computation and time expenditure. To reduce this overhead, we propose a deep learning based method of content aware convex hull prediction. We employ a recurrent convolutional network (RCN) to implicitly analyze the spatiotemporal complexity of video shots in order to predict their convex hulls. A two-step transfer learning scheme is adopted to train our proposed RCN-Hull model, which ensures sufficient content diversity to analyze scene complexity, while also making it possible capture the scene statistics of pristine source videos. Our experimental results reveal that our proposed model yields better approximations of the optimal convex hulls, and offers competitive time savings as compared to existing approaches. On average, the pre-encoding time was reduced by 58.0\% by our method, while the average Bjontegaard delta bitrate (BD-rate) of the predicted convex hulls against ground truth was 0.08\%, while the mean absolute deviation of the BD-rate distribution was 0.44\%},
	author = {Paul, Somdyuti and Norkin, Andrey and Bovik, Alan},
	month = jun,
	year = {2022},
	doi = {10.48550/arXiv.2206.04877},
}

@misc{noauthor_reproducible_2019,
	title = {Reproducible {Document} {Stack}: {Towards} a scalable solution for reproducible articles},
	copyright = {© 2019 eLife Sciences Publications Limited. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited.},
	shorttitle = {Reproducible {Document} {Stack}},
	url = {https://elifesciences.org/labs/b521cf4d/reproducible-document-stack-towards-a-scalable-solution-for-reproducible-articles},
	abstract = {We announce our roadmap towards an open, scalable infrastructure for the publication of computationally reproducible articles.},
	language = {en},
	urldate = {2022-06-16},
	journal = {eLife},
	month = may,
	year = {2019},
}

@book{verma_systematic_2020,
	title = {A {Systematic} {Review} on {Firefly} {Algorithm}: {Past}, {Present}, and {Future}},
	shorttitle = {A {Systematic} {Review} on {Firefly} {Algorithm}},
	abstract = {A comprehensive review of firefly algorithm is presented and various characteristics are discussed with various variant of FA such as binary, multi-objective and hybrid.},
	author = {Verma, Himanshu},
	month = apr,
	year = {2020},
	doi = {10.36227/techrxiv.12122748},
}

@article{fister_comprehensive_2013,
	title = {A comprehensive review of firefly algorithms},
	volume = {13},
	doi = {10.1016/j.swevo.2013.06.001},
	abstract = {The firefly algorithm has become an increasingly important tool of Swarm Intelligence that has been applied in almost all areas of optimization, as well as engineering practice. Many problems from various areas have been successfully solved using the firefly algorithm and its variants. In order to use the algorithm to solve diverse problems, the original firefly algorithm needs to be modified or hybridized. This paper carries out a comprehensive review of this living and evolving discipline of Swarm Intelligence, in order to show that the firefly algorithm could be applied to every problem arising in practice. On the other hand, it encourages new researchers and algorithm developers to use this simple and yet very efficient algorithm for problem solving. It often guarantees that the obtained results will meet the expectations.},
	journal = {Swarm and Evolutionary Computation},
	author = {Fister, Iztok and Fister jr, Iztok and Yang, Xin-She and Brest, Janez},
	month = dec,
	year = {2013},
	pages = {34--46},
}

@article{swaminathan_counterfactual_2015,
	title = {Counterfactual {Risk} {Minimization}: {Learning} from {Logged} {Bandit} {Feedback}},
	volume = {16},
	shorttitle = {Counterfactual {Risk} {Minimization}},
	abstract = {We develop a learning principle and an efficient algorithm for batch learning from logged bandit feedback. This learning setting is ubiquitous in online systems (e.g., ad placement, web search, recommendation), where an algorithm makes a prediction (e.g., ad ranking) for a given input (e.g., query) and observes bandit feedback (e.g., user clicks on presented ads). We first address the counterfactual nature of the learning problem through propensity scoring. Next, we prove generalization error bounds that account for the variance of the propensity-weighted empirical risk estimator. These constructive bounds give rise to the Counterfactual Risk Minimization (CRM) principle. We show how CRM can be used to derive a new learning method -- called Policy Optimizer for Exponential Models (POEM) -- for learning stochastic linear rules for structured output prediction. We present a decomposition of the POEM objective that enables efficient stochastic gradient optimization. POEM is evaluated on several multi-label classification problems showing substantially improved robustness and generalization performance compared to the state-of-the-art.},
	author = {Swaminathan, Adith and Joachims, Thorsten},
	month = feb,
	year = {2015},
}

@article{lefortier_large-scale_2016,
	title = {Large-scale {Validation} of {Counterfactual} {Learning} {Methods}: {A} {Test}-{Bed}},
	shorttitle = {Large-scale {Validation} of {Counterfactual} {Learning} {Methods}},
	abstract = {The ability to perform effective off-policy learning would revolutionize the process of building better interactive systems, such as search engines and recommendation systems for e-commerce, computational advertising and news. Recent approaches for off-policy evaluation and learning in these settings appear promising. With this paper, we provide real-world data and a standardized test-bed to systematically investigate these algorithms using data from display advertising. In particular, we consider the problem of filling a banner ad with an aggregate of multiple products the user may want to purchase. This paper presents our test-bed, the sanity checks we ran to ensure its validity, and shows results comparing state-of-the-art off-policy learning methods like doubly robust optimization, POEM, and reductions to supervised learning using regression baselines. Our results show experimental evidence that recent off-policy learning methods can improve upon state-of-the-art supervised learning techniques on a large-scale real-world data set.},
	author = {Lefortier, Damien and Swaminathan, Adith and Gu, Xiaotao and Joachims, Thorsten and Rijke, Maarten},
	month = dec,
	year = {2016},
}

@book{acharki_heterogeneous_2022,
	title = {Heterogeneous {Treatment} {Effects} {Estimation}: {When} {Machine} {Learning} meets multiple treatment regime},
	shorttitle = {Heterogeneous {Treatment} {Effects} {Estimation}},
	abstract = {In many scientific and engineering domains, inferring the effect of treatment and exploring its heterogeneity is crucial for optimization and decision making. In addition to Machine Learning based models (e.g. Random Forests or Neural Networks), many meta-algorithms have been developed to estimate the Conditional Average Treatment Effect (CATE) function in the binary setting, with the main advantage of not restraining the estimation to a specific supervised learning method. However, this task becomes more challenging when the treatment is not binary. In this paper, we investigate the Rubin Causal Model under the multi-treatment regime and we focus on estimating heterogeneous treatment effects. We generalize {\textbackslash}textit\{Meta-learning\} algorithms to estimate the CATE for each possible treatment value. Using synthetic and semi-synthetic simulation datasets, we assess the quality of each meta-learner in observational data, and we highlight in particular the performances of the X-learner.},
	author = {Acharki, Naoufal and Garnier, Josselin and Bertoncello, Antoine and Lugo, Ramiro},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.14714},
}

@incollection{steyerberg_missing_2019,
	title = {Missing {Values}},
	isbn = {9783030163983},
	abstract = {Missing data are a common problem in medical research. We may encounter missing values of predictor values (X) and for the outcome (y) that we want to predict. Traditional complete case analysis suffers from inefficiency, selection bias of subjects, and other limitations when developing a prediction model. We briefly review the theoretical background on mechanisms of missingness of predictor values and how these may affect prediction models. We further concentrate on imputation methods as a solution, where a completed data set is created by filling in missing values for the statistical analysis. Special attention is given to the specification of an imputation model, which is the essential step in imputation. Multiple imputation is a method is to generate completed data sets multiple times, while single imputation is more straightforward and may be sufficient for some prognostic research questions.},
	author = {Steyerberg, Ewout},
	month = jul,
	year = {2019},
	doi = {10.1007/978-3-030-16399-0_7},
	pages = {127--155},
}

@article{mishra_hybrid_2022,
	title = {Hybrid multiagent based adaptive genetic algorithm for limited view tomography using oppositional learning},
	volume = {75},
	doi = {10.1016/j.bspc.2022.103610},
	abstract = {Computed tomography (CT) plays a crucial role in the field of medical diagnosis. The prime objective of limited view tomography is to estimate the object’s internal structure with limited view projection data. Limited view computed tomography (CT) has the ability to reduce the X-ray radiation dose imposed on the patient. This manuscript presents Hybrid Multiagent based Adaptive Genetic Algorithm (HMAGA) for limited view tomography. HMAGA is a combination of multiagent-based genetic algorithms and simulated annealing with adaptive crossover and mutation rate. The proposed algorithm uses two methods for reducing the loss of diversity and increases the convergence rate, and these methods are oppositional learning and a new random population. Experimental results reveal that the proposed algorithm provides satisfactory results with low computation overhead. The present manuscript also outperforms other states of the art reconstruction algorithms.},
	journal = {Biomedical Signal Processing and Control},
	author = {Mishra, Raghavendra and Bajpai, Manish},
	month = may,
	year = {2022},
	pages = {103610},
}

@book{montesano_spatialtemporal_2022,
	title = {Spatial/{Temporal} {Locality}-based {Load}-sharing in {Speculative} {Discrete} {Event} {Simulation} on {Multi}-core {Machines}},
	author = {Montesano, Federica and Marotta, Romolo and Quaglia, Francesco},
	month = jun,
	year = {2022},
	doi = {10.1145/3518997.3531026},
}

@article{zenke_limits_2014,
	title = {Limits to high-speed simulations of spiking neural networks using general-purpose computers},
	volume = {8},
	doi = {10.3389/fninf.2014.00076},
	abstract = {To understand how the central nervous system performs computations using recurrent neuronal circuitry, simulations have become an indispensable tool for theoretical neuroscience. To study neuronal circuits and their ability to self-organize, increasing attention has been directed toward synaptic plasticity. In particular spike-timing-dependent plasticity (STDP) creates specific demands for simulations of spiking neural networks. On the one hand a high temporal resolution is required to capture the millisecond timescale of typical STDP windows. On the other hand network simulations have to evolve over hours up to days, to capture the timescale of long-term plasticity. To do this efficiently, fast simulation speed is the crucial ingredient rather than large neuron numbers. Using different medium-sized network models consisting of several thousands of neurons and off-the-shelf hardware, we compare the simulation speed of the simulators: Brian, NEST and Neuron as well as our own simulator Auryn. Our results show that real-time simulations of different plastic network models are possible in parallel simulations in which numerical precision is not a primary concern. Even so, the speed-up margin of parallelism is limited and boosting simulation speeds beyond one tenth of real-time is difficult. By profiling simulation code we show that the run times of typical plastic network simulations encounter a hard boundary. This limit is partly due to latencies in the inter-process communications and thus cannot be overcome by increased parallelism. Overall, these results show that to study plasticity in medium-sized spiking neural networks, adequate simulation tools are readily available which run efficiently on small clusters. However, to run simulations substantially faster than real-time, special hardware is a prerequisite.},
	journal = {Frontiers in neuroinformatics},
	author = {Zenke, Friedemann and Gerstner, Wulfram},
	month = sep,
	year = {2014},
	pages = {76},
}

@book{beyeler_carlsim_2015,
	title = {{CARLsim} 3: {A} {User}-{Friendly} and {Highly} {Optimized} {Library} for the {Creation} of {Neurobiologically} {Detailed} {Spiking} {Neural} {Networks}},
	shorttitle = {{CARLsim} 3},
	abstract = {Spiking neural network (SNN) models describe key aspects of neural function in a computationally efficient manner and have been used to construct large-scale brain models. Large-scale SNNs are challenging to implement, as they demand high-bandwidth communication, a large amount of memory, and are computationally intensive. Additionally, tuning parameters of these models becomes more difficult and time-consuming with the addition of biologically accurate descriptions. To meet these challenges, we have developed CARLsim 3, a user-friendly, GPU-accelerated SNN library written in C/C++ that is capable of simulating biologically detailed neural models. The present release of CARLsim provides a number of improvements over our prior SNN library to allow the user to easily analyze simulation data, explore synaptic plasticity rules, and automate parameter tuning. In the present paper, we provide examples and performance benchmarks highlighting the library's features.},
	author = {Beyeler, Michael and Carlson, Kristofor and Chou, Ting-Shuo and Dutt, Nikil and Krichmar, Jeff},
	month = jul,
	year = {2015},
	doi = {10.1109/IJCNN.2015.7280424},
}

@book{pimpini_speculative_2022,
	title = {Speculative {Distributed} {Simulation} of {Very} {Large} {Spiking} {Neural} {Networks}},
	author = {Pimpini, Adriano and Piccione, Andrea and Ciciani, Bruno and Pellegrini, Alessandro},
	month = jun,
	year = {2022},
	doi = {10.1145/3518997.3531027},
}

@article{thirupathi_editorial_2022,
	title = {Editorial: {Exercise} {Friend} or {Foe}? {For} the {Management} of {Oxidative} {Stress} in {Health} and {Diseases}},
	volume = {13},
	shorttitle = {Editorial},
	doi = {10.3389/fphys.2022.881197},
	journal = {Frontiers in Physiology},
	author = {Thirupathi, Anand and Gu, Yaodong and Wiltshire, Huw and Pinho, Ricardo},
	month = mar,
	year = {2022},
	pages = {881197},
}

@article{zhang_hessian_2020,
	title = {Hessian {Free} {Convolutional} {Dictionary} {Learning} for {Hyperspectral} {Imagery} {With} {Application} to {Compressive} {Chromo}-{Tomography}},
	volume = {PP},
	doi = {10.1109/ACCESS.2020.2999457},
	abstract = {Convolutional dictionary learning (CDL) is an unsupervised learning method to seek a translation-invariant sparse representation for signals, and has gained a lot of interest in various image processing and computer vision applications. However, 3D hyperspectral images pose unique challenges due to their high dimensionality and complex structures, making optimization of the dictionary and its application to inverse problems difficult. This paper proposes an efficient CDL algorithm that neither explicit evaluation of the Hessians nor their inversion is required in the optimization process, which leads to substantial acceleration and memory savings. Furthermore, we exploit the learned kernels as the convolutional sparse coding (CSC) image prior for the compressive chromo-tomographic (CCT) reconstruction problem, and examine the usability and performances of the proposed method for CCT reconstruction. Numerical experiments show that, for CCT, 1) the proposed CSC can provide an efficient representation for HSI by using several tens of 3D filters; 2) the learned convolutional dictionary has reliable generalization capability; and 3) the proposed CSC-based method outperforms the classical reconstruction method using an analytic sparsifying basis.},
	journal = {IEEE Access},
	author = {Zhang, Xuesong and Li, Baoping and Jiang, Jing},
	month = jun,
	year = {2020},
	pages = {1--1},
}

@book{kofler_convolutional_2022,
	title = {Convolutional {Dictionary} {Learning} by {End}-{To}-{End} {Training} of {Iterative} {Neural} {Networks}},
	abstract = {Sparsity-based methods have a long history in the field of signal processing and have been successfully applied to various image reconstruction problems. The involved sparsifying transformations or dictionaries are typically either pre-trained using a model which reflects the assumed properties of the signals or adaptively learned during the reconstruction - yielding so-called blind Compressed Sensing approaches. However, by doing so, the transforms are never explicitly trained in conjunction with the physical model which generates the signals. In addition, properly choosing the involved regularization parameters remains a challenging task. Another recently emerged training-paradigm for regularization methods is to use iterative neural networks (INNs) - also known as unrolled networks - which contain the physical model. In this work, we construct an INN which can be used as a supervised and physics-informed online convolutional dictionary learning algorithm. We evaluated the proposed approach by applying it to a realistic large-scale dynamic MR reconstruction problem and compared it to several other recently published works. We show that the proposed INN improves over two conventional model-agnostic training methods and yields competitive results also compared to a deep INN. Further, it does not require to choose the regularization parameters and - in contrast to deep INNs - each network component is entirely interpretable.},
	author = {Kofler, Andreas and Wald, Christian and Schaeffter, Tobias and Haltmeier, Markus and Kolbitsch, Christoph},
	month = jun,
	year = {2022},
}

@article{pahikkala_ranking_2009,
	title = {From {Ranking} to {Intransitive} {Preference} {Learning}: {Rock}-{Paper}-{Scissors} and beyond},
	shorttitle = {From {Ranking} to {Intransitive} {Preference} {Learning}},
	abstract = {In different fields like decision making, psychology, game theory and biology, it has been observed that paired-comparison data like preference relations defined by humans and animals can be intransitive. The relations may resemble the well-known game of rock-paper-scissors. In the game, rock defeats scissors and scissors defeat paper, but rock loses to paper. Intransitive relations cannot be modelled with existing machine learning methods like ranking models, because these models exhibit strong transitivity properties. More specifically, in a stochastic context, where often the reciprocity property characterizes probabilistic relations such as choice probabilities, it has been formally shown that ranking models always satisfy the well-known strong stochastic tran-sitivity property. Given this limitation of ranking models, we present a new kernel function that together with the regularized least-squares algorithm is capable of inferring intransitive reciprocal relations in problems where transitivity violations cannot be considered as noise. In this approach it is the kernel function that defines the transition from learning transitive to learning intransitive relations, and the Kronecker-product is introduced for representing the latter type of relations. In addition, we empirically demonstrate on two benchmark problems in game theory and biology that our algorithm outperforms methods not capable of learning intransitive reciprocal relations.},
	author = {Pahikkala, Tapio and Waegeman, Willem and Tsivtsivadze, Evgeni and Salakoski, Tapio and De Baets, Bernard},
	month = jan,
	year = {2009},
}

@book{hu_explaining_2022,
	title = {Explaining {Preferences} with {Shapley} {Values}},
	abstract = {While preference modelling is becoming one of the pillars of machine learning, the problem of preference explanation remains challenging and underexplored. In this paper, we propose {\textbackslash}textsc\{Pref-SHAP\}, a Shapley value-based model explanation framework for pairwise comparison data. We derive the appropriate value functions for preference models and further extend the framework to model and explain {\textbackslash}emph\{context specific\} information, such as the surface type in a tennis game. To demonstrate the utility of {\textbackslash}textsc\{Pref-SHAP\}, we apply our method to a variety of synthetic and real-world datasets and show that richer and more insightful explanations can be obtained over the baseline.},
	author = {Hu, Robert and Chau, Siu Lun and Huertas, Jaime and Sejdinovic, Dino},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.13662},
}

@book{hu_monotonically_2022,
	title = {Monotonically {Convergent} {Regularization} by {Denoising}},
	abstract = {Regularization by denoising (RED) is a widely-used framework for solving inverse problems by leveraging image denoisers as image priors. Recent work has reported the state-of-the-art performance of RED in a number of imaging applications using pre-trained deep neural nets as denoisers. Despite the recent progress, the stable convergence of RED algorithms remains an open problem. The existing RED theory only guarantees stability for convex data-fidelity terms and nonexpansive denoisers. This work addresses this issue by developing a new monotone RED (MRED) algorithm, whose convergence does not require nonexpansiveness of the deep denoising prior. Simulations on image deblurring and compressive sensing recovery from random matrices show the stability of MRED even when the traditional RED algorithm diverges.},
	author = {Hu, Yuyang and Liu, Jiaming and Xu, Xiaojian and Kamilov, Ulugbek},
	month = feb,
	year = {2022},
}

@article{wang_mams_2021,
	title = {The {MAMs} {Structure} and {Its} {Role} in {Cell} {Death}},
	volume = {10},
	doi = {10.3390/cells10030657},
	abstract = {The maintenance of cellular homeostasis involves the participation of multiple organelles. These organelles are associated in space and time, and either cooperate or antagonize each other with regards to cell function. Crosstalk between organelles has become a significant topic in research over recent decades. We believe that signal transduction between organelles, especially the endoplasmic reticulum (ER) and mitochondria, is a factor that can influence the cell fate. As the cellular center for protein folding and modification, the endoplasmic reticulum can influence a range of physiological processes by regulating the quantity and quality of proteins. Mitochondria, as the cellular “energy factory,” are also involved in cell death processes. Some researchers regard the ER as the sensor of cellular stress and the mitochondria as an important actuator of the stress response. The scientific community now believe that bidirectional communication between the ER and the mitochondria can influence cell death. Recent studies revealed that the death signals can shuttle between the two organelles. Mitochondria-associated membranes (MAMs) play a vital role in the complex crosstalk between the ER and mitochondria. MAMs are known to play an important role in lipid synthesis, the regulation of Ca2+ homeostasis, the coordination of ER-mitochondrial function, and the transduction of death signals between the ER and the mitochondria. Clarifying the structure and function of MAMs will provide new concepts for studying the pathological mechanisms associated with neurodegenerative diseases, aging, and cancers. Here, we review the recent studies of the structure and function of MAMs and its roles involved in cell death, especially in apoptosis.},
	journal = {Cells},
	author = {Wang, Nan and Wang, Chong and Zhao, Hongyang and He, Yi-Chun and Lan, Beiwu and Sun, Liankun and Gao, Yufei},
	month = mar,
	year = {2021},
	pages = {657},
}

@article{teka_mitochondrial_2022,
	title = {The mitochondrial associated endoplasmic reticulum membranes: {A} platform for the pathogenesis of inflammation-mediated metabolic diseases},
	volume = {10},
	shorttitle = {The mitochondrial associated endoplasmic reticulum membranes},
	doi = {10.1002/iid3.647},
	abstract = {Mitochondria-associated endoplasmic reticulum membranes (MAM) are specialized subcellular compartments that are shaped by endoplasmic reticulum (ER) subdomains placed side by side to the outer membrane of mitochondria (OMM) being connected by tethering proteins in mammalian cells. Studies showed that MAM has multiple physiological functions. These include regulation of lipid synthesis and transport, Ca 2+ transport and signaling, mitochondrial dynamics, apoptosis, autophagy, and formation and activation of an inflammasome. However, alterations of MAM integrity lead to deleterious effects due to an increased generation of mitochondrial reactive oxygen species (ROS) via increased Ca 2+ transfer from the ER to mitochon-dria. This, in turn, causes mitochondrial damage and release of mitochondrial components into the cytosol as damage-associated molecular patterns which rapidly activate MAM-resident Nod-like receptor protein-3 (NLRP3) inflam-masome components. This complex induces the release of pro-inflammatory cytokines that initiate low-grade chronic inflammation that subsequently causes the development of metabolic diseases. But, the mechanisms of how MAM is involved in the pathogenesis of these diseases are not exhaustively reviewed. Therefore, this review was aimed to highlight the contribution of MAM to a variety of cellular functions and consider its significance pertaining to the pathogenesis of inflammation-mediated metabolic diseases. K E Y W O R D S ER-stress, inflammatory mediated metabolic diseases, MAM, NLRP3-inflammasome},
	journal = {Immunity, Inflammation and Disease},
	author = {Teka, Sisay and Dabi, Yosef Tsegaye and Gizaw, Solomon},
	month = jun,
	year = {2022},
}

@article{shirokova_mercs_2020,
	title = {{MERCs}. {The} {Novel} {Assistant} to {Neurotransmission}?},
	volume = {14},
	doi = {10.3389/fnins.2020.589319},
	abstract = {In neuroscience, much attention is paid to intercellular interactions, in particular, to synapses. However, many researchers do not pay due attention to the contribution of intracellular contacts to the work of intercellular interactions. Nevertheless, along with synapses, intracellular contacts also have complex organization and a tremendous number of regulatory elements. Mitochondria-endoplasmic reticulum contacts (MERCs) are a specific site of interaction between the two organelles; they provide a basis for a large number of cellular functions, such as calcium homeostasis, lipid metabolism, autophagy, and apoptosis. Despite the presence of these contacts in various parts of neurons and glial cells, it is yet not known whether they fulfill the same functions. There are still many unsolved questions about the work of these intracellular contacts, and one of the most important among them is if MERCs, with their broad implication into synaptic events, can be considered the assistant to neurotransmission?},
	journal = {Frontiers in Neuroscience},
	author = {Shirokova, Olesya and Pchelin, Pavel and Mukhina, Irina},
	month = nov,
	year = {2020},
}

@book{russell_mfn2_2021,
	title = {{MFN2} {Influences} {Amyotrophic} {Lateral} {Sclerosis} {Pathology}},
	abstract = {Objective
To better understand the pathology of amyotrophic lateral sclerosis, we used sequence data from patients seen at the University of Utah to identify novel disease-associated loci. We utilized both in vitro and in vivo studies to determine the biological effect of patient mutations in MFN2 .

Method
Sequence data for a total of 140 patients were run through VAAST and Phevor to determine genes that were more burdened with rare, nonsynonymous variants compared to control longevity cohort. Variants identified in MFN2 were expressed in Mfn2 knockout cells to determine if mutant MFN2 could rescue mitochondrial morphology defects. We identified additional rare, nonsynonymous variants in MFN2 in ALSdb that were expressed in knockout mouse embryonic fibroblasts (MEFs). Membrane potential was measured to quantify mitochondrial health upon mutant MFN2 expression. mfn2 knockout zebrafish were used to examine movement compared to wildtype and protein aggregation in brain.

Results
MFN2 mutations identified in ALS patients from our University of Utah cohort and ALSdb were defective in rescuing morphological defects in Mfn2 knockout MEFs. Selected mutants showed decreased membrane potential compared to wildtype MFN2 expression. Zebrafish heterozygous and homozygous for loss of mfn2 showed increased TDP-43 levels in their hindbrain and cerebellum.

Conclusion
In total, 21 rare, deleterious mutations in MFN2 were tested in Mfn2 knockout MEFs. Mutant MFN2 expression was not able to rescue the knockout phenotype, though at differing degrees of severity. Decreased membrane potential also argues for inhibited mitochondrial function. Increased TDP-43 levels in mutant zebrafish illustrates MFN2’s function in ALS pathology. MFN2 variants influence ALS pathology and highlight the importance of mitochondria in neurodegeneration.},
	author = {Russell, Kristi and Downie, Jonathan and Gibson, Summer and Figueroa, Patty and Steely, Cody and Bromberg, Mark and Murtaugh, Lewis and Jorde, Lynn and Pulst, Stefan},
	month = oct,
	year = {2021},
	doi = {10.1101/2021.10.30.466517},
}

@article{zaman_role_2022,
	title = {The {Role} of {Impaired} {Mitochondrial} {Dynamics} in {MFN2}-{Mediated} {Pathology}},
	volume = {10},
	doi = {10.3389/fcell.2022.858286},
	abstract = {The Mitofusin 2 protein (MFN2), encoded by the MFN2 gene, was first described for its role in mediating mitochondrial fusion. However, MFN2 is now recognized to play additional roles in mitochondrial autophagy (mitophagy), mitochondrial motility, lipid transfer, and as a tether to other organelles including the endoplasmic reticulum (ER) and lipid droplets. The tethering role of MFN2 is an important mediator of mitochondrial-ER contact sites (MERCs), which themselves have many important functions that regulate mitochondria, including calcium homeostasis and lipid metabolism. Exemplifying the importance of MFN2, pathogenic variants in MFN2 are established to cause the peripheral neuropathy Charcot-Marie-Tooth Disease Subtype 2A (CMT2A). However, the mechanistic basis for disease is not clear. Moreover, additional pathogenic phenotypes such as lipomatosis, distal myopathy, optic atrophy, and hearing loss, can also sometimes be present in patients with CMT2A. Given these variable patient phenotypes, and the many cellular roles played by MFN2, the mechanistic underpinnings of the cellular impairments by which MFN2 dysfunction leads to disease are likely to be complex. Here, we will review what is known about the various functions of MFN2 that are impaired by pathogenic variants causing CMT2A, with a specific emphasis on the ties between MFN2 variants and MERCs.},
	journal = {Frontiers in Cell and Developmental Biology},
	author = {Zaman, Mashiat and Shutt, Timothy},
	month = mar,
	year = {2022},
	pages = {858286},
}

@article{huo_mfn1_2022,
	title = {The {MFN1} and {MFN2} mitofusins promote clustering between mitochondria and peroxisomes},
	volume = {5},
	doi = {10.1038/s42003-022-03377-x},
	abstract = {Mitochondria and peroxisomes are two types of functionally close-related organelles, and both play essential roles in lipid and ROS metabolism. However, how they physically interact with each other is not well understood. In this study, we apply the proximity labeling method with peroxisomal proteins and report that mitochondrial protein mitofusins (MFNs) are in proximity to peroxisomes. Overexpression of MFNs induces not only the mitochondria clustering but also the co-clustering of peroxisomes. We also report the enrichment of MFNs at the mitochondria-peroxisome interface. Induced mitofusin expression gives rise to more mitochondria-peroxisome contacting sites. Furthermore, the tethering of peroxisomes to mitochondria can be inhibited by the expression of a truncated MFN2, which lacks the transmembrane region. Collectively, our study suggests MFNs as regulators for mitochondria-peroxisome contacts. Our findings are essential for future studies of inter-organelle metabolism regulation and signaling, and may help understand the pathogenesis of mitofusin dysfunction-related disease.},
	journal = {Communications Biology},
	author = {Huo, Yinbo and Sun, Weiping and Shi, Tiezhu and Gao, Song and Zhuang, Min},
	month = may,
	year = {2022},
}

@misc{noauthor_mitochondrial_nodate,
	title = {Mitochondrial structural variations in the process of mitophagy},
	url = {https://www.researchgate.net/publication/358082918_Mitochondrial_structural_variations_in_the_process_of_mitophagy},
	urldate = {2022-06-07},
}

@article{marcon_mitochondrial_2022,
	title = {The mitochondrial poison carbonyl cyanide 3-chlorophenyl hydrazone ({CCCP}) induces aneugenic effects in primary human fibroblasts: a possible link between mitochondrial dysfunction and chromosomal loss},
	shorttitle = {The mitochondrial poison carbonyl cyanide 3-chlorophenyl hydrazone ({CCCP}) induces aneugenic effects in primary human fibroblasts},
	doi = {10.1093/mutage/geac008},
	abstract = {An association between proper chromosome segregation and intact mitochondria has been extensively reported. This could be related to the effects on the progression of cell division of altered energy production, increased oxidative stress, and deregulated calcium homeostasis. However, evidence for a direct relationship is still lacking. The present study was aimed at investigating the possible effect of mitochondrial dysfunction on chromosomal instability as detected in primary human cells treated with the mitochondrial poison carbonyl cyanide 3-chlorophenyl hydrazone (CCCP). Chromosome instability was analyzed in anaphase and interphase cells to follow the fate of chromosome damage during the progression of mitosis and the subsequent cell cycle. Through the combination of cytogenetic approaches and molecular analyses, i.e. morphological cell analysis, formation and characterization of micronucleus content, Comet assay, and gene expression, it was demonstrated that the prevalent DNA damage associated with CCCP treatment was the induction of chromosome loss, while primary DNA damage was not detected. No alterations in the shape of anaphase cells were observed nor induction of multipolar spindles. The proper activation of mitotic checkpoint was maintained. A linear dose-response curve characterizing the CCCP effects suggested that multiple cellular targets could be affected by the CCCP-induced mitochondrial dysfunctions triggering aneuploidy. Conversely, a steep increase was induced by the positive control vinblastine, known to have tubulin as a unique target. In addition, the effect of CCCP on mitochondrial function was demonstrated by changes in mitochondrial DNA copy number and in the expression of genes involved in mitochondrial maintenance. Overall, these results indicate that the mitochondrial poison CCCP may induce aneugenic effects.},
	journal = {Mutagenesis},
	author = {Marcon, Francesca and Battistis, Francesca and Siniscalchi, Ester and Crebelli, Riccardo and Meschini, Roberta},
	month = apr,
	year = {2022},
}

@article{zhou_optimization_2022,
	title = {Optimization of murine retinal mitochondrial injury model},
	volume = {9},
	doi = {10.1016/j.mex.2022.101701},
	abstract = {The retinal mitochondrial injury model in rat has been developed using the mitochondrial oxidative phosphorylation uncoupler, carbonylcyanide m-chlorophenyl hydrazine (CCCP). However, the CCCP-induced murine retinal mitochondrial injury model has not been reported. Here, the optimized conditions for the murine retinal mitochondrial injury model were established by intravitreal injection of different doses of CCCP (0, 2.5, 5, 7.5, 10, 12.5, 15 μg). Indeed, it has been reported that CCCP induces Opa1 cleavage and phosphorylation of ERK in cultured cells and rat retinas. Thus, we measured phosphorylated (p) -Erk and L/S-Opa1 following CCCP-induced retinal injury. Meanwhile, KW6002 (A2A receptor antagonist) pretreatment inhibited retinal injury induced by CCCP at 10μg and 15μg doses differently. Intravitreal injection of 10 μg doses of CCCP can induce apoptosis of retinal ganglion cells and decrease of retinal thickness, but Intravitreal injection of 15 μg doses of CCCP is the appropriate dose to study the protective effect of A2A receptor.
1) Dose dependent effects of intravitreal injection of CCCP on the levels of Opa1 and p-Erk;
2) A2A receptor antagonist (KW6002) only inhibited the apoptosis of ganglion cells, but did not affect the thickness of retina with 10µg dosage of CCCP intravitreal injection;
3) A2A receptor antagonist (KW6002) inhibited the apoptosis of ganglion cells and increased the thickness of retina with 15µg dosage of CCCP intravitreal injection.},
	journal = {MethodsX},
	author = {Zhou, Xiaopeng and Fang, Gengjing and Liping, Zhang},
	month = apr,
	year = {2022},
	pages = {101701},
}

@article{sun_lc3-mediated_2022,
	title = {{LC3}-{Mediated} {Mitophagy} {After} {CCCP} or {Vibrio} splendidus {Exposure} in the {Pacific} {Oyster} {Crassostrea} gigas},
	volume = {10},
	doi = {10.3389/fcell.2022.885478},
	abstract = {Mitochondrial selective autophagy, known as mitophagy, surveils the mitochondrial population by eliminating superfluous and/or impaired organelles to mediate cellular survival and viability in response to injury/trauma and infection. In this study, the components of the mitophagy pathway in the Pacific oyster Crassostrea gigas were screened from NCBI with reference to the protein sequences of the human mitophagy process. A total of 10 mitophagy process–related genes were identified from C. gigas, including NIX, FUNDC1, PHB2, Cardiolipin, P62, VDAC2, MFN2, PARL, MPP, and OPTN. They shared high similarities with their homologs in the human mitophagy pathway and were expressed in various tissues of C. gigas. After CCCP exposure, the fluorescence intensity of the mitochondrial probe JC-1 monomers increased significantly in hemocytes, while the fluorescence intensity of JC-1 aggregates decreased significantly. Meanwhile, the fluorescence of lysosomes was found to be co-localized with that of CgLC3 and mitochondria in CCCP-treated hemocytes. Double- and single-membrane-bound vacuoles resembling autophagic structures were observed in the hemocytes after CCCP exposure. The fluorescence intensity of JC-1 monomers and the abundance of CgLC3Ⅱ in hemocytes both increased after Vibrio splendidus exposure. At the same time, the green signals of CgLC3 were co-localized with red signals of the mitochondria, and the fluorescence intensity of autophagy increased significantly in hemocytes after V. splendidus exposure. The results confirmed the existence of a complete mitophagy pathway in mollusks for the first time, which was helpful for further study on the function of mitochondrial autophagy in mollusks.},
	journal = {Frontiers in Cell and Developmental Biology},
	author = {Sun, Jiejie and Lv, Xiaoqian and Leng, Jinyuan and Song, Linsheng},
	month = may,
	year = {2022},
	pages = {885478},
}

@book{schilling_classification_2022,
	title = {Classification at the {Accuracy} {Limit} -- {Facing} the {Problem} of {Data} {Ambiguity}},
	abstract = {Data classification, the process of analyzing data and organizing it into categories, is a fundamental computing problem of natural and artificial information processing systems. Ideally, the performance of classifier models would be evaluated using unambiguous data sets, where the 'correct' assignment of category labels to the input data vectors is unequivocal. In real-world problems, however, a significant fraction of actually occurring data vectors will be located in a boundary zone between or outside of all categories, so that perfect classification cannot even in principle be achieved. We derive the theoretical limit for classification accuracy that arises from the overlap of data categories. By using a surrogate data generation model with adjustable statistical properties, we show that sufficiently powerful classifiers based on completely different principles, such as perceptrons and Bayesian models, all perform at this universal accuracy limit. Remarkably, the accuracy limit is not affected by applying non-linear transformations to the data, even if these transformations are non-reversible and drastically reduce the information content of the input data. We compare emerging data embeddings produced by supervised and unsupervised training, using MNIST and human EEG recordings during sleep. We find that categories are not only well separated in the final layers of classifiers trained with back-propagation, but to a smaller degree also after unsupervised dimensionality reduction. This suggests that human-defined categories, such as hand-written digits or sleep stages, can indeed be considered as 'natural kinds'.},
	author = {Schilling, Achim},
	month = jun,
	year = {2022},
	doi = {10.48550/arXiv.2206.01922},
}

@incollection{beggs_dstorm_2020,
	title = {{dSTORM} {Imaging} and {Analysis} of {Desmosome} {Architecture}},
	volume = {2367},
	isbn = {9781071616727},
	abstract = {Desmosomes are cell-cell junctions responsible for mechanically integrating adjacent cells. Due to the small size of the junctions, their protein architecture cannot be elucidated using conventional fluorescence microscopy. Super-resolution microscopy techniques, including dSTORM, deliver higher-resolution images which can reveal the localization or arrangement of proteins within individual desmosomes. Herein we describe an imaging and analysis method to determine the nanoscale architecture of desmosomes using super-resolution dSTORM.},
	booktitle = {Methods in molecular biology ({Clifton}, {N}.{J}.)},
	author = {Beggs, Reena and Dean, William and Mattheyses, Alexa},
	month = nov,
	year = {2020},
	doi = {10.1007/7651_2020_325},
}

@article{liu_mitophagy_2020,
	title = {Mitophagy and {Its} {Contribution} to {Metabolic} and {Aging}-{Associated} {Disorders}},
	volume = {32},
	issn = {1523-0864},
	url = {https://www.liebertpub.com/doi/full/10.1089/ars.2019.8013},
	doi = {10.1089/ars.2019.8013},
	abstract = {Significance: Mitochondria are the cellular powerhouses for ATP synthesis through oxidative phosphorylation, and the centers for fatty acid β-oxidation, metabolite synthesis, reactive oxygen species production, innate immunity, and apoptosis. To fulfill these critical functions, mitochondrial quality and homeostasis must be well maintained. Abnormal mitochondrial quality contributes to aging and age-related disorders, such as metabolic syndrome, cancers, and neurodegenerative diseases.

Recent Advances: Mitophagy is a cellular process that selectively removes damaged or superfluous mitochondria by autolysosomal degradation and is regarded as one of the major mechanisms responsible for mitochondrial quality control.

Critical Issues: To date, distinct mitophagy pathways have been discovered, including receptor-mediated mitophagy and ubiquitin-dependent mitophagy. Emerging knowledge of these pathways shows that they play important roles in sensing mitochondrial stress and signaling for metabolic adaptations.

Future Directions: Here, we provide a review on the molecular mechanisms for mitophagy and its interplay with cellular metabolism, with a particular focus on its role in metabolic and age-related disorders.},
	number = {12},
	urldate = {2022-05-31},
	journal = {Antioxidants \& Redox Signaling},
	author = {Liu, Lei and Liao, Xudong and Wu, Hao and Li, Yanjun and Zhu, Yushan and Chen, Quan},
	month = apr,
	year = {2020},
	keywords = {aging, metabolic disorder, mitochondria, mitophagy, neurodegenerative diseases},
	pages = {906--927},
}

@book{hecht_multivariate_2020,
	title = {Multivariate {Interpolation} on {Unisolvent} {Nodes} -- {Lifting} the {Curse} of {Dimensionality}},
	abstract = {We present generalizations of the classic Newton and Lagrange interpolation schemes to arbitrary dimensions. The core contribution that enables this new method is the notion of unisolvent nodes, i.e., nodes on which the multivariate polynomial interpolant of a function is unique. We prove that by choosing these nodes in a proper way, the resulting interpolation schemes become generic, while approximating all continuous Sobolev functions. If in addition the function is analytical in the Trefethen domain then, by validation, we achieve the optimal exponential approximation rate given by the upper bound in Trefethen's Theorem. The number of interpolation nodes required for computing the optimal interpolant depends sub-exponentially on the dimension, hence resisting the curse of dimensionality. Based on this, we propose an algorithm that can efficiently and numerically stably solve arbitrary-dimensional interpolation problems, and approximate non-analytical functions, with at most quadratic runtime and linear memory requirement.},
	author = {Hecht, Michael and Gonciarz, Krzysztof and Michelfeit, Jannik and Sivkin, Vladimir and Sbalzarini, Ivo},
	month = oct,
	year = {2020},
}

@article{hecht_generalization_2016,
	title = {A {Generalization} of the {Most} {Common} {Subgraph} {Distance} and its {Application} to {Graph} {Editing}},
	doi = {10.1016/j.patrec.2016.09.008},
	abstract = {We relate the graph editing distance to a generalized weighted version of the most common subgraph distance. To do so, we introduce the new concepts of isotonic shifts and vector weighted graphs. As a consequence we can give a weak but sufficient condition on cost models to result in an edit metric, ensuring the richness of the class of these functions. Moreover, for arbitrary instances we are able to determine a within cubic time computable upper bound on the edit distance, which equals the minimized distance for infinitely many instances.},
	journal = {Pattern Recognition Letters},
	author = {Hecht, Michael},
	month = oct,
	year = {2016},
}

@book{paasen_-algorithm_2021,
	title = {An {A}*-algorithm for the {Unordered} {Tree} {Edit} {Distance} with {Custom} {Costs}},
	abstract = {The unordered tree edit distance is a natural metric to compute distances between trees without intrinsic child order, such as representations of chemical molecules. While the unordered tree edit distance is MAX SNP-hard in principle, it is feasible for small cases, e.g. via an A* algorithm. Unfortunately, current heuristics for the A* algorithm assume unit costs for deletions, insertions, and replacements, which limits our ability to inject domain knowledge. In this paper, we present three novel heuristics for the A* algorithm that work with custom cost functions. In experiments on two chemical data sets, we show that custom costs make the A* computation faster and improve the error of a 5-nearest neighbor regressor, predicting chemical properties. We also show that, on these data, polynomial edit distances can achieve similar results as the unordered tree edit distance.},
	author = {Paaßen, Benjamin},
	month = jul,
	year = {2021},
}

@book{sanchez_causal_2022,
	title = {Causal {Machine} {Learning} for {Healthcare} and {Precision} {Medicine}},
	abstract = {Causal machine learning (CML) has experienced increasing popularity in healthcare. Beyond the inherent capabilities of adding domain knowledge into learning systems, CML provides a complete toolset for investigating how a system would react to an intervention (e.g.{\textbackslash} outcome given a treatment). Quantifying effects of interventions allows actionable decisions to be made whilst maintaining robustness in the presence of confounders. Here, we explore how causal inference can be incorporated into different aspects of clinical decision support (CDS) systems by using recent advances in machine learning. Throughout this paper, we use Alzheimer's disease (AD) to create examples for illustrating how CML can be advantageous in clinical scenarios. Furthermore, we discuss important challenges present in healthcare applications such as processing high-dimensional and unstructured data, generalisation to out-of-distribution samples, and temporal relationships, that despite the great effort from the research community remain to be solved. Finally, we review lines of research within causal representation learning, causal discovery and causal reasoning which offer the potential towards addressing the aforementioned challenges.},
	author = {Sanchez, Pedro and Voisey, Jeremy and Xia, Tian and Watson, Hannah and ONeil, Alison and Tsaftaris, Sotirios},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.11402},
	keywords = {causality, machine learning, medicine, review},
}

@article{sbalzarini_anisotropic_2022,
	title = {Anisotropic kernels for self-organizing {Lagrangian} particles},
	abstract = {Lagrangian particle methods are powerful numerical tools for simulating convection-dominated prob-lems and problems in complex geometries. The method is adaptive, since particles naturally follow the flow map, and the resolution can be locally adapted by changing the core sizes (smoothing lengths) of the particles [2]. Determining the total number of particles required to reach a certain error level, as well as a good placement of the particles in the computational domain, however, is not trivial. Principles from particle self-organization (inverse statistical mechanics) allow automatically finding near-optimal dis-tributions of particles at runtime [4]. Additionally, particles are inserted in under-resolved regions and removed from over-resolved regions in order to ensure consistent function approximation everywhere and to dynamically adapt the total number of particles in the simulation [4]. We approximate derivatives using DC-PSE operators, which have been shown to be consistent on arbitrary particle distributions, as well as near boundaries [6]. Particle sizes and cutoff radii are lo-cally adapted as governed by a resolution monitor function [4]. The approximation error of adaptive-resolution DC-PSE operators is bounded by {\textbar}u(x)−u h ε (x){\textbar} ≤ Ch m x {\textbar}{\textbar}u(x){\textbar}{\textbar} W m ∞ (B) , where h x is the local inter-particle distance and {\textbar}{\textbar}u(x){\textbar}{\textbar} W m ∞ (Ω) = max {\textbar}α{\textbar}=m {\textbar}{\textbar}∂u/∂x α {\textbar}{\textbar} L ∞ (Ω) is a measure for the magni-tude of the derivatives of the function u. B is the ball with radius r c,p , the local cutoff radius around particle p. The integer m is the approximation order. The magnitude of the largest partial derivative in any direction hence determines the maximum error. If the directional derivatives of the function are anisotropic, this motivates the use of anisotropic ("elliptical") kernels to further reduce the total number of particles required to represent the function, as illustrated in Fig. 1. This is analogous to ideas used in anisotropic-smoothing SPH [3].},
	author = {Sbalzarini, Ivo and Häcki, Christoph and Reboux, Sylvain},
	month = may,
	year = {2022},
	keywords = {anisotropy, kernel, lagrangian, particles, point cloud},
}

@article{hacki_self-organizing_2015,
	title = {A {Self}-{Organizing} {Adaptive}-{Resolution} {Particle} {Method} with {Anisotropic} {Kernels}},
	volume = {18},
	doi = {10.1016/j.piutam.2015.11.005},
	abstract = {Adaptive-resolution particle methods reduce the computational cost for problems that develop a wide spectrum of length scales in their solution. Concepts from self-organization can be used to determine suitable particle distributions, sizes, and numbers at runtime. If the spatial derivatives of the function strongly depend on the direction, the computational cost and the required number of particles can be further reduced by using anisotropic particles. Anisotropic particles have ellipsoidal influence regions (shapes) that are locally aligned with the direction of smallest variation of the function. We present a framework that allows consistent evaluation of linear differential operators on arbitrary distributions of anisotropic particles. We further extend the concept of particle self-organization to anisotropic particles, where also the directions and magnitudes of anisotropy are self-adapted. We benchmark the accuracy and efficiency of the method in a number of 2D and 3D test cases.},
	journal = {Procedia IUTAM},
	author = {Häcki, Christoph and Reboux, Sylvain and Sbalzarini, Ivo},
	month = dec,
	year = {2015},
	keywords = {adaptive, kernel, particle, point cloud, self-organizing},
	pages = {40--55},
}

@article{singh_c_2021,
	title = {A {C}++ expression system for partial differential equations enables generic simulations of biological hydrodynamics},
	volume = {44},
	doi = {10.1140/epje/s10189-021-00121-x},
	abstract = {We present a user-friendly and intuitive C++ expression system to implement numerical simulations of continuum biological hydrodynamics. The expression system allows writing simulation programs in near-mathematical notation and makes codes more readable, more compact, and less error-prone. It also cleanly separates the implementation of the partial differential equation model from the implementation of the numerical methods used to discretize it. This allows changing either of them with minimal changes to the source code. The presented expression system is implemented in the high-performance computing platform OpenFPM, supporting simulations that transparently parallelize on multi-processor computer systems. We demonstrate that our expression system makes it easier to write scalable codes for simulating biological hydrodynamics in space and time. We showcase the present framework in numerical simulations of active polar fluids, as well as in classic simulations of fluid dynamics from the incompressible Navier–Stokes equations to Stokes flow in a ball. The presented expression system accelerates scalable simulations of spatio-temporal models that encode the physics and material properties of tissues in order to algorithmically study morphogenesis.

Graphicabstract},
	journal = {The European Physical Journal E},
	author = {Singh, Abhinav and Incardona, Pietro and Sbalzarini, Ivo},
	month = sep,
	year = {2021},
	keywords = {C++, partial differential equation, physics, simulation},
}

@book{singh_mesh-free_2022,
	title = {Mesh-free collocation for surface differential operators},
	abstract = {We present a mesh-free collocation scheme to discretize intrinsic surface differential operators over surface point clouds with given normal vectors. The method is based on Discretization-Corrected Particle Strength Exchange (DC-PSE), which generalizes finite difference methods to mesh-free point clouds and moving Lagrangian particles. The resulting Surface DC-PSE method is derived from an embedding theorem, but we analytically reduce the operator kernels along the surface normals, resulting in an embedding-free, purely surface-intrinsic computational scheme. We benchmark the scheme by discretizing the Laplace-Beltrami operator on a circle and a sphere, and present convergence results for both explicit and implicit solvers. We then showcase the algorithm on the problem of computing mean curvature of an ellipsoid and of the Stanford Bunny by evaluating the surface divergence of the normal vector field with the proposed Surface DC-PSE method.},
	author = {Singh, Abhinav and Foggia, Alejandra and Incardona, Pietro and Sbalzarini, Ivo},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.10898},
	keywords = {collocation, graph, mesh, particle, surface differential},
}

@book{morehead_egr_2022,
	title = {{EGR}: {Equivariant} {Graph} {Refinement} and {Assessment} of {3D} {Protein} {Complex} {Structures}},
	shorttitle = {{EGR}},
	abstract = {Protein complexes are macromolecules essential to the functioning and well-being of all living organisms. As the structure of a protein complex, in particular its region of interaction between multiple protein subunits (i.e., chains), has a notable influence on the biological function of the complex, computational methods that can quickly and effectively be used to refine and assess the quality of a protein complex's 3D structure can directly be used within a drug discovery pipeline to accelerate the development of new therapeutics and improve the efficacy of future vaccines. In this work, we introduce the Equivariant Graph Refiner (EGR), a novel E(3)-equivariant graph neural network (GNN) for multi-task structure refinement and assessment of protein complexes. Our experiments on new, diverse protein complex datasets, all of which we make publicly available in this work, demonstrate the state-of-the-art effectiveness of EGR for atomistic refinement and assessment of protein complexes and outline directions for future work in the field. In doing so, we establish a baseline for future studies in macromolecular refinement and structure analysis.},
	author = {Morehead, Alex and Chen, Xiao and Wu, Tianqi and Liu, Jian and Cheng, Jianlin},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.10390},
	keywords = {equivariance, graph, protein complex, protein structure},
}

@book{zwick_recovery_2022,
	title = {Recovery by discretization corrected particle strength exchange ({DC} {PSE}) operators},
	abstract = {A new recovery technique based on discretization corrected particle strength exchange (DC PSE) operators is developed in this paper. DC PSE is a collocation method that can be used to compute derivatives directly at nodal points, instead of by projection from Gauss points as is done in many finite element-based recovery techniques. The proposed method is truly meshless and does not require patches of elements to be defined, which makes it generally applicable to point clouds and arbitrary element topologies. Numerical examples show that the proposed method is accurate and robust.},
	author = {Zwick, Benjamin and Bourantas, George and Alkhatib, Farah and Wittek, Adam and Miller, Karol},
	month = apr,
	year = {2022},
}

@article{bernard_shape-aware_2017,
	title = {Shape-aware surface reconstruction from sparse {3D} point-clouds},
	volume = {38},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841517300233},
	doi = {10.1016/j.media.2017.02.005},
	abstract = {The reconstruction of an object’s shape or surface from a set of 3D points plays an important role in medical image analysis, e.g. in anatomy reconstruction from tomographic measurements or in the process of aligning intra-operative navigation and preoperative planning data. In such scenarios, one usually has to deal with sparse data, which significantly aggravates the problem of reconstruction. However, medical applications often provide contextual information about the 3D point data that allow to incorporate prior knowledge about the shape that is to be reconstructed. To this end, we propose the use of a statistical shape model (SSM) as a prior for surface reconstruction. The SSM is represented by a point distribution model (PDM), which is associated with a surface mesh. Using the shape distribution that is modelled by the PDM, we formulate the problem of surface reconstruction from a probabilistic perspective based on a Gaussian Mixture Model (GMM). In order to do so, the given points are interpreted as samples of the GMM. By using mixture components with anisotropic covariances that are “oriented” according to the surface normals at the PDM points, a surface-based fitting is accomplished. Estimating the parameters of the GMM in a maximum a posteriori manner yields the reconstruction of the surface from the given data points. We compare our method to the extensively used Iterative Closest Points method on several different anatomical datasets/SSMs (brain, femur, tibia, hip, liver) and demonstrate superior accuracy and robustness on sparse data.},
	language = {en},
	urldate = {2022-05-25},
	journal = {Medical Image Analysis},
	author = {Bernard, Florian and Salamanca, Luis and Thunberg, Johan and Tack, Alexander and Jentsch, Dennis and Lamecker, Hans and Zachow, Stefan and Hertel, Frank and Goncalves, Jorge and Gemmar, Peter},
	month = may,
	year = {2017},
	keywords = {Expected conditional maximisation, Gaussian mixture model, Point distribution model, Sparse shape reconstruction, Statistical shape model},
	pages = {77--89},
}

@inproceedings{golovinskiy_shape-based_2009,
	title = {Shape-based recognition of {3D} point clouds in urban environments},
	doi = {10.1109/ICCV.2009.5459471},
	abstract = {This paper investigates the design of a system for recognizing objects in 3D point clouds of urban environments. The system is decomposed into four steps: locating, segmenting, characterizing, and classifying clusters of 3D points. Specifically, we first cluster nearby points to form a set of potential object locations (with hierarchical clustering). Then, we segment points near those locations into foreground and background sets (with a graph-cut algorithm). Next, we build a feature vector for each point cluster (based on both its shape and its context). Finally, we label the feature vectors using a classifier trained on a set of manually labeled objects. The paper presents several alternative methods for each step. We quantitatively evaluate the system and tradeoffs of different alternatives in a truthed part of a scan of Ottawa that contains approximately 100 million points and 1000 objects of interest. Then, we use this truth data as a training set to recognize objects amidst approximately 1 billion points of the remainder of the Ottawa scan.},
	booktitle = {2009 {IEEE} 12th {International} {Conference} on {Computer} {Vision}},
	author = {Golovinskiy, Aleksey and Kim, Vladimir G. and Funkhouser, Thomas},
	month = sep,
	year = {2009},
	note = {ISSN: 2380-7504},
	keywords = {Clouds},
	pages = {2154--2161},
}

@article{xia_geometric_2020,
	title = {Geometric {Primitives} in {LiDAR} {Point} {Clouds}: {A} {Review}},
	volume = {13},
	issn = {2151-1535},
	shorttitle = {Geometric {Primitives} in {LiDAR} {Point} {Clouds}},
	doi = {10.1109/JSTARS.2020.2969119},
	abstract = {To the best of our knowledge, the most recent light detection and ranging (lidar)-based surveys have been focused only on specific applications such as reconstruction and segmentation, as well as data processing techniques based on a specific platform, e.g., mobile laser. However, in this article, lidar point clouds are understood from a new and universal perspective, i.e., geometric primitives embedded in versatile objects in the physical world. In lidar point clouds, the basic unit is the point coordinate. Geometric primitives that consist of a group of discrete points may be viewed as one kind of abstraction and representation of lidar data at the entity level. We categorize geometric primitives into two classes: shape primitives, e.g., lines, surfaces, and volumetric shapes, and structure primitives, represented by skeletons and edges. In recent years, many efforts from different communities, such as photogrammetry, computer vision, and computer graphics, have been made to finalize geometric primitive detection, regularization, and in-depth applications. Interpretations of geometric primitives from multiple disciplines try to convey the significance of geometric primitives, the latest processing techniques regarding geometric primitives, and their potential possibilities in the context of lidar point clouds. To this end, primitive-based applications are reviewed with an emphasis on object extraction and reconstruction to clearly show the significances of this article. Next, we survey and compare methods for geometric primitive extraction and then review primitive regularization methods that add real-world constrains to initial primitives. Finally, we summarize the challenges, expected applications, and describe possible future for primitive extraction methods that can achieve globally optimal results efficiently, even with disorganized, uneven, noisy, incomplete, and large-scale lidar point clouds.},
	journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	author = {Xia, Shaobo and Chen, Dong and Wang, Ruisheng and Li, Jonathan and Zhang, Xinchang},
	year = {2020},
	keywords = {Buildings, Edges, Image edge detection, Laser radar, Shape, Skeleton, Three-dimensional displays, Vegetation mapping, geometric primitives, light detection and ranging (lidar), lines, planes, point clouds, regularization, skeletons, volumetric shapes},
	pages = {685--707},
}

@inproceedings{achlioptas_learning_2018,
	title = {Learning {Representations} and {Generative} {Models} for {3D} {Point} {Clouds}},
	url = {https://proceedings.mlr.press/v80/achlioptas18a.html},
	abstract = {Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep AutoEncoder (AE) network with state-of-the-art reconstruction quality and generalization ability. The learned representations outperform existing methods on 3D recognition tasks and enable shape editing via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation, as well as shape completion. We perform a thorough study of different generative models including GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space of our AEs, and Gaussian Mixture Models (GMMs). To quantitatively evaluate generative models we introduce measures of sample fidelity and diversity based on matchings between sets of point clouds. Interestingly, our evaluation of generalization, fidelity and diversity reveals that GMMs trained in the latent space of our AEs yield the best results overall.},
	language = {en},
	urldate = {2022-05-25},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Achlioptas, Panos and Diamanti, Olga and Mitliagkas, Ioannis and Guibas, Leonidas},
	month = jul,
	year = {2018},
	pages = {40--49},
}

@article{bello_review_2020,
	title = {Review: {Deep} {Learning} on {3D} {Point} {Clouds}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	shorttitle = {Review},
	url = {https://www.mdpi.com/2072-4292/12/11/1729},
	doi = {10.3390/rs12111729},
	abstract = {A point cloud is a set of points defined in a 3D metric space. Point clouds have become one of the most significant data formats for 3D representation and are gaining increased popularity as a result of the increased availability of acquisition devices, as well as seeing increased application in areas such as robotics, autonomous driving, and augmented and virtual reality. Deep learning is now the most powerful tool for data processing in computer vision and is becoming the most preferred technique for tasks such as classification, segmentation, and detection. While deep learning techniques are mainly applied to data with a structured grid, the point cloud, on the other hand, is unstructured. The unstructuredness of point clouds makes the use of deep learning for its direct processing very challenging. This paper contains a review of the recent state-of-the-art deep learning techniques, mainly focusing on raw point cloud data. The initial work on deep learning directly with raw point cloud data did not model local regions; therefore, subsequent approaches model local regions through sampling and grouping. More recently, several approaches have been proposed that not only model the local regions but also explore the correlation between points in the local regions. From the survey, we conclude that approaches that model local regions and take into account the correlation between points in the local regions perform better. Contrary to existing reviews, this paper provides a general structure for learning with raw point clouds, and various methods were compared based on the general structure. This work also introduces the popular 3D point cloud benchmark datasets and discusses the application of deep learning in popular 3D vision tasks, including classification, segmentation, and detection.},
	language = {en},
	number = {11},
	urldate = {2022-05-25},
	journal = {Remote Sensing},
	author = {Bello, Saifullahi Aminu and Yu, Shangshu and Wang, Cheng and Adam, Jibril Muhmmad and Li, Jonathan},
	month = jan,
	year = {2020},
	keywords = {classification, datasets, deep learning, object detection, point cloud, segmentation},
	pages = {1729},
}

@article{guo_deep_2021,
	title = {Deep {Learning} for {3D} {Point} {Clouds}: {A} {Survey}},
	volume = {43},
	issn = {1939-3539},
	shorttitle = {Deep {Learning} for {3D} {Point} {Clouds}},
	doi = {10.1109/TPAMI.2020.3005434},
	abstract = {Point cloud learning has lately attracted increasing attention due to its wide applications in many areas, such as computer vision, autonomous driving, and robotics. As a dominating technique in AI, deep learning has been successfully used to solve various 2D vision problems. However, deep learning on point clouds is still in its infancy due to the unique challenges faced by the processing of point clouds with deep neural networks. Recently, deep learning on point clouds has become even thriving, with numerous methods being proposed to address different problems in this area. To stimulate future research, this paper presents a comprehensive review of recent progress in deep learning methods for point clouds. It covers three major tasks, including 3D shape classification, 3D object detection and tracking, and 3D point cloud segmentation. It also presents comparative results on several publicly available datasets, together with insightful observations and inspiring future research directions.},
	number = {12},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Guo, Yulan and Wang, Hanyun and Hu, Qingyong and Liu, Hao and Liu, Li and Bennamoun, Mohammed},
	month = dec,
	year = {2021},
	keywords = {3D data, Deep learning, Laser radar, Object detection, Sensors, Solid modeling, Task analysis, Three-dimensional displays, instance segmentation, object detection, object tracking, part segmentation, point clouds, scene flow, semantic segmentation, shape classification, shape retrieval},
	pages = {4338--4364},
}

@book{schnabel_shape_2008,
	title = {Shape {Recognition} in {3D} {Point}-{Clouds}},
	copyright = {© Václav Skala - UNION Agency},
	isbn = {9788086943152},
	url = {http://dspace5.zcu.cz/handle/11025/10920},
	abstract = {While the recent improvements in geometry acquisition techniques allow for the easy generation of large and detailed point
cloud representations of real-world objects, tasks as basic as for example the selection of all windows in 3D laser range data
of a house still require a disproportional amount of user interaction. In this paper we address this issue and present a flexible
framework for the rapid detection of such features in large point clouds. Features are represented as constrained graphs that
describe configurations of basic shapes, e.g. planes, cylinders, etc. Experimental results in various scenarios related to the
architectural domain demonstrate the feasibility of our approach.},
	language = {en},
	urldate = {2022-05-25},
	publisher = {Václav Skala - UNION Agency},
	author = {Schnabel, Ruwen and Wessel, Raoul and Wahl, Roland and Klein, Reinhard},
	year = {2008},
}

@inproceedings{komarichev_-cnn_2019,
	title = {A-{CNN}: {Annularly} {Convolutional} {Neural} {Networks} on {Point} {Clouds}},
	shorttitle = {A-{CNN}},
	url = {https://openaccess.thecvf.com/content_CVPR_2019/html/Komarichev_A-CNN_Annularly_Convolutional_Neural_Networks_on_Point_Clouds_CVPR_2019_paper.html},
	urldate = {2022-05-25},
	author = {Komarichev, Artem and Zhong, Zichun and Hua, Jing},
	year = {2019},
	pages = {7421--7430},
}

@book{noauthor_equivariant_2022,
	title = {Equivariant {Mesh} {Attention} {Networks}},
	abstract = {Equivariance to symmetries has proven to be a powerful inductive bias in deep learning research. Recent works on mesh processing have concentrated on various kinds of natural symmetries, including translations, rotations, scaling, node permutations, and gauge transformations. To date, no existing architecture is equivariant to all of these transformations. Moreover, previous implementations have not always applied these symmetry transformations to the test dataset. This inhibits the ability to determine whether the model attains the claimed equivariance properties. In this paper, we present an attention-based architecture for mesh data that is provably equivariant to all transformations mentioned above. We carry out experiments on the FAUST and TOSCA datasets, and apply the mentioned symmetries to the test set only. Our results confirm that our proposed architecture is equivariant, and therefore robust, to these local/global transformations.},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.10662},
}

@book{winter_unsupervised_2022,
	title = {Unsupervised {Learning} of {Group} {Invariant} and {Equivariant} {Representations}},
	abstract = {Equivariant neural networks, whose hidden features transform according to representations of a group G acting on the data, exhibit training efficiency and an improved generalisation performance. In this work, we extend group invariant and equivariant representation learning to the field of unsupervised deep learning. We propose a general learning strategy based on an encoder-decoder framework in which the latent representation is disentangled in an invariant term and an equivariant group action component. The key idea is that the network learns the group action on the data space and thus is able to solve the reconstruction task from an invariant data representation, hence avoiding the necessity of ad-hoc group-specific implementations. We derive the necessary conditions on the equivariant encoder, and we present a construction valid for any G, both discrete and continuous. We describe explicitly our construction for rotations, translations and permutations. We test the validity and the robustness of our approach in a variety of experiments with diverse data types employing different network architectures.},
	author = {Winter, Robin and Bertolini, Marco and Le, Tuan and Noé, Frank and Clevert, Djork-Arné},
	month = feb,
	year = {2022},
}

@article{celledoni_equivariant_2021,
	title = {Equivariant neural networks for inverse problems},
	volume = {37},
	doi = {10.1088/1361-6420/ac104f},
	abstract = {In recent years the use of convolutional layers to encode an inductive bias (translational equivariance) in neural networks has proven to be a very fruitful idea. The successes of this approach have motivated a line of research into incorporating other symmetries into deep learning methods, in the form of group equivariant convolutional neural networks. Much of this work has been focused on roto-translational symmetry of R d , but other examples are the scaling symmetry of R d and rotational symmetry of the sphere. In this work, we demonstrate that group equivariant convolutional operations can naturally be incorporated into learned reconstruction methods for inverse problems that are motivated by the variational regularisation approach. Indeed, if the regularisation functional is invariant under a group symmetry, the corresponding proximal operator will satisfy an equivariance property with respect to the same group symmetry. As a result of this observation, we design learned iterative methods in which the proximal operators are modelled as group equivariant convolutional neural networks. We use roto-translationally equivariant operations in the proposed methodology and apply it to the problems of low-dose computerised tomography reconstruction and subsampled magnetic resonance imaging reconstruction. The proposed methodology is demonstrated to improve the reconstruction quality of a learned reconstruction method with a little extra computational cost at training time but without any extra cost at test time.},
	journal = {Inverse Problems},
	author = {Celledoni, Elena and Ehrhardt, Matthias and Etmann, Christian and Owren, Brynjulf and Schönlieb, Carola-Bibiane and Sherry, Ferdia},
	month = jun,
	year = {2021},
}

@article{bribiesca_measure_2000,
	title = {A measure of compactness for {3D} shapes},
	volume = {40},
	issn = {0898-1221},
	url = {https://www.sciencedirect.com/science/article/pii/S0898122100002388},
	doi = {10.1016/S0898-1221(00)00238-8},
	abstract = {A measure of compactness for 3D (three dimensional) shapes composed of voxels, is presented. The work proposed here improves and extends to the measure of discrete compactness [1] from 2D (two dimensional) domain to 3D. The measure of discrete compactness proposed here corresponds to the sum of the contact surface areas of the face-connected voxels of 3D shapes. A relation between the area of the surface enclosing the volume and the contact surface area, is presented. The concept of contact surfaces is extended to 3D shapes composed of different polyhedrons, which divide space generating different 3D lattices. The measure proposed here of discrete compactness is invariant under translation, rotation, and scaling. In this work, the term of compactness does not refer to point-set topology, but is related to intrinsic properties of objects. Finally, in order to prove our measure of compactness, we calculate the measures of discrete compactness of different volcanos (which are compared with their classical measures) from the valley of México using Digital Elevation Model (DEM) data.},
	language = {en},
	number = {10},
	urldate = {2022-05-24},
	journal = {Computers \& Mathematics with Applications},
	author = {Bribiesca, E.},
	month = nov,
	year = {2000},
	keywords = {3D shape analysis, 3D shape classification, Contact surface, Discrete compactness, Geometric solids, Measure of compactness, Polyhedrons},
	pages = {1275--1284},
}

@inproceedings{fonseca_using_2000,
	title = {Using fuzzy logic to recognize geometric shapes interactively},
	volume = {1},
	doi = {10.1109/FUZZY.2000.838674},
	abstract = {Presents a simple method, based on fuzzy logic, to recognize multi-stroke sketches of geometric shapes and uni-stroke gestural commands. It uses temporal adjacency and global geometric properties of figures to recognize a simple vocabulary of geometric shapes drawn in different line styles. The geometric features used (convex hull, largest-area inscribed and smallest-area enclosing polygons, perimeter and area ratios) are invariant with rotation and scale of figures. Through experimental evaluation we have found the method very usable with acceptable recognition rates although the multi-stroke approach poses problems in choosing appropriate values for timeouts. Although we have privileged simplicity over robustness, the method has proved suitable for interactive applications.},
	booktitle = {Ninth {IEEE} {International} {Conference} on {Fuzzy} {Systems}. {FUZZ}- {IEEE} 2000 ({Cat}. {No}.{00CH37063})},
	author = {Fonseca, M.J. and Jorge, J.A.},
	month = may,
	year = {2000},
	note = {ISSN: 1098-7584},
	keywords = {Application software, Computer peripherals, Degradation, Filters, Fuzzy logic, Humans, Noise shaping, Personal digital assistants, Robustness, Shape},
	pages = {291--296 vol.1},
}

@article{semwal_ray_1995,
	series = {Virtual {Reality} for {Medicine}},
	title = {Ray casting and the enclosing-net algorithm for extracting shapes from volume data},
	volume = {25},
	issn = {0010-4825},
	url = {https://www.sciencedirect.com/science/article/pii/001048259400044Q},
	doi = {10.1016/0010-4825(94)00044-Q},
	abstract = {One of the most useful applications of virtual reality is to let doctors view the inside of the human body non-invasively and in real time. In this paper, we first survey the area of virtual reality and volume-visualization techniques. We discuss our ray casting implementation for viewing the medical data which is available as a set of slices from NMR and CT scans. Next we present a new method, the enclosing-net algorithm, for extracting iso-surfaces from volume data. A simple implementation of our technique is described. Since the topology of the extracted surface is well defined and non-ambiguous, the enclosing-net algorithm eliminates a major problem of surface extraction techniques. In addition, the number of polygons representing the surface can be controlled to obtain a finer shape. Therefore real-time interaction is feasible on both low-end and high-end graphics machines, making the enclosing-net algorithm suitable for virtual reality experiments.},
	language = {en},
	number = {2},
	urldate = {2022-05-24},
	journal = {Computers in Biology and Medicine},
	author = {Semwal, Sudhanshu K. and Barnhart, Brian K.},
	month = mar,
	year = {1995},
	keywords = {Medical imaging, Ray casting, Surface extraction, Virtual reality},
	pages = {261--276},
}

@article{schlei_new_2009,
	title = {A new computational framework for {2D} shape-enclosing contours},
	volume = {27},
	issn = {0262-8856},
	url = {https://www.sciencedirect.com/science/article/pii/S0262885608001467},
	doi = {10.1016/j.imavis.2008.06.014},
	abstract = {In this paper, a new framework for one-dimensional contour extraction from discrete two-dimensional data sets is presented. Contour extraction is important in many scientific fields such as digital image processing, computer vision, pattern recognition, etc. This novel framework includes (but is not limited to) algorithms for dilated contour extraction, contour displacement, shape skeleton extraction, contour continuation, shape feature based contour refinement and contour simplification. Many of the new techniques depend strongly on the application of a Delaunay tessellation. In order to demonstrate the versatility of this novel toolbox approach, the contour extraction techniques presented here are applied to scientific problems in material science, biology, handwritten letter recognition, astronomy and heavy ion physics.},
	language = {en},
	number = {6},
	urldate = {2022-05-24},
	journal = {Image and Vision Computing},
	author = {Schlei, B. R.},
	month = may,
	year = {2009},
	keywords = {Bacterial colony, Constellation, Contour, Delaunay tessellation, Edge, Freeze-out hyper-surface, Handwritten letter recognition, Isocontour, Material surface, Shape morphology, Skeleton, Unstructured grid},
	pages = {637--647},
}

@inproceedings{notarstefano_distributed_2006,
	title = {Distributed consensus on enclosing shapes and minimum time rendezvous},
	doi = {10.1109/CDC.2006.377264},
	abstract = {In this paper we introduce the notion of optimization under control and communication constraint in a robotic network. Starting from a general setup, we focus our attention on the problem of achieving rendezvous in minimum time for a network of first order agents with bounded inputs and limited range communication. We propose two dynamic control and communication laws. These laws are based on consensus algorithms for distributed computation of the minimal enclosing ball and orthotope of a set of points. We prove that these control laws converge to the optimal solution of the centralized problem (i.e., when no communication constrains are enforced) as the bound on the control input goes to zero. Moreover, we give a bound for the time complexity of one of the two laws},
	booktitle = {Proceedings of the 45th {IEEE} {Conference} on {Decision} and {Control}},
	author = {Notarstefano, Giuseppe and Bullo, Francesco},
	month = dec,
	year = {2006},
	note = {ISSN: 0191-2216},
	keywords = {Centralized control, Communication system control, Constraint optimization, Distributed computing, Mobile communication, Motion control, Network topology, Optimal control, Robot kinematics, Shape control},
	pages = {4295--4300},
}

@incollection{epasto_massively_2022,
	series = {Proceedings},
	title = {Massively {Parallel} and {Dynamic} {Algorithms} for {Minimum} {Size} {Clustering}},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611977073.66},
	abstract = {Streaming computation plays an important role in large-scale data analysis. The sliding window model is a model of streaming computation which also captures the recency of the data. In this model, data arrives one item at a time, but only the latest W data items are considered for a particular problem. The goal is to output a good solution at the end of the stream by maintaining a small summary during the stream.In this work, we propose a new algorithmic framework for designing efficient sliding window algorithms via bucketing-based sketches. Based on this new framework, we develop space-efficient sliding window algorithms for k-cover, k-clustering and diversity maximization problems. For each of the above problems, our algorithm achieves (1 ± ∊)-approximation. Compared with the previous work, it improves both the approximation ratio and the space.},
	urldate = {2022-05-24},
	booktitle = {Proceedings of the 2022 {Annual} {ACM}-{SIAM} {Symposium} on {Discrete} {Algorithms} ({SODA})},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Epasto, Alessandro and Mahdian, Mohammad and Mirrokni, Vahab and Zhong, Peilin},
	month = jan,
	year = {2022},
	doi = {10.1137/1.9781611977073.66},
	pages = {1613--1660},
}

@incollection{esfandiari_almost_2022,
	series = {Proceedings},
	title = {Almost {Tight} {Approximation} {Algorithms} for {Explainable} {Clustering}},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611977073.103},
	abstract = {Many clustering algorithms are guided by certain cost functions such as the widely-used k-means cost. These algorithms divide data points into clusters with often complicated boundaries, creating difficulties in explaining the clustering decision. In a recent work, Dasgupta, Frost, Moshkovitz, and Rashtchian (ICML 2020) introduced explainable clustering, where the cluster boundaries are axis-parallel hyperplanes and the clustering is obtained by applying a decision tree to the data. The central question here is: how much does the explainability constraint increase the value of the cost function?Given d-dimensional data points, we show an efficient algorithm that finds an explainable clustering whose k-means cost is at most k1–2/d poly(d log k) times the minimum cost achievable by a clustering without the explainability constraint, assuming k, d ≥ 2. Taking the minimum of this bound and the k polylog(k) bound in independent work by Makarychev-Shan (ICML 2021), Gamlath-Jia-Polak-Svensson (2021), or Esfandiari-Mirrokni-Narayanan (2021), we get an improved bound of k1–2/d polylog(k), which we show is optimal for every choice of k, d ≥ 2 up to a poly-logarithmic factor in k. For d = 2 in particular, we show an O(log k log log k) bound, improving near-exponentially over the previous best bound of O(k log k) by Laber and Murtinho (ICML 2021).},
	urldate = {2022-05-24},
	booktitle = {Proceedings of the 2022 {Annual} {ACM}-{SIAM} {Symposium} on {Discrete} {Algorithms} ({SODA})},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Esfandiari, Hossein and Mirrokni, Vahab and Narayanan, Shyam},
	month = jan,
	year = {2022},
	doi = {10.1137/1.9781611977073.103},
	pages = {2641--2663},
}

@incollection{saha_new_2011,
	series = {Proceedings},
	title = {New {Approximation} {Algorithms} for {Minimum} {Enclosing} {Convex} {Shapes}},
	isbn = {9780898719932},
	url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611973082.86},
	abstract = {Clustering of data in metric spaces is a fundamental problem and has many applications in data mining and it is often used as an unsupervised learning tool inside other machine learning systems. In many scenarios where we are concerned with the privacy implications of clustering users, clusters are required to have minimum-size constraint. A canonical example of min-size clustering is in enforcing anonymization and the protection of the privacy of user data. Our work is motivated by real-world applications (such as the Federated Learning of Cohorts project–FLoC) where a min size clustering algorithm needs to handle very large amount of data and the data may also change over time. Thus efficient parallel or dynamic algorithms are desired.In this paper, we study the r-gather problem, a natural formulation of minimum-size clustering in metric spaces. The goal of r-gather is to partition n points into clusters such that each cluster has size at least r, and the maximum radius of the clusters is minimized. This additional constraint completely changes the algorithmic nature of the problem, and many clustering techniques fail. Also previous dynamic and parallel algorithms do not achieve desirable complexity. We propose algorithms both in the Massively Parallel Computation (MPC) model and in the dynamic setting. Our MPC algorithm handles input points from the Euclidean space ℝd. It computes an O(1)-approximate solution of r-gather in O(log∊ n) rounds using total space O(n1 + γ · d) for arbitrarily small constants ∊, γ {\textgreater} 0. In addition our algorithm is fully scalable, i.e., there is no lower bound on the memory per machine. Our dynamic algorithm maintains an O(1)-approximate r-gather solution under insertions/deletions of points in a metric space with doubling dimension d. The update time is r·2O(d)·logO(1) Λ and the query time is 2O(d) · logO(1) Λ, where Λ is the ratio between the largest and the smallest distance.To obtain our results, we reveal connections between r-gather and r-nearest neighbors and provide several geometric and graph algorithmic tools including a near neighbor graph construction, and results on the maximal independent set / ruling set of the power graph in the MPC model, which might be both of independent interest. To show their generality, we extend our algorithm to solve several variants of r-gather in the MPC model, including r-gather with outliers and r-gather with total distance cost. Finally, we show effectiveness of these algorithmic techniques via a preliminary empirical study for Interest-Based Advertisement applications.},
	urldate = {2022-05-24},
	booktitle = {Proceedings of the 2011 {Annual} {ACM}-{SIAM} {Symposium} on {Discrete} {Algorithms} ({SODA})},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Saha, Ankan and Vishwanathan, S.v. N. and Zhang, Xinhua},
	month = jan,
	year = {2011},
	doi = {10.1137/1.9781611973082.86},
	pages = {1146--1160},
}

@article{demaine_wrapping_2009,
	series = {Special {Issue} on the 23rd {European} {Workshop} on {Computational} {Geometry}},
	title = {Wrapping spheres with flat paper},
	volume = {42},
	issn = {0925-7721},
	url = {https://www.sciencedirect.com/science/article/pii/S0925772109000182},
	doi = {10.1016/j.comgeo.2008.10.006},
	abstract = {We study wrappings of smooth (convex) surfaces by a flat piece of paper or foil. Such wrappings differ from standard mathematical origami because they require infinitely many infinitesimally small folds (“crumpling”) in order to transform the flat sheet into a surface of nonzero curvature. Our goal is to find shapes that wrap a given surface, have small area and small perimeter (for efficient material usage), and tile the plane (for efficient mass production). Our results focus on the case of wrapping a sphere. We characterize the smallest square that wraps the unit sphere, show that a 0.1\% smaller equilateral triangle suffices, and find a 20\% smaller shape contained in the equilateral triangle that still tiles the plane and has small perimeter.},
	language = {en},
	number = {8},
	urldate = {2022-05-24},
	journal = {Computational Geometry},
	author = {Demaine, Erik D. and Demaine, Martin L. and Iacono, John and Langerman, Stefan},
	month = oct,
	year = {2009},
	keywords = {Contractive mapping, Folding, Mozartkugel, Sphere},
	pages = {748--757},
}

@incollection{edelsbrunner_surface_2003,
	address = {Berlin, Heidelberg},
	series = {Algorithms and {Combinatorics}},
	title = {Surface {Reconstruction} by {Wrapping} {Finite} {Sets} in {Space}},
	isbn = {9783642555664},
	url = {https://doi.org/10.1007/978-3-642-55566-4_17},
	abstract = {Given a finite point set in ℝ3, the surface reconstruction problem asks for a surface that passes through many but not necessarily all points. We describe an unambiguous definition of such a surface in geometric and topological terms,and sketch a fast algorithm for constructing it. Our solution overcomes past limitations to special point distributions and heuristic design decisions.},
	language = {en},
	urldate = {2022-05-24},
	booktitle = {Discrete and {Computational} {Geometry}: {The} {Goodman}-{Pollack} {Festschrift}},
	publisher = {Springer},
	author = {Edelsbrunner, Herbert},
	editor = {Aronov, Boris and Basu, Saugata and Pach, János and Sharir, Micha},
	year = {2003},
	doi = {10.1007/978-3-642-55566-4_17},
	keywords = {Homotopy Type, Simplicial Complex, Stable Manifold, Surface Reconstruction, Voronoi Cell},
	pages = {379--404},
}

@article{charlton_application_2001,
	title = {Application of spherical and cylindrical wrapping algorithms in a musculoskeletal model of the upper limb},
	volume = {34},
	issn = {0021-9290},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929001000744},
	doi = {10.1016/S0021-9290(01)00074-4},
	abstract = {In the modelling of the upper limb, many muscles cannot be represented as a straight line from origin to insertion due to the complex morphology causing them to wrap around passive structures. The majority of bony contours that form these obstructions can be described adequately as simple geometric shapes such as spheres and cylinders. A novel technique for the parameterisation of muscle paths as they wrap around such shapes has been developed for use in an upper limb model. The new method involves the definition of moving co-ordinate systems in which the path of a wrapped muscle does not move, allowing simplified specification. In addition, an analytical calculation of the wrapping path around a cylinder is presented over previous approximate methods. Muscle moment arms were pre-calculated from vector considerations and within SIMM by tendon excursion. Close agreement between the two suggests that the proposed implementations accurately follow the theoretical relationship and can be used with confidence in musculoskeletal models.},
	language = {en},
	number = {9},
	urldate = {2022-05-24},
	journal = {Journal of Biomechanics},
	author = {Charlton, Iain W. and Johnson, Garth R.},
	month = sep,
	year = {2001},
	keywords = {Elbow, Flexion, Muscle wrapping, Pronation, Upper limb},
	pages = {1209--1216},
}

@article{ion_shape_2020,
	title = {Shape approximation by developable wrapping},
	volume = {39},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/3414685.3417835},
	doi = {10.1145/3414685.3417835},
	abstract = {We present an automatic tool to approximate curved geometries with piece-wise developable surfaces. At the center of our work is an algorithm that wraps a given 3D input surface with multiple developable patches, each modeled as a discrete orthogonal geodesic net. Our algorithm features a global optimization routine for effectively finding the placement of the developable patches. After wrapping the mesh, we use these patches and a non-linear projection step to generate a surface that approximates the original input, but is also amendable to simple and efficient fabrication techniques thanks to being piecewise developable. Our algorithm allows users to steer the trade-off between approximation power and the number of developable patches used. We demonstrate the effectiveness of our approach on a range of 3D shapes. Compared to previous approaches, our results exhibit a smaller or comparable error with fewer patches to fabricate.},
	number = {6},
	urldate = {2022-05-24},
	journal = {ACM Transactions on Graphics},
	author = {Ion, Alexandra and Rabinovich, Michael and Herholz, Philipp and Sorkine-Hornung, Olga},
	month = nov,
	year = {2020},
	keywords = {developable surfaces, discrete differential geometry, geodesic nets, shape modeling},
	pages = {200:1--200:12},
}

@article{van_den_berg_parameterised_2007,
	title = {Parameterised, constraint-based wrapping of freeform shapes},
	volume = {31},
	issn = {0097-8493},
	url = {https://www.sciencedirect.com/science/article/pii/S0097849306001786},
	doi = {10.1016/j.cag.2006.09.011},
	abstract = {A new technique for creating freeform shapes, called parameterised, constraint-based wrapping, is presented. Here, a shape is defined by a parameterised cross-section that is placed at several positions along a trajectory lying on a freeform surface. The shape is determined in such a way that a seamless connection is established with the existing shape. The mapping between the parameters and the eventual shape is achieved by specifying combinations of geometric and algebraic constraints in a generic shape definition. Specific properties of the wrap shape can be declared in this definition. Parameterised, contraint-based wrapping provides a way of defining freeform geometry in a more intuitive and controlled way than previously possible for similar shapes. It can be applied in a wide variety of areas, and provides an important addition to the collection of existing modelling techniques.},
	language = {en},
	number = {1},
	urldate = {2022-05-24},
	journal = {Computers \& Graphics},
	author = {van den Berg, Eelco and Bronsvoort, Willem F.},
	month = jan,
	year = {2007},
	keywords = {Constraint solving, Constraints, Freeform shapes, Geometric modelling, Parameterisation},
	pages = {89--99},
}

@misc{noauthor_vector-field-smoothed_nodate,
	title = {Vector-field-smoothed {Bayesian} learning for fast and incremental speaker/telephone-channel adaptation - {ScienceDirect}},
	url = {https://www-sciencedirect-com.proxy.lib.sfu.ca/science/article/pii/S088523089690025X},
	urldate = {2022-05-24},
}

@inproceedings{takahashi_vector-field-smoothed_1995,
	title = {Vector-field-smoothed {Bayesian} learning for incremental speaker adaptation},
	volume = {1},
	doi = {10.1109/ICASSP.1995.479789},
	abstract = {The paper presents a fast and incremental speaker adaptation method called MAP/VFS, which combines maximum a posteriori (MAP) estimation, or in other words Bayesian learning, with vector field smoothing (VFS). The point is that MAP is an intra-class training scheme while VFS is an inter-class smoothing technique. This is a basic technique for on-line adaptation which will be important in constructing a practical speech recognition system. Speaker adaptation speed of the incremental MAP is experimentally shown to be significantly accelerated by the use of VFS in word-by-word adaptation. The recognition performance of MAP is consistently improved and stabilized by VFS. The word error reduction rate achieved in incrementally adapting a few words of sample data is about 22\%.},
	booktitle = {1995 {International} {Conference} on {Acoustics}, {Speech}, and {Signal} {Processing}},
	author = {Takahashi, J. and Sagayama, S.},
	month = may,
	year = {1995},
	note = {ISSN: 1520-6149},
	keywords = {Acceleration, Bayesian methods, Data acquisition, Hidden Markov models, Humans, Laboratories, Smoothing methods, Speech recognition, Telephony, Training data},
	pages = {696--699 vol.1},
}

@misc{noauthor_vector_nodate,
	title = {Vector {Field} {Based} {Path} {Planning} and {Petri}-{Net} {Based} {Role} {Selection} {Mechanism} with {Q}-{Learning} for the {Soccer} {Robot} {System}: {Intelligent} {Automation} \& {Soft} {Computing}: {Vol} 6, {No} 1},
	url = {https://www-tandfonline-com.proxy.lib.sfu.ca/doi/abs/10.1080/10798587.2000.10768161?casa_token=_ipINaKqwn4AAAAA:Hr5iz-vZOdF8pz6c8to6pm6WgpEM-rzpV2JOqFNBVErrovLZEruu8KqxKkMmsAwrPgC65ABodjKbjQ},
	urldate = {2022-05-24},
}

@article{ma_robust_2014,
	title = {Robust {Point} {Matching} via {Vector} {Field} {Consensus}},
	volume = {23},
	issn = {1941-0042},
	doi = {10.1109/TIP.2014.2307478},
	abstract = {In this paper, we propose an efficient algorithm, called vector field consensus, for establishing robust point correspondences between two sets of points. Our algorithm starts by creating a set of putative correspondences which can contain a very large number of false correspondences, or outliers, in addition to a limited number of true correspondences (inliers). Next, we solve for correspondence by interpolating a vector field between the two point sets, which involves estimating a consensus of inlier points whose matching follows a nonparametric geometrical constraint. We formulate this a maximum a posteriori (MAP) estimation of a Bayesian model with hidden/latent variables indicating whether matches in the putative set are outliers or inliers. We impose nonparametric geometrical constraints on the correspondence, as a prior distribution, using Tikhonov regularizers in a reproducing kernel Hilbert space. MAP estimation is performed by the EM algorithm which by also estimating the variance of the prior model (initialized to a large value) is able to obtain good estimates very quickly (e.g., avoiding many of the local minima inherent in this formulation). We illustrate this method on data sets in 2D and 3D and demonstrate that it is robust to a very large number of outliers (even up to 90\%). We also show that in the special case where there is an underlying parametric geometrical model (e.g., the epipolar line constraint) that we obtain better results than standard alternatives like RANSAC if a large number of outliers are present. This suggests a two-stage strategy, where we use our nonparametric model to reduce the size of the putative set and then apply a parametric variant of our approach to estimate the geometric parameters. Our algorithm is computationally efficient and we provide code for others to use it. In addition, our approach is general and can be applied to other problems, such as learning with a badly corrupted training data set.},
	number = {4},
	journal = {IEEE Transactions on Image Processing},
	author = {Ma, Jiayi and Zhao, Ji and Tian, Jinwen and Yuille, Alan L. and Tu, Zhuowen},
	month = apr,
	year = {2014},
	keywords = {Estimation, Interpolation, Kernel, Mathematical model, Point correspondence, Robustness, Standards, Vectors, matching, outlier removal, regularization},
	pages = {1706--1721},
}

@article{gutmann_vector_2012,
	title = {Vector {Field} {SLAM}—{Localization} by {Learning} the {Spatial} {Variation} of {Continuous} {Signals}},
	volume = {28},
	issn = {1941-0468},
	doi = {10.1109/TRO.2011.2177691},
	abstract = {Localization in unknown environments using low-cost sensors on embedded hardware is challenging. Yet, it is a requirement for consumer robots if systematic navigation is desired. In this paper, we present a localization approach that learns the spatial variation of an observed continuous signal over the environment. We model the signal as a piecewise linear function and estimate its parameters using a simultaneous localization and mapping (SLAM) approach. By applying the concepts of the exactly sparse extended information filter (ESEIF) , a constant-time, linear-space algorithm is obtained under certain approximations. We apply our framework to a sensor measuring bearing to active beacons, where measurements are distorted because of occlusion and signal reflections. Experimental results from running GraphSLAM, extended Kalman filter SLAM, and ESEIF-SLAM on manually collected sensor measurements, as well as on data recorded on a vacuum-cleaner robot, validate our model. The ESEIF-SLAM solution is evaluated on an ARM 7 embedded board with 64-kB RAM connected to a Roomba 510 vacuum cleaner. The presented methods are also used in Evolution Robotics ' Mint Cleaner product for autonomous floor cleaning.},
	number = {3},
	journal = {IEEE Transactions on Robotics},
	author = {Gutmann, Jens-Steffen and Eade, Ethan and Fong, Philip and Munich, Mario E.},
	month = jun,
	year = {2012},
	keywords = {Calibration, Continuous vector signal, Manganese, Simultaneous localization and mapping, Vectors, localization, simultaneous localization and mapping (SLAM), sparse extended information filter (SEIF)},
	pages = {650--667},
}

@article{mussa-ivaldi_vector_1992,
	title = {Vector field approximation: a computational paradigm for motor control and learning},
	volume = {67},
	issn = {1432-0770},
	shorttitle = {Vector field approximation},
	url = {https://doi.org/10.1007/BF00198756},
	doi = {10.1007/BF00198756},
	abstract = {Recent experiments in the spinalized frog (Bizzi et al. 1991) have shown that focal microstimulation of a site in the premotor layers in the lumbar grey matter of the spinal cord results in a field of forces acting on the frog's ankle and converging to a single equilibrium position. These experiments suggested that the neural circuits in the spinal cord are organized in a set of control modules that “store” a few limb postures in the form of convergent force fields acting on the limb's end-point. Here, we investigate how such postural modules can be combined by the central nervous system for generating and representing a wider repertoire of control patterns. Our work is related to some recent investigations by Poggio and Girosi (1990a, b) who have proposed to represent the task of learning scalar maps as a problem of surface approximation. Consistent both with this view and with our experimental findings in the spinal frog, we regard the issue of generating motor repertoires as a problem of vector-field approximation. To this end, we characterize the output of a control module as a “basis field” (Mussa-Ivaldi 1992), that is as the vectorial equivalent of a basis function. Our theoretical findings indicate that by combining basis fields, the central nervous system may achieve a number of goals such as (1) the generation of a wide repertoire of control patterns and (2) the representation of these control patterns with a set of coefficients that are invariant under coordinate transformations.},
	language = {en},
	number = {6},
	urldate = {2022-05-24},
	journal = {Biological Cybernetics},
	author = {Mussa-Ivaldi, Ferdinando A. and Giszter, Simon F.},
	month = oct,
	year = {1992},
	keywords = {Control Module, Equilibrium Position, Grey Matter, Neural Circuit, Spinal Cord},
	pages = {491--500},
}

@inproceedings{baldassarre_vector_2010,
	title = {Vector {Field} {Learning} via {Spectral} {Filtering}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-15880-3_10},
	doi = {10.1007/978-3-642-15880-3_10},
	abstract = {In this paper we present and study a new class of regularized kernel methods for learning vector fields, which are based on filtering the spectrum of the kernel matrix. These methods include Tikhonov regularization as a special case, as well as interesting...},
	language = {en},
	urldate = {2022-05-24},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Baldassarre, Luca and Rosasco, Lorenzo and Barla, Annalisa and Verri, Alessandro},
	year = {2010},
	pages = {56--71},
}

@article{ma_regularized_2013,
	title = {Regularized vector field learning with sparse approximation for mismatch removal},
	volume = {46},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320313002410},
	doi = {10.1016/j.patcog.2013.05.017},
	abstract = {In vector field learning, regularized kernel methods such as regularized least-squares require the number of basis functions to be equivalent to the training sample size, N. The learning process thus has O(N3) and O(N2) in the time and space complexity, respectively. This poses significant burden on the vector learning problem for large datasets. In this paper, we propose a sparse approximation to a robust vector field learning method, sparse vector field consensus (SparseVFC), and derive a statistical learning bound on the speed of the convergence. We apply SparseVFC to the mismatch removal problem. The quantitative results on benchmark datasets demonstrate the significant speed advantage of SparseVFC over the original VFC algorithm (two orders of magnitude faster) without much performance degradation; we also demonstrate the large improvement by SparseVFC over traditional methods like RANSAC. Moreover, the proposed method is general and it can be applied to other applications in vector field learning.},
	language = {en},
	number = {12},
	urldate = {2022-05-24},
	journal = {Pattern Recognition},
	author = {Ma, Jiayi and Zhao, Ji and Tian, Jinwen and Bai, Xiang and Tu, Zhuowen},
	month = dec,
	year = {2013},
	keywords = {Mismatch removal, Outlier, Regularization, Reproducing kernel Hilbert space, Sparse approximation, Vector field learning},
	pages = {3519--3532},
}

@inproceedings{zhao_robust_2011,
	title = {A robust method for vector field learning with application to mismatch removing},
	doi = {10.1109/CVPR.2011.5995336},
	abstract = {We propose a method for vector field learning with outliers, called vector field consensus (VFC). It could distinguish inliers from outliers and learn a vector field fitting for the inliers simultaneously. A prior is taken to force the smoothness of the field, which is based on the Tiknonov regularization in vector-valued reproducing kernel Hilbert space. Under a Bayesian framework, we associate each sample with a latent variable which indicates whether it is an inlier, and then formulate the problem as maximum a posteriori problem and use Expectation Maximization algorithm to solve it. The proposed method possesses two characteristics: 1) robust to outliers, and being able to tolerate 90\% outliers and even more, 2) computationally efficient. As an application, we apply VFC to solve the problem of mismatch removing. The results demonstrate that our method outperforms many state-of-the-art methods, and it is very robust.},
	booktitle = {{CVPR} 2011},
	author = {Zhao, Ji and Ma, Jiayi and Tian, Jinwen and Ma, Jie and Zhang, Dazhi},
	month = jun,
	year = {2011},
	note = {ISSN: 1063-6919},
	keywords = {Hilbert space, Kernel, Linear systems, Matrix decomposition, Robustness, Training, Vectors},
	pages = {2977--2984},
}

@inproceedings{brault_random_2016,
	title = {Random {Fourier} {Features} {For} {Operator}-{Valued} {Kernels}},
	url = {https://proceedings.mlr.press/v63/Brault39.html},
	abstract = {Devoted to multi-task learning and structured output learning, operator-valued kernels provide a flexible tool to build vector-valued functions in the context of Reproducing Kernel Hilbert Spaces. To scale up these methods, we extend the celebrated Random Fourier Feature methodology to get an approximation of operator-valued kernels. We propose a general principle for Operator-valued Random Fourier Feature construction relying on a generalization of Bochner’s theorem for translation-invariant operator-valued Mercer kernels. We prove the uniform convergence of the kernel approximation for bounded and unbounded operator random Fourier features using appropriate Bernstein matrix concentration inequality. An experimental proof-of-concept shows the quality of the approximation and the efficiency of the corresponding linear models on example datasets.},
	language = {en},
	urldate = {2022-05-24},
	booktitle = {Proceedings of {The} 8th {Asian} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Brault, Romain and Heinonen, Markus and Buc, Florence},
	month = nov,
	year = {2016},
	pages = {110--125},
}

@article{corman_continuous_2015,
	title = {Continuous {Matching} via {Vector} {Field} {Flow}},
	volume = {34},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12702},
	doi = {10.1111/cgf.12702},
	abstract = {We present a new method for non-rigid shape matching designed to enforce continuity of the resulting correspondence. Our method is based on the recently proposed functional map representation, which allows efficient manipulation and inference but often fails to provide a continuous point-to-point mapping. We address this problem by exploiting the connection between the operator representation of mappings and flows of vector fields. In particular, starting from an arbitrary continuous map between two surfaces we find an optimal flow that makes the final correspondence operator as close as possible to the initial functional map. Our method also helps to address the symmetric ambiguity problem inherent in many intrinsic correspondence methods when matching symmetric shapes. We provide practical and theoretical results showing that our method can be used to obtain an orientation preserving or reversing map starting from a functional map that represents the mixture of the two. We also show how this method can be used to improve the quality of maps produced by existing shape matching methods, and compare the resulting map's continuity with results obtained by other operator-based techniques.},
	language = {en},
	number = {5},
	urldate = {2022-05-24},
	journal = {Computer Graphics Forum},
	author = {Corman, Etienne and Ovsjanikov, Maks and Chambolle, Antonin},
	year = {2015},
	keywords = {Categories and Subject Descriptors (according to ACM CCS), I.3.3 Computer Graphics—Shape Analysis},
	pages = {129--139},
}

@inproceedings{tsung_phase-space_1994,
	title = {Phase-{Space} {Learning}},
	volume = {7},
	url = {https://proceedings.neurips.cc/paper/1994/hash/2f885d0fbe2e131bfc9d98363e55d1d4-Abstract.html},
	abstract = {Existing recurrent  net learning algorithms are inadequate.  We  in(cid:173) troduce the conceptual framework of viewing recurrent  training as  matching vector fields of dynamical systems in phase space.  Phase(cid:173) space  reconstruction  techniques  make  the  hidden  states  explicit,  reducing  temporal  learning  to  a  feed-forward  problem.  In  short,  we  propose  viewing  iterated  prediction  [LF88]  as  the  best  way  of  training  recurrent  networks  on  deterministic  signals.  Using  this  framework,  we  can  train  multiple trajectories,  insure  their  stabil(cid:173) ity,  and  design  arbitrary dynamical systems.},
	urldate = {2022-05-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Tsung, Fu-Sheng and Cottrell, Garrison},
	year = {1994},
}

@article{rudy_deep_2019,
	title = {Deep learning of dynamics and signal-noise decomposition with time-stepping constraints},
	volume = {396},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999119304644},
	doi = {10.1016/j.jcp.2019.06.056},
	abstract = {A critical challenge in the data-driven modeling of dynamical systems is producing methods robust to measurement error, particularly when data is limited. Many leading methods either rely on denoising prior to learning or on access to large volumes of data to average over the effect of noise. We propose a novel paradigm for data-driven modeling that simultaneously learns the dynamics and estimates the measurement noise at each observation. By constraining our learning algorithm, our method explicitly accounts for measurement error in the map between observations, treating both the measurement error and the dynamics as unknowns to be identified, rather than assuming idealized noiseless trajectories. We model the unknown vector field using a deep neural network, imposing a Runge-Kutta integrator structure to isolate this vector field, even when the data has a non-uniform timestep, thus constraining and focusing the modeling effort. We demonstrate the ability of this framework to form predictive models on a variety of canonical test problems of increasing complexity and show that it is robust to substantial amounts of measurement error. We also discuss issues with the generalizability of neural network models for dynamical systems and provide open-source code for all examples.},
	language = {en},
	urldate = {2022-05-24},
	journal = {Journal of Computational Physics},
	author = {Rudy, Samuel H. and Nathan Kutz, J. and Brunton, Steven L.},
	month = nov,
	year = {2019},
	keywords = {Data-driven models, Deep learning, Dynamical systems, Machine learning, Neural networks, System identification},
	pages = {483--506},
}

@article{an_stsrnet_2021,
	title = {{STSRNet}: {Deep} {Joint} {Space}–{Time} {Super}-{Resolution} for {Vector} {Field} {Visualization}},
	volume = {41},
	issn = {1558-1756},
	shorttitle = {{STSRNet}},
	doi = {10.1109/MCG.2021.3097555},
	abstract = {We propose STSRNet, a joint space–time super-resolution deep learning based model for time-varying vector field data. Our method is designed to reconstruct high temporal resolution and high spatial resolution vector fields sequence from the corresponding low-resolution key frames. For large scale simulations, only data from a subset of time steps with reduced spatial resolution can be stored for post hoc analysis. In this article, we leverage a deep learning model to capture the nonlinear complex changes of vector field data with a two-stage architecture: the first stage deforms a pair of low spatial resolution (LSR) key frames forward and backward to generate the intermediate LSR frames, and the second stage performs spatial super-resolution to output the high-resolution sequence. Our method is scalable and can handle different datasets. We demonstrate the effectiveness of our framework with several datasets through quantitative and qualitative evaluations.},
	number = {6},
	journal = {IEEE Computer Graphics and Applications},
	author = {An, Yifei and Shen, Han-Wei and Shan, Guihua and Li, Guan and Liu, Jun},
	month = nov,
	year = {2021},
	keywords = {Deep learning, Magnetic susceptibility, Magnetization, Magnetostatics, Space-time codes, Uniform resource locators, Vector quantization},
	pages = {122--132},
}

@article{mussa-ivaldi_basis_1992,
	title = {From basis functions to basis fields: vector field approximation from sparse data},
	volume = {67},
	copyright = {1992 Springer-Verlag},
	issn = {1432-0770},
	shorttitle = {From basis functions to basis fields},
	url = {https://link.springer.com/article/10.1007/BF00198755},
	doi = {10.1007/BF00198755},
	abstract = {Recent investigations (Poggio and Girosi 1990b) have pointed out the equivalence between a wide class of learning problems and the reconstruction of a real-valued function from a sparse set of data. However, in order to process sensory information and to generate purposeful actions living organisms must deal not only with real-valued functions but also with vector-valued mappings. Examples of such vector-valued mappings range from the optical flow fields associated with visual motion to the fields of mechanical forces produced by neuromuscular activation. In this paper, I discuss the issue of vector-field processing from a broad computational perspective. A variety of vector patterns can be efficiently represented by a combination of linearly independent vector fields that I call “basis fields”. Basis fields offer in some cases a better alternative to treating each component of a vector as an independent scalar entity. In spite of its apparent simplicity, such a component-based representation is bound to change with any change of coordinates. In contrast, vector-valued primitives such as basis fields generate vector field representations that are invariant under coordinate transformations.},
	language = {en},
	number = {6},
	urldate = {2022-05-24},
	journal = {Biological Cybernetics},
	author = {Mussa-Ivaldi, Ferdinando A.},
	month = oct,
	year = {1992},
	pages = {479--489},
}

@book{fan_investigation_2021,
	title = {Investigation of effect of modulation frequency on high-density diffuse optical tomography image quality},
	author = {Fan, Weihao and Dehghani, Hamid and Eggebrecht, Adam},
	month = dec,
	year = {2021},
	doi = {10.1117/12.2615344},
}

@article{perkins_quantitative_2021,
	title = {Quantitative evaluation of frequency domain measurements in high density diffuse optical tomography},
	volume = {26},
	doi = {10.1117/1.JBO.26.5.056001},
	abstract = {Significance: 
High density diffuse optical tomography (HD-DOT) as applied in functional near-infrared spectroscopy (fNIRS) is largely limited to continuous wave (CW) data. Using a single modulation frequency, frequency domain (FD) HD-DOT has recently demonstrated better localization of focal activation as compared to CW data. We show that combining CW and FD measurements and multiple modulation frequencies increases imaging performance in fNIRS.

Aim:
We evaluate the benefits of multiple modulation frequencies, combining different frequencies as well as CW data in fNIRS HD-DOT.

Approach:
A layered model was used, with activation occurring within a cortex layer. CW and FD measurements were simulated at 78, 141, and 203 MHz with and without noise. The localization error, full width half maximum, and effective resolution were evaluated.

Results:
Across the average of the three metrics, at 141 MHz, FD performed 8.4\% better than CW, and the combination of CW and FD was 21.7\% better than CW. FD measurements at 203 MHz performed 5\% better than 78 MHz. Moreover, the three combined modulation frequencies of FD and CW performed up to 3.92\% better than 141 MHz alone.

Conclusions:
We show that combining CW and FD measurements offers better performance than FD alone, with higher modulation frequencies increasing accuracy. Combining CW and FD measurements at multiple modulation frequencies yields the best overall performance.},
	journal = {Journal of Biomedical Optics},
	author = {Perkins, Guy and Eggebrecht, Adam and Dehghani, Hamid},
	month = may,
	year = {2021},
}

@article{weinmann_feature_2013,
	title = {Feature relevance assessment for the semantic interpretation of {3D} point cloud data},
	doi = {10.5194/isprsannals-II-5-W2-313-2013},
	abstract = {The automatic analysis of large 3D point clouds represents a crucial task in photogrammetry, remote sensing and computer vision.
In this paper, we propose a new methodology for the semantic interpretation of such point clouds which involves feature relevance
assessment in order to reduce both processing time and memory consumption. Given a standard benchmark dataset with 1.3 million 3D
points, we first extract a set of 21 geometric 3D and 2D features. Subsequently, we apply a classifier-independent ranking procedure
which involves a general relevance metric in order to derive compact and robust subsets of versatile features which are generally
applicable for a large variety of subsequent tasks. This metric is based on 7 different feature selection strategies and thus addresses
different intrinsic properties of the given data. For the example of semantically interpreting 3D point cloud data, we demonstrate the
great potential of smaller subsets consisting of only the most relevant features with 4 different state-of-the-art classifiers. The results
reveal that, instead of including as many features as possible in order to compensate for lack of knowledge, a crucial task such as scene
interpretation can be carried out with only few versatile features and even improved accuracy.},
	journal = {ISPRS Workshop Laser Scanning 2013. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Vol. II-5/W2},
	author = {Weinmann, Martin and Jutzi, Boris and Mallet, Clément},
	month = nov,
	year = {2013},
	pages = {313--318},
}

@article{blomley_shape_2014,
	title = {Shape distribution features for point cloud analysis - {A} geometric histogram approach on multiple scales},
	volume = {II},
	doi = {10.5194/isprsannals-II-3-9-2014},
	abstract = {Due to ever more efficient and accurate laser scanning technologies, the analysis of 3D point clouds has become an important task
in modern photogrammetry and remote sensing. To exploit the full potential of such data for structural analysis and object detection,
reliable geometric features are of crucial importance. Since multiscale approaches have proved very successful for image-based applications,
efforts are currently made to apply similar approaches on 3D point clouds. In this paper we analyse common geometric
covariance features, pinpointing some severe limitations regarding their performance on varying scales. Instead, we propose a different
feature type based on shape distributions known from object recognition. These novel features show a very reliable performance on a
wide scale range and their results in classification outnumber covariance features in all tested cases.},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Blomley, Rosmarie and Weinmann, Martin and Leitloff, Jens and Jutzi, Boris},
	month = sep,
	year = {2014},
}

@article{dragicevic_caffeine_2012,
	title = {Caffeine increases mitochondrial function and blocks melatonin signaling to mitochondria in {Alzheimer}'s mice and cells},
	volume = {63},
	issn = {0028-3908},
	url = {https://www.sciencedirect.com/science/article/pii/S0028390812004546},
	doi = {10.1016/j.neuropharm.2012.08.018},
	abstract = {Caffeine and melatonin have been shown to protect the Swedish mutant amyloid precursor protein (APPsw) transgenic mouse model of Alzheimer's disease from cognitive dysfunction. But their mechanisms of action remain incompletely understood. These Alzheimer's mice have extensive mitochondrial dysfunction, which likely contributes to their cognitive decline. To further explore the mechanism through which caffeine and melatonin protect cognitive function in these mice, we monitored the function of isolated mitochondria from APPsw mice treated with caffeine, melatonin, or both in their drinking water for one month. Melatonin treatment yielded a near complete restoration of mitochondrial function in assays of respiratory rate, membrane potential, reactive oxygen species production, and ATP levels. Caffeine treatment by itself yielded a small increase in mitochondrial function. However, caffeine largely blocked the large enhancement of mitochondrial function provided by melatonin. Studies with N2a neuroblastoma cells stably expressing APPsw showed that specific inhibition of cAMP-dependent phosphodiesterase (PDE) 4 or cGMP-dependent PDE5 also blocked melatonin protection of mitochondrial function, but A2a and A1 adenosine receptor antagonists were without effect. Melatonin or caffeine at the concentrations used to modulate mitochondrial function in the cells had no effect on cAMP-dependent PDE activity or cellular cAMP or cGMP levels. Therefore, caffeine and increased cyclic nucleotide levels likely block melatonin signaling to mitochondria by independent mechanisms that do not involve adenosine receptor antagonism. The results of this study indicate that melatonin restores mitochondrial function much more potently than caffeine in APPsw transgenic mouse and cell models of Alzheimer's disease.},
	language = {en},
	number = {8},
	urldate = {2022-05-23},
	journal = {Neuropharmacology},
	author = {Dragicevic, Natasa and Delic, Vedad and Cao, Chuanhai and Copes, Neil and Lin, Xiaoyang and Mamcarz, Maggie and Wang, Li and Arendash, Gary W. and Bradshaw, Patrick C.},
	month = dec,
	year = {2012},
	keywords = {Alzheimer's disease, Caffeine, Melatonin, Melatonin receptor, Mice, Mitochondrial, Phosphodiesterase},
	pages = {1368--1379},
}

@article{noauthor_caffeine_2021,
	title = {Caffeine and mitochondria with a focus on the central nervous system},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128215623000216},
	doi = {10.1016/B978-0-12-821562-3.00021-6},
	abstract = {Mitochondria are central pieces of machinery of energy production within the cells. Mitochondrial deficits may be functional and structural or a resul…},
	language = {en},
	urldate = {2022-05-23},
	journal = {Mitochondrial Physiology and Vegetal Molecules},
	month = jan,
	year = {2021},
	pages = {413--437},
}

@article{monkemoller_multimodal_2015,
	title = {Multimodal super-resolution optical microscopy visualizes the close connection between membrane and the cytoskeleton in liver sinusoidal endothelial cell fenestrations},
	volume = {5},
	copyright = {2015 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/srep16279},
	doi = {10.1038/srep16279},
	abstract = {Liver sinusoidal endothelial cells (LSECs) act as a filter between blood and the hepatocytes. LSECs are highly fenestrated cells; they contain transcellular pores with diameters between 50 to 200 nm. The small sizes of the fenestrae have so far prohibited any functional analysis with standard and advanced light microscopy techniques. Only the advent of super-resolution optical fluorescence microscopy now permits the recording of such small cellular structures. Here, we demonstrate the complementary use of two different super-resolution optical microscopy modalities, 3D structured illumination microscopy (3D-SIM) and single molecule localization microscopy in a common optical platform to obtain new insights into the association between the cytoskeleton and the plasma membrane that supports the formation of fenestrations. We applied 3D-SIM to multi-color stained LSECs to acquire highly resolved overviews of large sample areas. We then further increased the spatial resolution for imaging fenestrations by single molecule localization microscopy applied to select small locations of interest in the same sample on the same microscope setup. We optimized the use of fluorescent membrane stains for these imaging conditions. The combination of these techniques offers a unique opportunity to significantly improve studies of subcellular ultrastructures such as LSEC fenestrations.},
	language = {en},
	number = {1},
	urldate = {2022-05-22},
	journal = {Scientific Reports},
	author = {Mönkemöller, Viola and Øie, Cristina and Hübner, Wolfgang and Huser, Thomas and McCourt, Peter},
	month = nov,
	year = {2015},
	keywords = {Actin, Applied optics, Molecular biophysics, Super-resolution microscopy},
	pages = {16279},
}

@article{waldchen_whole-cell_2020,
	title = {Whole-cell imaging of plasma membrane receptors by {3D} lattice light-sheet {dSTORM}},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-14731-0},
	doi = {10.1038/s41467-020-14731-0},
	abstract = {The molecular organization of receptors in the plasma membrane of cells is paramount for their functionality. We combined lattice light-sheet (LLS) microscopy with three-dimensional (3D) single-molecule localization microscopy (dSTORM) and single-particle tracking to quantify the expression and distribution, and mobility of CD56 receptors on whole fixed and living cells, finding that CD56 accumulated at cell–cell interfaces. For comparison, we investigated two other receptors, CD2 and CD45, which showed different expression levels and distributions in the plasma membrane. Overall, 3D-LLS-dSTORM enabled imaging and single-particle tracking of plasma membrane receptors with single-molecule sensitivity unperturbed by surface effects. Our results demonstrate that receptor distribution and mobility are largely unaffected by contact to the coverslip but the measured localization densities are in general lower at the basal plasma membrane due to partial limited accessibility for antibodies.},
	language = {en},
	number = {1},
	urldate = {2022-05-22},
	journal = {Nature Communications},
	author = {Wäldchen, Felix and Schlegel, Jan and Götz, Ralph and Luciano, Michael and Schnermann, Martin and Doose, Sören and Sauer, Markus},
	month = feb,
	year = {2020},
	keywords = {Membrane biophysics, Single-molecule biophysics, Super-resolution microscopy},
	pages = {887},
}

@article{bon_self-interference_2018,
	title = {Self-interference {3D} super-resolution microscopy for deep tissue investigations},
	volume = {15},
	copyright = {2018 The Author(s)},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-018-0005-3},
	doi = {10.1038/s41592-018-0005-3},
	abstract = {Fluorescence localization microscopy has achieved near-molecular resolution capable of revealing ultra-structures, with a broad range of applications, especially in cellular biology. However, it remains challenging to attain such resolution in three dimensions and inside biological tissues beyond the first cell layer. Here we introduce SELFI, a framework for 3D single-molecule localization within multicellular specimens and tissues. The approach relies on self-interference generated within the microscope's point spread function (PSF) to simultaneously encode equiphase and intensity fluorescence signals, which together provide the 3D position of an emitter. We combined SELFI with conventional localization microscopy to visualize F-actin 3D filament networks and reveal the spatial distribution of the transcription factor OCT4 in human induced pluripotent stem cells at depths up to 50 µm inside uncleared tissue spheroids. SELFI paves the way to nanoscale investigations of native cellular processes in intact tissues.},
	language = {en},
	number = {6},
	urldate = {2022-05-22},
	journal = {Nature Methods},
	author = {Bon, Pierre and Linarès-Loyez, Jeanne and Feyeux, Maxime and Alessandri, Kevin and Lounis, Brahim and Nassoy, Pierre and Cognet, Laurent},
	month = jun,
	year = {2018},
	keywords = {Interference microscopy, Super-resolution microscopy},
	pages = {449--454},
}

@article{noauthor_mesh_2004,
	title = {A mesh reconstruction algorithm driven by an intrinsic property of a point cloud},
	volume = {36},
	issn = {0010-4485},
	url = {https://www.sciencedirect.com/science/article/pii/S0010448503000642},
	doi = {10.1016/S0010-4485(03)00064-2},
	abstract = {This paper presents an algorithm for reconstructing a triangle mesh surface from a given point cloud. Starting with a seed triangle, the algorithm gro…},
	language = {en},
	number = {1},
	urldate = {2022-05-22},
	journal = {Computer-Aided Design},
	month = jan,
	year = {2004},
	pages = {1--9},
}

@article{jenke_bayesian_2006,
	title = {Bayesian {Point} {Cloud} {Reconstruction}},
	volume = {25},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2006.00957.x},
	doi = {10.1111/j.1467-8659.2006.00957.x},
	abstract = {In this paper, we propose a novel surface reconstruction technique based on Bayesian statistics: The measurement process as well as prior assumptions on the measured objects are modeled as probability distributions and Bayes’ rule is used to infer a reconstruction of maximum probability. The key idea of this paper is to define both measurements and reconstructions as point clouds and describe all statistical assumptions in terms of this finite dimensional representation. This yields a discretization of the problem that can be solved using numerical optimization techniques. The resulting algorithm reconstructs both topology and geometry in form of a well-sampled point cloud with noise removed. In a final step, this representation is then converted into a triangle mesh. The proposed approach is conceptually simple and easy to extend. We apply the approach to reconstruct piecewise-smooth surfaces with sharp features and examine the performance of the algorithm on different synthetic and real-world data sets. Categories and Subject Descriptors (according to ACM CCS): I.5.1 [Models]: Statistical; I.3.5 [Computer Graphics]: Curve, surface, solid and object representations},
	language = {en},
	number = {3},
	urldate = {2022-05-22},
	journal = {Computer Graphics Forum},
	author = {Jenke, P. and Wand, M. and Bokeloh, M. and Schilling, A. and Straßer, W.},
	year = {2006},
	pages = {379--388},
}

@article{nehme_deepstorm3d_2020,
	title = {{DeepSTORM3D}: dense {3D} localization microscopy and {PSF} design by deep learning},
	volume = {17},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{DeepSTORM3D}},
	url = {https://www.nature.com/articles/s41592-020-0853-5},
	doi = {10.1038/s41592-020-0853-5},
	abstract = {An outstanding challenge in single-molecule localization microscopy is the accurate and precise localization of individual point emitters in three dimensions in densely labeled samples. One established approach for three-dimensional single-molecule localization is point-spread-function (PSF) engineering, in which the PSF is engineered to vary distinctively with emitter depth using additional optical elements. However, images of dense emitters, which are desirable for improving temporal resolution, pose a challenge for algorithmic localization of engineered PSFs, due to lateral overlap of the emitter PSFs. Here we train a neural network to localize multiple emitters with densely overlapping Tetrapod PSFs over a large axial range. We then use the network to design the optimal PSF for the multi-emitter case. We demonstrate our approach experimentally with super-resolution reconstructions of mitochondria and volumetric imaging of fluorescently labeled telomeres in cells. Our approach, DeepSTORM3D, enables the study of biological processes in whole cells at timescales that are rarely explored in localization microscopy.},
	language = {en},
	number = {7},
	urldate = {2022-05-22},
	journal = {Nature Methods},
	author = {Nehme, Elias and Freedman, Daniel and Gordon, Racheli and Ferdman, Boris and Weiss, Lucien E. and Alalouf, Onit and Naor, Tal and Orange, Reut and Michaeli, Tomer and Shechtman, Yoav},
	month = jul,
	year = {2020},
	keywords = {Fluorescence imaging, Super-resolution microscopy},
	pages = {734--740},
}

@article{shen_3d_2019,
	title = {{3D} {dSTORM} imaging reveals novel detail of ryanodine receptor localization in rat cardiac myocytes},
	volume = {597},
	issn = {1469-7793},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1113/JP277360},
	doi = {10.1113/JP277360},
	abstract = {Key points Using 3D direct stochastic optical reconstruction microscopy (dSTORM), we developed novel approaches to quantitatively describe the nanoscale, 3D organization of ryanodine receptors (RyRs) in cardiomyocytes. Complex arrangements of RyR clusters were observed in 3D space, both at the cell surface and within the cell interior, with allocation to dyadic and non-dyadic pools. 3D imaging importantly allowed discernment of clusters overlapping in the z-axis, for which detection was obscured by conventional 2D imaging techniques. Thus, RyR clusters were found to be significantly smaller than previous 2D estimates. Ca2+ release units (CRUs), i.e. functional groupings of neighbouring RyR clusters, were similarly observed to be smaller than earlier reports. Internal CRUs contained more RyRs in more clusters than CRUs on the cell surface, and yielded longer duration Ca2+ sparks. Abstract Cardiomyocyte contraction is dependent on Ca2+ release from ryanodine receptors (RyRs). However, the precise localization of RyRs remains unknown, due to shortcomings of imaging techniques which are diffraction limited or restricted to 2D. We aimed to determine the 3D nanoscale organization of RyRs in rat cardiomyocytes by employing direct stochastic optical reconstruction microscopy (dSTORM) with phase ramp technology. Initial observations at the cell surface showed an undulating organization of RyR clusters, resulting in their frequent overlap in the z-axis and obscured detection by 2D techniques. Non-overlapping clusters were imaged to create a calibration curve for estimating RyR number based on recorded fluorescence blinks. Employing this method at the cell surface and interior revealed smaller RyR clusters than 2D estimates, as erroneous merging of axially aligned RyRs was circumvented. Functional groupings of RyR clusters (Ca2+ release units, CRUs), contained an average of 18 and 23 RyRs at the surface and interior, respectively, although half of all CRUs contained only a single ‘rogue’ RyR. Internal CRUs were more tightly packed along z-lines than surface CRUs, contained larger and more numerous RyR clusters, and constituted ∼75\% of the roughly 1 million RyRs present in an average cardiomyocyte. This complex internal 3D geometry was underscored by correlative imaging of RyRs and t-tubules, which enabled quantification of dyadic and non-dyadic RyR populations. Mirroring differences in CRU size and complexity, Ca2+ sparks originating from internal CRUs were of longer duration than those at the surface. These data provide novel, nanoscale insight into RyR organization and function across cardiomyocytes.},
	language = {en},
	number = {2},
	urldate = {2022-05-22},
	journal = {The Journal of Physiology},
	author = {Shen, Xin and van den Brink, Jonas and Hou, Yufeng and Colli, Dylan and Le, Christopher and Kolstad, Terje R. and MacQuaide, Niall and Carlson, Cathrine R. and Kekenes-Huskey, Peter M. and Edwards, Andrew G. and Soeller, Christian and Louch, William E.},
	year = {2019},
	keywords = {3D super-resolution imaging, Ryanodine Receptors, calcium homeostasis, excitation-contraction coupling, t-tubule},
	pages = {399--418},
}

@article{navaneet_capnet_2019,
	title = {{CAPNet}: {Continuous} {Approximation} {Projection} for {3D} {Point} {Cloud} {Reconstruction} {Using} {2D} {Supervision}},
	volume = {33},
	copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {{CAPNet}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4908},
	doi = {10.1609/aaai.v33i01.33018819},
	abstract = {Knowledge of 3D properties of objects is a necessity in order to build effective computer vision systems. However, lack of large scale 3D datasets can be a major constraint for datadriven approaches in learning such properties. We consider the task of single image 3D point cloud reconstruction, and aim to utilize multiple foreground masks as our supervisory data to alleviate the need for large scale 3D datasets. A novel differentiable projection module, called ‘CAPNet’, is introduced to obtain such 2D masks from a predicted 3D point cloud. The key idea is to model the projections as a continuous approximation of the points in the point cloud. To overcome the challenges of sparse projection maps, we propose a loss formulation termed ‘affinity loss’ to generate outlierfree reconstructions. We significantly outperform the existing projection based approaches on a large-scale synthetic dataset. We show the utility and generalizability of such a 2D supervised approach through experiments on a real-world dataset, where lack of 3D data can be a serious concern. To further enhance the reconstructions, we also propose a test stage optimization procedure to obtain reconstructions that display high correspondence with the observed input image.},
	language = {en},
	number = {01},
	urldate = {2022-05-22},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Navaneet, K. L. and Mandikal, Priyanka and Agarwal, Mayank and Babu, R. Venkatesh},
	month = jul,
	year = {2019},
	pages = {8819--8826},
}

@techreport{mandikal_3d-lmnet_2019,
	title = {{3D}-{LMNet}: {Latent} {Embedding} {Matching} for {Accurate} and {Diverse} {3D} {Point} {Cloud} {Reconstruction} from a {Single} {Image}},
	shorttitle = {{3D}-{LMNet}},
	url = {http://arxiv.org/abs/1807.07796},
	abstract = {3D reconstruction from single view images is an ill-posed problem. Inferring the hidden regions from self-occluded images is both challenging and ambiguous. We propose a two-pronged approach to address these issues. To better incorporate the data prior and generate meaningful reconstructions, we propose 3D-LMNet, a latent embedding matching approach for 3D reconstruction. We first train a 3D point cloud auto-encoder and then learn a mapping from the 2D image to the corresponding learnt embedding. To tackle the issue of uncertainty in the reconstruction, we predict multiple reconstructions that are consistent with the input view. This is achieved by learning a probablistic latent space with a novel view-specific diversity loss. Thorough quantitative and qualitative analysis is performed to highlight the significance of the proposed approach. We outperform state-of-the-art approaches on the task of single-view 3D reconstruction on both real and synthetic datasets while generating multiple plausible reconstructions, demonstrating the generalizability and utility of our approach.},
	number = {arXiv:1807.07796},
	urldate = {2022-05-22},
	institution = {arXiv},
	author = {Mandikal, Priyanka and Navaneet, K. L. and Agarwal, Mayank and Babu, R. Venkatesh},
	month = mar,
	year = {2019},
	note = {arXiv:1807.07796 [cs]
type: article},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{mandikal_dense_2019,
	title = {Dense {3D} {Point} {Cloud} {Reconstruction} {Using} a {Deep} {Pyramid} {Network}},
	doi = {10.1109/WACV.2019.00117},
	abstract = {Reconstructing a high-resolution 3D model of an object is a challenging task in computer vision. Designing scalable and light-weight architectures is crucial while addressing this problem. Existing point-cloud based reconstruction approaches directly predict the entire point cloud in a single stage. Although this technique can handle low-resolution point clouds, it is not a viable solution for generating dense, high-resolution outputs. In this work, we introduce DensePCR, a deep pyramidal network for point cloud reconstruction that hierarchically predicts point clouds of increasing resolution. Towards this end, we propose an architecture that first predicts a low-resolution point cloud, and then hierarchically increases the resolution by aggregating local and global point features to deform a grid. Our method generates point clouds that are accurate, uniform and dense. Through extensive quantitative and qualitative evaluation on synthetic and real datasets, we demonstrate that DensePCR outperforms the existing state-of-the-art point cloud reconstruction works, while also providing a light-weight and scalable architecture for predicting high-resolution outputs.},
	booktitle = {2019 {IEEE} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	author = {Mandikal, Priyanka and Radhakrishnan, Venkatesh Babu},
	month = jan,
	year = {2019},
	note = {ISSN: 1550-5790},
	keywords = {Computer architecture, Image reconstruction, Image resolution, Shape, Surface reconstruction, Three-dimensional displays, Training},
	pages = {1052--1060},
}

@inproceedings{feng_2d3d-matchnet_2019,
	title = {{2D3D}-{Matchnet}: {Learning} {To} {Match} {Keypoints} {Across} {2D} {Image} {And} {3D} {Point} {Cloud}},
	shorttitle = {{2D3D}-{Matchnet}},
	doi = {10.1109/ICRA.2019.8794415},
	abstract = {Large-scale point cloud generated from 3D sensors is more accurate than its image-based counterpart. However, it is seldom used in visual pose estimation due to the difficulty in obtaining 2D-3D image to point cloud correspondences. In this paper, we propose the 2D3D-MatchNet - an end-to-end deep network architecture to jointly learn the descriptors for 2D and 3D keypoint from image and point cloud, respectively. As a result, we are able to directly match and establish 2D-3D correspondences from the query image and 3D point cloud reference map for visual pose estimation. We create our Oxford 2D-3D Patches dataset from the Oxford Robotcar dataset with the ground truth camera poses and 2D-3D image to point cloud correspondences for training and testing the deep network. Experimental results verify the feasibility of our approach.},
	booktitle = {2019 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Feng, Mengdan and Hu, Sixing and Ang, Marcelo H and Lee, Gim Hee},
	month = may,
	year = {2019},
	note = {ISSN: 2577-087X},
	keywords = {Cameras, Detectors, Pose estimation, Three-dimensional displays, Training, Two dimensional displays, Visualization},
	pages = {4790--4796},
}

@techreport{jiang_pointsift_2018,
	title = {{PointSIFT}: {A} {SIFT}-like {Network} {Module} for {3D} {Point} {Cloud} {Semantic} {Segmentation}},
	shorttitle = {{PointSIFT}},
	url = {http://arxiv.org/abs/1807.00652},
	abstract = {Recently, 3D understanding research sheds light on extracting features from point cloud directly, which requires effective shape pattern description of point clouds. Inspired by the outstanding 2D shape descriptor SIFT, we design a module called PointSIFT that encodes information of different orientations and is adaptive to scale of shape. Specifically, an orientation-encoding unit is designed to describe eight crucial orientations, and multi-scale representation is achieved by stacking several orientation-encoding units. PointSIFT module can be integrated into various PointNet-based architecture to improve the representation ability. Extensive experiments show our PointSIFT-based framework outperforms state-of-the-art method on standard benchmark datasets. The code and trained model will be published accompanied by this paper.},
	number = {arXiv:1807.00652},
	urldate = {2022-05-22},
	institution = {arXiv},
	author = {Jiang, Mingyang and Wu, Yiran and Zhao, Tianqi and Zhao, Zelin and Lu, Cewu},
	month = nov,
	year = {2018},
	note = {arXiv:1807.00652 [cs]
type: article},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{yang_predicting_2021,
	title = {Predicting the {Perceptual} {Quality} of {Point} {Cloud}: {A} {3D}-to-{2D} {Projection}-{Based} {Exploration}},
	volume = {23},
	issn = {1941-0077},
	shorttitle = {Predicting the {Perceptual} {Quality} of {Point} {Cloud}},
	doi = {10.1109/TMM.2020.3033117},
	abstract = {Point cloud is emerged as a promising media format to represent realistic 3D objects or scenes in applications, such as virtual reality, teleportation, etc. How to accurately quantify the subjective point cloud quality for application-driven optimization, however, is still a challenging and open problem. In this paper, we attempt to tackle this problem in a systematic means. First, we produce a fairly large point cloud dataset where ten popular point clouds are augmented with seven types of impairments (e.g., compression, photometry/color noise, geometry noise, scaling) at six different distortion levels, and organize a formal subjective assessment with tens of subjects to collect mean opinion scores (MOS) for all 420 processed point cloud samples (PPCS). We then try to develop an objective metric that can accurately estimate the subjective quality. Towards this goal, we choose to project the 3D point cloud onto six perpendicular image planes of a cube for the color texture image and corresponding depth image, and aggregate image-based global (e.g., Jensen-Shannon (JS) divergence) and local features (e.g., edge, depth, pixel-wise similarity, complexity) among all projected planes for a final objective index. Model parameters are fixed constants after performing the regression using a small and independent dataset previously published. The proposed metric has demonstrated the state-of-the-art performance for predicting the subjective point cloud quality compared with multiple full-reference and no-reference models, e.g., the weighted peak signal-to-noise ratio (PSNR), structural similarity (SSIM), feature similarity (FSIM) and natural image quality evaluator (NIQE). The dataset is made publicly accessible at http://smt.sjtu.edu.cn or http://vision.nju.edu.cn for all interested audiences.},
	journal = {IEEE Transactions on Multimedia},
	author = {Yang, Qi and Chen, Hao and Ma, Zhan and Xu, Yiling and Tang, Rongjun and Sun, Jun},
	year = {2021},
	keywords = {3D-to-2D projection, Distortion, Distortion measurement, Image color analysis, Image edge detection, Indexes, Three-dimensional displays, image features, point cloud, quality assessment},
	pages = {3877--3891},
}

@techreport{xu_image2point_2022,
	title = {{Image2Point}: {3D} {Point}-{Cloud} {Understanding} with {2D} {Image} {Pretrained} {Models}},
	shorttitle = {{Image2Point}},
	url = {http://arxiv.org/abs/2106.04180},
	abstract = {3D point-clouds and 2D images are different visual representations of the physical world. While human vision can understand both representations, computer vision models designed for 2D image and 3D point-cloud understanding are quite different. Our paper explores the potential of transferring 2D model architectures and weights to understand 3D point-clouds, by empirically investigating the feasibility of the transfer, the benefits of the transfer, and shedding light on why the transfer works. We discover that we can indeed use the same architecture and pretrained weights of a neural net model to understand both images and point-clouds. Specifically, we transfer the image-pretrained model to a point-cloud model by copying or inflating the weights. We find that finetuning the transformed image-pretrained models (FIP) with minimal efforts -- only on input, output, and normalization layers -- can achieve competitive performance on 3D point-cloud classification, beating a wide range of point-cloud models that adopt task-specific architectures and use a variety of tricks. When finetuning the whole model, the performance improves even further. Meanwhile, FIP improves data efficiency, reaching up to 10.0 top-1 accuracy percent on few-shot classification. It also speeds up the training of point-cloud models by up to 11.1x for a target accuracy (e.g., 90 \% accuracy). Lastly, we provide an explanation of the image to point-cloud transfer from the aspect of neural collapse. The code is available at: {\textbackslash}url\{https://github.com/chenfengxu714/image2point\}.},
	number = {arXiv:2106.04180},
	urldate = {2022-05-22},
	institution = {arXiv},
	author = {Xu, Chenfeng and Yang, Shijia and Galanti, Tomer and Wu, Bichen and Yue, Xiangyu and Zhai, Bohan and Zhan, Wei and Vajda, Peter and Keutzer, Kurt and Tomizuka, Masayoshi},
	month = apr,
	year = {2022},
	note = {arXiv:2106.04180 [cs]
type: article},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
}

@inproceedings{klokov_escape_2017,
	title = {Escape {From} {Cells}: {Deep} {Kd}-{Networks} for the {Recognition} of {3D} {Point} {Cloud} {Models}},
	shorttitle = {Escape {From} {Cells}},
	url = {https://openaccess.thecvf.com/content_iccv_2017/html/Klokov_Escape_From_Cells_ICCV_2017_paper.html},
	urldate = {2022-05-22},
	author = {Klokov, Roman and Lempitsky, Victor},
	year = {2017},
	pages = {863--872},
}

@inproceedings{fan_stacked_2021,
	title = {Stacked {Pointnets} {For} {Alignment} {Of} {Particles} {With} {Cylindrical} {Symmetry} {In} {Single} {Molecule} {Localization} {Microscopy}},
	doi = {10.1109/ISBI48211.2021.9434116},
	abstract = {Single molecule localization microscopy is an essential observation tool in biology that yields data in the form of point clouds. It is still limited by an anisotropic resolution and inhomogeneous labeling density. This issue can be addressed by reconstructing a single model from multiple aligned copies of the same particle. However, generic registration methods fail to align point clouds in the presence of anisotropic noise and outliers. Therefore, we propose an alignment method dedicated to a common type of particle geometry, namely cylindrical symmetry. We focus on the centriole, a fundamental macromolecular assembly with ninefold cylindrical symmetry. We design a neural network based on stacked PointNet architectures that estimates the center and axis of symmetry of individual particles in SMLM, in order to align them in the same canonical space. We demonstrate the robustness of our approach on simulated and real dSTORM data.},
	booktitle = {2021 {IEEE} 18th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Fan, Youbo and Faisan, Sylvain and Baudrier, Étienne and Zwettler, Fabian and Sauer, Markus and Fortun, Denis},
	month = apr,
	year = {2021},
	note = {ISSN: 1945-8452},
	keywords = {Geometry, Location awareness, Microscopy, Neural networks, Nonhomogeneous media, PointNet, SMLM, Three-dimensional displays, Tools, centriole, neural networks, point clouds},
	pages = {858--862},
}

@techreport{fortun_multiview_2022,
	title = {Multiview point cloud registration with anisotropic and space-varying localization noise},
	url = {http://arxiv.org/abs/2201.00708},
	abstract = {In this paper, we address the problem of registering multiple point clouds corrupted with high anisotropic localization noise. Our approach follows the widely used framework of Gaussian mixture model (GMM) reconstruction with an expectation-maximization (EM) algorithm. Existing methods are based on an implicit assumption of space-invariant isotropic Gaussian noise. However, this assumption is violated in practice in applications such as single molecule localization microscopy (SMLM). To address this issue, we propose to introduce an explicit localization noise model that decouples shape modeling with the GMM from noise handling. We design a stochastic EM algorithm that considers noise-free data as a latent variable, with closed-form solutions at each EM step. The first advantage of our approach is to handle space-variant and anisotropic Gaussian noise with arbitrary covariances. The second advantage is to leverage the explicit noise model to impose prior knowledge about the noise that may be available from physical sensors. We show on various simulated data that our noise handling strategy improves significantly the robustness to high levels of anisotropic noise. We also demonstrate the performance of our method on real SMLM data.},
	number = {arXiv:2201.00708},
	urldate = {2022-05-22},
	institution = {arXiv},
	author = {Fortun, Denis and Baudrier, Etienne and Zwettler, Fabian and Sauer, Markus and Faisan, Sylvain},
	month = jan,
	year = {2022},
	note = {arXiv:2201.00708 [cs]
type: article},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{pike_topological_2020,
	title = {Topological data analysis quantifies biological nano-structure from single molecule localization microscopy},
	volume = {36},
	issn = {1367-4803},
	url = {https://doi.org/10.1093/bioinformatics/btz788},
	doi = {10.1093/bioinformatics/btz788},
	abstract = {Localization microscopy data is represented by a set of spatial coordinates, each corresponding to a single detection, that form a point cloud. This can be analyzed either by rendering an image from these coordinates, or by analyzing the point cloud directly. Analysis of this type has focused on clustering detections into distinct groups which produces measurements such as cluster area, but has limited capacity to quantify complex molecular organization and nano-structure.We present a segmentation protocol which, through the application of persistence-based clustering, is capable of probing densely packed structures which vary in scale. An increase in segmentation performance over state-of-the-art methods is demonstrated. Moreover we employ persistent homology to move beyond clustering, and quantify the topological structure within data. This provides new information about the preserved shapes formed by molecular architecture. Our methods are flexible and we demonstrate this by applying them to receptor clustering in platelets, nuclear pore components, endocytic proteins and microtubule networks. Both 2D and 3D implementations are provided within RSMLM, an R package for pointillist-based analysis and batch processing of localization microscopy data.RSMLM has been released under the GNU General Public License v3.0 and is available at https://github.com/JeremyPike/RSMLM. Tutorials for this library implemented as Binder ready Jupyter notebooks are available at https://github.com/JeremyPike/RSMLM-tutorials.Supplementary data are available at Bioinformatics online.},
	number = {5},
	urldate = {2022-05-22},
	journal = {Bioinformatics},
	author = {Pike, Jeremy A and Khan, Abdullah O and Pallini, Chiara and Thomas, Steven G and Mund, Markus and Ries, Jonas and Poulter, Natalie S and Styles, Iain B},
	month = mar,
	year = {2020},
	pages = {1614--1621},
}

@inproceedings{chung_slice_2019,
	title = {Slice {Finder}: {Automated} {Data} {Slicing} for {Model} {Validation}},
	shorttitle = {Slice {Finder}},
	doi = {10.1109/ICDE.2019.00139},
	abstract = {As machine learning (ML) systems become democratized, it becomes increasingly important to help users easily debug their models. However, current data tools are still primitive when it comes to helping users trace model performance problems all the way to the data. We focus on the particular problem of slicing data to identify subsets of the validation data where the model performs poorly. This is an important problem in model validation because the overall model performance can fail to reflect that of the smaller subsets, and slicing allows users to analyze the model performance on a more granular-level. Unlike general techniques (e.g., clustering) that can find arbitrary slices, our goal is to find interpretable slices (which are easier to take action compared to arbitrary subsets) that are large and problematic. We propose Slice Finder, which is an interactive framework for identifying such slices using statistical techniques. Applications include diagnosing model fairness and fraud detection, where identifying slices that are interpretable to humans is crucial.},
	booktitle = {2019 {IEEE} 35th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	author = {Chung, Yeounoh and Kraska, Tim and Polyzotis, Neoklis and Tae, Ki Hyun and Whang, Steven Euijong},
	month = apr,
	year = {2019},
	note = {ISSN: 2375-026X},
	keywords = {Analytical models, Data models, Decision trees, Lattices, Loss measurement, Search problems, Training, data slicing, model validation},
	pages = {1550--1553},
}

@article{tumminello_multivariate_2022,
	title = {A multivariate statistical test for differential expression analysis},
	volume = {12},
	copyright = {2022 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-022-12246-w},
	doi = {10.1038/s41598-022-12246-w},
	abstract = {Statistical tests of differential expression usually suffer from two problems. Firstly, their statistical power is often limited when applied to small and skewed data sets. Secondly, gene expression data are usually discretized by applying arbitrary criteria to limit the number of false positives. In this work, a new statistical test obtained from a convolution of multivariate hypergeometric distributions, the Hy-test, is proposed to address these issues. Hy-test has been carried out on transcriptomic data from breast and kidney cancer tissues, and it has been compared with other differential expression analysis methods. Hy-test allows implicit discretization of the expression profiles and is more selective in retrieving both differential expressed genes and terms of Gene Ontology. Hy-test can be adopted together with other tests to retrieve information that would remain hidden otherwise, e.g., terms of (1) cell cycle deregulation for breast cancer and (2) “programmed cell death” for kidney cancer.},
	language = {en},
	number = {1},
	urldate = {2022-05-18},
	journal = {Scientific Reports},
	author = {Tumminello, Michele and Bertolazzi, Giorgio and Sottile, Gianluca and Sciaraffa, Nicolina and Arancio, Walter and Coronnello, Claudia},
	month = may,
	year = {2022},
	keywords = {Bioinformatics, Biological techniques, Gene expression analysis, Software},
	pages = {8265},
}

@misc{noauthor_how_nodate,
	title = {How not to lie with statistics: the correct way to summarize benchmark results {\textbar} {Communications} of the {ACM}},
	url = {https://dl.acm.org/doi/abs/10.1145/5666.5673},
	urldate = {2022-05-18},
}

@article{box_analysis_1964,
	title = {An {Analysis} of {Transformations}},
	volume = {26},
	issn = {2517-6161},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1964.tb00553.x},
	doi = {10.1111/j.2517-6161.1964.tb00553.x},
	abstract = {In the analysis of data it is often assumed that observations y1, y2, …, yn are independently normally distributed with constant variance and with expectations specified by a model linear in a set of parameters θ. In this paper we make the less restrictive assumption that such a normal, homoscedastic, linear model is appropriate after some suitable transformation has been applied to the y's. Inferences about the transformation and about the parameters of the linear model are made by computing the likelihood function and the relevant posterior distribution. The contributions of normality, homoscedasticity and additivity to the transformation are separated. The relation of the present methods to earlier procedures for finding transformations is discussed. The methods are illustrated with examples.},
	language = {en},
	number = {2},
	urldate = {2022-05-18},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Box, G. E. P. and Cox, D. R.},
	year = {1964},
	pages = {211--243},
}

@article{qi_using_2020,
	title = {Using machine learning to predict extreme events in complex systems},
	volume = {117},
	url = {https://www.pnas.org/doi/10.1073/pnas.1917285117},
	doi = {10.1073/pnas.1917285117},
	number = {1},
	urldate = {2022-05-17},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Qi, Di and Majda, Andrew J.},
	month = jan,
	year = {2020},
	pages = {52--59},
}

@article{ren_deep_2021,
	title = {Deep {Learning}-{Based} {Weather} {Prediction}: {A} {Survey}},
	volume = {23},
	issn = {2214-5796},
	shorttitle = {Deep {Learning}-{Based} {Weather} {Prediction}},
	url = {https://www.sciencedirect.com/science/article/pii/S2214579620300460},
	doi = {10.1016/j.bdr.2020.100178},
	abstract = {Weather forecasting plays a fundamental role in the early warning of weather impacts on various aspects of human livelihood. For instance, weather forecasting provides decision making support for autonomous vehicles to reduce traffic accidents and congestions, which completely depend on the sensing and predicting of external environmental factors such as rainfall, air visibility and so on. Accurate and timely weather prediction has always been the goal of meteorological scientists. However, the conventional theory-driven numerical weather prediction (NWP) methods face many challenges, such as incomplete understanding of physical mechanisms, difficulties in obtaining useful knowledge from the deluge of observation data, and the requirement of powerful computing resources. With the successful application of data-driven deep learning method in various fields, such as computer vision, speech recognition, and time series prediction, it has been proven that deep learning method can effectively mine the temporal and spatial features from the spatio-temporal data. Meteorological data is a typical big geospatial data. Deep learning-based weather prediction (DLWP) is expected to be a strong supplement to the conventional method. At present, many researchers have tried to introduce data-driven deep learning into weather forecasting, and have achieved some preliminary results. In this paper, we survey the state-of-the-art studies of deep learning-based weather forecasting, in the aspects of the design of neural network (NN) architectures, spatial and temporal scales, as well as the datasets and benchmarks. Then we analyze the advantages and disadvantages of DLWP by comparing it with the conventional NWP, and summarize the potential future research topics of DLWP.},
	language = {en},
	urldate = {2022-05-17},
	journal = {Big Data Research},
	author = {Ren, Xiaoli and Li, Xiaoyong and Ren, Kaijun and Song, Junqiang and Xu, Zichen and Deng, Kefeng and Wang, Xiang},
	month = feb,
	year = {2021},
	keywords = {Big meteorological data, Deep learning, Spatio-temporal feature, Time series, Weather forecasting},
	pages = {100178},
}

@article{st-pierre_count_2018,
	title = {Count data in biology—{Data} transformation or model reformation?},
	volume = {8},
	issn = {2045-7758},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.3807},
	doi = {10.1002/ece3.3807},
	abstract = {Statistical analyses are an integral component of scientific research, and for decades, biologists have applied transformations to data to meet the normal error assumptions for F and t tests. Over the years, there has been a movement from data transformation toward model reformation—the use of non-normal error structures within the framework of the generalized linear model (GLM). The principal advantage of model reformation is that parameters are estimated on the original, rather than the transformed scale. However, data transformation has been shown to give better control over type I error, for simulated data with known error structures. We conducted a literature review of statistical textbooks directed toward biologists and of journal articles published in the primary literature to determine temporal trends in both the text recommendations and the practice in the refereed literature over the past 35 years. In this review, a trend of increasing use of reformation in the primary literature was evident, moving from no use of reformation before 1996 to {\textgreater}50\% of the articles reviewed applying GLM after 2006. However, no such trend was observed in the recommendations in statistical textbooks. We then undertook 12 analyses based on published datasets in which we compared the type I error estimates, residual plot diagnostics, and coefficients yielded by analyses using square root transformations, log transformations, and the GLM. All analyses yielded acceptable residual versus fit plots and had similar p-values within each analysis, but as expected, the coefficient estimates differed substantially. Furthermore, no consensus could be found in the literature regarding a procedure to back-transform the coefficient estimates obtained from linear models performed on transformed datasets. This lack of consistency among coefficient estimates constitutes a major argument for model reformation over data transformation in biology.},
	language = {en},
	number = {6},
	urldate = {2022-05-17},
	journal = {Ecology and Evolution},
	author = {St-Pierre, Anne P. and Shikon, Violaine and Schneider, David C.},
	year = {2018},
	keywords = {Poisson distribution, coefficients estimates, count data, generalized linear model, model comparison, non-normal error structure, residuals, transformation},
	pages = {3077--3085},
}

@techreport{ewald_geometric_2007,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Geometric {Mean} {Reversion}: {Formulas} for the {Equilibrium} {Density} and {Analytic} {Moment} {Matching}},
	shorttitle = {Geometric {Mean} {Reversion}},
	url = {https://papers.ssrn.com/abstract=999561},
	abstract = {We study the classical geometric mean reversion process which has been used to model commodity prices by various authors in Economics and Finance. We obtain certain regularity results which guarantee positivity and the existence of a stationary distribution. More important we derive an analytical formula for the stationary distribution and all of its higher moments. Furthermore we derive a computationally simple but efficient recursive formula for the higher moments which we apply to moment matching.},
	language = {en},
	number = {999561},
	urldate = {2022-05-17},
	institution = {Social Science Research Network},
	author = {Ewald, Christian-Oliver and Yang, Zhaojun},
	month = jul,
	year = {2007},
	keywords = {Models of mean-reversion, equilibrium distributions},
}

@article{bridges_log_2022,
	title = {Log transformations: {What} not to expect when you’re expecting},
	volume = {51},
	issn = {0361-0926},
	shorttitle = {Log transformations},
	url = {https://doi.org/10.1080/03610926.2020.1771368},
	doi = {10.1080/03610926.2020.1771368},
	abstract = {We note that log transformations can be problematic when the variance of the underlying distribution is other than very small. We illustrate these problems in terms of lognormal sampling issues, interval estimation of the mean, and comparison of lognormal and logbinomial distributions with similar means and variances.},
	number = {5},
	urldate = {2022-05-17},
	journal = {Communications in Statistics - Theory and Methods},
	author = {Bridges, William C. and Calkin, Neil J. and Kenyon, Catherine M. and Saltzman, Matthew J.},
	month = mar,
	year = {2022},
	keywords = {60E05, Log transformation, logbinomial, lognormal, sampling},
	pages = {1514--1521},
}

@article{vogel_geometric_2022,
	title = {The geometric mean?},
	volume = {51},
	issn = {0361-0926},
	url = {https://doi.org/10.1080/03610926.2020.1743313},
	doi = {10.1080/03610926.2020.1743313},
	abstract = {The sample geometric mean (SGM) introduced by Cauchy in 1821, is a measure of central tendency with many applications in the natural and social sciences including environmental monitoring, scientometrics, nuclear medicine, infometrics, economics, finance, ecology, surface and groundwater hydrology, geoscience, geomechanics, machine learning, chemical engineering, poverty and human development, to name a few. Remarkably, it was not until 2013 that a theoretical definition of the population geometric mean (GM) was introduced. Analytic expressions for the GM are derived for many common probability distributions, including: lognormal, Gamma, exponential, uniform, Chi-square, F, Beta, Weibull, Power law, Pareto, generalized Pareto and Rayleigh. Many previous applications of SGM assumed lognormal data, though investigators were unaware that for that case, the GM is the median and SGM is a maximum likelihood estimator of the median. Unlike other measures of central tendency such as the mean, median, and mode, the GM lacks a clear physical interpretation and its estimator SGM exhibits considerable bias and mean square error, which depends significantly on sample size, pd, and skewness. A review of the literature reveals that there is little justification for use of the GM in many applications. Recommendations for future research and application of the GM are provided.},
	number = {1},
	urldate = {2022-05-17},
	journal = {Communications in Statistics - Theory and Methods},
	author = {Vogel, Richard M.},
	month = jan,
	year = {2022},
	keywords = {Central tendency, arithmetic mean, effective, log transformation, lognormal, median, multiplicative aggregation},
	pages = {82--94},
}

@article{jacquier_geometric_2003,
	title = {Geometric or {Arithmetic} {Mean}: {A} {Reconsideration}},
	volume = {59},
	issn = {0015-198X},
	shorttitle = {Geometric or {Arithmetic} {Mean}},
	url = {https://doi.org/10.2469/faj.v59.n6.2574},
	doi = {10.2469/faj.v59.n6.2574},
	abstract = {An unbiased forecast of the terminal value of a portfolio requires compounding of its initial value at its arithmetic mean return for the length of the investment period. Compounding at the arithmetic average historical return, however, results in an upwardly biased forecast. This bias does not necessarily disappear even if the sample average return is itself an unbiased estimator of the true mean, the average is computed from a long data series, and returns are generated according to a stable distribution. In contrast, forecasts obtained by compounding at the geometric average will generally be biased downward. The biases are empirically significant. For investment horizons of 40 years, the difference in forecasts of cumulative performance can easily exceed a factor of 2. And the percentage difference in forecasts grows with the investment horizon, as well as with the imprecision in the estimate of the mean return. For typical investment horizons, the proper compounding rate is in between the arithmetic and geometric values.},
	number = {6},
	urldate = {2022-05-17},
	journal = {Financial Analysts Journal},
	author = {Jacquier, Eric and Kane, Alex and Marcus, Alan J.},
	month = nov,
	year = {2003},
	pages = {46--53},
}

@article{jean_geometric_1980,
	title = {The {Geometric} {Mean} and {Stochastic} {Dominance}},
	volume = {35},
	issn = {0022-1082},
	url = {https://www.jstor.org/stable/2327187},
	doi = {10.2307/2327187},
	number = {1},
	urldate = {2022-05-17},
	journal = {The Journal of Finance},
	author = {Jean, William H.},
	year = {1980},
	pages = {151--158},
}

@article{young_geometric_1969,
	title = {Geometric {Mean} {Approximations} of {Individual} {Security} and {Portfolio} {Performance}**},
	volume = {4},
	issn = {1756-6916, 0022-1090},
	url = {https://www.cambridge.org/core/journals/journal-of-financial-and-quantitative-analysis/article/geometric-mean-approximations-of-individual-security-and-portfolio-performance/3AB5611006FF572B3B49FE29F858E71D},
	doi = {10.2307/2329839},
	abstract = {The objectives of this paper are to derive the relationship of the geometric mean of a distribution of positive values to the conventional first four moments — arithmetic mean, variance, absolute skewness, and absolute kurtosis — and to empirically evaluate certain approximations involving these four moments for estimating the geometric means of monthly and annual holding period returns for individual stocks and for portfolios. The geometric mean is shown to be positively related to the arithmetic mean and absolute skewness and negatively related to variance and absolute kurtosis. In the case of a normal distribution a very good approximation to the geometric mean is revealed to be a function of just the arithmetic mean and variance. Additionally, empirical evidence indicates that even though a number of the monthly and annual distributions deviate significantly from normality, the approximation involving only the mean and variance produces quite accurate estimates of the geometric means of these distributions.},
	language = {en},
	number = {2},
	urldate = {2022-05-17},
	journal = {Journal of Financial and Quantitative Analysis},
	author = {Young, William E. and Trent, Robert H.},
	month = jun,
	year = {1969},
	pages = {179--199},
}

@misc{noauthor_use_nodate,
	title = {On the use of log‐transformation vs. nonlinear regression for analyzing biological power laws},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/epdf/10.1890/11-0538.1},
	language = {en},
	urldate = {2022-05-17},
	doi = {10.1890/11-0538.1},
}

@misc{noauthor_log_nodate,
	title = {The log transformation is special},
	url = {https://onlinelibrary.wiley.com/doi/epdf/10.1002/sim.4780140810},
	language = {en},
	urldate = {2022-05-17},
	doi = {10.1002/sim.4780140810},
}

@misc{goytom_forecasting_2021,
	title = {Forecasting {Maxima} in {Climate} {Time} {Series}},
	copyright = {MIT},
	url = {https://github.com/isrugeek/climate_extreme_values},
	urldate = {2022-05-16},
	author = {Goytom, Israel},
	month = mar,
	year = {2021},
	note = {original-date: 2019-04-17T22:27:31Z},
	keywords = {climate-change, lstm, pytorch, time-series},
}

@article{xiao_use_2011,
	title = {On the use of log-transformation vs. nonlinear regression for analyzing biological power laws},
	volume = {92},
	issn = {1939-9170},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1890/11-0538.1},
	doi = {10.1890/11-0538.1},
	abstract = {Power-law relationships are among the most well-studied functional relationships in biology. Recently the common practice of fitting power laws using linear regression (LR) on log-transformed data has been criticized, calling into question the conclusions of hundreds of studies. It has been suggested that nonlinear regression (NLR) is preferable, but no rigorous comparison of these two methods has been conducted. Using Monte Carlo simulations, we demonstrate that the error distribution determines which method performs better, with NLR better characterizing data with additive, homoscedastic, normal error and LR better characterizing data with multiplicative, heteroscedastic, lognormal error. Analysis of 471 biological power laws shows that both forms of error occur in nature. While previous analyses based on log-transformation appear to be generally valid, future analyses should choose methods based on a combination of biological plausibility and analysis of the error distribution. We provide detailed guidelines and associated computer code for doing so, including a model averaging approach for cases where the error structure is uncertain.},
	language = {en},
	number = {10},
	urldate = {2022-05-16},
	journal = {Ecology},
	author = {Xiao, Xiao and White, Ethan P. and Hooten, Mevin B. and Durham, Susan L.},
	year = {2011},
	keywords = {allometry, log-transformation, model averaging, model comparison, nonlinear regression, parameter estimation, power law},
	pages = {1887--1894},
}

@article{liu_combining_2021,
	title = {Combining {Two}-{Layer} {Semi}-{Three}-{Dimensional} {Reconstruction} and {Multi}-{Wavelength} {Image} {Fusion} for {Functional} {Diffuse} {Optical} {Tomography}},
	volume = {7},
	issn = {2333-9403},
	doi = {10.1109/TCI.2021.3115384},
	abstract = {High-density (HD) diffuse optical tomography (DOT), as an advanced modality of functional near-infrared spectroscopy, is finding increasing applications in neuroimaging regime. However, it is a primary challenge that the superficial physiological interferences usually significantly contaminate the functional activation reconstruction. In addition, the random noises, majorly the photon-shot and instrumental ones, also cast negative influences on the measurements, and further distort the reconstructed image. To mitigate the adversities, we herein propose a combined scheme of two-layer semi-three-dimensional (S3D) reconstruction and multi-wavelength image fusion, which leverages a mathematical model with explicit physical significance, to suppress the physiological interferences and random noises in HD-DOT reconstruction, respectively. The approach is purely data-driven without additional auxiliary measurement, and comprised of two steps: First, the absorption perturbations are topographically reconstructed over both the scalp (SC) and cerebral-cortex (CC) layers using the two-layer S3D scheme, of which the superficial interferences are estimated from the SC reconstruction and adaptively filtered out from the CC one; Second, the interference-suppressed multi-wavelength CC-images are decomposed using the discrete wavelet transform, and fused at multi-resolutions into a mask for further removal of the random noises. We comprehensively validate the proposed scheme using simulations and phantom experiments, and demonstrate its sound effectiveness in suppressing the physiological interferences and random noises. The performance improvement rather than by more cycles or longer sampling time offers additional payoff: shorter measurement time or higher temporal resolution.},
	journal = {IEEE Transactions on Computational Imaging},
	author = {Liu, Dongyuan and Zhang, Yao and Bai, Lu and Zhang, Pengrui and Gao, Feng},
	year = {2021},
	keywords = {Diffuse optical tomography, Image fusion, Image reconstruction, Mathematical models, Noise measurement, Photonics, Physiology, Pollution measurement, S3D reconstruction, multi-wavelength image fusion},
	pages = {1055--1068},
}

@inproceedings{pifferi_solus_2021,
	title = {{SOLUS}: an innovative multimodal imaging system to improve breast cancer diagnosis through diffuse optics and ultrasounds},
	volume = {11639},
	shorttitle = {{SOLUS}},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11639/116390C/SOLUS--an-innovative-multimodal-imaging-system-to-improve-breast/10.1117/12.2576778.full},
	doi = {10.1117/12.2576778},
	abstract = {To improve non-invasively the specificity in the diagnosis of breast cancer after a positive screening mammography or doubt/suspicious ultrasound examination, the SOLUS project developed a multimodal imaging system that combines: Bmode ultrasound (US) scans (to assess morphology), Color Doppler (to visualize vascularization), shear-wave elastography (to measure stiffness), and time domain multi-wavelength diffuse optical tomography (to estimate tissue composition in terms of oxy- and deoxy-hemoglobin, lipid, water, and collagen concentrations). The multimodal probe arranges 8 innovative photonic modules (optodes) around the US transducer, providing capability for optical tomographic reconstruction. For more accurate estimate of lesion composition, US-assessed morphological priors can be used to guide the optical reconstructions. Each optode comprises: i) 8 picosecond pulsed laser diodes with different wavelengths, covering a wide spectral range (635-1064 nm) for good probing of the different tissue constituents; ii) a large-area (variable, up to 8.6 mm$^{\textrm{2}}$ ) fast-gated digital Silicon Photomultiplier; iii) the acquisition electronics to record the distribution of time-of-flight of the re-emitted photons. The optode is the basic element of the optical part of the system, but is also a stand-alone, ultra-compact (about 4 cm$^{\textrm{3}}$ ) device for time domain multi-wavelength diffuse optics, with potential application in various fields.},
	urldate = {2022-05-16},
	booktitle = {Optical {Tomography} and {Spectroscopy} of {Tissue} {XIV}},
	publisher = {SPIE},
	author = {Pifferi, Antonio and Mora, Alberto Dalla and Sieno, Laura Di and Ferocino, Edoardo and Tosi, Alberto and Conca, Enrico and Sesta, Vincenzo and Giudice, Andrea and Ruggeri, Alessandro and Tisa, Simone and Flocke, Alexander and Rosinski, Bogdan and Dinten, Jean-Marc and Perriollat, Mathieu and Fraschini, Christophe and Sportouche, Hélène and Arridge, Simon and Sciacca, Giuseppe Di and Farina, Andrea and Panizza, Pietro and Venturini, Elena and Gordebeke, Peter and Zolda, Pamela and Taroni, Paola},
	month = mar,
	year = {2021},
	pages = {37--41},
}

@article{kazanci_frequency_2021,
	title = {Frequency shifting model for diffuse optical tomography},
	volume = {53},
	doi = {10.1007/s11082-021-03308-w},
	abstract = {The Diffuse Optical Tomography (DOT) imaging modality is an interesting research field for researchers since it has uncertainties in the solution space. DOT imaging modality is an unsolved scientific problem. Inverse problem solution and image reconstruction have never been of their best quality. Reconstructed images have low spatial resolution. The scattering nature of low-energized diffusive light is the obscuring effect for DOT modality. DOT has 3 functional sub-branches which are Continuous Wave, Time-Resolved, and Frequency-Domain. In this work, one new approach to Frequency Domain Diffuse Optical Tomography (FDDOT) biomedical optic imaging modality is presented to the readers. Frequency shifting data were added to the forward model problem which has source-detector couplings and several imaging voxels. 100 MHz center core light modulation frequency was selected as modulation frequency. 169 source-detector matches were used on back-reflected imaging geometry. Absorption coefficient µa was selected 0.1 cm−1. Scattering coefficient µs was selected 100 cm−1. 1-µm x, y, z cartesian grid coordinates were used in each direction for imaging tissue-like simulation media. A total of 100 frequency shifts were added to the forward model problem which has 5 Hz frequency step. 2 inclusion objects were embedded inside the imaging simulation phantom to be reconstructed. Their optical absorption coefficient µa = 0.7 cm−1. Two inclusion images were successfully reconstructed with the low contrast to noise ratio (CNR) and position error. The frequency shifting technique is first applied for FDDOT here in this work. This technique increased the total number of equations in the forward model problem; hence it is helping to solve the inverse problem more accurately. In this work, the positive effect of using frequency shifting methodology was observed. Differentiation of 2 embedded inclusions was completed and illustrated in this work. Two different scenarios were compared with each other. In the first scenario, only 100 MHz center core frequency was used for one source-detector match. In the second scenario, 100 additional shifted frequencies over 100 MHz center core frequency were added. It was seen that the second scenario which has more frequency shifts is superior to the general concept FDDOT methodology. This work shows that the frequency shift technique might be used for future FDDOT devices.},
	journal = {Optical and Quantum Electronics},
	author = {Kazanci, huseyin ozgur and Oral, Okan},
	month = nov,
	year = {2021},
}

@article{sciacca_evaluation_2022,
	title = {Evaluation of a pipeline for simulation, reconstruction, and classification in ultrasound-aided diffuse optical tomography of breast tumors},
	volume = {27},
	issn = {1083-3668, 1560-2281},
	url = {https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-27/issue-3/036003/Evaluation-of-a-pipeline-for-simulation-reconstruction-and-classification-in/10.1117/1.JBO.27.3.036003.full},
	doi = {10.1117/1.JBO.27.3.036003},
	abstract = {Significance: Diffuse optical tomography is an ill-posed problem. Combination with ultrasound can improve the results of diffuse optical tomography applied to the diagnosis of breast cancer and allow for classification of lesions. Aim: To provide a simulation pipeline for the assessment of reconstruction and classification methods for diffuse optical tomography with concurrent ultrasound information. Approach: A set of breast digital phantoms with benign and malignant lesions was simulated building on the software VICTRE. Acoustic and optical properties were assigned to the phantoms for the generation of B-mode images and optical data. A reconstruction algorithm based on a two-region nonlinear fitting and incorporating the ultrasound information was tested. Machine learning classification methods were applied to the reconstructed values to discriminate lesions into benign and malignant after reconstruction. Results: The approach allowed us to generate realistic US and optical data and to test a two-region reconstruction method for a large number of realistic simulations. When information is extracted from ultrasound images, at least 75\% of lesions are correctly classified. With ideal two-region separation, the accuracy is higher than 80\%. Conclusions: A pipeline for the generation of realistic ultrasound and diffuse optics data was implemented. Machine learning methods applied to a optical reconstruction with a nonlinear optical model and morphological information permit to discriminate malignant lesions from benign ones.},
	number = {3},
	urldate = {2022-05-16},
	journal = {Journal of Biomedical Optics},
	author = {Sciacca, Giuseppe Di and Maffeis, Giulia and Farina, Andrea and Mora, Alberto Dalla and Pifferi, Antonio and Taroni, Paola and Arridge, Simon},
	month = mar,
	year = {2022},
	pages = {036003},
}

@article{gao_log_2019,
	title = {Log {Transformation} and the {Effect} on {Estimation}, {Implication}, and {Interpretation} of {Mean} and {Measurement} {Uncertainty} in {Microbial} {Enumeration}},
	volume = {102},
	issn = {1060-3271},
	url = {https://doi.org/10.5740/jaoacint.18-0161},
	doi = {10.5740/jaoacint.18-0161},
	abstract = {Background: Estimation of measurement uncertainty (MU) has been extensively addressed in documents from standard authorities. In microbiology, bacterial counts are log transformed to get a more normal distribution. Unfortunately, the difference between using original and log-transformed data appears to not have been investigated even in publications focusing on MU estimation. Method: Statistical formulae inferencing and estimation of MU using real bacterial enumeration datasets. Results: Both mean and SD calculated from original data carry the same scale and unit as the original data. However, the mean of log-transformed data becomes a geometric mean in log, and the SD becomes the logarithm of a ratio. Furthermore, calculation of RSD obtained by dividing the SD by the mean is meaningless and misleading for log-transformed data. The ratio, the antilog of the SD of log-transformed data, copes with multiplicative and divisive relationships to geometric mean (without log), instead of the arithmetic mean. The ratio can be converted to an analog ratio, which is similar or almost identical to the RSD of the untransformed data, especially when the within-subject variation is small. When MU is estimated from multiple samples with different measurands, the calculated RSD of original data is independent of the mean and can be pooled; however, for log-transformed data, the SD can be combined to estimate the common uncertainty. Conclusions: Calculation and use of RSD of log-transformed data are meaningless and misleading. Procedures outlining the estimation and interpretation of MU from log-transformed data require re-evaluation.},
	number = {1},
	urldate = {2022-05-16},
	journal = {Journal of AOAC INTERNATIONAL},
	author = {Gao, Anli and Martos, Perry},
	month = jan,
	year = {2019},
	pages = {233--238},
}

@article{feng_log-transformation_2014,
	title = {Log-transformation and its implications for data analysis},
	volume = {26},
	issn = {1002-0829},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4120293/},
	doi = {10.3969/j.issn.1002-0829.2014.02.009},
	abstract = {The log-transformation is widely used in biomedical and psychosocial research to deal with skewed data. This paper highlights serious problems in this classic approach for dealing with skewed data. Despite the common belief that the log transformation can decrease the variability of data and make data conform more closely to the normal distribution, this is usually not the case. Moreover, the results of standard statistical tests performed on log-transformed data are often not relevant for the original, non-transformed data.We demonstrate these problems by presenting examples that use simulated data. We conclude that if used at all, data transformations must be applied very cautiously. We recommend that in most circumstances researchers abandon these traditional methods of dealing with skewed data and, instead, use newer analytic methods that are not dependent on the distribution the data, such as generalized estimating equations (GEE).},
	number = {2},
	urldate = {2022-05-16},
	journal = {Shanghai Archives of Psychiatry},
	author = {FENG, Changyong and WANG, Hongyue and LU, Naiji and CHEN, Tian and HE, Hua and LU, Ying and TU, Xin M.},
	month = apr,
	year = {2014},
	pmid = {25092958},
	pmcid = {PMC4120293},
	pages = {105--109},
}

@book{li_deep_2021,
	title = {Deep {Algorithm} {Unrolling} for {Biomedical} {Imaging}},
	abstract = {In this chapter, we review biomedical applications and breakthroughs via leveraging algorithm unrolling, an important technique that bridges between traditional iterative algorithms and modern deep learning techniques. To provide context, we start by tracing the origin of algorithm unrolling and providing a comprehensive tutorial on how to unroll iterative algorithms into deep networks. We then extensively cover algorithm unrolling in a wide variety of biomedical imaging modalities and delve into several representative recent works in detail. Indeed, there is a rich history of iterative algorithms for biomedical image synthesis, which makes the field ripe for unrolling techniques. In addition, we put algorithm unrolling into a broad perspective, in order to understand why it is particularly effective and discuss recent trends. Finally, we conclude the chapter by discussing open challenges, and suggesting future research directions.},
	author = {Li, Yuelong and Bar-Shira, Or and Monga, Vishal and Eldar, Yonina},
	month = aug,
	year = {2021},
}

@inproceedings{cai_frequency_2021,
	title = {Frequency {Domain} {Image} {Translation}: {More} {Photo}-{Realistic}, {Better} {Identity}-{Preserving}},
	shorttitle = {Frequency {Domain} {Image} {Translation}},
	url = {https://openaccess.thecvf.com/content/ICCV2021/html/Cai_Frequency_Domain_Image_Translation_More_Photo-Realistic_Better_Identity-Preserving_ICCV_2021_paper.html},
	language = {en},
	urldate = {2022-05-12},
	author = {Cai, Mu and Zhang, Hong and Huang, Huijuan and Geng, Qichuan and Li, Yixuan and Huang, Gao},
	year = {2021},
	pages = {13930--13940},
}

@book{lunz_adversarial_2018,
	title = {Adversarial {Regularizers} in {Inverse} {Problems}},
	abstract = {Inverse Problems in medical imaging and computer vision are traditionally solved using purely model-based methods. Among those variational regularization models are one of the most popular approaches. We propose a new framework for applying data-driven approaches to inverse problems, using a neural network as a regularization functional. The network learns to discriminate between the distribution of ground truth images and the distribution of unregularized reconstructions. Once trained, the network is applied to the inverse problem by solving the corresponding variational problem. Unlike other data-based approaches for inverse problems, the algorithm can be applied even if only unsupervised training data is available. Experiments demonstrate the potential of the framework for denoising on the BSDS dataset and for computer tomography reconstruction on the LIDC dataset.},
	author = {Lunz, Sebastian and Ozan, Öktem and Schönlieb, Carola-Bibiane},
	month = may,
	year = {2018},
}

@article{adler_learned_2017,
	title = {Learned {Primal}-{Dual} {Reconstruction}},
	volume = {PP},
	doi = {10.1109/TMI.2018.2799231},
	abstract = {We propose a Learned Primal-Dual algorithm for tomographic reconstruction. The algorithm includes the (possibly non-linear) forward operator in a deep neural network inspired by unrolled proximal primal-dual optimization methods, but where the proximal operators have been replaced with convolutional neural networks. The algorithm is trained end-to-end, working directly from raw measured data and does not depend on any initial reconstruction such as FBP. We evaluate the algorithm on low dose CT reconstruction using both analytic and human phantoms against classical reconstruction given by FBP and TV regularized reconstruction as well as deep learning based post-processing of a FBP reconstruction. For the analytic data we demonstrate PSNR improvements of {\textgreater}10 dB when compared to both TV reconstruction and learned post-processing. For the human phantom we demonstrate a 6.6 dB improvement compared to TV and a 2.2 dB improvement as compared to learned post-processing. The proposed algorithm also improves upon the compared algorithms with respect to the SSIM and the evaluation time is approximately 600 ms for a 512 x 512 pixel dataset.},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Adler, Jonas and Ozan, Öktem},
	month = jul,
	year = {2017},
}

@misc{noauthor_open_nodate,
	title = {Open {Science} {Framework}},
	url = {https://datamanagement.hms.harvard.edu/share/data-repositories/open-science-framework},
	abstract = {Open Science Framework (OSF), provided from the Center for Open Science (COS), is a free and open source project management tool that supports researchers throughout their entire project lifecycle in open science best practices. OSF promotes open, centralized workflows by enabling capture of different aspects and products of the research.},
	language = {en},
	urldate = {2022-05-12},
}

@article{chu_image_2022,
	title = {Image {Analysis} of the {Mitochondrial} {Network} {Morphology} {With} {Applications} in {Cancer} {Research}},
	volume = {10},
	issn = {2296-424X},
	url = {https://www.frontiersin.org/article/10.3389/fphy.2022.855775},
	abstract = {Mitochondria are dynamic organelles that integrate bioenergetics, biosynthesis, and signaling in cells and regulate redox homeostasis, apoptotic pathways, and cell proliferation and differentiation. Depending on the environmental conditions, the mitochondrial morphology dynamically changes to match the energy demands. The mitochondrial dynamics is related to the initiation, migration, and invasion of diverse human cancers and thus affects cancer metastasis, metabolism, drug resistance, and cancer stem cell survival. We reviewed the current image-based analytical tools and machine-learning techniques for phenotyping mitochondrial morphology in different cancer cell lines from confocal microscopy images. We listed and applied pipelines and packages available in ImageJ/Fiji, CellProfiler, MATLAB, Java, and Python for the analysis of fluorescently labeled mitochondria in microscopy images and compared their performance, usability and applications. Furthermore, we discussed the potential of automatic mitochondrial segmentation, classification and prediction of mitochondrial abnormalities using machine learning techniques. Quantification of the mitochondrial morphology provides potential indicators for identifying metabolic changes and drug responses in cancer cells.},
	urldate = {2022-05-12},
	journal = {Frontiers in Physics},
	author = {Chu, Ching-Hsiang and Tseng, Wen-Wei and Hsu, Chan-Min and Wei, An-Chi},
	year = {2022},
}

@article{fischer_mitosegnet_2020,
	title = {{MitoSegNet}: {Easy}-to-use {Deep} {Learning} {Segmentation} for {Analyzing} {Mitochondrial} {Morphology}},
	volume = {23},
	issn = {2589-0042},
	shorttitle = {{MitoSegNet}},
	doi = {10.1016/j.isci.2020.101601},
	abstract = {While the analysis of mitochondrial morphology has emerged as a key tool in the study of mitochondrial function, efficient quantification of mitochondrial microscopy images presents a challenging task and bottleneck for statistically robust conclusions. Here, we present Mitochondrial Segmentation Network (MitoSegNet), a pretrained deep learning segmentation model that enables researchers to easily exploit the power of deep learning for the quantification of mitochondrial morphology. We tested the performance of MitoSegNet against three feature-based segmentation algorithms and the machine-learning segmentation tool Ilastik. MitoSegNet outperformed all other methods in both pixelwise and morphological segmentation accuracy. We successfully applied MitoSegNet to unseen fluorescence microscopy images of mitoGFP expressing mitochondria in wild-type and catp-6 ATP13A2 mutant C. elegans adults. Additionally, MitoSegNet was capable of accurately segmenting mitochondria in HeLa cells treated with fragmentation inducing reagents. We provide MitoSegNet in a toolbox for Windows and Linux operating systems that combines segmentation with morphological analysis.},
	language = {eng},
	number = {10},
	journal = {iScience},
	author = {Fischer, Christian A. and Besora-Casals, Laura and Rolland, Stéphane G. and Haeussler, Simon and Singh, Kritarth and Duchen, Michael and Conradt, Barbara and Marr, Carsten},
	month = oct,
	year = {2020},
	pmid = {33083756},
	pmcid = {PMC7554024},
	keywords = {Artificial Intelligence, Automation in Bioinformatics, Bioinformatics, Cell Biology},
	pages = {101601},
}

@inproceedings{mishra_quantifying_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Quantifying {Structural} {Heterogeneity} of {Healthy} and {Cancerous} {Mitochondria} {Using} a {Combined} {Segmentation} and {Classification} {USK}-{Net}},
	isbn = {9783030304935},
	doi = {10.1007/978-3-030-30493-5_30},
	abstract = {Mitochondria are the main source of cellular energy and thus essential for cell survival. Pathological conditions like cancer, can cause functional alterations and lead to mitochondrial dysfunction. Indeed, electron micrographs of mitochondria that are isolated from cancer cells show a different morphology as compared to mitochondria from healthy cells. However, the description of mitochondrial morphology and the classification of the respective samples are so far qualitative. Furthermore, large intra-class variability and impurities such as mitochondrial fragments and other organelles in the micrographs make a clear separation between healthy and cancerous samples challenging. In this study, we propose a deep-learning based model to quantitatively assess the status of each intact mitochondrion with a continuous score, which measures its closeness to the healthy/tumor classes based on its morphology. This allows us to describe the structural transition from healthy to cancerous mitochondria. Methodologically, we train two USK networks, one to segment individual mitochondria from an electron micrograph, and the other to softly classify each image pixel as belonging to (i) healthy mitochondrial, (ii) cancerous mitochondrial and (iii) non-mitochondrial (image background \& impurities) tissue. Our combined model outperforms each network alone in both pixel classification and object segmentation. Moreover, our model can quantitatively assess the mitochondrial heterogeneity within and between healthy samples and different tumor types, hence providing insightful information of mitochondrial alterations in cancer development.},
	language = {en},
	booktitle = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2019: {Workshop} and {Special} {Sessions}},
	publisher = {Springer International Publishing},
	author = {Mishra, Manish and Schmitt, Sabine and Zischka, Hans and Strasser, Michael and Navab, Nassir and Marr, Carsten and Peng, Tingying},
	editor = {Tetko, Igor V. and Kůrková, Věra and Karpov, Pavel and Theis, Fabian},
	year = {2019},
	keywords = {Cancer, Classification, Convolutional neural network, Deep learning, Mitochondria, Segmentation, USK-net},
	pages = {289--298},
}

@article{sukhorukov_emergence_2012,
	title = {Emergence of the mitochondrial reticulum from fission and fusion dynamics},
	volume = {8},
	issn = {1553-7358},
	doi = {10.1371/journal.pcbi.1002745},
	abstract = {Mitochondria form a dynamic tubular reticulum within eukaryotic cells. Currently, quantitative understanding of its morphological characteristics is largely absent, despite major progress in deciphering the molecular fission and fusion machineries shaping its structure. Here we address the principles of formation and the large-scale organization of the cell-wide network of mitochondria. On the basis of experimentally determined structural features we establish the tip-to-tip and tip-to-side fission and fusion events as dominant reactions in the motility of this organelle. Subsequently, we introduce a graph-based model of the chondriome able to encompass its inherent variability in a single framework. Using both mean-field deterministic and explicit stochastic mathematical methods we establish a relationship between the chondriome structural network characteristics and underlying kinetic rate parameters. The computational analysis indicates that mitochondrial networks exhibit a percolation threshold. Intrinsic morphological instability of the mitochondrial reticulum resulting from its vicinity to the percolation transition is proposed as a novel mechanism that can be utilized by cells for optimizing their functional competence via dynamic remodeling of the chondriome. The detailed size distribution of the network components predicted by the dynamic graph representation introduces a relationship between chondriome characteristics and cell function. It forms a basis for understanding the architecture of mitochondria as a cell-wide but inhomogeneous organelle. Analysis of the reticulum adaptive configuration offers a direct clarification for its impact on numerous physiological processes strongly dependent on mitochondrial dynamics and organization, such as efficiency of cellular metabolism, tissue differentiation and aging.},
	language = {eng},
	number = {10},
	journal = {PLoS computational biology},
	author = {Sukhorukov, Valerii M. and Dikov, Daniel and Reichert, Andreas S. and Meyer-Hermann, Michael},
	year = {2012},
	pmid = {23133350},
	pmcid = {PMC3486901},
	keywords = {Animals, Cluster Analysis, Computational Biology, HeLa Cells, Humans, Mitochondria, Mitochondrial Dynamics, Models, Biological, Stochastic Processes},
	pages = {e1002745},
}

@article{rohani_mito_2020,
	title = {Mito {Hacker}: a set of tools to enable high-throughput analysis of mitochondrial network morphology},
	volume = {10},
	issn = {2045-2322},
	shorttitle = {Mito {Hacker}},
	doi = {10.1038/s41598-020-75899-5},
	abstract = {Mitochondria are highly dynamic organelles that can exhibit a wide range of morphologies. Mitochondrial morphology can differ significantly across cell types, reflecting different physiological needs, but can also change rapidly in response to stress or the activation of signaling pathways. Understanding both the cause and consequences of these morphological changes is critical to fully understanding how mitochondrial function contributes to both normal and pathological physiology. However, while robust and quantitative analysis of mitochondrial morphology has become increasingly accessible, there is a need for new tools to generate and analyze large data sets of mitochondrial images in high throughput. The generation of such datasets is critical to fully benefit from rapidly evolving methods in data science, such as neural networks, that have shown tremendous value in extracting novel biological insights and generating new hypotheses. Here we describe a set of three computational tools, Cell Catcher, Mito Catcher and MiA, that we have developed to extract extensive mitochondrial network data on a single-cell level from multi-cell fluorescence images. Cell Catcher automatically separates and isolates individual cells from multi-cell images; Mito Catcher uses the statistical distribution of pixel intensities across the mitochondrial network to detect and remove background noise from the cell and segment the mitochondrial network; MiA uses the binarized mitochondrial network to perform more than 100 mitochondria-level and cell-level morphometric measurements. To validate the utility of this set of tools, we generated a database of morphological features for 630 individual cells that encode 0, 1 or 2 alleles of the mitochondrial fission GTPase Drp1 and demonstrate that these mitochondrial data could be used to predict Drp1 genotype with 87\% accuracy. Together, this suite of tools enables the high-throughput and automated collection of detailed and quantitative mitochondrial structural information at a single-cell level. Furthermore, the data generated with these tools, when combined with advanced data science approaches, can be used to generate novel biological insights.},
	language = {eng},
	number = {1},
	journal = {Scientific Reports},
	author = {Rohani, Ali and Kashatus, Jennifer A. and Sessions, Dane T. and Sharmin, Salma and Kashatus, David F.},
	month = nov,
	year = {2020},
	pmid = {33144635},
	pmcid = {PMC7642274},
	keywords = {Animals, Computational Biology, Humans, Image Processing, Computer-Assisted, Mitochondria, Mitochondrial Dynamics, Signal Transduction, Software},
	pages = {18941},
}

@article{collier_machine_2021,
	title = {Machine learning algorithms reveal the secrets of mitochondrial dynamics},
	volume = {13},
	issn = {1757-4684},
	doi = {10.15252/emmm.202114316},
	abstract = {Mitochondria exist as dynamic networks whose morphology is driven by the complex interplay between fission and fusion events. Failure to modulate these processes can be detrimental to human health as evidenced by dominantly inherited, pathogenic variants in OPA1, an effector enzyme of mitochondrial fusion, that lead to network fragmentation, cristae dysmorphology and impaired oxidative respiration, manifesting typically as isolated optic atrophy. However, a significant number of patients develop more severe, systemic phenotypes, although no genetic modifiers of OPA1-related disease have been identified to date. In this issue of EMBO Molecular Medicine, supervised machine learning algorithms underlie a novel tool that enables automated, high throughput and unbiased screening of changes in mitochondrial morphology measured using confocal microscopy. By coupling this approach with a bespoke siRNA library targeting the entire mitochondrial proteome, the work described by Cretin and colleagues yielded significant insight into mitochondrial biology, discovering 91 candidate genes whose endogenous depletion can remedy impaired mitochondrial dynamics caused by OPA1 deficiency.},
	language = {eng},
	number = {6},
	journal = {EMBO molecular medicine},
	author = {Collier, Jack J. and Taylor, Robert W.},
	month = jun,
	year = {2021},
	pmid = {34043876},
	pmcid = {PMC8185547},
	keywords = {Algorithms, GTP Phosphohydrolases, Humans, Machine Learning, Mitochondria, Mitochondrial Dynamics},
	pages = {e14316},
}

@inproceedings{hsu_convolutional_2021,
	title = {Convolutional neural networks predict mitochondrial structures from label-free microscopy images},
	volume = {11792},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11792/117920G/Convolutional-neural-networks-predict-mitochondrial-structures-from-label-free-microscopy/10.1117/12.2591089.full},
	doi = {10.1117/12.2591089},
	abstract = {Convolutional neural networks (CNNs) have shown significant success in image recognition and segmentation. Based on a CNN-like U-Net architecture, such a model can effectively predict subcellular structures from transmitted light (TL) images after learning the relationships between TL images and fluorescent-labeled images. In this paper, we focused on building corresponding models of subcellular mitochondrial structures using the CNN method and compared the prediction results derived from confocal microscopic, Airyscan microscopic, z-stack, and time-series images. With multi-model combined prediction, it is possible to generate integrated images using only TL inputs, which reduces the time required for sample preparation and increases the temporal resolution. This enables visualization, measurement, and understanding of the morphology and dynamics of mitochondria and mitochondrial DNA.},
	urldate = {2022-05-12},
	booktitle = {International {Forum} on {Medical} {Imaging} in {Asia} 2021},
	publisher = {SPIE},
	author = {Hsu, Chan-Min and Lee, Yi-Ju and Wei, An-Chi},
	month = apr,
	year = {2021},
	pages = {85--93},
}

@article{guo_organelle-specific_2021,
	title = {Organelle-specific phase contrast microscopy enables gentle monitoring and analysis of mitochondrial network dynamics},
	volume = {12},
	issn = {2156-7085},
	doi = {10.1364/BOE.425848},
	abstract = {Mitochondria are delicate organelles that play a key role in cell fate. Current research methods rely on fluorescence labeling that introduces stress due to photobleaching and phototoxicity. Here we propose a new, gentle method to study mitochondrial dynamics, where organelle-specific three-dimensional information is obtained in a label-free manner at high resolution, high specificity, and without detrimental effects associated with staining. A mitochondria cleavage experiment demonstrates that not only do the label-free mitochondria-specific images have the required resolution and precision, but also fairly include all cells and mitochondria in downstream morphological analysis, while fluorescence images omit dim cells and mitochondria. The robustness of the method was tested on samples of different cell lines and on data collected from multiple systems. Thus, we have demonstrated that our method is an attractive alternative to study mitochondrial dynamics, connecting behavior and function in a simpler and more robust way than traditional fluorescence imaging.},
	language = {eng},
	number = {7},
	journal = {Biomedical Optics Express},
	author = {Guo, Siyue and Ma, Ying and Pan, Yang and Smith, Zachary J. and Chu, Kaiqin},
	month = jul,
	year = {2021},
	pmid = {34457419},
	pmcid = {PMC8367278},
	pages = {4363--4379},
}

@article{chai_characterizing_2018,
	title = {Characterizing robustness and sensitivity of convolutional neural networks for quantitative analysis of mitochondrial morphology},
	volume = {6},
	copyright = {2018 Higher Education Press},
	issn = {2095-4689},
	url = {https://journal.hep.com.cn/qb/EN/10.1007/s40484-018-0156-3},
	doi = {10.1007/s40484-018-0156-3},
	abstract = {{\textless}p{\textgreater}\textit{Background}: Quantitative analysis of mitochondrial morphology plays important roles in studies of mitochondrial biology. The analysis depends critically on segmentation of mitochondria, the image analysis process of extracting mitochondrial morphology from images. The main goal of this study is to characterize the performance of convolutional neural networks (CNNs) in segmentation of mitochondria from fluorescence microscopy images. Recently, CNNs have achieved remarkable success in challenging image segmentation tasks in several disciplines. So far, however, our knowledge of their performance in segmenting biological images remains limited. In particular, we know little about their robustness, which defines their capability of segmenting biological images of different conditions, and their sensitivity, which defines their capability of detecting subtle morphological changes of biological objects. {\textless}/p{\textgreater}{\textless}p{\textgreater}\textit{Methods}: We have developed a method that uses realistic synthetic images of different conditions to characterize the robustness and sensitivity of CNNs in segmentation of mitochondria. Using this method, we compared performance of two widely adopted CNNs: the fully convolutional network (FCN) and the U-Net. We further compared the two networks against the adaptive active-mask (AAM) algorithm, a representative of high-performance conventional segmentation algorithms. {\textless}/p{\textgreater}{\textless}p{\textgreater}\textit{Results}: The FCN and the U-Net consistently outperformed the AAM in accuracy, robustness, and sensitivity, often by a significant margin. The U-Net provided overall the best performance. {\textless}/p{\textgreater}{\textless}p{\textgreater}\textit{Conclusions}: Our study demonstrates superior performance of the U-Net and the FCN in segmentation of mitochondria. It also provides quantitative measurements of the robustness and sensitivity of these networks that are essential to their applications in quantitative analysis of mitochondrial morphology.{\textless}/p{\textgreater}},
	language = {en},
	number = {4},
	urldate = {2022-05-12},
	journal = {Quantitative Biology},
	author = {Chai, Xiaoqi and Ba, Qinle and Yang, Ge},
	month = dec,
	year = {2018},
	pages = {344--358},
}

@article{schrepfer_mitofusins_2016,
	title = {Mitofusins, from {Mitochondria} to {Metabolism}},
	volume = {61},
	issn = {1097-4164},
	doi = {10.1016/j.molcel.2016.02.022},
	abstract = {Mitochondrial architecture is involved in several functions crucial for cell viability, proliferation, senescence, and signaling. In particular, mitochondrial dynamics, through the balance between fusion and fission events, represents a central mechanism for bioenergetic adaptation to metabolic needs of the cell. As key regulators of mitochondrial dynamics, the fusogenic mitofusins have recently been linked to mitochondrial biogenesis and respiratory functions, impacting on cell fate and organism homeostasis. Here we review the implication of mitofusins in the regulation of mitochondrial metabolism, and their consequence on energy homeostasis at the cellular and physiological level, highlighting their crucial role in metabolic disorders, cancer, and aging.},
	language = {eng},
	number = {5},
	journal = {Molecular Cell},
	author = {Schrepfer, Emilie and Scorrano, Luca},
	month = mar,
	year = {2016},
	pmid = {26942673},
	keywords = {Aging, Animals, Energy Metabolism, GTP Phosphohydrolases, Homeostasis, Humans, Metabolic Diseases, Mitochondria, Mitochondrial Dynamics, Mitochondrial Membrane Transport Proteins, Mitochondrial Proteins, Neoplasms, Signal Transduction, bioenergetic, mitochondrial dynamics, mitofusins},
	pages = {683--694},
}

@article{chandhok_structure_2018,
	title = {Structure, function, and regulation of mitofusin-2 in health and disease},
	volume = {93},
	issn = {1469-185X},
	doi = {10.1111/brv.12378},
	abstract = {Mitochondria are highly dynamic organelles that constantly migrate, fuse, and divide to regulate their shape, size, number, and bioenergetic function. Mitofusins (Mfn1/2), optic atrophy 1 (OPA1), and dynamin-related protein 1 (Drp1), are key regulators of mitochondrial fusion and fission. Mutations in these molecules are associated with severe neurodegenerative and non-neurological diseases pointing to the importance of functional mitochondrial dynamics in normal cell physiology. In recent years, significant progress has been made in our understanding of mitochondrial dynamics, which has raised interest in defining the physiological roles of key regulators of fusion and fission and led to the identification of additional functions of Mfn2 in mitochondrial metabolism, cell signalling, and apoptosis. In this review, we summarize the current knowledge of the structural and functional properties of Mfn2 as well as its regulation in different tissues, and also discuss the consequences of aberrant Mfn2 expression.},
	language = {eng},
	number = {2},
	journal = {Biological Reviews of the Cambridge Philosophical Society},
	author = {Chandhok, Gursimran and Lazarou, Michael and Neumann, Brent},
	month = may,
	year = {2018},
	pmid = {29068134},
	pmcid = {PMC6446723},
	keywords = {Charcot-Marie-Tooth disease, GTP Phosphohydrolases, Gene Expression Regulation, Enzymologic, Humans, Mitochondria, Mitochondrial Proteins, diabetes, mitochondria, mitochondrial dynamics, mitofusin-1, mitofusin-2, neurodegenerative disease, obesity, vascular disease},
	pages = {933--949},
}

@article{allegra_relationship_2019,
	title = {Relationship between mitofusin 2 and cancer},
	volume = {116},
	issn = {1876-1631},
	doi = {10.1016/bs.apcsb.2018.11.009},
	abstract = {Mitochondria are dynamic organelles whose actions are fundamental for cell viability. Within the cell, the mitochondrial system is incessantly modified via the balance between fusion and fission processes. Among other proteins, mitofusin 2 is a central protagonist in all these mitochondrial events (fusion, trafficking, contacts with other organelles), the balance of which causes the correct mitochondrial action, shape, and distribution within the cell. Here we examine the structural and functional characteristics of mitofusin 2, underlining its essential role in numerous intracellular pathways, as well as in the pathogenesis of cancer.},
	language = {eng},
	journal = {Advances in Protein Chemistry and Structural Biology},
	author = {Allegra, Alessandro and Innao, Vanessa and Allegra, Andrea Gaetano and Musolino, Caterina},
	year = {2019},
	pmid = {31036292},
	keywords = {Animals, Cancer, Fission, Fusion, GTP Phosphohydrolases, Humans, Mitochondria, Mitochondrial Dynamics, Mitochondrial Proteins, Mitofusin 2, Neoplasms, Signal Transduction},
	pages = {209--236},
}

@article{filadi_mitofusin_2018,
	title = {Mitofusin 2: from functions to disease},
	volume = {9},
	issn = {2041-4889},
	shorttitle = {Mitofusin 2},
	doi = {10.1038/s41419-017-0023-6},
	abstract = {Mitochondria are highly dynamic organelles whose functions are essential for cell viability. Within the cell, the mitochondrial network is continuously remodeled through the balance between fusion and fission events. Moreover, it dynamically contacts other organelles, particularly the endoplasmic reticulum, with which it enterprises an important functional relationship able to modulate several cellular pathways. Being mitochondria key bioenergetics organelles, they have to be transported to all the specific high-energy demanding sites within the cell and, when damaged, they have to be efficiently removed. Among other proteins, Mitofusin 2 represents a key player in all these mitochondrial activities (fusion, trafficking, turnover, contacts with other organelles), the balance of which results in the appropriate mitochondrial shape, function, and distribution within the cell. Here we review the structural and functional properties of Mitofusin 2, highlighting its crucial role in several cell pathways, as well as in the pathogenesis of neurodegenerative diseases, metabolic disorders, cardiomyopathies, and cancer.},
	language = {eng},
	number = {3},
	journal = {Cell Death \& Disease},
	author = {Filadi, Riccardo and Pendin, Diana and Pizzo, Paola},
	month = feb,
	year = {2018},
	pmid = {29491355},
	pmcid = {PMC5832425},
	keywords = {Animals, Cardiomyopathies, GTP Phosphohydrolases, Humans, Metabolic Diseases, Mitochondrial Proteins, Neoplasms, Neurodegenerative Diseases},
	pages = {330},
}

@book{ramzi_wavelets_2021,
	title = {Wavelets in the {Deep} {Learning} {Era}},
	abstract = {Sparsity based methods, such as wavelets, have been state-of-the-art for more than 20 years for inverse problems before being overtaken by neural networks. In particular, U-nets have proven to be extremely effective. Their main ingredients are a highly non-linear processing, a massive learning made possible by the flourishing of optimization algorithms with the power of computers (GPU) and the use of large available datasets for training. It is far from obvious to say which of these three ingredients has the biggest impact on the performance. While the many stages of non-linearity are intrinsic to deep learning, the usage of learning with training data could also be exploited by sparsity based approaches. The aim of our study is to push the limits of sparsity to use, similarly to U-nets, massive learning and large datasets, and then to compare the results with U-nets. We present a new network architecture , called learnlets, which conserves the properties of sparsity based methods such as exact reconstruction and good generalization properties, while fostering the power of neural networks for learning and fast calculation. We evaluate the model on image denoising tasks. Our conclusion is that U-nets perform better than learn-lets, while learnlets have better generalization properties .},
	author = {Ramzi, Zaccharie and Michalewicz, Kevin and Starck, Jean-Luc and Moreau, Thomas and Ciuciu, Philippe},
	month = sep,
	year = {2021},
	doi = {10.13140/RG.2.2.23081.88169},
}

@misc{noauthor_filling_nodate,
	title = {Filling cavities in point clouds representing human body surface using {Bezier} patches {\textbar} {SpringerLink}},
	url = {https://link-springer-com.proxy.lib.sfu.ca/article/10.1007/s11042-020-10120-3},
	urldate = {2022-05-12},
}

@misc{noauthor_elmi2021_nodate,
	title = {elmi2021 {\textbar} {Generalized} {Statistical} {Object} {Distance} {Analysis} ({GSODA}) {For} {Object} {Based} {Colocalization} {In} {Quantitative} {Microscopy}},
	url = {https://www.elmi2021.org/abstract/generalized-statistical-object-distance-analysis-gsoda-for-object-based-colocalization-in-quantitative-microscopy.html},
	urldate = {2022-05-12},
}

@misc{noauthor_anomalous_nodate,
	title = {Anomalous dynamics of the endoplasmic reticulum network - {PubMed}},
	url = {https://pubmed.ncbi.nlm.nih.gov/30110830/},
	urldate = {2022-05-12},
}

@misc{noauthor_point_nodate,
	title = {Point {Cloud} {Denoising} {Using} {Normal} {Vector}-{Based} {Graph} {Wavelet} {Shrinkage} {\textbar} {IEEE} {Conference} {Publication} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/abstract/document/9746795?casa_token=4WdGlpuuVcsAAAAA:YLns-MEm3bYfeOhdJZqXAcYAkRrqGf4k31NGIGC89LF42-85cK3cC8ygPh37lEMk2d8AkPvr9w},
	urldate = {2022-05-12},
}

@inproceedings{anis_compression_2016,
	title = {Compression of dynamic {3D} point clouds using subdivisional meshes and graph wavelet transforms},
	doi = {10.1109/ICASSP.2016.7472901},
	abstract = {The advent of advanced acquisition techniques in 3D media applications has led to an increasing trend of capturing dynamic objects and scenes via 3D point cloud sequences. This form of data is composed of time-indexed frames, each consisting of a collection of points with position and color attributes. Compression of such datasets is challenging because of the lack of efficient techniques for exploiting spatial and temporal correlations between the attributes. In our approach, we create an intermediate high-resolution representation of the point clouds, using consistent subdivisional triangular meshes, that captures all the features of the underlying object or scene. This representation is easy to obtain, significantly simplifies motion compensation and allows us to design efficient wavelet transforms using the recently developed framework of Biorthogonal Graph Wavelet Filterbanks. Preliminary experiments show that our approach can be an effective compression technique for 3D point cloud sequences.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Anis, Aamir and Chou, Philip A. and Ortega, Antonio},
	month = mar,
	year = {2016},
	note = {ISSN: 2379-190X},
	keywords = {3D point cloud sequences, Color, Geometry, Image color analysis, Three-dimensional displays, Topology, Wavelet transforms, graph wavelet transform, motion compensation, subdivisional meshes},
	pages = {6360--6364},
}

@inproceedings{zhang_3d_2019,
	title = {A {3D} {Haar} {Wavelet} {Transform} for {Point} {Cloud} {Attribute} {Compression} {Based} on {Local} {Surface} {Analysis}},
	doi = {10.1109/PCS48520.2019.8954557},
	abstract = {Point cloud is a main representation of 3D scenes. It is widely applied in many fields including autonomous driving, heritage reconstruction, virtual reality and augmented reality. The data size of this type of media is massive since it contains numerous points with each associated with a large amount of information including geometric coordinate, color, reflectance, and normal. It is thus of great significance to investigate the compression of point cloud data to boost its application. However, developing efficient point cloud compression method is challenging mainly due to the unstructured nature and nonuniform distribution of the data. In this paper, we propose a novel point cloud attribute compression algorithm based on Haar Wavelet Transform (HWT). More specifically, the transform is performed taking into account the surface orientation of point cloud. Experimental results demonstrate that the proposed method outperforms other state-of-the-art transforms.},
	booktitle = {2019 {Picture} {Coding} {Symposium} ({PCS})},
	author = {Zhang, Sujun and Zhang, Wei and Yang, Fuzheng and Huo, Junyan},
	month = nov,
	year = {2019},
	note = {ISSN: 2472-7822},
	keywords = {Haar wavelet transform, attribute compression, point cloud, surface orientation},
	pages = {1--5},
}

@article{guevara_3d_2022,
	title = {{3D} {Spectral} {Graph} {Wavelet} {Point} {Signatures} in {Pre}-{Processing} {Stage} for {Mobile} {Laser} {Scanning} {Point} {Cloud} {Registration} in {Unstructured} {Orchard} {Environments}},
	volume = {22},
	issn = {1558-1748},
	doi = {10.1109/JSEN.2021.3129340},
	abstract = {The use of three-dimensional registration techniques is an important component for sensor-based localization and mapping. Several approaches have been proposed to align three-dimensional data, obtaining meaningful results in structured scenarios. However, the increased use of high-frame-rate 3D sensors has lead to more challenging application scenarios where the performance of registration techniques may degrade significantly. In order to improve the accuracy of the procedure, different works have considered a representative subset of points while preserving application-dependent features for registration. In this work, we tackle such a problem, considering the use of a general feature-extraction operator in the spectral domain as a prior step to the registration. The proposed spectral strategies use three wavelet transforms that are evaluated along with four well-known registration techniques. The methodology was experimentally validated in a dense orchard environment. The results show that the probability of failure in registration can be reduced up to 12.04\% for the evaluated approaches, leading to a significant increase in the localization accuracy. Those results validate the effectiveness and efficiency of the spectral-assisted registration algorithms in an agricultural setting and motivate their usage for a wider range of applications.},
	number = {2},
	journal = {IEEE Sensors Journal},
	author = {Guevara, Javier and Gené-Mola, Jordi and Gregorio, Eduard and Auat Cheein, Fernando},
	month = jan,
	year = {2022},
	keywords = {3D point cloud registration, Kernel, Laser radar, Location awareness, Meters, Spectral analysis, Three-dimensional displays, Wavelet analysis, Wavelet transforms, filtering algorithms, robot localization},
	pages = {1720--1728},
}

@inproceedings{watanabe_point_2022,
	title = {Point {Cloud} {Denoising} {Using} {Normal} {Vector}-{Based} {Graph} {Wavelet} {Shrinkage}},
	doi = {10.1109/ICASSP43922.2022.9746795},
	abstract = {Many applications that use point clouds, such as 3D immersive telepresence, suffer from geometric quality degradation. This noise may be caused by measurement errors of the capturing device or by the point cloud estimation method. In this paper, we propose a novel graph-based point cloud denoising approach using the spectral graph wavelet transform (SGWT) and graph wavelet shrinkage. Unlike conventional SGWT-based denoising methods, the proposed wavelet shrinkage thresholds are determined based on the normal vector at each point and are thus based on the local geometric structure of the point cloud. This approach avoids excessive wavelet shrinkage, which can lead to the loss of complex geometric structure. Experimental results show that the proposed method achieves the best accuracy as compared with recent deep-learning-based and graph-based state-of-the-art denoising methods.},
	booktitle = {{ICASSP} 2022 - 2022 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Watanabe, Ryosuke and Nonaka, Keisuke and Kato, Haruhisa and Pavez, Eduardo and Kobayashi, Tatsuya and Ortega, Antonio},
	month = may,
	year = {2022},
	note = {ISSN: 2379-190X},
	keywords = {Estimation, Measurement errors, Noise reduction, Point cloud compression, Telepresence, Three-dimensional displays, Wavelet transforms, graph signal processing, point cloud denoising, spectral graph wavelets, wavelet shrinkage},
	pages = {2569--2573},
}

@article{speckner_anomalous_2018,
	title = {Anomalous dynamics of the endoplasmic reticulum network},
	volume = {98},
	issn = {2470-0053},
	doi = {10.1103/PhysRevE.98.012406},
	abstract = {Large portions of the endoplasmic reticulum (ER) in eukaryotic cells are organized as dynamic networks whose segments are connected by three-way junctions. Here we show that ER junctions move subdiffusively with signatures of fractional Brownian motion and a strong dependence on the cytoskeleton's integrity: The time-averaged mean square displacement scales as 〈r{\textasciicircum}\{2\}(τ)〉\_\{t\}∼τ{\textasciicircum}\{α\} with α≈0.5 in untreated cells and α≈0.3 when disrupting microtubules, with successive steps being anticorrelated in both cases. We explain our observations by considering ER junctions to move like monomers in (semi)flexible polymer segments immersed in a viscoelastic environment. We also report that ER networks have a nontrivial fractal dimension d\_\{f\}≈1.6 on mesoscopic scales and we provide evidence that the organelle's dynamics is governed by fractons.},
	language = {eng},
	number = {1-1},
	journal = {Physical Review. E},
	author = {Speckner, Konstantin and Stadler, Lorenz and Weiss, Matthias},
	month = jul,
	year = {2018},
	pmid = {30110830},
	keywords = {Animals, Endoplasmic Reticulum, Fractals, Microtubules, Models, Biological, Motion},
	pages = {012406},
}

@article{nowak_filling_2021,
	title = {Filling cavities in point clouds representing human body surface using {Bezier} patches},
	volume = {80},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-020-10120-3},
	doi = {10.1007/s11042-020-10120-3},
	abstract = {In this paper we introduce a cavity reconstructing algorithm for 3D surface scans (CRASS) developed for filling cavities in point clouds representing human body surfaces. The presented method uses Bezier patches to reconstruct missing data. The source of input data for the algorithm was an 8-directional structured light scanning system for the human body. Typical 3D scan representing human body consists of about 1 million points with average sampling density of 1 mm. The paper describes the complete scan processing pipeline: data pre-processing, boundary selection, cavity extraction and reconstruction, and a post-processing step to smooth and resample resulting geometry. The developed algorithm was tested on simulated and scanned 3D input data. Quality assessment was made based on simulated cavities, reconstructed using presented method and compared to original 3D geometry. Additionally, comparison to the state-of-the-art screened Poisson method is presented. Values’ ranges of parameters influencing result of described method were estimated for sample scans and comprehensively discussed. The results of the quantitative assessment of the reconstruction were lower than 0,5 of average sampling density.},
	language = {en},
	number = {10},
	urldate = {2022-05-11},
	journal = {Multimedia Tools and Applications},
	author = {Nowak, Marta and Michoński, Jakub and Sitnik, Robert},
	month = apr,
	year = {2021},
	keywords = {Bezier patches, Cavity filling, Full body scanning, Hole filling, Parametric surfaces, Point cloud},
	pages = {15093--15134},
}

@article{noauthor_incremental_1995,
	title = {An incremental algorithm for {Betti} numbers of simplicial complexes on the 3-sphere},
	volume = {12},
	issn = {0167-8396},
	url = {https://www.sciencedirect.com/science/article/pii/016783969500016Y},
	doi = {10.1016/0167-8396(95)00016-Y},
	abstract = {A general and direct method for computing the Betti numbers of a finite simplicial complex in Sd is given. This method is complete for d ⩽ 3, where ve…},
	language = {en},
	number = {7},
	urldate = {2022-05-11},
	journal = {Computer Aided Geometric Design},
	month = nov,
	year = {1995},
	pages = {771--784},
}

@article{edelsbrunner_three-dimensional_1994,
	title = {Three-{Dimensional} {Alpha} {Shapes}},
	volume = {13},
	doi = {10.1145/147130.147153},
	abstract = {Frequently, data in scientific computing is in its abstract form a finite point set in space, and it is sometimes useful or required to compute what one might call the ``shape'' of the set. For that purpose, this paper introduces the formal notion of the family of \${\textbackslash}alpha\$-shapes of a finite point set in \${\textbackslash}Real{\textasciicircum}3\$. Each shape is a well-defined polytope, derived from the Delaunay triangulation of the point set, with a parameter \${\textbackslash}alpha {\textbackslash}in {\textbackslash}Real\$ controlling the desired level of detail. An algorithm is presented that constructs the entire family of shapes for a given set of size \$n\$ in time \$O(n{\textasciicircum}2)\$, worst case. A robust implementation of the algorithm is discussed and several applications in the area of scientific computing are mentioned. Comment: 32 pages},
	journal = {ACM Transactions on Graphics},
	author = {Edelsbrunner, Herbert and Mucke, Ernst},
	month = oct,
	year = {1994},
}

@book{dey_algorithms_1996,
	title = {Algorithms for {Manifolds} and {Simplicial} {Complexes} in {Euclidean} 3-{Space} ({Preliminary} {Version}).},
	abstract = {A new approach to analyze simplicial complexes in Euclidean 3-space R3 is described. First, methods from topology are used to analyze triangulated 3-manifolds in R3. Then it is shown that these methods can in fact be applied to arbitrary simplicial complexes in R3 after (simulating) the process of thickening a complex to a 3-manifold homotopic to it. As a consequence considerable structural information about the complex can be determined and certain d{\textasciitilde}crete problems solved as well. For example, it is shown how to determine the homology groups, as well as concrete representations of their generators, for a given complex K. Further, given a l-cycle or 2-cycle in K it is shown how to express th{\textasciitilde} cycle in terms of the generators of a homology group, which solves the problem of classifying cycles up to their homology class. An application is to the classification of simplicial maps up to their actions on homology groups. Recent developments in analyzing molecular structures through a dual simplicial complex, called Delaunay complex, haa further enhanced the need for computin structural information about simplicial complexes in 5 R . This paper develops basic techniques to manipulate and analyze structures of complexes in R3.},
	author = {Dey, Tamal and Guha, Sumanta},
	month = jan,
	year = {1996},
	doi = {10.1145/237814.237987},
}

@article{gardiner_alpha_2018,
	title = {Alpha shapes: determining {3D} shape complexity across morphologically diverse structures},
	volume = {18},
	copyright = {2018 The Author(s).},
	issn = {1471-2148},
	shorttitle = {Alpha shapes},
	url = {https://bmcecolevol.biomedcentral.com/articles/10.1186/s12862-018-1305-z},
	doi = {10.1186/s12862-018-1305-z},
	abstract = {Following recent advances in bioimaging, high-resolution 3D models of biological structures are now generated rapidly and at low-cost. To use this data to address evolutionary and ecological questions, an array of tools has been developed to conduct shape analysis and quantify topographic complexity. Here we focus particularly on shape techniques applied to irregular-shaped objects lacking clear homologous landmarks, and propose a new ‘alpha-shapes’ method for quantifying 3D shape complexity. We apply alpha-shapes to quantify shape complexity in the mammalian baculum as an example of a morphologically disparate structure. Micro- computed-tomography (μCT) scans of bacula were conducted. Bacula were binarised and converted into point clouds. Following application of a scaling factor to account for absolute size differences, a suite of alpha-shapes was fitted per specimen. An alpha shape is formed from a subcomplex of the Delaunay triangulation of a given set of points, and ranges in refinement from a very coarse mesh (approximating convex hulls) to a very fine fit. ‘Optimal’ alpha was defined as the refinement necessary in order for alpha-shape volume to equal CT voxel volume, and was taken as a metric of overall ‘complexity’. Our results show that alpha-shapes can be used to quantify interspecific variation in shape ‘complexity’ within biological structures of disparate geometry. The ‘stepped’ nature of alpha curves is informative with regards to the contribution of specific morphological features to overall ‘complexity’. Alpha-shapes agrees with other measures of complexity (dissection index, Dirichlet normal energy) in identifying ursid bacula as having low shape complexity. However, alpha-shapes estimates mustelid bacula as being most complex, contrasting with other shape metrics. 3D fractal dimension is identified as an inappropriate metric of complexity when applied to bacula. Alpha-shapes is used to calculate ‘optimal’ alpha refinement as a proxy for shape ‘complexity’ without identifying landmarks. The implementation of alpha-shapes is straightforward, and is automated to process large datasets quickly. We interpret alpha-shapes as being particularly sensitive to concavities in surface topology, potentially distinguishing it from other shape complexity metrics. Beyond genital shape, the alpha-shapes technique holds considerable promise for new applications across evolutionary, ecological and palaeoecological disciplines.},
	language = {en},
	number = {1},
	urldate = {2022-05-10},
	journal = {BMC Evolutionary Biology},
	author = {Gardiner, James D. and Behnsen, Julia and Brassey, Charlotte A.},
	month = dec,
	year = {2018},
	pages = {1--16},
}

@misc{noauthor_euler_2022,
	title = {Euler characteristic},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Euler_characteristic&oldid=1082487615},
	abstract = {In mathematics, and more specifically in algebraic topology and polyhedral combinatorics, the Euler characteristic (or Euler number, or Euler–Poincaré characteristic) is a topological invariant, a number that describes a topological space's shape or structure regardless of the way it is bent. It is commonly denoted by 
  
    
      
        χ
      
    
    \{{\textbackslash}displaystyle {\textbackslash}chi \}
   (Greek lower-case letter chi).
The Euler characteristic was originally defined for polyhedra and used to prove various theorems about them, including the classification of the Platonic solids. It was stated for Platonic solids in 1537 in an unpublished manuscript by Francesco Maurolico. Leonhard Euler, for whom the concept is named, introduced it for convex polyhedra more generally but failed to rigorously prove that it is an invariant. In modern mathematics, the Euler characteristic arises from homology and, more abstractly, homological algebra.},
	language = {en},
	urldate = {2022-05-10},
	journal = {Wikipedia},
	month = apr,
	year = {2022},
	note = {Page Version ID: 1082487615},
}

@misc{noauthor_euler_2021,
	title = {Euler number (physics)},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Euler_number_(physics)&oldid=1024848982},
	abstract = {The Euler number (Eu) is a dimensionless number used in fluid flow calculations. It expresses the relationship between a local pressure drop caused by a restriction and the kinetic energy per volume of the flow, and is used to characterize energy losses in the flow, where a perfect frictionless flow corresponds to an Euler number of 0.  The inverse of the Euler number is referred to as the Ruark Number with the symbol Ru.
The Euler number is defined as

  
    
      
        
          E
          u
        
        =
        
          
            
              
                pressure forces
              
              
                inertial forces
              
            
          
        
        =
        
          
            
              
                (pressure)(area)
              
              
                (mass)(acceleration)
              
            
          
        
        =
        
          
            
              (
              
                p
                
                  u
                
              
              −
              
                p
                
                  d
                
              
              )
              
              
                L
                
                  2
                
              
            
            
              (
              ρ
              
                L
                
                  3
                
              
              )
              (
              
                v
                
                  2
                
              
              
                /
              
              L
              )
            
          
        
        =
        
          
            
              
                p
                
                  u
                
              
              −
              
                p
                
                  d
                
              
            
            
              ρ
              
                v
                
                  2
                
              
            
          
        
      
    
    \{{\textbackslash}displaystyle {\textbackslash}mathrm \{Eu\} =\{{\textbackslash}dfrac \{{\textbackslash}mbox\{pressure forces\}\}\{{\textbackslash}mbox\{inertial forces\}\}\}=\{{\textbackslash}dfrac \{{\textbackslash}mbox\{(pressure)(area)\}\}\{{\textbackslash}mbox\{(mass)(acceleration)\}\}\}=\{{\textbackslash}frac \{(p\_\{u\}-p\_\{d\}){\textbackslash},L{\textasciicircum}\{2\}\}\{({\textbackslash}rho L{\textasciicircum}\{3\})(v{\textasciicircum}\{2\}/L)\}\}=\{{\textbackslash}frac \{p\_\{u\}-p\_\{d\}\}\{{\textbackslash}rho v{\textasciicircum}\{2\}\}\}\}
  where

  
    
      
        ρ
      
    
    \{{\textbackslash}displaystyle {\textbackslash}rho \}
   is the density of the fluid.

  
    
      
        
          p
          
            u
          
        
      
    
    \{{\textbackslash}displaystyle p\_\{u\}\}
   is the upstream pressure.

  
    
      
        
          p
          
            d
          
        
      
    
    \{{\textbackslash}displaystyle p\_\{d\}\}
   is the downstream pressure.

  
    
      
        v
      
    
    \{{\textbackslash}displaystyle v\}
   is a characteristic velocity of the flow.},
	language = {en},
	urldate = {2022-05-10},
	journal = {Wikipedia},
	month = may,
	year = {2021},
	note = {Page Version ID: 1024848982},
}

@article{peralta_evaluation_2021,
	title = {An {Evaluation} of {Order} {Significance} of {Euler} {Angles} in {Voting}-based {Registration} of {3D} {Point} {Clouds}},
	volume = {49},
	doi = {10.11371/aiieej.49.0_15},
	abstract = {Voting-based methods are not a conventional approach for the registration of 3D point clouds. Nonetheless, recent proposals have achieved outstanding results in low overlapping scenarios around 40\% and below. The quaternion is the rotation representation of choice to bin into the voting accumulator that determines the best transformation matrix within their pipeline. Compared to the unit quaternion, the Euler angles are a rotation representation formed by fewer arguments and are easier to interpret. However, the order in which these are applied plays a critical role in the final transformation. In this paper, we evaluate the significance of the order in which the Euler Angles are searched and applied within a voting-based registration framework.},
	journal = {画像電子学会年次大会予稿集},
	author = {Peralta, Luis and Iwakiri, Munetoshi and Tanaka, Kiyoshi},
	year = {2021},
	keywords = {3D point cloud, 3次元点群, Euler angles, low overlapping, registration, voting, オイラー角, レジストレーション, 低いオーバーラッピング, 投票},
	pages = {15--15},
}

@article{bercovici_point-cloud_2017,
	title = {Point-{Cloud} {Processing} {Using} {Modified} {Rodrigues} {Parameters} for {Relative} {Navigation}},
	volume = {40},
	issn = {0731-5090},
	url = {https://doi.org/10.2514/1.G002787},
	doi = {10.2514/1.G002787},
	abstract = {Point-cloud registration pertains to the computation of point pairs between a source and a destination point cloud, followed by the calculation of the rigid transform minimizing a relative distance (such as the iterative closest point-to-plane distance criterion) between the set of point pairs. The work described in this paper presents an alternative parametrization of the rotational component of the rigid transform using modified Rodrigues parameters. The performance of this formulation is compared with that of Euler angles-based algorithms over random and structured point clouds, using additive and multiplicative formulations. Monte Carlo results assuming perfect point-pair matching show a better performance for the new modified Rodrigues parameter formulation in terms of accuracy and speed, with convergence achieved on average 30\% faster than the baseline algorithm. Relying on a realistic pair-matching procedure degrades the convergence basin of all methods, but the modified Rodrigues parameter formulation still retains the best performance.},
	number = {12},
	urldate = {2022-05-10},
	journal = {Journal of Guidance, Control, and Dynamics},
	author = {Bercovici, Benjamin and McMahon, Jay W.},
	year = {2017},
	pages = {3167--3179},
}

@article{liang_solving_2013,
	title = {Solving {Partial} {Differential} {Equations} on {Point} {Clouds}},
	volume = {35},
	issn = {1064-8275},
	url = {https://epubs.siam.org/doi/abs/10.1137/120869730},
	doi = {10.1137/120869730},
	abstract = {In this paper we present a general framework for solving partial differential equations on manifolds represented by meshless points, i.e., point clouds, without parameterization or connection information. Our method is based on a local approximation of the manifold as well as functions defined on the manifold, such as using least squares, simultaneously in a local intrinsic coordinate system constructed by local principal component analysis using \$K\$ nearest neighbors. Once the local reconstruction is available, differential operators on the manifold can be approximated discretely. The framework extends to manifolds of any dimension. The complexity of our method scales well with the total number of points and the true dimension of the manifold (not the embedded dimension). The numerical algorithms, error analysis, and test examples are presented.},
	number = {3},
	urldate = {2022-05-10},
	journal = {SIAM Journal on Scientific Computing},
	author = {Liang, Jian and Zhao, Hongkai},
	month = jan,
	year = {2013},
	keywords = {35, 65, Laplace--Beltrami operator, constrained quadratic optimization, eigenvalue problem, gradient, manifold, moving least squares, principle component analysis, semi-Lagrangian method, time dependent PDE, upwind scheme},
	pages = {A1461--A1486},
}

@article{carlsson_topological_2014,
	title = {Topological pattern recognition for point cloud data*},
	volume = {23},
	issn = {0962-4929, 1474-0508},
	url = {https://www.cambridge.org/core/journals/acta-numerica/article/topological-pattern-recognition-for-point-cloud-data/BB0DA0F0EBD79809C563AF80B555A23C},
	doi = {10.1017/S0962492914000051},
	abstract = {In this paper we discuss the adaptation of the methods of homology from algebraic topology to the problem of pattern recognition in point cloud data sets. The method is referred to as persistent homology, and has numerous applications to scientific problems. We discuss the definition and computation of homology in the standard setting of simplicial complexes and topological spaces, then show how one can obtain useful signatures, called barcodes, from finite metric spaces, thought of as sampled from a continuous object. We present several different cases where persistent homology is used, to illustrate the different ways in which the method can be applied.},
	language = {en},
	urldate = {2022-05-10},
	journal = {Acta Numerica},
	author = {Carlsson, Gunnar},
	month = may,
	year = {2014},
	pages = {289--368},
}

@incollection{chazal_homology_2018,
	address = {Cambridge},
	series = {Cambridge {Texts} in {Applied} {Mathematics}},
	title = {Homology {Inference}},
	isbn = {9781108419390},
	url = {https://www.cambridge.org/core/books/geometric-and-topological-inference/homology-inference/9F214607B44012DB8B69491D573291EE},
	urldate = {2022-05-10},
	booktitle = {Geometric and {Topological} {Inference}},
	publisher = {Cambridge University Press},
	editor = {Chazal, Frédéric and Boissonnat, Jean-Daniel and Yvinec, Mariette},
	year = {2018},
	doi = {10.1017/9781108297806.012},
	pages = {197--223},
}

@incollection{blumberg_statistics_2019,
	address = {Cambridge},
	title = {Statistics and {Topological} {Inference}},
	isbn = {9781107159549},
	url = {https://www.cambridge.org/core/books/topological-data-analysis-for-genomics-and-evolution/statistics-and-topological-inference/EA6CA1321D15B18C880069577DC05D12},
	urldate = {2022-05-10},
	booktitle = {Topological {Data} {Analysis} for {Genomics} and {Evolution}: {Topology} in {Biology}},
	publisher = {Cambridge University Press},
	editor = {Blumberg, Andrew J. and Rabadan, Raul},
	year = {2019},
	doi = {10.1017/9781316671665.005},
	pages = {170--234},
}

@incollection{giardina_topological_2016,
	address = {Cambridge},
	title = {Topological {Field} {Theory} of {Data}: {Mining} {Data} {Beyond} {Complex} {Networks}},
	isbn = {9781107124103},
	shorttitle = {Topological {Field} {Theory} of {Data}},
	url = {https://www.cambridge.org/core/books/advances-in-disordered-systems-random-processes-and-some-applications/topological-field-theory-of-data-mining-data-beyond-complex-networks/CCAB5AC5765621E4771EDCBD261707CA},
	abstract = {A Philosophical IntroductionIt has become increasingly obvious that very detailed, intricate interactions and interdependencies among and within large systems are often central to most of the important problems that science and society face. Distributed information technologies, neuroscience and genomics are just a few examples of rapidly emerging areas where very complex large-scale system interactions are viewed more and more as central to understanding, as well as to practical advances. Decision makers in these environments increasingly use computer models, simulation and data access resources to try to integrate and make sense of information and courses of action. There is also mounting concern that, in spite of the extended use of these simulations and models, we are repeatedly experiencing unexpected cascading systemic failures in society. We feel that, without resolving the issue of learning how to cope with complex situations, we also do not know enough about our methods of modeling complex systems to make effective decisions.In the late eighties Saunders Mac Lane started a philosophical debate which, over thirty years later, is still going on with varying interest in the outcomes. This paper stems partly out of the crucial fundamental question that debate gave life to in contemporary science. This deep long-standing philosophical question, that can be formulated in several different ways, concerns mathematics. Are the formalisms of mathematics based on or derived from the facts and, if not, how are they derived? Alternatively, if mathematics is a purely formal game – an elaborate and tightly connected network of formal structures, axiom systems and connections – why do the formal conclusions in most of the cases fit the facts? Or, is mathematics invented or discovered? In the language of Karl Popper, statements of a science should be falsifiable by factual data; those of mathematics are not. Thus mathematics is not a science, it is something else. Yet the mathematical network is tied to numberless sources in human activities, to crucial parts of human knowledge and, most especially, to the various sciences.},
	urldate = {2022-05-10},
	booktitle = {Advances in {Disordered} {Systems}, {Random} {Processes} and {Some} {Applications}},
	publisher = {Cambridge University Press},
	author = {Rasetti, Mario and Merelli, Emanuela},
	editor = {Giardinà, Cristian and Contucci, Pierluigi},
	year = {2016},
	doi = {10.1017/9781316403877.002},
	pages = {1--42},
}

@incollection{anderson_brief_2009,
	title = {A {Brief}, {Subjective} {History} of {Homology} and {Homotopy} {Theory} in this {Century}},
	isbn = {9780883855690},
	url = {https://www.cambridge.org/core/books/who-gave-you-the-epsilon/brief-subjective-history-of-homology-and-homotopy-theory-in-this-century/625179734AD054938CBE1EFA6A951E41},
	abstract = {I have recently been recalling that about twenty-five years ago, when I first came to settle in this country, I was invited to participate in the celebration of the opening of the Mathematics Building, Van Vleck Hall, at the University ofWisconsin. On that occasion I learned a new American word, namely “banquet”, which has a totally different meaning in the United States from the meaning that it has in Britain. But more importantly, I must recall the immense respect I felt for some of the after-dinner speakers who were able to make the recounting of an event last much longer than the event itself. So I'm very conscious of the fact that in attempting to recount to you the history of algebraic topology in this century, I must not make the recounting of this history last longer than the history. In fact, I must telescope it very dramatically, one might almost say, abruptly. So I apologize in advance that much of the treatment will be necessarily very superficial. I would like to start off with the first epoch which is up to 1926. And here the inspiration for homology theory comes from the work of Poincaré.Poincaré, during a period earlier than the one I'm thinking of, had already invented or discovered, according to your philosophy, the fundamental group. But he published a series of papers in which he was studying what we would call algebraic varieties, the configuration of points in higher-dimensional Euclidean space given by polynomial equalities and inequalities; and he was looking again at what we might call vector fields and generalizations of vector fields on such varieties.},
	urldate = {2022-05-10},
	booktitle = {Who {Gave} {You} the {Epsilon}?: {And} {Other} {Tales} of {Mathematical} {History}},
	publisher = {Mathematical Association of America},
	author = {Hilton, Peter},
	editor = {Anderson, Marlow and Wilson, Robin and Katz, Victor},
	year = {2009},
	doi = {10.5948/UPO9781614445043.021},
	pages = {148--156},
}

@article{rupe_disco_2019,
	title = {{DisCo}: {Physics}-{Based} {Unsupervised} {Discovery} of {Coherent} {Structures} in {Spatiotemporal} {Systems}},
	shorttitle = {{DisCo}},
	url = {http://arxiv.org/abs/1909.11822},
	abstract = {Extracting actionable insight from complex unlabeled scientific data is an open challenge and key to unlocking data-driven discovery in science. Complementary and alternative to supervised machine learning approaches, unsupervised physics-based methods based on behavior-driven theories hold great promise. Due to computational limitations, practical application on real-world domain science problems has lagged far behind theoretical development. We present our first step towards bridging this divide - DisCo - a high-performance distributed workflow for the behavior-driven local causal state theory. DisCo provides a scalable unsupervised physics-based representation learning method that decomposes spatiotemporal systems into their structurally relevant components, which are captured by the latent local causal state variables. Complex spatiotemporal systems are generally highly structured and organize around a lower-dimensional skeleton of coherent structures, and in several firsts we demonstrate the efficacy of DisCo in capturing such structures from observational and simulated scientific data. To the best of our knowledge, DisCo is also the first application software developed entirely in Python to scale to over 1000 machine nodes, providing good performance along with ensuring domain scientists' productivity. We developed scalable, performant methods optimized for Intel many-core processors that will be upstreamed to open-source Python library packages. Our capstone experiment, using newly developed DisCo workflow and libraries, performs unsupervised spacetime segmentation analysis of CAM5.1 climate simulation data, processing an unprecedented 89.5 TB in 6.6 minutes end-to-end using 1024 Intel Haswell nodes on the Cori supercomputer obtaining 91\% weak-scaling and 64\% strong-scaling efficiency.},
	urldate = {2022-05-10},
	journal = {arXiv:1909.11822 [physics]},
	author = {Rupe, Adam and Kumar, Nalini and Epifanov, Vladislav and Kashinath, Karthik and Pavlyk, Oleksandr and Schlimbach, Frank and Patwary, Mostofa and Maidanov, Sergey and Lee, Victor and {Prabhat} and Crutchfield, James P.},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.11822},
	keywords = {Computer Science - Machine Learning, Computer Science - Performance, Physics - Computational Physics},
}

@article{noauthor_topological_2022,
	title = {Topological {Data} {Analysis} in {Biomedicine}: {A} {Review}},
	issn = {1532-0464},
	shorttitle = {Topological {Data} {Analysis} in {Biomedicine}},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046422000983},
	doi = {10.1016/j.jbi.2022.104082},
	abstract = {Significant technological advances made in recent years have shepherded a dramatic increase in utilization of digital technologies for biomedicine– ev…},
	language = {en},
	urldate = {2022-05-09},
	journal = {Journal of Biomedical Informatics},
	month = may,
	year = {2022},
	pages = {104082},
}

@article{guha_roy_does_2022,
	title = {Does your dermatology classifier know what it doesn't know? {Detecting} the long-tail of unseen conditions},
	volume = {75},
	issn = {1361-8423},
	shorttitle = {Does your dermatology classifier know what it doesn't know?},
	doi = {10.1016/j.media.2021.102274},
	abstract = {Supervised deep learning models have proven to be highly effective in classification of dermatological conditions. These models rely on the availability of abundant labeled training examples. However, in the real-world, many dermatological conditions are individually too infrequent for per-condition classification with supervised learning. Although individually infrequent, these conditions may collectively be common and therefore are clinically significant in aggregate. To prevent models from generating erroneous outputs on such examples, there remains a considerable unmet need for deep learning systems that can better detect such infrequent conditions. These infrequent 'outlier' conditions are seen very rarely (or not at all) during training. In this paper, we frame this task as an out-of-distribution (OOD) detection problem. We set up a benchmark ensuring that outlier conditions are disjoint between the model training, validation, and test sets. Unlike traditional OOD detection benchmarks where the task is to detect dataset distribution shift, we aim at the more challenging task of detecting subtle differences resulting from a different pathology or condition. We propose a novel hierarchical outlier detection (HOD) loss, which assigns multiple abstention classes corresponding to each training outlier class and jointly performs a coarse classification of inliers vs. outliers, along with fine-grained classification of the individual classes. We demonstrate that the proposed HOD loss based approach outperforms leading methods that leverage outlier data during training. Further, performance is significantly boosted by using recent representation learning methods (BiT, SimCLR, MICLe). Further, we explore ensembling strategies for OOD detection and propose a diverse ensemble selection process for the best result. We also perform a subgroup analysis over conditions of varying risk levels and different skin types to investigate how OOD performance changes over each subgroup and demonstrate the gains of our framework in comparison to baseline. Furthermore, we go beyond traditional performance metrics and introduce a cost matrix for model trust analysis to approximate downstream clinical impact. We use this cost matrix to compare the proposed method against the baseline, thereby making a stronger case for its effectiveness in real-world scenarios.},
	language = {eng},
	journal = {Medical Image Analysis},
	author = {Guha Roy, Abhijit and Ren, Jie and Azizi, Shekoofeh and Loh, Aaron and Natarajan, Vivek and Mustafa, Basil and Pawlowski, Nick and Freyberg, Jan and Liu, Yuan and Beaver, Zach and Vo, Nam and Bui, Peggy and Winter, Samantha and MacWilliams, Patricia and Corrado, Greg S. and Telang, Umesh and Liu, Yun and Cemgil, Taylan and Karthikesalingam, Alan and Lakshminarayanan, Balaji and Winkens, Jim},
	month = jan,
	year = {2022},
	pmid = {34731777},
	keywords = {Benchmarking, Deep learning, Dermatology, Ensembles, Humans, Long-tailed recognition, Out-of-distribution detection, Outlier exposure, Representation learning},
	pages = {102274},
}

@article{xu_endoplasmic_2020,
	title = {Endoplasmic {Reticulum}–{Mitochondria} {Contact} {Sites} and {Neurodegeneration}},
	volume = {8},
	doi = {10.3389/fcell.2020.00428},
	abstract = {Endoplasmic reticulum–mitochondria contact sites (ERMCSs) are dynamic contact regions with a distance of 10–30 nm between the endoplasmic reticulum and mitochondria. Endoplasmic reticulum–mitochondria contact sites regulate various biological processes, including lipid transfer, calcium homeostasis, autophagy, and mitochondrial dynamics. The dysfunction of ERMCS is closely associated with various neurodegenerative diseases, including Parkinson’s disease, Alzheimer’s disease, and amyotrophic lateral sclerosis. In this review, we will summarize the current knowledge of the components and organization of ERMCSs, the methods for monitoring ERMCSs, and the physiological functions of ERMCSs in different model systems. Additionally, we will emphasize the current understanding of the malfunction of ERMCSs and their potential roles in neurodegenerative diseases.},
	journal = {Frontiers in Cell and Developmental Biology},
	author = {Xu, Lingna and Wang, Xi and Tong, Chao},
	month = jun,
	year = {2020},
	pages = {428},
}

@article{kaksonen_mechanisms_2018,
	title = {Mechanisms of clathrin-mediated endocytosis},
	volume = {19},
	issn = {1471-0080},
	url = {https://www.nature.com/articles/nrm.2017.132},
	doi = {10.1038/nrm.2017.132},
	abstract = {Clathrin-coated endocytic vesicles are produced by a complex modular protein machinery that transiently assembles on the plasma membrane. This machinery selects and concentrates cargo molecules and shapes the membrane into a vesicle.Forces arising within the membrane during deformation counteract forces generated by the endocytic protein modules. Physical parameters such as membrane tension and rigidity control the dynamics of clathrin-mediated endocytosis.Many endocytic proteins bind phosphoinositides, which are critical for organizing the sequence of protein assembly throughout endocytosis.The endocytic machinery is evolutionarily ancient and highly conserved, but it has adapted to varying force requirements in different lineages.},
	language = {en},
	number = {5},
	urldate = {2022-05-08},
	journal = {Nature Reviews Molecular Cell Biology},
	author = {Kaksonen, Marko and Roux, Aurélien},
	month = may,
	year = {2018},
	keywords = {Endocytosis, Membrane curvature},
	pages = {313--326},
}

@article{andrews_multi-region_2015,
	title = {Multi-{Region} {Probabilistic} {Dice} {Similarity} {Coefficient} using the {Aitchison} {Distance} and {Bipartite} {Graph} {Matching}},
	url = {http://arxiv.org/abs/1509.07244},
	abstract = {Validation of image segmentation methods is of critical importance. Probabilistic image segmentation is increasingly popular as it captures uncertainty in the results. Image segmentation methods that support multi-region (as opposed to binary) delineation are more favourable as they capture interactions between the different objects in the image. The Dice similarity coefficient (DSC) has been a popular metric for evaluating the accuracy of automated or semi-automated segmentation methods by comparing their results to the ground truth. In this work, we develop an extension of the DSC to multi-region probabilistic segmentations (with unordered labels). We use bipartite graph matching to establish label correspondences and propose two functions that extend the DSC, one based on absolute probability differences and one based on the Aitchison distance. These provide a robust and accurate measure of multi-region probabilistic segmentation accuracy.},
	urldate = {2022-05-08},
	journal = {arXiv:1509.07244 [cs]},
	author = {Andrews, Shawn and Hamarneh, Ghassan},
	month = oct,
	year = {2015},
	note = {arXiv: 1509.07244},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{chang_mixup-cam_2020,
	title = {Mixup-{CAM}: {Weakly}-supervised {Semantic} {Segmentation} via {Uncertainty} {Regularization}},
	shorttitle = {Mixup-{CAM}},
	url = {http://arxiv.org/abs/2008.01201},
	abstract = {Obtaining object response maps is one important step to achieve weakly-supervised semantic segmentation using image-level labels. However, existing methods rely on the classification task, which could result in a response map only attending on discriminative object regions as the network does not need to see the entire object for optimizing the classification loss. To tackle this issue, we propose a principled and end-to-end train-able framework to allow the network to pay attention to other parts of the object, while producing a more complete and uniform response map. Specifically, we introduce the mixup data augmentation scheme into the classification network and design two uncertainty regularization terms to better interact with the mixup strategy. In experiments, we conduct extensive analysis to demonstrate the proposed method and show favorable performance against state-of-the-art approaches.},
	urldate = {2022-05-08},
	journal = {arXiv:2008.01201 [cs, eess]},
	author = {Chang, Yu-Ting and Wang, Qiaosong and Hung, Wei-Chih and Piramuthu, Robinson and Tsai, Yi-Hsuan and Yang, Ming-Hsuan},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.01201},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{islam_segmix_2021,
	title = {{SegMix}: {Co}-occurrence {Driven} {Mixup} for {Semantic} {Segmentation} and {Adversarial} {Robustness}},
	shorttitle = {{SegMix}},
	url = {http://arxiv.org/abs/2108.09929},
	abstract = {In this paper, we present a strategy for training convolutional neural networks to effectively resolve interference arising from competing hypotheses relating to inter-categorical information throughout the network. The premise is based on the notion of feature binding, which is defined as the process by which activations spread across space and layers in the network are successfully integrated to arrive at a correct inference decision. In our work, this is accomplished for the task of dense image labelling by blending images based on (i) categorical clustering or (ii) the co-occurrence likelihood of categories. We then train a feature binding network which simultaneously segments and separates the blended images. Subsequent feature denoising to suppress noisy activations reveals additional desirable properties and high degrees of successful predictions. Through this process, we reveal a general mechanism, distinct from any prior methods, for boosting the performance of the base segmentation and saliency network while simultaneously increasing robustness to adversarial attacks.},
	urldate = {2022-05-08},
	journal = {arXiv:2108.09929 [cs]},
	author = {Islam, Md Amirul and Kowal, Matthew and Derpanis, Konstantinos G. and Bruce, Neil D. B.},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.09929},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{su_comparison_2020,
	title = {A {Comparison} of {Surgical} {Cavity} {3D} {Reconstruction} {Methods}},
	doi = {10.1109/SII46433.2020.9026289},
	abstract = {In robot-assisted minimally invasive surgery (RMIS), surgeons are tasked with navigating and operating in dynamic 3D cavities. 3D spatial information can specifically indicate resection targets or delicate structures to avoid, and is critical to many surgical tasks. While preoperative imaging can provide information about relative anatomical or spatial locations of interest, these data are only a snapshot of a dynamically changing environment; natural movement due to breathing, deformation or natural heartbeat require the operator to make intraoperative, on-the-fly decisions. Online monocular RGB visual feedback may assist, but lacks the spatial information critical to precise surgical operations. In reality, surgeons must negotiate static, offline preoperative data with reduced dimensionality or sparse imaging to perform intricate, life-critical tasks. Real-time dense 3D reconstruction can alleviate these issues. In this comparative work, three approaches towards dense 3D reconstruction from laparoscopic imaging are investigated. For this, a new laparoscopic surgical scene dataset is introduced, and was captured using a pre-calibrated stereo camera. This camera recorded a surgical scene from various viewpoints in time, and a ground truth dense surgical scene was recorded with a high-precision 3D scanner. Three different reconstruction algorithms were then implemented and compared, including simultaneous localization and mapping (SLAM), visual odometry (VO), and structure from motion (SFM). A successful method will enable real-time registration of preoperative imaging and segmentation, thus resulting in safer and more robust surgical operations. This work also enables future research in vision-based force estimation and other research areas in RMIS.},
	booktitle = {2020 {IEEE}/{SICE} {International} {Symposium} on {System} {Integration} ({SII})},
	author = {Su, Yun-Hsuan and Lindgren, Kyle and Huang, Kevin and Hannaford, Blake},
	month = jan,
	year = {2020},
	note = {ISSN: 2474-2325},
	keywords = {Cameras, Feature extraction, Simultaneous localization and mapping, Solid modeling, Streaming media, Surgery, Three-dimensional displays, medical imaging, medical robotics, robotic surgery, teleoperation},
	pages = {329--336},
}

@article{hsung_orbit_2018,
	title = {Orbit {Segmentation} by {Surface} {Reconstruction} {With} {Automatic} {Sliced} {Vertex} {Screening}},
	volume = {65},
	issn = {1558-2531},
	doi = {10.1109/TBME.2017.2720184},
	abstract = {GOAL: The purpose of this paper is to develop a computational approach to the segmentation of human orbits.
METHODS: The first step is to perform Hounsfield units thresholding to segment the bony structure around the orbit. Then, a three-dimensional mesh model is generated. Poisson surface reconstruction is applied to a set of automatically screened vertices, which are facing the inner orbital walls. These procedures effectively close orbital fissures; various nerves foramina; and interpolate the broken surfaces due to thin bone structures around the orbit. We also developed validation models with five dried skulls, where the orbits were filled with dental impression. Validations on the proposed algorithm were performed with the corresponding CT images and verified by experienced radiographer.
RESULTS: The mean volume differences are less than 0.3\%. Surface differences are within 0.3 mm of root mean square. Both differences are not clinically significant.
SIGNIFICANCE: Traditional approaches are slice-by-slice manual editing or shape interpolation with selected slices interactively. It is not only time consuming, but also inefficient, exhibits interoperator variability, and repeatability problems. In the proposed method, most of the manual processes are eliminated with adjustable vertex screening parameters. It makes the proposed method repeatable.},
	language = {eng},
	number = {4},
	journal = {IEEE transactions on bio-medical engineering},
	author = {Hsung, Tai-Chiu and Lo, John and Chong, Mei-Man and Goto, Tazuko K. and Cheung, Lim-Kwong},
	month = apr,
	year = {2018},
	pmid = {28682243},
	keywords = {Adult, Algorithms, Female, Humans, Imaging, Three-Dimensional, Infant, Male, Middle Aged, Orbit, Tomography, X-Ray Computed, Young Adult},
	pages = {828--838},
}

@article{zhu_density_2017,
	title = {A density based algorithm to detect cavities and holes from planar points},
	volume = {109},
	issn = {0098-3004},
	url = {https://www.sciencedirect.com/science/article/pii/S0098300416308615},
	doi = {10.1016/j.cageo.2017.08.008},
	abstract = {Delaunay-based shape reconstruction algorithms are widely used in approximating the shape from planar points. However, these algorithms cannot ensure the optimality of varied reconstructed cavity boundaries and hole boundaries. This inadequate reconstruction can be primarily attributed to the lack of efficient mathematic formulation for the two structures (hole and cavity). In this paper, we develop an efficient algorithm for generating cavities and holes from planar points. The algorithm yields the final boundary based on an iterative removal of the Delaunay triangulation. Our algorithm is mainly divided into two steps, namely, rough and refined shape reconstructions. The rough shape reconstruction performed by the algorithm is controlled by a relative parameter. Based on the rough result, the refined shape reconstruction mainly aims to detect holes and pure cavities. Cavity and hole are conceptualized as a structure with a low-density region surrounded by the high-density region. With this structure, cavity and hole are characterized by a mathematic formulation called as compactness of point formed by the length variation of the edges incident to point in Delaunay triangulation. The boundaries of cavity and hole are then found by locating a shape gradient change in compactness of point set. The experimental comparison with other shape reconstruction approaches shows that the proposed algorithm is able to accurately yield the boundaries of cavity and hole with varying point set densities and distributions.},
	language = {en},
	urldate = {2022-05-06},
	journal = {Computers \& Geosciences},
	author = {Zhu, Jie and Sun, Yizhong and Pang, Yueyong},
	month = dec,
	year = {2017},
	keywords = {Cavity and hole, Delaunay triangulation, GIS, Planar point, Shape reconstruction},
	pages = {178--193},
}

@article{zhang_how_2021,
	title = {How {Does} {Mixup} {Help} {With} {Robustness} and {Generalization}?},
	url = {http://arxiv.org/abs/2010.04819},
	abstract = {Mixup is a popular data augmentation technique based on taking convex combinations of pairs of examples and their labels. This simple technique has been shown to substantially improve both the robustness and the generalization of the trained model. However, it is not well-understood why such improvement occurs. In this paper, we provide theoretical analysis to demonstrate how using Mixup in training helps model robustness and generalization. For robustness, we show that minimizing the Mixup loss corresponds to approximately minimizing an upper bound of the adversarial loss. This explains why models obtained by Mixup training exhibits robustness to several kinds of adversarial attacks such as Fast Gradient Sign Method (FGSM). For generalization, we prove that Mixup augmentation corresponds to a specific type of data-adaptive regularization which reduces overfitting. Our analysis provides new insights and a framework to understand Mixup.},
	urldate = {2022-05-05},
	journal = {arXiv:2010.04819 [cs, stat]},
	author = {Zhang, Linjun and Deng, Zhun and Kawaguchi, Kenji and Ghorbani, Amirata and Zou, James},
	month = mar,
	year = {2021},
	note = {arXiv: 2010.04819},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{noauthor_measurement_nodate,
	title = {Measurement of caveolin-1 densities in the cell membrane for quantification of caveolar deformation after exposure to hypotonic membrane tension - {PubMed}},
	url = {https://pubmed.ncbi.nlm.nih.gov/28798329/},
	urldate = {2022-05-05},
}

@article{castro_causality_2020,
	title = {Causality matters in medical imaging},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-17478-w},
	doi = {10.1038/s41467-020-17478-w},
	abstract = {Causal reasoning can shed new light on the major challenges in machine learning for medical imaging: scarcity of high-quality annotated data and mismatch between the development dataset and the target environment. A causal perspective on these issues allows decisions about data collection, annotation, preprocessing, and learning strategies to be made and scrutinized more transparently, while providing a detailed categorisation of potential biases and mitigation techniques. Along with worked clinical examples, we highlight the importance of establishing the causal relationship between images and their annotations, and offer step-by-step recommendations for future studies.},
	language = {en},
	number = {1},
	urldate = {2022-05-04},
	journal = {Nature Communications},
	author = {Castro, Daniel C. and Walker, Ian and Glocker, Ben},
	month = jul,
	year = {2020},
	keywords = {Computational models, Data processing, Machine learning, Medical research, Predictive medicine},
	pages = {3673},
}

@article{shojaie_granger_2022,
	title = {Granger {Causality}: {A} {Review} and {Recent} {Advances}},
	volume = {9},
	shorttitle = {Granger {Causality}},
	url = {https://doi.org/10.1146/annurev-statistics-040120-010930},
	doi = {10.1146/annurev-statistics-040120-010930},
	abstract = {Introduced more than a half-century ago, Granger causality has become a popular tool for analyzing time series data in many application domains, from economics and finance to genomics and neuroscience. Despite this popularity, the validity of this framework for inferring causal relationships among time series has remained the topic of continuous debate. Moreover, while the original definition was general, limitations in computational tools have constrained the applications of Granger causality to primarily simple bivariate vector autoregressive processes. Starting with a review of early developments and debates, this article discusses recent advances that address various shortcomings of the earlier approaches, from models for high-dimensional time series to more recent developments that account for nonlinear and non-Gaussian observations and allow for subsampled and mixed-frequency time series.},
	number = {1},
	urldate = {2022-05-04},
	journal = {Annual Review of Statistics and Its Application},
	author = {Shojaie, Ali and Fox, Emily B.},
	year = {2022},
	keywords = {deep neural networks, graphical models, mixed-frequency time series, multivariate time series, penalized estimation, vector autoregressive model},
	pages = {289--319},
}

@article{peng_generalized_2022,
	title = {A {Generalized} {Quantile} {Tree} {Method} for {Subgroup} {Identification}},
	volume = {0},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2022.2032723},
	doi = {10.1080/10618600.2022.2032723},
	abstract = {One primary goal of subgroup analysis is to identify subgroups of subjects with differential treatment effects. Existing methods have focused on the mean treatment effect and may be ineffective when the two distributions differ in scales or in the upper or lower tails. We develop a new generalized quantile tree method for subgroup identification. The method first uses quantile rank score tests to select split variables and then estimates the split point by minimizing a composite quantile loss. The proposed split rule is free of variable selection bias and robust against outliers and heavy-tailed distributions. In addition, we introduce a generalized quantile treatment effect estimator and a testing method for the selection and confirmation of predictive subgroups. Simulation shows that the proposed method gives more accurate subgroup identification than existing methods for cases with heteroscedastic or heavy-tailed errors. The practical value of the method is demonstrated through the analysis of an AIDS clinical trial data. Supplementary materials for this article are available online.},
	number = {0},
	urldate = {2022-05-04},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Peng, Xiang and Wang, Huixia Judy},
	month = jan,
	year = {2022},
	keywords = {Quantile treatment effect, Rank score, Recursive partitioning, Regression tree, Subgroup analysis},
	pages = {1--11},
}

@article{cohen_role_2004,
	title = {Role of {Caveolae} and {Caveolins} in {Health} and {Disease}},
	volume = {84},
	issn = {0031-9333},
	url = {https://journals.physiology.org/doi/full/10.1152/physrev.00046.2003},
	doi = {10.1152/physrev.00046.2003},
	abstract = {Although they were discovered more than 50 years ago, caveolae have remained enigmatic plasmalemmal organelles. With their characteristic “flasklike” shape and virtually ubiquitous tissue distribution, these interesting structures have been implicated in a wide range of cellular functions. Similar to clathrin-coated pits, caveolae function as macromolecular vesicular transporters, while their unique lipid composition classifies them as plasma membrane lipid rafts, structures enriched in a variety of signaling molecules. The caveolin proteins (caveolin-1, -2, and -3) serve as the structural components of caveolae, while also functioning as scaffolding proteins, capable of recruiting numerous signaling molecules to caveolae, as well as regulating their activity. That so many signaling molecules and signaling cascades are regulated by an interaction with the caveolins provides a paradigm by which numerous disease processes may be affected by ablation or mutation of these proteins. Indeed, studies in caveolin-deficient mice have implicated these structures in a host of human diseases, including diabetes, cancer, cardiovascular disease, atherosclerosis, pulmonary fibrosis, and a variety of degenerative muscular dystrophies. In this review, we provide an in depth summary regarding the mechanisms by which caveolae and caveolins participate in human disease processes.},
	number = {4},
	urldate = {2022-05-04},
	journal = {Physiological Reviews},
	author = {Cohen, Alex W. and Hnasko, Robert and Schubert, William and Lisanti, Michael P.},
	month = oct,
	year = {2004},
	pages = {1341--1379},
}

@article{stan_structure_2005,
	series = {Lipid {Rafts}: {From} {Model} {Membranes} to {Cells}},
	title = {Structure of caveolae},
	volume = {1746},
	issn = {0167-4889},
	url = {https://www.sciencedirect.com/science/article/pii/S0167488905001862},
	doi = {10.1016/j.bbamcr.2005.08.008},
	abstract = {The introduction of the electron microscope to the study of the biological materials in the second half of the last century has dramatically expanded our view and understanding of the inner workings of cells by enabling the discovery and study of subcellular organelles. A population of flask-shaped or spherical invaginations of the plasma membrane were described and named plasmalemmal vesicles or caveolae. Until the discovery of caveolin-1 as their first molecular marker in early 1990s, the study of caveolae was the exclusive domain of electron microscopists that demonstrated caveolae at different surface densities in most mammalian cells with few exceptions. Electron microscopy techniques in combination with other approaches have also revealed the structural features of caveolae as well as some of their protein and lipid residents. This review summarizes the data on the structure and components of caveolae and their stomatal diaphragms.},
	language = {en},
	number = {3},
	urldate = {2022-05-04},
	journal = {Biochimica et Biophysica Acta (BBA) - Molecular Cell Research},
	author = {Stan, Radu V.},
	month = dec,
	year = {2005},
	pages = {334--348},
}

@article{kurzchalia_membrane_1999,
	title = {Membrane microdomains and caveolae},
	volume = {11},
	issn = {0955-0674},
	url = {https://www.sciencedirect.com/science/article/pii/S0955067499800611},
	doi = {10.1016/S0955-0674(99)80061-1},
	abstract = {Glycosphingolipid- and cholesterol-enriched microdomains, or rafts, within the plasma membrane of eukaryotic cells have been implicated in many important cellular processes, such as polarized sorting of apical membrane proteins in epithelial cells and signal transduction. Until recently, however, the existence of such domains remained controversial. The past year has brought compelling evidence that microdomains indeed exist in living cells. In addition, several recent papers have suggested that caveolae, which are considered to be a specific form of raft, and caveolins, the major membrane proteins of caveolae, are involved in the dynamic cholesterol-dependent regulation of specific signal transduction pathways.},
	language = {en},
	number = {4},
	urldate = {2022-05-04},
	journal = {Current Opinion in Cell Biology},
	author = {Kurzchalia, Teymuras V and Partan, Robert G},
	month = aug,
	year = {1999},
	pages = {424--431},
}

@article{fink_faqs_2009,
	title = {The {FAQs} on {Data} {Transformation}},
	volume = {76},
	issn = {0363-7751},
	url = {https://www.tandfonline.com/doi/full/10.1080/03637750903310352},
	doi = {10.1080/03637750903310352},
	number = {4},
	urldate = {2022-05-04},
	journal = {Communication Monographs},
	author = {Fink, Edward L.},
	month = dec,
	year = {2009},
	pages = {379--397},
}

@misc{noauthor_role_nodate,
	title = {A role for endoplasmic reticulum dynamics in the cellular distribution of microtubules},
	url = {https://www.pnas.org/doi/10.1073/pnas.2104309119},
	language = {en},
	urldate = {2022-04-26},
	doi = {10.1073/pnas.2104309119},
}

@article{yousefirizi_ai-based_2022,
	title = {{AI}-{Based} {Detection}, {Classification} and {Prediction}/{Prognosis} in {Medical} {Imaging}: {Towards} {Radiophenomics}},
	shorttitle = {{AI}-{Based} {Detection}, {Classification} and {Prediction}/{Prognosis} in {Medical} {Imaging}},
	url = {http://arxiv.org/abs/2110.10332},
	abstract = {Artificial intelligence (AI) techniques have significant potential to enable effective, robust and automated image phenotyping including identification of subtle patterns. AI-based detection searches the image space to find the regions of interest based on patterns and features. There is a spectrum of tumor histologies from benign to malignant that can be identified by AI-based classification approaches using image features. The extraction of minable information from images gives way to the field of radiomics and can be explored via explicit (handcrafted/engineered) and deep radiomics frameworks. Radiomics analysis has the potential to be utilized as a noninvasive technique for the accurate characterization of tumors to improve diagnosis and treatment monitoring. This work reviews AI-based techniques, with a special focus on oncological PET and PET/CT imaging, for different detection, classification, and prediction/prognosis tasks. We also discuss needed efforts to enable the translation of AI techniques to routine clinical workflows, and potential improvements and complementary techniques such as the use of natural language processing on electronic health records and neuro-symbolic AI techniques.},
	urldate = {2022-04-13},
	journal = {arXiv:2110.10332 [physics]},
	author = {Yousefirizi, Fereshteh and Decazes, Pierre and Amyar, Amine and Ruan, Su and Saboury, Babak and Rahmim, Arman},
	month = jan,
	year = {2022},
	note = {arXiv: 2110.10332},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Physics - Medical Physics},
}

@article{mondal_xvitcos_2022,
	title = {{xViTCOS}: {Explainable} {Vision} {Transformer} {Based} {COVID}-19 {Screening} {Using} {Radiography}},
	volume = {10},
	issn = {2168-2372},
	shorttitle = {{xViTCOS}},
	doi = {10.1109/JTEHM.2021.3134096},
	abstract = {Objective: Since its outbreak, the rapid spread of COrona VIrus Disease 2019 (COVID-19) across the globe has pushed the health care system in many countries to the verge of collapse. Therefore, it is imperative to correctly identify COVID-19 positive patients and isolate them as soon as possible to contain the spread of the disease and reduce the ongoing burden on the healthcare system. The primary COVID-19 screening test, RT-PCR although accurate and reliable, has a long turn-around time. In the recent past, several researchers have demonstrated the use of Deep Learning (DL) methods on chest radiography (such as X-ray and CT) for COVID-19 detection. However, existing CNN based DL methods fail to capture the global context due to their inherent image-specific inductive bias. Methods: Motivated by this, in this work, we propose the use of vision transformers (instead of convolutional networks) for COVID-19 screening using the X-ray and CT images. We employ a multi-stage transfer learning technique to address the issue of data scarcity. Furthermore, we show that the features learned by our transformer networks are explainable. Results: We demonstrate that our method not only quantitatively outperforms the recent benchmarks but also focuses on meaningful regions in the images for detection (as confirmed by Radiologists), aiding not only in accurate diagnosis of COVID-19 but also in localization of the infected area. The code for our implementation can be found here - https://github.com/arnabkmondal/xViTCOS. Conclusion: The proposed method will help in timely identification of COVID-19 and efficient utilization of limited resources.},
	journal = {IEEE Journal of Translational Engineering in Health and Medicine},
	author = {Mondal, Arnab Kumar and Bhattacharjee, Arnab and Singla, Parag and Prathosh, A. P.},
	year = {2022},
	keywords = {AI for COVID-19 detection, COVID-19, CT scan and CXR, Computed tomography, Feature extraction, Predictive models, Radiography, Transformers, X-ray imaging, deep learning, vision transformer},
	pages = {1--10},
}

@misc{noauthor_biologically-aware_nodate,
	title = {Biologically-{Aware} {Skeleton} {Generation}},
	url = {https://www.rhoana.org/blockbased_synapseaware/},
	urldate = {2022-04-09},
}

@misc{noauthor_domain_nodate,
	title = {Domain {Adaptive} {Box}-supervised {Instance} {Segmentation} {Network} for {Mitosis} {Detection} – {Jeff} and {Penny} {Vinik} {Center} for {Translational} {Immunology} {Research}},
	url = {https://www.vinikimmunology.org/2022/04/07/domain-adaptive-box-supervised-instance-segmentation-network-for-mitosis-detection/},
	language = {en-US},
	urldate = {2022-04-09},
}

@article{serdar_sample_2021,
	title = {Sample size, power and effect size revisited: simplified and practical approaches in pre-clinical, clinical and laboratory studies},
	volume = {31},
	issn = {1330-0962},
	shorttitle = {Sample size, power and effect size revisited},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7745163/},
	doi = {10.11613/BM.2021.010502},
	abstract = {Calculating the sample size in scientific studies is one of the critical issues as regards the scientific contribution of the study. The sample size critically affects the hypothesis and the study design, and there is no straightforward way of calculating the effective sample size for reaching an accurate conclusion. Use of a statistically incorrect sample size may lead to inadequate results in both clinical and laboratory studies as well as resulting in time loss, cost, and ethical problems. This review holds two main aims. The first aim is to explain the importance of sample size and its relationship to effect size (ES) and statistical significance. The second aim is to assist researchers planning to perform sample size estimations by suggesting and elucidating available alternative software, guidelines and references that will serve different scientific purposes.},
	number = {1},
	urldate = {2022-04-07},
	journal = {Biochemia Medica},
	author = {Serdar, Ceyhan Ceran and Cihan, Murat and Yücel, Doğan and Serdar, Muhittin A},
	month = feb,
	year = {2021},
	pmid = {33380887},
	pmcid = {PMC7745163},
	pages = {010502},
}

@article{henry_enforced_2022,
	title = {Enforced tethering elongates the cortical endoplasmic reticulum and limits store-operated {Ca2}+ entry},
	volume = {135},
	issn = {0021-9533},
	url = {https://doi.org/10.1242/jcs.259313},
	doi = {10.1242/jcs.259313},
	abstract = {Recruitment of STIM proteins to cortical endoplasmic reticulum (cER) domains forming membrane contact sites (MCSs) mediate the store-operated Ca2+ entry (SOCE) pathway essential for human immunity. The cER is dynamically regulated by STIM and tethering proteins during SOCE, but the ultrastructural rearrangement and functional consequences of cER remodeling are unknown. Here, we express natural (E-Syt1 and E-Syt2) and artificial (MAPPER-S and MAPPER-L) protein tethers in HEK-293T cells and correlate the changes in cER length and gap distance, as measured by electron microscopy, with ionic fluxes. We found that native cER cisternae extended during store depletion and remained elongated at a constant ER-plasma membrane (PM) gap distance during subsequent Ca2+ elevations. Tethering proteins enhanced store-dependent cER expansion, anchoring the enlarged cER at tether-specific gap distances of 12-15 nm (E-Syts) and 5-9 nm (MAPPERs). Cells with artificially extended cER had reduced SOCE and reduced agonist-induced Ca2+ release. SOCE remained modulated by calmodulin and exhibited enhanced Ca2+-dependent inhibition. We propose that cER expansion mediated by ER-PM tethering at a close distance negatively regulates SOCE by confining STIM-ORAI complexes to the periphery of enlarged cER sheets, a process that might participate in the termination of store-operated Ca2+ entry.},
	number = {6},
	urldate = {2022-04-04},
	journal = {Journal of Cell Science},
	author = {Henry, Christopher and Carreras-Sureda, Amado and Demaurex, Nicolas},
	month = mar,
	year = {2022},
	pages = {jcs259313},
}

@article{tanaka_mitochondrial_2020,
	title = {Mitochondrial dynamics in exercise physiology},
	volume = {472},
	doi = {10.1007/s00424-019-02258-3},
	abstract = {A growing body of evidence suggests that exercise shows pleiotropic effects on the maintenance of systemic homeostasis through mitochondria. Dysregulation of mitochondrial dynamism is associated with metabolic inflexibility, resulting in many of the metabolic diseases and aging. Studies have suggested that exercise prevents and delays the progression of mitochondrial dysfunction by improving mitochondrial metabolism, biogenesis, and quality control. Exercise modulates functions of mitochondrial dynamics-regulating proteins through post-translational modification mechanisms. In this review, we discuss the putative mechanisms underlying maintenance of mitochondrial homeostasis by exercise, especially focusing on the post-translational modifications of several signaling proteins contributing to mitochondrial biogenesis, autophagy or mitophagy flux, and fission/fusion cycle. We also introduce novel small molecules that can potentially mimic exercise therapy through preserving mitochondrial dynamism. These recent advancements in the field of mitochondrial biology may lead to a greater understanding of exercise signaling.},
	journal = {Pflügers Archiv - European Journal of Physiology},
	author = {Tanaka, Tomohiro and Nishimura, Akiyuki and Nishiyama, Kazuhiro and Goto, Takumi and Numaga-Tomita, Takuro and Nishida, Motohiro},
	month = feb,
	year = {2020},
}

@misc{noauthor_critical_nodate,
	title = {A {Critical} {Look} at the {Consistency} of {Causal} {Estimation} with {Deep} {Latent} {Variable} {Models} at {DuckDuckGo}},
	url = {https://duckduckgo.com/?t=ffab&q=A+Critical+Look+at+the+Consistency+of+Causal+Estimation+with+Deep+Latent+Variable+Models&ia=web},
	urldate = {2022-04-02},
}

@misc{noauthor_bayesimp_nodate,
	title = {{BayesIMP}: {Uncertainty} {Quantification} for {Causal} {Data} {Fusion} at {DuckDuckGo}},
	url = {https://duckduckgo.com/?t=ffab&q=BayesIMP%3A+Uncertainty+Quantification+for+Causal+Data+Fusion&ia=web},
	urldate = {2022-04-02},
}

@article{maier_known_2022,
	title = {Known operator learning and hybrid machine learning in medical imaging — {A} review of the {Past}, the {Present}, and the {Future}},
	volume = {4},
	doi = {10.1088/2516-1091/ac5b13},
	abstract = {In this article, we perform a review of the state-of-the-art of hybrid machine learning in medical imaging. We start with a short summary of the general developments of the past in machine learning and how general and specialized approaches have been in competition in the past decades. A particular focus will be the theoretical and experimental evidence pro and contra hybrid modelling. Next, we inspect several new developments regarding hybrid machine learning with a particular focus on so-called known operator learning and how hybrid approaches gain more and more momentum across essentially all applications in medical imaging and medical image analysis. As we will point out by numerous examples, hybrid models are taking over in image reconstruction and analysis. Even domains such as physical simulation and scanner and acquisition design are being addressed using machine learning grey box modelling approaches. Towards the end of the article, we will investigate a few future directions and point out relevant areas in which hybrid modelling, meta learning, and other domains will likely be able to drive the state-of-the-art ahead.},
	journal = {Progress in Biomedical Engineering},
	author = {Maier, Andreas and Köstler, Harald and Heisig, Marco and Krauss, Patrick and Yang, Seung},
	month = mar,
	year = {2022},
}

@article{rahmim_tensor_2022,
	title = {Tensor {Radiomics}: {Paradigm} for {Systematic} {Incorporation} of {Multi}-{Flavoured} {Radiomics} {Features}},
	shorttitle = {Tensor {Radiomics}},
	url = {http://arxiv.org/abs/2203.06314},
	abstract = {Radiomics features extract quantitative information from medical images, towards the derivation of biomarkers for clinical tasks, such as diagnosis, prognosis, or treatment response assessment. Different image discretization parameters (e.g. bin number or size), convolutional filters, segmentation perturbation, or multi-modality fusion levels can be used to generate radiomics features and ultimately signatures. Commonly, only one set of parameters is used; resulting in only one value or flavour for a given RF. We propose tensor radiomics (TR) where tensors of features calculated with multiple combinations of parameters (i.e. flavours) are utilized to optimize the construction of radiomics signatures. We present examples of TR as applied to PET/CT, MRI, and CT imaging invoking machine learning or deep learning solutions, and reproducibility analyses: (1) TR via varying bin sizes on CT images of lung cancer and PET-CT images of head \& neck cancer (HNC) for overall survival prediction. A hybrid deep neural network, referred to as TR-Net, along with two ML-based flavour fusion methods showed improved accuracy compared to regular rediomics features. (2) TR built from different segmentation perturbations and different bin sizes for classification of late-stage lung cancer response to first-line immunotherapy using CT images. TR improved predicted patient responses. (3) TR via multi-flavour generated radiomics features in MR imaging showed improved reproducibility when compared to many single-flavour features. (4) TR via multiple PET/CT fusions in HNC. Flavours were built from different fusions using methods, such as Laplacian pyramids and wavelet transforms. TR improved overall survival prediction. Our results suggest that the proposed TR paradigm has the potential to improve performance capabilities in different medical imaging tasks.},
	urldate = {2022-03-30},
	journal = {arXiv:2203.06314 [physics]},
	author = {Rahmim, Arman and Toosi, Amirhosein and Salmanpour, Mohammad R. and Dubljevic, Natalia and Janzen, Ian and Shiri, Isaac and Ramezani, Mohamad A. and Yuan, Ren and Ho, Cheryl and Zaidi, Habib and MacAulay, Calum and Uribe, Carlos and Yousefirizi, Fereshteh},
	month = mar,
	year = {2022},
	note = {arXiv: 2203.06314},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Physics - Medical Physics},
}

@article{passini_human_2017,
	title = {Human {In} {Silico} {Drug} {Trials} {Demonstrate} {Higher} {Accuracy} than {Animal} {Models} in {Predicting} {Clinical} {Pro}-{Arrhythmic} {Cardiotoxicity}},
	volume = {8},
	issn = {1664-042X},
	doi = {10.3389/fphys.2017.00668},
	abstract = {Early prediction of cardiotoxicity is critical for drug development. Current animal models raise ethical and translational questions, and have limited accuracy in clinical risk prediction. Human-based computer models constitute a fast, cheap and potentially effective alternative to experimental assays, also facilitating translation to human. Key challenges include consideration of inter-cellular variability in drug responses and integration of computational and experimental methods in safety pharmacology. Our aim is to evaluate the ability of in silico drug trials in populations of human action potential (AP) models to predict clinical risk of drug-induced arrhythmias based on ion channel information, and to compare simulation results against experimental assays commonly used for drug testing. A control population of 1,213 human ventricular AP models in agreement with experimental recordings was constructed. In silico drug trials were performed for 62 reference compounds at multiple concentrations, using pore-block drug models (IC50/Hill coefficient). Drug-induced changes in AP biomarkers were quantified, together with occurrence of repolarization/depolarization abnormalities. Simulation results were used to predict clinical risk based on reports of Torsade de Pointes arrhythmias, and further evaluated in a subset of compounds through comparison with electrocardiograms from rabbit wedge preparations and Ca2+-transient recordings in human induced pluripotent stem cell-derived cardiomyocytes (hiPS-CMs). Drug-induced changes in silico vary in magnitude depending on the specific ionic profile of each model in the population, thus allowing to identify cell sub-populations at higher risk of developing abnormal AP phenotypes. Models with low repolarization reserve (increased Ca2+/late Na+ currents and Na+/Ca2+-exchanger, reduced Na+/K+-pump) are highly vulnerable to drug-induced repolarization abnormalities, while those with reduced inward current density (fast/late Na+ and Ca2+ currents) exhibit high susceptibility to depolarization abnormalities. Repolarization abnormalities in silico predict clinical risk for all compounds with 89\% accuracy. Drug-induced changes in biomarkers are in overall agreement across different assays: in silico AP duration changes reflect the ones observed in rabbit QT interval and hiPS-CMs Ca2+-transient, and simulated upstroke velocity captures variations in rabbit QRS complex. Our results demonstrate that human in silico drug trials constitute a powerful methodology for prediction of clinical pro-arrhythmic cardiotoxicity, ready for integration in the existing drug safety assessment pipelines.},
	language = {eng},
	journal = {Frontiers in Physiology},
	author = {Passini, Elisa and Britton, Oliver J. and Lu, Hua Rong and Rohrbacher, Jutta and Hermans, An N. and Gallacher, David J. and Greig, Robert J. H. and Bueno-Orovio, Alfonso and Rodriguez, Blanca},
	year = {2017},
	pmid = {28955244},
	pmcid = {PMC5601077},
	keywords = {Torsade de Pointes, computer models, drug cardiotoxicity, drug safety, human ventricular action potential, in silico drug trials},
	pages = {668},
}

@article{pappalardo_silico_2019,
	title = {In silico clinical trials: concepts and early adoptions},
	volume = {20},
	issn = {1477-4054},
	shorttitle = {In silico clinical trials},
	url = {https://doi.org/10.1093/bib/bby043},
	doi = {10.1093/bib/bby043},
	abstract = {Innovations in information and communication technology infuse all branches of science, including life sciences. Nevertheless, healthcare is historically slow in adopting technological innovation, compared with other industrial sectors. In recent years, new approaches in modelling and simulation have started to provide important insights in biomedicine, opening the way for their potential use in the reduction, refinement and partial substitution of both animal and human experimentation. In light of this evidence, the European Parliament and the United States Congress made similar recommendations to their respective regulators to allow wider use of modelling and simulation within the regulatory process. In the context of in silico medicine, the term ‘in silico clinical trials’ refers to the development of patient-specific models to form virtual cohorts for testing the safety and/or efficacy of new drugs and of new medical devices. Moreover, it could be envisaged that a virtual set of patients could complement a clinical trial (reducing the number of enrolled patients and improving statistical significance), and/or advise clinical decisions. This article will review the current state of in silico clinical trials and outline directions for a full-scale adoption of patient-specific modelling and simulation in the regulatory evaluation of biomedical products. In particular, we will focus on the development of vaccine therapies, which represents, in our opinion, an ideal target for this innovative approach.},
	number = {5},
	urldate = {2022-03-22},
	journal = {Briefings in Bioinformatics},
	author = {Pappalardo, Francesco and Russo, Giulia and Tshinanu, Flora Musuamba and Viceconti, Marco},
	month = sep,
	year = {2019},
	pages = {1699--1708},
}

@article{wedlund_simulated_2021,
	title = {Simulated trials: in silico approach adds depth and nuance to the {RCT} gold-standard},
	volume = {4},
	issn = {2398-6352},
	shorttitle = {Simulated trials},
	doi = {10.1038/s41746-021-00492-7},
	language = {eng},
	number = {1},
	journal = {NPJ digital medicine},
	author = {Wedlund, Leia and Kvedar, Joseph},
	month = aug,
	year = {2021},
	pmid = {34381148},
	pmcid = {PMC8357951},
	pages = {121},
}

@techreport{velicky_saturated_2022,
	title = {Saturated reconstruction of living brain tissue},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.03.16.484431v1},
	abstract = {Complex wiring between neurons underlies the information-processing network enabling all brain functions, including cognition and memory. For understanding how the network is structured, processes information, and changes over time, comprehensive visualization of the architecture of living brain tissue with its cellular and molecular components would open up major opportunities. However, electron microscopy (EM) provides nanometre-scale resolution required for full in-silico reconstruction1–6, yet is limited to fixed specimens and static representations. Light microscopy allows live observation, with super-resolution approaches7–15 facilitating nanoscale visualization, but comprehensive 3D-reconstruction of living brain tissue has been hindered by tissue photo-burden, photobleaching, insufficient 3D-resolution, and inadequate signal-to-noise ratio (SNR). Here we demonstrate saturated reconstruction of living brain tissue. We developed an integrated imaging and analysis technology, adapting stimulated emission depletion (STED) microscopy7,16 in extracellularly labelled tissue17 for high SNR and isotropic resolution. Centrally, a two-stage deep-learning approach leveraged previously obtained information on sample structure to drastically reduce photo-burden and enable automated volumetric reconstruction down to synapse level. Live reconstruction provides unbiased analysis of tissue architecture across time in relation to functional activity and targeted activation, and contextual understanding of molecular labelling. This adoptable technology will facilitate novel insights into the dynamic functional architecture of living brain tissue.},
	language = {en},
	urldate = {2022-03-22},
	institution = {bioRxiv},
	author = {Velicky, Philipp and Miguel, Eder and Michalska, Julia M. and Wei, Donglai and Lin, Zudi and Watson, Jake F. and Troidl, Jakob and Beyer, Johanna and Ben-Simon, Yoav and Sommer, Christoph and Jahr, Wiebke and Cenameri, Alban and Broichhagen, Johannes and Grant, Seth G. N. and Jonas, Peter and Novarino, Gaia and Pfister, Hanspeter and Bickel, Bernd and Danzl, Johann G.},
	month = mar,
	year = {2022},
	note = {Type: article},
	pages = {2022.03.16.484431},
}

@article{wang_stickyland_2022,
	title = {{StickyLand}: {Breaking} the {Linear} {Presentation} of {Computational} {Notebooks}},
	shorttitle = {{StickyLand}},
	url = {http://arxiv.org/abs/2202.11086},
	doi = {10.1145/3491101.3519653},
	abstract = {How can we better organize code in computational notebooks? Notebooks have become a popular tool among data scientists, as they seamlessly weave text and code together, supporting users to rapidly iterate and document code experiments. However, it is often challenging to organize code in notebooks, partially because there is a mismatch between the linear presentation of code and the non-linear process of exploratory data analysis. We present StickyLand, a notebook extension for empowering users to freely organize their code in non-linear ways. With sticky cells that are always shown on the screen, users can quickly access their notes, instantly observe experiment results, and easily build interactive dashboards that support complex visual analytics. Case studies highlight how our tool can enhance notebook users's productivity and identify opportunities for future notebook designs. StickyLand is available at https://github.com/xiaohk/stickyland.},
	urldate = {2022-03-18},
	journal = {arXiv:2202.11086 [cs]},
	author = {Wang, Zijie J. and Dai, Katie and Edwards, W. Keith},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.11086},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
}

@incollection{korns_feature_2022,
	title = {Feature {Discovery} with {Deep} {Learning} {Algebra} {Networks}},
	isbn = {9789811681127},
	author = {Korns, Michael},
	month = jan,
	year = {2022},
	doi = {10.1007/978-981-16-8113-4_6},
	pages = {109--127},
}

@article{cai_wedge_2019,
	title = {Wedge prism approach for simultaneous multichannel microscopy},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-019-53581-9},
	doi = {10.1038/s41598-019-53581-9},
	abstract = {Multichannel (multicolor) imaging has become a powerful technique in biology research for performing in vivo neuronal calcium imaging, colocalization of fluorescent labels, non-invasive pH measurement, and other procedures. We describe a novel add-on approach for simultaneous multichannel optical microscopy based on simple wedge prisms. Our device requires no alignment and is simple, robust, user-friendly, and less expensive than current commercial instruments based on switchable filters or dual-view strategies. Point spread function measurements and simulations in Zemax indicate a reduction in resolution in the direction orthogonal to the wedge interface and in the axial direction, without introducing aberration. These effects depend on the objective utilized and are most significant near the periphery of the field of view. We tested a two-channel device on C. elegans neurons in vivo and demonstrated comparable signals to a conventional dual-view instrument. We also tested a four-channel device on fixed chick embryo Brainbow samples and identified individual neurons by their spectra without extensive image postprocessing. Therefore, we believe that this technology has the potential for broad use in microscopy.},
	language = {en},
	number = {1},
	urldate = {2022-03-15},
	journal = {Scientific Reports},
	author = {Cai, Hanna and Wang, Yao L. and Wainner, Richard T. and Iftimia, Nicusor V. and Gabel, Christopher V. and Chung, Samuel H.},
	month = nov,
	year = {2019},
	keywords = {Ca2+ imaging, Fluorescence imaging, Optical imaging, Wide-field fluorescence microscopy},
	pages = {17795},
}

@book{sanchez_diffusion_2022,
	title = {Diffusion {Causal} {Models} for {Counterfactual} {Estimation}},
	abstract = {We consider the task of counterfactual estimation from observational imaging data given a known causal structure. In particular, quantifying the causal effect of interventions for high-dimensional data with neural networks remains an open challenge. Herein we propose Diff-SCM, a deep structural causal model that builds on recent advances of generative energy-based models. In our setting, inference is performed by iteratively sampling gradients of the marginal and conditional distributions entailed by the causal model. Counterfactual estimation is achieved by firstly inferring latent variables with deterministic forward diffusion, then intervening on a reverse diffusion process using the gradients of an anti-causal predictor w.r.t the input. Furthermore, we propose a metric for evaluating the generated counterfactuals. We find that Diff-SCM produces more realistic and minimal counterfactuals than baselines on MNIST data and can also be applied to ImageNet data. Code is available https://github.com/vios-s/Diff-SCM.},
	author = {Sanchez, Pedro and Tsaftaris, Sotirios},
	month = feb,
	year = {2022},
}

@techreport{chen_allen_2020,
	title = {The {Allen} {Cell} and {Structure} {Segmenter}: a new open source toolkit for segmenting {3D} intracellular structures in fluorescence microscopy images},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	shorttitle = {The {Allen} {Cell} and {Structure} {Segmenter}},
	url = {https://www.biorxiv.org/content/10.1101/491035v2},
	abstract = {A continuing challenge in quantitative cell biology is the accurate and robust 3D segmentation of structures of interest from fluorescence microscopy images in an automated, reproducible, and widely accessible manner for subsequent interpretable data analysis. We describe the Allen Cell and Structure Segmenter (Segmenter), a Python-based open source toolkit developed for 3D segmentation of cells and intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high-replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes. The Segmenter consists of two complementary elements, a classic image segmentation workflow with a restricted set of algorithms and parameters and an iterative deep learning segmentation workflow. We created a collection of 20 classic image segmentation workflows based on 20 distinct and representative intracellular structure localization patterns as a “lookup table” reference and starting point for users. The iterative deep learning workflow can take over when the classic segmentation workflow is insufficient. Two straightforward “human-in-the-loop” curation strategies convert a set of classic image segmentation workflow results into a set of 3D ground truth images for iterative model training without the need for manual painting in 3D. The deep learning model architectures used in this toolkit were designed and tested specifically for 3D fluorescence microscope images and implemented as readable scripts. The Segmenter thus leverages state of the art computer vision algorithms in an accessible way to facilitate their application by the experimental biology researcher.
We include two useful applications to demonstrate how we used the classic image segmentation and iterative deep learning workflows to solve more challenging 3D segmentation tasks. First, we introduce the ‘Training Assay’ approach, a new experimental-computational co-design concept to generate more biologically accurate segmentation ground truths. We combined the iterative deep learning workflow with three Training Assays to develop a robust, scalable cell and nuclear instance segmentation algorithm, which could achieve accurate target segmentation for over 98\% of individual cells and over 80\% of entire fields of view. Second, we demonstrate how to extend the lamin B1 segmentation model built from the iterative deep learning workflow to obtain more biologically accurate lamin B1 segmentation by utilizing multi-channel inputs and combining multiple ML models. The steps and workflows used to develop these algorithms are generalizable to other similar segmentation challenges. More information, including tutorials and code repositories, are available at allencell.org/segmenter.},
	language = {en},
	urldate = {2022-03-09},
	institution = {bioRxiv},
	author = {Chen, Jianxu and Ding, Liya and Viana, Matheus P. and Lee, HyeonWoo and Sluezwski, M. Filip and Morris, Benjamin and Hendershott, Melissa C. and Yang, Ruian and Mueller, Irina A. and Rafelski, Susanne M.},
	month = dec,
	year = {2020},
	note = {Type: article},
	pages = {491035},
}

@article{williams_kinesio_2012,
	title = {Kinesio {Taping} in {Treatment} and {Prevention} of {Sports} {Injuries}},
	volume = {42},
	issn = {1179-2035},
	url = {https://doi.org/10.2165/11594960-000000000-00000},
	doi = {10.2165/11594960-000000000-00000},
	abstract = {Kinesio tape (KT) is an elastic therapeutic tape used for treating sports injuries and a variety of other disorders. Chiropractor, Dr Kenso Kase, developed KT taping techniques in the 1970s. It is claimed that KT supports injuredmuscles and joints and helps relieve pain by lifting the skin and allowing improved blood and lymph flow. The profile of KT rose after the tape was donated to 58 countries for use during the 2008 Olympic Games, and was seen on high-profile athletes. Practitioners are asking whether they should use KT over other elastic adhesive tapes. The aim of this review was to evaluate, using meta-analysis, the effectiveness ofKT in the treatment and prevention of sports injuries. Electronic databases including SPORTDiscus®, Scopus,MEDLINE, ScienceDirect and sports medicine websites were searched using keywords ‘kinesio taping/tape’. From 97 articles, ten met the inclusion criteria (article reported data for effect of KT on a musculoskeletal outcome and had a control group) and were retained for meta-analyses.Magnitude-based inferences were used to assess clinical worth of positive outcomes reported in studies. Only two studies investigated sports-related injuries (shoulder impingement), and just one of these involved injured athletes. Studies attending to musculoskeletal outcomes in healthy participants were included on the basis that these outcomes may have implications for the prevention of sporting injuries. The efficacy of KT in pain relief was trivial given there were no clinically important results. There were inconsistent range-of-motion outcome results, with at least small beneficial results seen in two studies, but trivial results in two other studies across numerous joint measurements. There was a likely beneficial effect for proprioception regarding grip force sense error, but no positive outcome for ankle proprioception. Seven outcomes relating to strength were beneficial, although there were numerous trivial findings for quadriceps and hamstrings peak torque, and grip strength measures. KT had some substantial effects on muscle activity, but it was unclear whether these changes were beneficial or harmful. In conclusion, there was little quality evidence to support the use ofKT over other types of elastic taping in themanagement or prevention of sports injuries. KT may have a small beneficial role in improving strength, range of motion in certain injured cohorts and force sense error compared with other tapes, but further studies are needed to confirm these findings. The amount of case study and anecdotal support for KT warrants well designed experimental research, particularly pertaining to sporting injuries, so that practitioners can be confident that KT is beneficial for their athletes.},
	language = {en},
	number = {2},
	urldate = {2022-02-28},
	journal = {Sports Medicine},
	author = {Williams, Sean and Whatman, Chris and Hume, Patria A. and Sheerin, Kelly},
	month = feb,
	year = {2012},
	pages = {153--164},
}

@article{bickel_regularization_2006,
	title = {Regularization in statistics},
	volume = {15},
	issn = {1863-8260},
	url = {https://doi.org/10.1007/BF02607055},
	doi = {10.1007/BF02607055},
	abstract = {This paper is a selective review of the regularization methods scattered in statistics literature. We introduce a general conceptual approach to regularization and fit most existing methods into it. We have tried to focus on the importance of regularization when dealing with today's high-dimensional objects: data and models. A wide range of examples are discussed, including nonparametric regression, boosting, covariance matrix estimation, principal component estimation, subsampling.},
	language = {en},
	number = {2},
	urldate = {2022-02-28},
	journal = {Test},
	author = {Bickel, Peter J. and Li, Bo and Tsybakov, Alexandre B. and van de Geer, Sara A. and Yu, Bin and Valdés, Teófilo and Rivero, Carlos and Fan, Jianqing and van der Vaart, Aad},
	month = sep,
	year = {2006},
	pages = {271--344},
}

@book{saad_survey_2022,
	title = {A {Survey} on {Training} {Challenges} in {Generative} {Adversarial} {Networks} for {Biomedical} {Image} {Analysis}},
	abstract = {In biomedical image analysis, the applicability of deep learning methods is directly impacted by the quantity of image data available. This is due to deep learning models requiring large image datasets to provide high-level performance. Generative Adversarial Networks (GANs) have been widely utilized to address data limitations through the generation of synthetic biomedical images. GANs consist of two models. The generator, a model that learns how to produce synthetic images based on the feedback it receives. The discriminator, a model that classifies an image as synthetic or real and provides feedback to the generator. Throughout the training process, a GAN can experience several technical challenges that impede the generation of suitable synthetic imagery. First, the mode collapse problem whereby the generator either produces an identical image or produces a uniform image from distinct input features. Second, the non-convergence problem whereby the gradient descent optimizer fails to reach a Nash equilibrium. Thirdly, the vanishing gradient problem whereby unstable training behavior occurs due to the discriminator achieving optimal classification performance resulting in no meaningful feedback being provided to the generator. These problems result in the production of synthetic imagery that is blurry, unrealistic, and less diverse. To date, there has been no survey article outlining the impact of these technical challenges in the context of the biomedical imagery domain. This work presents a review and taxonomy based on solutions to the training problems of GANs in the biomedical imaging domain. This survey highlights important challenges and outlines future research directions about the training of GANs in the domain of biomedical imagery.},
	author = {Saad, Muhammad Muneeb and O'Reilly, Ruairi and Rehmani, Mubashir},
	month = jan,
	year = {2022},
}

@article{kesner_original_2019,
	title = {Original {GIF} {Animations} to {Support} the {Teaching} of {Medical} {Image} {Reconstruction}},
	volume = {7},
	abstract = {Understanding the principles of 3D imaging and how measured data can be reconstructed into images is fundamental to the modern field of medical imaging. Visual representations of multi-step technological or mathematical concepts can aid their understanding, provide a resource for students in their education, and increase interest in the field. To help explain the basic principles of three-dimensional medical imaging, we developed a series of multi-frame gif animations and text that describe the foundational concepts of tomographic imaging, used in computed tomography (CT), positron emission tomography (PET), and single photon emission computed tomography (SPECT). The animation based-learning package is available online – viewable in a web browser, or as slides contained in a downloadable PowerPoint lecture. The material covers the principles of sinograms/image data storage, forward projection, PET/CT/SPECT acquisitions, and filtered backprojection. Moreover, the package is free and readily downloadable by anyone interested, such as teachers/students, clinicians, and engaged patients.},
	author = {Kesner, Adam and Häggström, Ida},
	month = jun,
	year = {2019},
	pages = {9--10},
}

@article{silva_exercise_2021,
	title = {Exercise as a {Peripheral} {Circadian} {Clock} {Resynchronizer} in {Vascular} and {Skeletal} {Muscle} {Aging}},
	volume = {18},
	doi = {10.3390/ijerph182412949},
	abstract = {Aging is characterized by several progressive physiological changes, including changes in
the circadian rhythm. Circadian rhythms influence behavior, physiology, and metabolic processes in order to maintain homeostasis; they also influence the function of endothelial cells, smooth muscle cells, and immune cells in the vessel wall. A clock misalignment could favor vascular damage and indirectly also affect skeletal muscle function. In this review, we focus on the dysregulation of circadian rhythm due to aging and its relationship with skeletal muscle changes and vascular health as possible risk factors for the development of sarcopenia, as well as the role of physical exercise as a potential modulator of these processes.},
	journal = {International Journal of Environmental Research and Public Health},
	author = {Silva, Bruna and Uzeloto, Juliana and Lira, Fabio and Pereira, Telmo and Coelho-E-Silva, Manuel and Caseiro, Armando},
	month = dec,
	year = {2021},
	pages = {12949},
}

@article{mcclean_circadian_2022,
	title = {Circadian {Clocks}, {Redox} {Homeostasis}, and {Exercise}: {Time} to {Connect} the {Dots}?},
	volume = {11},
	shorttitle = {Circadian {Clocks}, {Redox} {Homeostasis}, and {Exercise}},
	doi = {10.3390/antiox11020256},
	abstract = {Compelling research has documented how the circadian system is essential for the maintenance of several key biological processes including homeostasis, cardiovascular control, and glucose metabolism. Circadian clock disruptions, or losses of rhythmicity, have been implicated in the development of several diseases, premature ageing, and are regarded as health risks. Redox reactions involving reactive oxygen and nitrogen species (RONS) regulate several physiological functions such as cell signalling and the immune response. However, oxidative stress is associated with the pathological effects of RONS, resulting in a loss of cell signalling and damaging modifications to important molecules such as DNA. Direct connections have been established between circadian rhythms and oxidative stress on the basis that disruptions to circadian rhythms can affect redox biology, and vice versa, in a bi-directional relationship. For instance, the expression and activity of several key antioxidant enzymes (SOD, GPx, and CAT) appear to follow circadian patterns. Consequently, the ability to unravel these interactions has opened an exciting area of redox biology. Exercise exerts numerous benefits to health and, as a potent environmental cue, has the capacity to adjust disrupted circadian systems. In fact, the response to a given exercise stimulus may also exhibit circadian variation. At the same time, the relationship between exercise, RONS, and oxidative stress has also been scrutinised, whereby it is clear that exercise-induced RONS can elicit both helpful and potentially harmful health effects that are dependent on the type, intensity, and duration of exercise. To date, it appears that the emerging interface between circadian rhythmicity and oxidative stress/redox metabolism has not been explored in relation to exercise. This review aims to summarise the evidence supporting the conceptual link between the circadian clock, oxidative stress/redox homeostasis, and exercise stimuli. We believe carefully designed investigations of this nexus are required, which could be harnessed to tackle theories concerned with, for example, the existence of an optimal time to exercise to accrue physiological benefits.},
	journal = {Antioxidants},
	author = {McClean, Conor and Davison, Gareth},
	month = jan,
	year = {2022},
	pages = {256},
}

@article{mathiasen_backpropagating_2021,
	title = {Backpropagating through {Fr}{\textbackslash}'echet {Inception} {Distance}},
	url = {http://arxiv.org/abs/2009.14075},
	abstract = {The Fr{\textbackslash}'echet Inception Distance (FID) has been used to evaluate hundreds of generative models. We introduce FastFID, which can efficiently train generative models with FID as a loss function. Using FID as an additional loss for Generative Adversarial Networks improves their FID.},
	urldate = {2022-01-27},
	journal = {arXiv:2009.14075 [cs, stat]},
	author = {Mathiasen, Alexander and Hvilshøj, Frederik},
	month = apr,
	year = {2021},
	note = {arXiv: 2009.14075},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{sheth_adenosine_2014,
	title = {Adenosine {Receptors}: {Expression}, {Function} and {Regulation}},
	volume = {15},
	issn = {1422-0067},
	shorttitle = {Adenosine {Receptors}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3958836/},
	doi = {10.3390/ijms15022024},
	abstract = {Adenosine receptors (ARs) comprise a group of G protein-coupled receptors (GPCR) which mediate the physiological actions of adenosine. To date, four AR subtypes have been cloned and identified in different tissues. These receptors have distinct localization, signal transduction pathways and different means of regulation upon exposure to agonists. This review will describe the biochemical characteristics and signaling cascade associated with each receptor and provide insight into how these receptors are regulated in response to agonists. A key property of some of these receptors is their ability to serve as sensors of cellular oxidative stress, which is transmitted by transcription factors, such as nuclear factor (NF)-κB, to regulate the expression of ARs. Recent observations of oligomerization of these receptors into homo- and heterodimers will be discussed. In addition, the importance of these receptors in the regulation of normal and pathological processes such as sleep, the development of cancers and in protection against hearing loss will be examined.},
	number = {2},
	urldate = {2022-01-26},
	journal = {International Journal of Molecular Sciences},
	author = {Sheth, Sandeep and Brito, Rafael and Mukherjea, Debashree and Rybak, Leonard P. and Ramkumar, Vickram},
	month = jan,
	year = {2014},
	pmid = {24477263},
	pmcid = {PMC3958836},
	pages = {2024--2052},
}

@article{vargas-mendoza_oxidative_2021,
	title = {Oxidative {Stress}, {Mitochondrial} {Function} and {Adaptation} to {Exercise}: {New} {Perspectives} in {Nutrition}},
	volume = {11},
	shorttitle = {Oxidative {Stress}, {Mitochondrial} {Function} and {Adaptation} to {Exercise}},
	doi = {10.3390/life11111269},
	abstract = {Cells have the ability to adapt to stressful environments as a part of their evolution. Physical exercise induces an increase of a demand for energy that must be met by mitochondria as the main (ATP) provider. However, this process leads to the increase of free radicals and the so-called reactive oxygen species (ROS), which are necessary for the maintenance of cell signaling and homeostasis. In addition, mitochondrial biogenesis is influenced by exercise in continuous crosstalk between the mitochondria and the nuclear genome. Excessive workloads may induce severe mitochondrial stress, resulting in oxidative damage. In this regard, the objective of this work was to provide a general overview of the molecular mechanisms involved in mitochondrial adaptation during exercise and to understand if some nutrients such as antioxidants may be implicated in blunt adaptation and/or an impact on the performance of exercise by different means.},
	journal = {Life},
	author = {Vargas-Mendoza, Nancy and Angeles-Valencia, Marcelo and Morales-González, Ángel and Madrigal-Santillán, Eduardo and Morales-Martínez, Mauricio and Madrigal-Bujaidar, Eduardo and Álvarez-González, Isela and Gutiérrez-Salinas, José and Esquivel-Chirino, César and Chamorro, German and Cristobal-Luna, Jose and Morales-González, José},
	month = nov,
	year = {2021},
	pages = {1269},
}

@article{nielsen_elementary_2020,
	title = {An {Elementary} {Introduction} to {Information} {Geometry}},
	volume = {22},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1099-4300/22/10/1100},
	doi = {10.3390/e22101100},
	abstract = {In this survey, we describe the fundamental differential-geometric structures of information manifolds, state the fundamental theorem of information geometry, and illustrate some use cases of these information manifolds in information sciences. The exposition is self-contained by concisely introducing the necessary concepts of differential geometry. Proofs are omitted for brevity.},
	language = {en},
	number = {10},
	urldate = {2021-12-30},
	journal = {Entropy},
	author = {Nielsen, Frank},
	month = oct,
	year = {2020},
	keywords = {Bayesian hypothesis testing, Fisher–Rao distance, Hessian manifolds, affine connection, conjugate connections, curvature and flatness, differential geometry, dual metric-compatible parallel transport, dually flat manifolds, exponential family, gauge freedom, information manifold, metric compatibility, metric tensor, mixed parameterization, mixture clustering, mixture family, parameter divergence, separable divergence, statistical divergence, statistical invariance, statistical manifold, α-embeddings},
	pages = {1100},
}

@book{oltean_dacia_2007,
	address = {London},
	title = {Dacia: {Landscape}, {Colonization} and {Romanization}},
	isbn = {9780203945834},
	shorttitle = {Dacia},
	abstract = {Providing a detailed consideration of previous theories of native settlement patterns and the impact of Roman colonization, Dacia offers fresh insight into the province Dacia and the nature of Romanization. 
It analyzes Roman-native interaction from a landscape perspective focusing on the core territory of both the Iron Age and Roman Dacia. Oltean considers the nature and distribution of settlement in the pre-Roman and Roman periods, the human impact on the local landscapes and the changes which occurred as a result of Roman occupation.

Dealing with the way that the Roman conquest and organization of Dacia impacted on the native settlement pattern and society, this book will find itself widely used amongst students of ancient Rome.},
	publisher = {Routledge},
	author = {Oltean, Ioana A.},
	month = jul,
	year = {2007},
	doi = {10.4324/9780203945834},
}

@book{southern_domitian_2013,
	address = {London},
	title = {Domitian: {Tragic} {Tyrant}},
	isbn = {9781315812403},
	shorttitle = {Domitian},
	abstract = {This is the first ever study to assess Emperor Domitian from a psychological point of view and covers his entire career from the early years and the civil war AD through the imperial rule to the dark years and the psychology of suspicion. Pat Southern strips away hyperbole and sensationalism from the literary record, revealing an individual who caused undoubted suffering which must be accounted for.},
	publisher = {Routledge},
	author = {Southern, Pat},
	month = dec,
	year = {2013},
	doi = {10.4324/9781315812403},
}

@article{cui_techniques_2019,
	title = {Techniques for detecting protein-protein interactions in living cells: principles, limitations, and recent progress},
	volume = {62},
	issn = {1869-1889},
	shorttitle = {Techniques for detecting protein-protein interactions in living cells},
	url = {https://doi.org/10.1007/s11427-018-9500-7},
	doi = {10.1007/s11427-018-9500-7},
	abstract = {Detecting protein-protein interactions (PPIs) provides fundamental information for understanding biochemical processes such as the transduction of signals from one cellular location to another; however, traditional biochemical techniques cannot provide sufficient spatio-temporal information to elucidate these molecular interactions in living cells. Over the past decade, several new techniques have enabled the identification and characterization of PPIs. In this review, we summarize three main techniques for detecting PPIs in vivo, focusing on their basic principles and applications in biological studies. We place a special emphasis on their advantages and limitations, and, in particular, we introduced some uncommon new techniques, such as single-molecule FRET (smFRET), FRET-fluorescence lifetime imaging microscopy (FRET-FLIM), cytoskeleton-based assay for protein-protein interaction (CAPPI) and single-molecule protein proximity index (smPPI), highlighting recent improvements to the established techniques. We hope that this review will provide a valuable reference to enable researchers to select the most appropriate technique for detecting PPIs.},
	language = {en},
	number = {5},
	urldate = {2021-12-14},
	journal = {Science China Life Sciences},
	author = {Cui, Yaning and Zhang, Xi and Yu, Meng and Zhu, Yingfang and Xing, Jingjing and Lin, Jinxing},
	month = may,
	year = {2019},
	pages = {619--632},
}

@article{chenouard_objective_2014,
	title = {Objective comparison of particle tracking methods},
	volume = {11},
	copyright = {2013 The Author(s)},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.2808},
	doi = {10.1038/nmeth.2808},
	abstract = {The first community competition designed to objectively compare the performance of particle tracking algorithms provides valuable practical information for both users and developers.},
	language = {en},
	number = {3},
	urldate = {2021-12-14},
	journal = {Nature Methods},
	author = {Chenouard, Nicolas and Smal, Ihor and de Chaumont, Fabrice and Maška, Martin and Sbalzarini, Ivo F. and Gong, Yuanhao and Cardinale, Janick and Carthel, Craig and Coraluppi, Stefano and Winter, Mark and Cohen, Andrew R. and Godinez, William J. and Rohr, Karl and Kalaidzidis, Yannis and Liang, Liang and Duncan, James and Shen, Hongying and Xu, Yingke and Magnusson, Klas E. G. and Jaldén, Joakim and Blau, Helen M. and Paul-Gilloteaux, Perrine and Roudot, Philippe and Kervrann, Charles and Waharte, François and Tinevez, Jean-Yves and Shorte, Spencer L. and Willemse, Joost and Celler, Katherine and van Wezel, Gilles P. and Dan, Han-Wei and Tsai, Yuh-Show and de Solórzano, Carlos Ortiz and Olivo-Marin, Jean-Christophe and Meijering, Erik},
	month = mar,
	year = {2014},
	keywords = {Fluorescence imaging, Image processing, Microscopy},
	pages = {281--289},
}

@article{cheeseman_adaptive_2018,
	title = {Adaptive particle representation of fluorescence microscopy images},
	volume = {9},
	copyright = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-018-07390-9},
	doi = {10.1038/s41467-018-07390-9},
	abstract = {Modern microscopes create a data deluge with gigabytes of data generated each second, and terabytes per day. Storing and processing this data is a severe bottleneck, not fully alleviated by data compression. We argue that this is because images are processed as grids of pixels. To address this, we propose a content-adaptive representation of fluorescence microscopy images, the Adaptive Particle Representation (APR). The APR replaces pixels with particles positioned according to image content. The APR overcomes storage bottlenecks, as data compression does, but additionally overcomes memory and processing bottlenecks. Using noisy 3D images, we show that the APR adaptively represents the content of an image while maintaining image quality and that it enables orders of magnitude benefits across a range of image processing tasks. The APR provides a simple and efficient content-aware representation of fluosrescence microscopy images.},
	language = {en},
	number = {1},
	urldate = {2021-12-14},
	journal = {Nature Communications},
	author = {Cheeseman, Bevan L. and Günther, Ulrik and Gonciarz, Krzysztof and Susik, Mateusz and Sbalzarini, Ivo F.},
	month = dec,
	year = {2018},
	keywords = {Applied mathematics, Image processing},
	pages = {5160},
}

@article{okamoto_single-molecule_2018,
	title = {Single-molecule fluorescence-based analysis of protein conformation, interaction, and oligomerization in cellular systems},
	volume = {10},
	issn = {1867-2469},
	url = {https://doi.org/10.1007/s12551-017-0366-3},
	doi = {10.1007/s12551-017-0366-3},
	abstract = {Single-molecule imaging (SMI) of proteins in operation has a history of intensive investigations over 20 years and is now widely used in various fields of biology and biotechnology. We review the recent advances in SMI of fluorescently-tagged proteins in structural biology, focusing on technical applicability of SMI to the measurements in living cells. Basic technologies and recent applications of SMI in structural biology are introduced. Distinct from other methods in structural biology, SMI directly observes single molecules and single-molecule events one-by-one, thus, explicitly analyzing the distribution of protein structures and the history of protein dynamics. It also allows one to detect single events of protein interaction. One unique feature of SMI is that it is applicable in complicated and heterogeneous environments, including living cells. The numbers, location, movements, interaction, oligomerization, and conformation of single-protein molecules have been determined using SMI in cellular systems.},
	language = {en},
	number = {2},
	urldate = {2021-12-13},
	journal = {Biophysical Reviews},
	author = {Okamoto, Kenji and Hiroshima, Michio and Sako, Yasushi},
	month = apr,
	year = {2018},
	pages = {317--326},
}

@misc{noauthor_hidden_2021,
	title = {The {Hidden} {Mathematical} {Patterns} {Behind} {Seemingly} {Random} {Events}},
	url = {https://www.simonsfoundation.org/2021/11/29/the-hidden-mathematical-patterns-behind-seemingly-random-events/},
	abstract = {The Hidden Mathematical Patterns Behind Seemingly Random Events on Simons Foundation},
	language = {en-US},
	urldate = {2021-12-13},
	journal = {Simons Foundation},
	month = nov,
	year = {2021},
}

@article{noauthor_objective_2021,
	title = {Objective {Numerical} {Evaluation} of {Diffuse}, {Optically} {Reconstructed} {Images} {Using} {Structural} {Similarity} {Index}},
	volume = {11},
	doi = {10.3390/bios11120504},
	abstract = {Diffuse optical tomography is emerging as a non-invasive optical modality used to evaluate tissue information by obtaining the optical properties’ distribution. Two procedures are performed to produce reconstructed absorption and reduced scattering images, which provide structural information that can be used to locate inclusions within tissues with the assistance of a known light intensity around the boundary. These methods are referred to as a forward problem and an inverse solution. Once the reconstructed image is obtained, a subjective measurement is used as the conventional way to assess the image. Hence, in this study, we developed an algorithm designed to numerically assess reconstructed images to identify inclusions using the structural similarity (SSIM) index. We compared four SSIM algorithms with 168 simulated reconstructed images involving the same inclusion position with different contrast ratios and inclusion sizes. A multiscale, improved SSIM containing a sharpness parameter (MS-ISSIM-S) was proposed to represent the potential evaluation compared with the human visible perception. The results indicated that the proposed MS-ISSIM-S is suitable for human visual perception by demonstrating a reduction of similarity score related to various contrasts with a similar size of inclusion; thus, this metric is promising for the objective numerical assessment of diffuse, optically reconstructed images.},
	journal = {Biosensors},
	month = dec,
	year = {2021},
	pages = {504},
}

@article{guan_novel_2014,
	title = {A novel {RGB} {Fourier} transform-based color space for optical microscopic image processing},
	volume = {1},
	copyright = {2014 Guan et al.; licensee Springer.},
	issn = {2197-3768},
	url = {https://jrobio.springeropen.com/articles/10.1186/s40638-014-0016-1},
	doi = {10.1186/s40638-014-0016-1},
	abstract = {This paper presents an IF1F2 color space for describing colors in microscopic images. Unlike the classical color spaces that treat the R, G, and B (RGB) components of a pixel’s color as independent elements, the proposed color space treats RGB as a sampled spectral signal, called a RGB signal. Then, based on the Fourier spectrum analysis of the RGB signal, the 1-D discrete Fourier transform is introduced to describe the color features of microscopic images. K-means clustering experiments on two microscopic image datasets validate the superiority of the proposed IF1F2 color space compared with the classical RGB and HSV (hue, saturation, and value) color spaces.},
	language = {en},
	number = {1},
	urldate = {2021-12-09},
	journal = {Robotics and Biomimetics},
	author = {Guan, Tao and Zhou, Dongxiang and Xu, Chao and Liu, Yunhui},
	month = dec,
	year = {2014},
	pages = {1--6},
}

@misc{noauthor_plasma_nodate,
	title = {The {Plasma} {Membrane} {At} {The} {Nanoscale} {Cs}},
	url = {https://www.calameo.com/read/005686042d5bae30b0341},
	abstract = {Publishing platform for digital magazines, interactive publications and online catalogs. Convert documents to beautiful publications and share them worldwide. Title: The Plasma Membrane At The Nanoscale Cs, Author: abbelight, Length: 4 pages, Published: 2021-02-18},
	urldate = {2021-12-08},
	journal = {calameo.com},
}

@article{qiao_evaluation_2021,
	title = {Evaluation and development of deep neural networks for image super-resolution in optical microscopy},
	volume = {18},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-020-01048-5},
	doi = {10.1038/s41592-020-01048-5},
	abstract = {Deep neural networks have enabled astonishing transformations from low-resolution (LR) to super-resolved images. However, whether, and under what imaging conditions, such deep-learning models outperform super-resolution (SR) microscopy is poorly explored. Here, using multimodality structured illumination microscopy (SIM), we first provide an extensive dataset of LR–SR image pairs and evaluate the deep-learning SR models in terms of structural complexity, signal-to-noise ratio and upscaling factor. Second, we devise the deep Fourier channel attention network (DFCAN), which leverages the frequency content difference across distinct features to learn precise hierarchical representations of high-frequency information about diverse biological structures. Third, we show that DFCAN’s Fourier domain focalization enables robust reconstruction of SIM images under low signal-to-noise ratio conditions. We demonstrate that DFCAN achieves comparable image quality to SIM over a tenfold longer duration in multicolor live-cell imaging experiments, which reveal the detailed structures of mitochondrial cristae and nucleoids and the interaction dynamics of organelles and cytoskeleton.},
	language = {en},
	number = {2},
	urldate = {2021-12-08},
	journal = {Nature Methods},
	author = {Qiao, Chang and Li, Di and Guo, Yuting and Liu, Chong and Jiang, Tao and Dai, Qionghai and Li, Dong},
	month = feb,
	year = {2021},
	keywords = {Fluorescence imaging, Super-resolution microscopy},
	pages = {194--202},
}

@phdthesis{green_amp-activated_2013,
	title = {{AMP}-{Activated} {Protein} {Kinase} ({AMPK}) {Activation} for the {Treatment} of {Mitochondrial} {Disease}},
	abstract = {There are multiple copies of mtDNA per cell and each mtDNA molecule contains the information to encode 13 electron transport chain (ETC) proteins. When mtDNA is depleted, there is a decrease in ETC activity. 5' AMP-activated protein kinase (AMPK) is a kinase that can initiate mitochondrial biogenesis and mitophagy. We hypothesized that treating cells harbouring low numbers of mtDNA with an AMPK activator (5-Aminoimidazole-4-carboxamide ribonucleoside; AICAR) would ameliorate the decrease in ETC activity and improve mtDNA copy number. We developed myoblasts (C2C12 cells) depleted of mtDNA with long-term ethidium bromide treatment. We treated selected clones for 24 hours with 1 mM AICAR to activate AMPK. AICAR treatment decreased markers of mitochondrial biogenesis, mitochondrial function (e.g. maximal cellular respiration), and mitochondrial degradation. Thus, failing to increase the energy producing capacity of the cell, activation of AMPK may have induced an energy sparing mechanism.},
	author = {Green, Alex},
	month = oct,
	year = {2013},
	doi = {10.13140/RG.2.2.31375.41129},
}

@article{wang_deep_2021,
	title = {A {Deep} {Graph} {Wavelet} {Convolutional} {Neural} {Network} for {Semi}-supervised {Node} {Classification}},
	url = {http://arxiv.org/abs/2102.09780},
	abstract = {Graph convolutional neural network provides good solutions for node classification and other tasks with non-Euclidean data. There are several graph convolutional models that attempt to develop deep networks but do not cause serious over-smoothing at the same time. Considering that the wavelet transform generally has a stronger ability to extract useful information than the Fourier transform, we propose a new deep graph wavelet convolutional network (DeepGWC) for semi-supervised node classification tasks. Based on the optimized static filtering matrix parameters of vanilla graph wavelet neural networks and the combination of Fourier bases and wavelet ones, DeepGWC is constructed together with the reuse of residual connection and identity mappings in network architectures. Extensive experiments on three benchmark datasets including Cora, Citeseer, and Pubmed are conducted. The experimental results demonstrate that our DeepGWC outperforms existing graph deep models with the help of additional wavelet bases and achieves new state-of-the-art performances eventually.},
	urldate = {2021-11-23},
	journal = {arXiv:2102.09780 [cs]},
	author = {Wang, Jingyi and Deng, Zhidong},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.09780},
	keywords = {Computer Science - Machine Learning},
}

@incollection{rustamov_wavelets_2018,
	address = {Cham},
	series = {Signals and {Communication} {Technology}},
	title = {Wavelets on {Graphs} via {Deep} {Learning}},
	isbn = {9783030035730},
	abstract = {An increasing number of applications require processing of signals defined on weighted graphs. While wavelets provide a flexible tool for signal processing in the classical setting of regular domains, the existing graph wavelet constructions are less flexible—they are guided solely by the structure of the underlying graph and do not take directly into consideration the particular class of signals to be processed. This chapter introduces a machine learning framework for constructing graph wavelets that can sparsely represent a given class of signals. Our construction uses the lifting scheme, and is based on the observation that the recurrent nature of the lifting scheme gives rise to a structure resembling a deep auto-encoder network. Particular properties that the resulting wavelets must satisfy determine the training objective and the structure of the involved neural networks. The training is unsupervised, and is conducted similarly to the greedy pre-training of a stack of auto-encoders. After training is completed, we obtain a linear wavelet transform that can be applied to any graph signal in time and memory linear in the size of the graph. Improved sparsity of our wavelet transform for the test signals is confirmed via experiments both on synthetic and real data.},
	language = {eng},
	booktitle = {Vertex-{Frequency} {Analysis} of {Graph} {Signals}},
	publisher = {Springer International Publishing},
	author = {Rustamov, Raif M. and Guibas, Leonidas J.},
	year = {2018},
	keywords = {Deep Auto-encoder Network, Detail Coefficients, Graph Wavelet, Lifting Scheme, Wavelet Construction},
	pages = {207--222},
}

@article{cui_learning_2020,
	title = {Learning traffic as a graph: {A} gated graph wavelet recurrent neural network for network-scale traffic prediction},
	volume = {115},
	shorttitle = {Learning traffic as a graph},
	journal = {Transportation Research Part C: Emerging Technologies},
	author = {Cui, Zhiyong and Ke, Ruimin and Pu, Ziyuan and Ma, Xiaolei and Wang, Yinhai},
	year = {2020},
	pages = {102620},
}

@article{ruiz-martin_integration_2022,
	title = {Integration and {Automation} of {Modeling} of {Biological} {Cell} {Processes}},
	volume = {114},
	issn = {1569-190X},
	url = {https://www.sciencedirect.com/science/article/pii/S1569190X21001180},
	doi = {10.1016/j.simpat.2021.102419},
	abstract = {The System Biology Markup Language (SBML) has been used to build numerous models of biological processes. Here we introduce a new method to translate SBML specifications of cellular models into formal specifications for analysis and simulation. To do so we define a generic biological model architecture that can be instantiated with different parameters for different types of cells and at different levels of detail using the information available in SBML models. We discuss said architecture, a prototype implementation and different examples of use of the method with a synthetic model and model of E. Coli.},
	language = {en},
	urldate = {2021-11-21},
	journal = {Simulation Modelling Practice and Theory},
	author = {Ruiz-Martin, Cristina and Wainer, Gabriel A. and Belloli, Laouen},
	month = jan,
	year = {2022},
	keywords = {Automatic model generation, DEVS, Metabolic Networks, SBML, Simulation},
	pages = {102419},
}

@article{milano_materia_2021,
	title = {In materia reservoir computing with a fully memristive architecture based on self-organizing nanowire networks},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4660},
	url = {https://www.nature.com/articles/s41563-021-01099-9},
	doi = {10.1038/s41563-021-01099-9},
	abstract = {Neuromorphic computing aims at the realization of intelligent systems able to process information similarly to our brain. Brain-inspired computing paradigms have been implemented in crossbar arrays of memristive devices; however, this approach does not emulate the topology and the emergent behaviour of biological neuronal circuits, where the principle of self-organization regulates both structure and function. Here, we report on in materia reservoir computing in a fully memristive architecture based on self-organized nanowire networks. Thanks to the functional synaptic connectivity with nonlinear dynamics and fading memory properties, the designless nanowire complex network acts as a network-wide physical reservoir able to map spatio-temporal inputs into a feature space that can be analysed by a memristive resistive switching memory read-out layer. Computing capabilities, including recognition of spatio-temporal patterns and time-series prediction, show that the emergent memristive behaviour of nanowire networks allows in materia implementation of brain-inspired computing paradigms characterized by a reduced training cost.},
	language = {en},
	urldate = {2021-10-06},
	journal = {Nature Materials},
	author = {Milano, Gianluca and Pedretti, Giacomo and Montano, Kevin and Ricci, Saverio and Hashemkhani, Shahin and Boarino, Luca and Ielmini, Daniele and Ricciardi, Carlo},
	month = oct,
	year = {2021},
	pages = {1--8},
}

@article{tang_synthetic_2015,
	title = {Synthetic mitochondria as therapeutics against systemic aging: a hypothesis},
	volume = {39},
	issn = {1095-8355},
	shorttitle = {Synthetic mitochondria as therapeutics against systemic aging},
	doi = {10.1002/cbin.10362},
	abstract = {We hypothesize herein that synthetic mitochondria, engineered, or reprogrammed to be more energetically efficient and to have mildly elevated levels of reactive oxygen species (ROS) production, would be an effective form of therapeutics against systemic aging. The free radical and mitochondria theories of aging hold that mitochondria-generated ROS underlies chronic organelle, cell and tissues damages that contribute to systemic aging. More recent findings, however, collectively suggest that while acute and massive ROS generation during events such as tissue injury is indeed detrimental, subacute stresses, and chronic elevation in ROS production may instead induce a state of mitochondrial hormesis (or "mitohormesis") that could extend lifespan. Mitohormesis appears to be a convergent mechanism for several known anti-aging signaling pathways. Importantly, mitohormetic signaling could also occur in a non-cell autonomous manner, with its induction in neurons affecting gut cells, for example. Technologies are outlined that could lead towards testing of the hypothesis, which include genetic and epigenetic engineering of the mitochondria, as well as intercellular transfer of mitochondria from transplanted helper cells to target tissues.},
	language = {eng},
	number = {2},
	journal = {Cell Biology International},
	author = {Tang, Bor Luen},
	month = feb,
	year = {2015},
	pmid = {25182226},
	keywords = {Aging, Animals, Caenorhabditis elegans, Clustered Regularly Interspaced Short Palindromic Repeats, Electron Transport Chain Complex Proteins, Genes, Mitochondrial, MicroRNAs, Mitochondria, Reactive Oxygen Species, Saccharomyces cerevisiae, Signal Transduction, aging, mitochondria, synthetic biology},
	pages = {131--135},
}

@article{skerjanc_interaction_1987,
	title = {The interaction of a synthetic mitochondrial signal peptide with lipid membranes is independent of transbilayer potential.},
	volume = {6},
	url = {https://www.ncbi.nlm.nih.gov/sites/ppmc/articles/PMC553752/},
	abstract = {We have used fluorescence measurements and assays of vesicle disruption (contents leakage) to monitor the interaction between lipid vesicles and a synthetic peptide corresponding to the N-terminal 27 amino acids of rat mitochondrial pre-ornithine carbamyltransferase ...},
	language = {en},
	number = {10},
	urldate = {2021-10-04},
	journal = {The EMBO Journal},
	author = {Skerjanc, I. S. and Shore, G. C. and Silvius, J. R.},
	month = oct,
	year = {1987},
	pmid = {3691482},
	pages = {3117},
}

@article{kumar_programmed_2021,
	title = {Programmed exosome fusion for energy generation in living cells},
	volume = {4},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2520-1158},
	url = {https://www.nature.com/articles/s41929-021-00669-z},
	doi = {10.1038/s41929-021-00669-z},
	abstract = {Biological membrane-enclosed organelles are fascinating examples of spatially confined nanoreactors for biocatalytic transformations such as cascade reactions involving multiple enzymes; however, the fabrication of their synthetic mimics remains a considerable challenge. Here we demonstrate supramolecular chemistry-based bridging of two membranes leading to controlled fusion of exosomes that act as nanoreactors for effective biocatalytic cascades, with prolonged functionality inside of living cells. Exosome membrane proteins were chemically engineered with a catechol moiety to drive fusion by supramolecular complexation to bridge the membranes. This strategy successfully encapsulated multiple enzymes and assembled the minimal electron transport chain in the plasma membrane, leading to tuneable, enhanced catalytic cascade activity capable of ATP synthesis inside of tissue spheroids. This nanoreactor was functional for many hours after uptake into living cells, showed successful penetration into tissue spheroids and repaired the damaged region by supplying ATP, all of which represent an advance in the mimicking of nature’s own organelles.},
	language = {en},
	number = {9},
	urldate = {2021-10-04},
	journal = {Nature Catalysis},
	author = {Kumar, Sumit and Karmacharya, Mamata and Michael, Issac J. and Choi, Yongjun and Kim, Junyoung and Kim, InUn and Cho, Yoon-Kyoung},
	month = sep,
	year = {2021},
	pages = {763--774},
}

@incollection{mann_mckenzie_2021,
	address = {Treasure Island (FL)},
	title = {{McKenzie} {Back} {Exercises}},
	copyright = {Copyright © 2021, StatPearls Publishing LLC.},
	url = {http://www.ncbi.nlm.nih.gov/books/NBK539720/},
	abstract = {The McKenzie back exercises belong to an exercise protocol pioneered by physiotherapist Robin Anthony McKenzie in the 1950s and popularized around 1985.[1] The McKenzie method, also known as Mechanical Diagnosis and Therapy (MDT), is widely used as a classification system for the diagnosis and treatment of a variety of musculoskeletal conditions, including lower back, neck, and extremity pain.[2] Over time the McKenzie exercises have become synonymous with spinal extension exercises, as opposed to Williams exercises (named after Dr. Paul C. Williams) which have become synonymous with lumbar flexion exercises. The McKenzie method has wide acceptance as an effective program for back pain. It stresses self-treatment through posture correction and repeated exercise movements at end-range performed with high frequency.[3] The hallmark of the McKenzie method for back pain involves the identification and classification of nonspecific spinal pain into homogenous subgroups. These subgroups are based on the similar responses of a patient's symptoms when subjected to mechanical forces.[4] The subgroups include postural syndrome, dysfunction syndrome, derangement syndrome, or “other,” with treatment plans directed to each subgroup.[5] The McKenzie method emphasizes the centralization phenomenon in the assessment and treatment of spinal pain, in which pain originating from the spine refers distally, and through targeted repetitive movements the pain migrates back toward the spine.[4] The clinician will then use the information obtained from this assessment to prescribe specific exercises and advise on which postures to adopt or avoid. Through an individualized treatment program, the patient will perform specific exercises at home approximately ten times per day, as opposed to 1 or 2 physical therapy visits per week. According to the McKenzie method, if there is no restoration of normal function, tissue healing will not occur, and the problem will persist. Classification: The postural syndrome is pain which is caused by mechanical deformation of soft tissue or vasculature arising from prolonged postural stresses. These may affect the joint surfaces, muscles, or tendons, and can occur in sitting, standing or lying. Pain may be reproducible when such individuals maintain positions or postures for sustained periods. Repeated movements should not affect symptoms, and relief of pain typically occurs immediately following the correction of abnormal posture.[5] The dysfunction syndrome is pain which is caused by the mechanical deformation of structurally impaired soft tissue; this may be due to traumatic, inflammatory, or degenerative processes, causing tissue contraction, scarring, adhesion, or adaptive shortening. The hallmark is a loss of movement and pain at the end range of motion. Dysfunction has subsyndromes based upon the end-range direction that elicits this pain: flexion, extension, side-glide, multidirectional, adherent nerve root, and nerve root entrapment subsyndromes. Successful treatment focuses on patient education and mobilization exercises that focus on the direction of the dysfunction/direction of pain. The goal is on tissue remodeling which can be a prolonged process. The derangement syndrome is the most commonly encountered pain syndrome, reported in one study to have a prevalence as high as 78\% of patients classified by the McKenzie method.[6] It is caused by an internal dislocation of articular tissue, causing a disturbance in the normal position of affected joint surfaces, deforming the capsule, and periarticular supportive ligaments. This derangement will both generate pain and obstruct movement in the direction of the displacement. There are seven different subsyndromes which are classified by the location of pain and the presence, or absence, of deformities. Pain is typically elicited by provocative assessment movements, such as flexion or extension of the spine. The centralization and peripheralization of symptoms can only occur in the derangement syndrome. Thus the treatment for derangement syndrome focuses on repeated movement in a single direction that causes a gradual reduction in pain. Studies have shown approximately anywhere between 58\% to 91\% prevalence of centralization of lower back pain.[7] Studies have also shown that between 67\% to 85\% of centralizers displayed the directional preference for a spinal extension.[8] This preference may partially explain why the McKenzie method has become synonymous with spinal extension exercises. However, care must be taken to accurately diagnose the direction of pain, as one randomized controlled study has shown that giving the ‘wrong’ direction of exercises can actually lead to poorer outcomes.[9] Other or Nonmechanical syndrome refers to any symptom that does not fit in with the other mechanical syndromes, but exhibit signs and symptoms of other known pathology; Some of these examples include spinal stenosis, sacroiliac disorders, hip disorders, zygapophyseal disorders, post-surgical complications, low back pain secondary to pregnancy, spondylolysis, and spondylolisthesis.},
	language = {eng},
	urldate = {2021-10-02},
	booktitle = {{StatPearls}},
	publisher = {StatPearls Publishing},
	author = {Mann, Steven J. and Lam, Jason C. and Singh, Paramvir},
	year = {2021},
	pmid = {30969542},
}

@misc{noauthor_physically_nodate,
	title = {Physically {Based} {Rendering}: {From} {Theory} to {Implementation}},
	url = {https://pbr-book.org/3ed-2018/contents},
	urldate = {2021-09-27},
}

@misc{noauthor_improving_nodate,
	title = {Improving {Gradient} {Regularization} using {Complex}-{Valued} {Neural} {Networks}},
	url = {https://icml.cc/virtual/2021/spotlight/10760},
	urldate = {2021-09-03},
}

@article{wang_overlapping_2021,
	title = {Overlapping {Structures} {Detection} in {Protein}-{Protein} {Interaction} {Networks} {Using} {Community} {Detection} {Algorithm} {Based} on {Neighbor} {Clustering} {Coefficient}},
	volume = {12},
	copyright = {cc by},
	issn = {1664-8021},
	url = {https://europepmc.org/articles/PMC8261288},
	doi = {10.3389/fgene.2021.689515},
	abstract = {With the rapid development of bioinformatics, researchers have applied community detection algorithms to detect functional modules in protein-protein interaction (PPI) networks that can predict the function of unknown proteins at the molecular level and further reveal the regularity of cell activity. Clusters in a PPI network may overlap where a protein is involved in multiple functional modules. To identify overlapping structures in protein functional modules, this paper proposes a novel overlapping community detection algorithm based on the neighboring local clustering coefficient (NLC). The contributions of the NLC algorithm are threefold: (i) Combine the edge-based community detection method with local expansion in seed selection and the local clustering coefficient of neighboring nodes to improve the accuracy of seed selection; (ii) A method of measuring the distance between edges is improved to make the result of community division more accurate; (iii) A community optimization strategy for the excessive overlapping nodes makes the overlapping structure more reasonable. The experimental results on standard networks, Lancichinetti-Fortunato-Radicchi (LFR) benchmark networks and PPI networks show that the NLC algorithm can improve the Extended modularity (EQ) value and Normalized Mutual Information (NMI) value of the community division, which verifies that the algorithm can not only detect reasonable communities but also identify overlapping structures in networks.},
	language = {eng},
	urldate = {2021-08-25},
	journal = {Frontiers in genetics},
	author = {Wang, Yan and Qiong, Chen and Yang, Lili and Yang, Sen and He, Kai and Xie, Xuping},
	month = jan,
	year = {2021},
	pmid = {34249104},
	pmcid = {PMC8261288},
	keywords = {Central Edge, Clustering Coefficient, Community Detection, Overlapping Structure, protein-protein interaction network},
	pages = {689515},
}

@article{mill_synthetic_2021,
	title = {Synthetic {Image} {Rendering} {Solves} {Annotation} {Problem} in {Deep} {Learning} {Nanoparticle} {Segmentation}},
	volume = {5},
	issn = {2366-9608},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/smtd.202100223},
	doi = {10.1002/smtd.202100223},
	abstract = {Nanoparticles occur in various environments as a consequence of man-made processes, which raises concerns about their impact on the environment and human health. To allow for proper risk assessment, a precise and statistically relevant analysis of particle characteristics (such as size, shape, and composition) is required that would greatly benefit from automated image analysis procedures. While deep learning shows impressive results in object detection tasks, its applicability is limited by the amount of representative, experimentally collected and manually annotated training data. Here, an elegant, flexible, and versatile method to bypass this costly and tedious data acquisition process is presented. It shows that using a rendering software allows to generate realistic, synthetic training data to train a state-of-the art deep neural network. Using this approach, a segmentation accuracy can be derived that is comparable to man-made annotations for toxicologically relevant metal-oxide nanoparticle ensembles which were chosen as examples. The presented study paves the way toward the use of deep learning for automated, high-throughput particle detection in a variety of imaging techniques such as in microscopies and spectroscopies, for a wide range of applications, including the detection of micro- and nanoplastic particles in water and tissue samples.},
	language = {en},
	number = {7},
	urldate = {2021-08-19},
	journal = {Small Methods},
	author = {Mill, Leonid and Wolff, David and Gerrits, Nele and Philipp, Patrick and Kling, Lasse and Vollnhals, Florian and Ignatenko, Andrew and Jaremenko, Christian and Huang, Yixing and Castro, Olivier De and Audinot, Jean-Nicolas and Nelissen, Inge and Wirtz, Tom and Maier, Andreas and Christiansen, Silke},
	year = {2021},
	keywords = {helium ion microscopy, image analysis, machine learning, nanoparticles, segmentation, toxicology},
	pages = {2100223},
}

@misc{noauthor_ethics_nodate,
	title = {Ethics and governance of artificial intelligence for health},
	url = {https://www.who.int/publications-detail-redirect/9789240029200},
	abstract = {WHO guidance},
	language = {en},
	urldate = {2021-08-11},
}

@article{babic_beware_2021,
	title = {Beware explanations from {AI} in health care},
	volume = {373},
	copyright = {Copyright © 2021, American Association for the Advancement of Science. http://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/373/6552/284},
	doi = {10.1126/science.abg1834},
	abstract = {Artificial intelligence and machine learning (AI/ML) algorithms are increasingly developed in health care for diagnosis and treatment of a variety of medical conditions (1). However, despite the technical prowess of such systems, their adoption has been challenging, and whether and how much they will actually improve health care remains to be seen. A central reason for this is that the effectiveness of AI/ML-based medical devices depends largely on the behavioral characteristics of its users, who, for example, are often vulnerable to well-documented biases or algorithmic aversion (2). Many stakeholders increasingly identify the so-called black-box nature of predictive algorithms as the core source of users' skepticism, lack of trust, and slow uptake (3, 4). As a result, lawmakers have been moving in the direction of requiring the availability of explanations for black-box algorithmic decisions (5). Indeed, a near-consensus is emerging in favor of explainable AI/ML among academics, governments, and civil society groups. Many are drawn to this approach to harness the accuracy benefits of noninterpretable AI/ML such as deep learning or neural nets while also supporting transparency, trust, and adoption. We argue that this consensus, at least as applied to health care, both overstates the benefits and undercounts the drawbacks of requiring black-box algorithms to be explainable.
The benefits of explainable artificial intelligence are not what they appear
The benefits of explainable artificial intelligence are not what they appear},
	language = {en},
	number = {6552},
	urldate = {2021-08-11},
	journal = {Science},
	author = {Babic, Boris and Gerke, Sara and Evgeniou, Theodoros and Cohen, I. Glenn},
	month = jul,
	year = {2021},
	pages = {284--286},
}

@techreport{qin_direct_2021,
	title = {Direct focus sensing and shaping for high-resolution multi-photon imaging in deep tissue},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.08.04.455159v1},
	abstract = {High-resolution optical imaging of deep tissue in-situ such as the living brain is fundamentally challenging because of the aberration and scattering of light. In this work, we develop an innovative adaptive optics three-photon microscope based on direct focus sensing and shaping that can accurately measure and effectively compensate for both low- and high-order specimen-induced aberrations and recover near-diffraction-limited performance at depth. A conjugate adaptive optics configuration with remote focusing enables in vivo imaging of fine neuronal structures in the mouse cortex through the intact skull up to a depth of 750 µm below pia, making high-resolution microscopy in cortex near non-invasive. Functional calcium imaging with high sensitivity and accuracy, and high-precision laser-mediated microsurgery through the intact skull were demonstrated. Moreover, we also achieved in vivo high-resolution imaging of the deep cortex and subcortical hippocampus up to 1.1 mm below pia within the intact brain.},
	language = {en},
	urldate = {2021-08-11},
	author = {Qin, Zhongya and She, Zhentao and Chen, Congping and Wu, Wanjie and Lau, Jackie K. Y. and Ip, Nancy Y. and Qu, Jianan Y.},
	month = aug,
	year = {2021},
	note = {Type: article},
	pages = {2021.08.04.455159},
}

@article{gan_modir_2021,
	title = {{MoDIR}: {Motion}-{Compensated} {Training} for {Deep} {Image} {Reconstruction} without {Ground} {Truth}},
	shorttitle = {{MoDIR}},
	url = {https://arxiv.org/abs/2107.05533v1},
	abstract = {Deep neural networks for medical image reconstruction are traditionally trained using high-quality ground-truth images as training targets. Recent work onNoise2Noise (N2N) has shown the potential of using multiple noisy measurements of the same object as an alternative to having a ground truth. However, existing N2N-based methods cannot exploit information from various motion states, limiting their ability to learn on moving objects. This paper addresses this issue by proposing a novel motion-compensated deep image reconstruction (MoDIR) method that can use information from several unregistered and noisy measurements for training. MoDIR deals with object motion by including a deep registration module jointly trained with the deep reconstruction network without any ground-truth supervision. We validate MoDIR on both simulated and experimentally collected magnetic resonance imaging (MRI) data and show that it significantly improves imaging quality.},
	language = {en},
	urldate = {2021-07-26},
	author = {Gan, Weijie and Sun, Yu and Eldeniz, Cihat and Liu, Jiaming and An, Hongyu and Kamilov, Ulugbek S.},
	month = jul,
	year = {2021},
}

@inproceedings{moghadam_enabling_2021,
	address = {New York, NY, USA},
	series = {{MMSys} '21},
	title = {Enabling hyperspectral imaging in diverse illumination conditions for indoor applications},
	isbn = {9781450384346},
	url = {https://doi.org/10.1145/3458305.3459594},
	doi = {10.1145/3458305.3459594},
	abstract = {Hyperspectral imaging provides rich information across many wavelengths of the captured scene, which is useful for many potential applications such as food quality inspection, medical diagnosis, material identification, artwork authentication, and crime scene analysis. However, hyperspectral imaging has not been widely deployed for such indoor applications. In this paper, we address one of the main challenges stifling this wide adoption, which is the strict illumination requirements for hyperspectral cameras. Hyperspectral cameras require a light source that radiates power across a wide range of the electromagnetic spectrum. Such light sources are expensive to setup and operate, and in some cases, they are not possible to use because they could damage important objects in the scene. We propose a data-driven method that enables indoor hyper-spectral imaging using cost-effective and widely available lighting sources such as LED and fluorescent. These common sources, however, introduce significant noise in the hyperspectral bands in the invisible range, which are the most important for the applications. Our proposed method restores the damaged bands using a carefully-designed supervised deep-learning model. We conduct an extensive experimental study to analyze the performance of the proposed method and compare it against the state-of-the-art using real hyperspectral datasets that we have collected. Our results show that the proposed method outperforms the state-of-the-art across all considered objective and subjective metrics, and it produces hyperspectral bands that are close to the ground truth bands captured under ideal illumination conditions.},
	urldate = {2021-07-22},
	booktitle = {Proceedings of the 12th {ACM} {Multimedia} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Moghadam, Puria Azadi and Sharma, Neha and Hefeeda, Mohamed},
	month = jul,
	year = {2021},
	keywords = {deep learning, hyperspectral imaging, illumination},
	pages = {23--35},
}

@article{godau_task_2021,
	title = {Task {Fingerprinting} for {Meta} {Learning} in {Biomedical} {Image} {Analysis}},
	url = {http://arxiv.org/abs/2107.03949},
	abstract = {Shortage of annotated data is one of the greatest bottlenecks in biomedical image analysis. Meta learning studies how learning systems can increase in eﬃciency through experience and could thus evolve as an important concept to overcome data sparsity. However, the core capability of meta learning-based approaches is the identiﬁcation of similar previous tasks given a new task - a challenge largely unexplored in the biomedical imaging domain. In this paper, we address the problem of quantifying task similarity with a concept that we refer to as task ﬁngerprinting. The concept involves converting a given task, represented by imaging data and corresponding labels, to a ﬁxed-length vector representation. In ﬁngerprint space, diﬀerent tasks can be directly compared irrespective of their data set sizes, types of labels or speciﬁc resolutions. An initial feasibility study in the ﬁeld of surgical data science (SDS) with 26 classiﬁcation tasks from various medical and non-medical domains suggests that task ﬁngerprinting could be leveraged for both (1) selecting appropriate data sets for pretraining and (2) selecting appropriate architectures for a new task. Task ﬁngerprinting could thus become an important tool for meta learning in SDS and other ﬁelds of biomedical image analysis.},
	language = {en},
	urldate = {2021-07-13},
	journal = {arXiv:2107.03949 [cs]},
	author = {Godau, Patrick and Maier-Hein, Lena},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.03949},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{polsterl_estimation_2021,
	title = {Estimation of {Causal} {Effects} in the {Presence} of {Unobserved} {Confounding} in the {Alzheimer}'s {Continuum}},
	volume = {12729},
	url = {http://arxiv.org/abs/2006.13135},
	doi = {10.1007/978-3-030-78191-0_4},
	abstract = {Studying the relationship between neuroanatomy and cognitive decline due to Alzheimer's has been a major research focus in the last decade. However, to infer cause-effect relationships rather than simple associations from observational data, we need to (i) express the causal relationships leading to cognitive decline in a graphical model, and (ii) ensure the causal effect of interest is identifiable from the collected data. We derive a causal graph from the current clinical knowledge on cause and effect in the Alzheimer's disease continuum, and show that identifiability of the causal effect requires all confounders to be known and measured. However, in complex neuroimaging studies, we neither know all potential confounders nor do we have data on them. To alleviate this requirement, we leverage the dependencies among multiple causes by deriving a substitute confounder via a probabilistic latent factor model. In our theoretical analysis, we prove that using the substitute confounder enables identifiability of the causal effect of neuroanatomy on cognition. We quantitatively evaluate the effectiveness of our approach on semi-synthetic data, where we know the true causal effects, and illustrate its use on real data on the Alzheimer's disease continuum, where it reveals important causes that otherwise would have been missed.},
	urldate = {2021-06-26},
	journal = {arXiv:2006.13135 [cs, stat]},
	author = {Pölsterl, Sebastian and Wachinger, Christian},
	year = {2021},
	note = {arXiv: 2006.13135},
	keywords = {Computer Science - Machine Learning, Statistics - Applications, Statistics - Methodology},
	pages = {45--57},
}

@article{woolston_researchers_2021,
	title = {Researchers’ career insecurity needs attention and reform now, says international coalition},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-021-01548-0},
	doi = {10.1038/d41586-021-01548-0},
	abstract = {Postdocs and PhD students around the world require professional training to prepare them for a possible career outside academia, finds the Organisation for Economic Co-operation and Development.},
	language = {en},
	urldate = {2021-06-16},
	journal = {Nature},
	author = {Woolston, Chris},
	month = jun,
	year = {2021},
}

@article{garcia-pelegrin_exploring_2021,
	title = {Exploring the perceptual inabilities of {Eurasian} jays ({Garrulus} glandarius) using magic effects},
	volume = {118},
	copyright = {© 2021 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/118/24/e2026106118},
	doi = {10.1073/pnas.2026106118},
	abstract = {In recent years, scientists have begun to use magic effects to investigate the blind spots in our attention and perception [G. Kuhn, Experiencing the Impossible: The Science of Magic (2019); S. Macknik, S. Martinez-Conde, S. Blakeslee, Sleights of Mind: What the Neuroscience of Magic Reveals about Our Everyday Deceptions (2010)]. Recently, we suggested that similar techniques could be transferred to nonhuman animal observers and that such an endeavor would provide insight into the inherent commonalities and discrepancies in attention and perception in human and nonhuman animals [E. Garcia-Pelegrin, A. K. Schnell, C. Wilkins, N. S. Clayton, Science 369, 1424–1426 (2020)]. Here, we performed three different magic effects (palming, French drop, and fast pass) to a sample of six Eurasian jays (Garrulus glandarius). These magic effects were specifically chosen as they utilize different cues and expectations that mislead the spectator into thinking one object has or has not been transferred from one hand to the other. Results from palming and French drop experiments suggest that Eurasian jays have different expectations from humans when observing some of these effects. Specifically, Eurasian jays were not deceived by effects that required them to expect an object to move between hands when observing human hand manipulations. However, similar to humans, Eurasian jays were misled by magic effects that utilize fast movements as a deceptive action. This study investigates how another taxon perceives the magician’s techniques of deception that commonly deceive humans.},
	language = {en},
	number = {24},
	urldate = {2021-06-15},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Garcia-Pelegrin, Elias and Schnell, Alexandra K. and Wilkins, Clive and Clayton, Nicola S.},
	month = jun,
	year = {2021},
	pmid = {34074798},
	keywords = {attention, comparative cognition, corvids, magic, perception},
}

@misc{noauthor_page_nodate,
	title = {Page {Not} {Found} {\textbar} {PNAS}},
	url = {https://www.pnas.org/content/118/24/e2026106118https://start.fedoraproject.org},
	language = {en},
	urldate = {2021-06-15},
}

@article{lunz_learned_2021,
	title = {On {Learned} {Operator} {Correction} in {Inverse} {Problems}},
	volume = {14},
	doi = {10.1137/20M1338460},
	abstract = {We discuss the possibility of learning a data-driven explicit model correction for inverse problems and whether such a model correction can be used within a variational framework to obtain regularized reconstructions. This paper discusses the conceptual difficulty of learning such a forward model correction and proceeds to present a possible solution as a forward-adjoint correction that explicitly corrects in both data and solution spaces. We then derive conditions under which solutions to the variational problem with a learned correction converge to solutions obtained with the correct operator. The proposed approach is evaluated on an application to limited view photoacoustic tomography and compared to the established framework of the Bayesian approximation error method.},
	journal = {SIAM Journal on Imaging Sciences},
	author = {Lunz, Sebastian and Hauptmann, Andreas and Tarvainen, Tanja and Schönlieb, Carola-Bibiane and Arridge, Simon},
	month = jan,
	year = {2021},
	pages = {92--127},
}

@article{noauthor_interpretable_2021,
	title = {Interpretable deep learning uncovers cellular properties in label-free live cell images that are predictive of highly metastatic melanoma},
	issn = {2405-4712},
	url = {https://www.sciencedirect.com/science/article/pii/S2405471221001587},
	doi = {10.1016/j.cels.2021.05.003},
	abstract = {Deep learning has emerged as the technique of choice for identifying hidden patterns in cell imaging data but is often criticized as “black box.” Here…},
	language = {en},
	urldate = {2021-06-03},
	journal = {Cell Systems},
	month = jun,
	year = {2021},
}

@article{ramazi_post-translational_2021,
	title = {Post-translational modifications in proteins: resources, tools and prediction methods},
	volume = {2021},
	issn = {1758-0463},
	shorttitle = {Post-translational modifications in proteins},
	url = {https://doi.org/10.1093/database/baab012},
	doi = {10.1093/database/baab012},
	abstract = {Posttranslational modifications (PTMs) refer to amino acid side chain modification in some proteins after their biosynthesis. There are more than 400 different types of PTMs affecting many aspects of protein functions. Such modifications happen as crucial molecular regulatory mechanisms to regulate diverse cellular processes. These processes have a significant impact on the structure and function of proteins. Disruption in PTMs can lead to the dysfunction of vital biological processes and hence to various diseases. High-throughput experimental methods for discovery of PTMs are very laborious and time-consuming. Therefore, there is an urgent need for computational methods and powerful tools to predict PTMs. There are vast amounts of PTMs data, which are publicly accessible through many online databases. In this survey, we comprehensively reviewed the major online databases and related tools. The current challenges of computational methods were reviewed in detail as well.},
	number = {baab012},
	urldate = {2021-05-29},
	journal = {Database},
	author = {Ramazi, Shahin and Zahiri, Javad},
	month = may,
	year = {2021},
}

@article{sogancioglu_deep_2021,
	title = {Deep {Learning} for {Chest} {X}-ray {Analysis}: {A} {Survey}},
	shorttitle = {Deep {Learning} for {Chest} {X}-ray {Analysis}},
	url = {http://arxiv.org/abs/2103.08700},
	abstract = {Recent advances in deep learning have led to a promising performance in many medical image analysis tasks. As the most commonly performed radiological exam, chest radiographs are a particularly important modality for which a variety of applications have been researched. The release of multiple, large, publicly available chest X-ray datasets in recent years has encouraged research interest and boosted the number of publications. In this paper, we review all studies using deep learning on chest radiographs, categorizing works by task: image-level prediction (classification and regression), segmentation, localization, image generation and domain adaptation. Commercially available applications are detailed, and a comprehensive discussion of the current state of the art and potential future directions are provided.},
	urldate = {2021-05-28},
	journal = {arXiv:2103.08700 [cs, eess]},
	author = {Sogancioglu, Ecem and Çallı, Erdi and van Ginneken, Bram and van Leeuwen, Kicky G. and Murphy, Keelin},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.08700},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{mahbod_investigating_2021,
	title = {Investigating the {Impact} of the {Bit} {Depth} of {Fluorescence}-{Stained} {Images} on the {Performance} of {Deep} {Learning}-{Based} {Nuclei} {Instance} {Segmentation}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2075-4418/11/6/967},
	doi = {10.3390/diagnostics11060967},
	abstract = {Nuclei instance segmentation can be considered as a key point in the computer-mediated analysis of histological fluorescence-stained (FS) images. Many computer-assisted approaches have been proposed for this task, and among them, supervised deep learning (DL) methods deliver the best performances. An important criterion that can affect the DL-based nuclei instance segmentation performance of FS images is the utilised image bit depth, but to our knowledge, no study has been conducted so far to investigate this impact. In this work, we released a fully annotated FS histological image dataset of nuclei at different image magnifications and from five different mouse organs. Moreover, by different pre-processing techniques and using one of the state-of-the-art DL-based methods, we investigated the impact of image bit depth (i.e., eight bits vs. sixteen bits) on the nuclei instance segmentation performance. The results obtained from our dataset and another publicly available dataset showed very competitive nuclei instance segmentation performances for the models trained with 8 bit and 16 bit images. This suggested that processing 8 bit images is sufficient for nuclei instance segmentation of FS images in most cases. The dataset including the raw image patches, as well as the corresponding segmentation masks is publicly available in the published GitHub repository.},
	language = {en},
	number = {6},
	urldate = {2021-05-27},
	journal = {Diagnostics},
	author = {Mahbod, Amirreza and Schaefer, Gerald and Löw, Christine and Dorffner, Georg and Ecker, Rupert and Ellinger, Isabella},
	month = jun,
	year = {2021},
	keywords = {bit depth, computational pathology, deep learning, fluorescence staining, medical image analysis, nuclei segmentation},
	pages = {967},
}

@book{aggarwal_model_2021,
	title = {Model {Adaptation} for {Image} {Reconstruction} using {Generalized} {Stein}'s {Unbiased} {Risk} {Estimator}},
	abstract = {Deep learning image reconstruction algorithms often suffer from model mismatches when the acquisition scheme differs significantly from the forward model used during training. We introduce a Generalized Stein's Unbiased Risk Estimate (GSURE) loss metric to adapt the network to the measured k-space data and minimize model misfit impact. Unlike current methods that rely on the mean square error in kspace, the proposed metric accounts for noise in the measurements. This makes the approach less vulnerable to overfitting, thus offering improved reconstruction quality compared to schemes that rely on mean-square error. This approach may be useful to rapidly adapt pre-trained models to new acquisition settings (e.g., multi-site) and different contrasts than training data},
	author = {Aggarwal, Hemant and Jacob, Mathews},
	month = jan,
	year = {2021},
}

@article{laak_deep_2021,
	title = {Deep learning in histopathology: the path to the clinic},
	volume = {27},
	copyright = {2021 Springer Nature America, Inc.},
	issn = {1546-170X},
	shorttitle = {Deep learning in histopathology},
	url = {https://www.nature.com/articles/s41591-021-01343-4},
	doi = {10.1038/s41591-021-01343-4},
	abstract = {Machine learning techniques have great potential to improve medical diagnostics, offering ways to improve accuracy, reproducibility and speed, and to ease workloads for clinicians. In the field of histopathology, deep learning algorithms have been developed that perform similarly to trained pathologists for tasks such as tumor detection and grading. However, despite these promising results, very few algorithms have reached clinical implementation, challenging the balance between hope and hype for these new techniques. This Review provides an overview of the current state of the field, as well as describing the challenges that still need to be addressed before artificial intelligence in histopathology can achieve clinical value. Recent advances in machine learning techniques have created opportunities to improve medical diagnostics, but implementing these advances in the clinic will not be without challenge.},
	language = {en},
	number = {5},
	urldate = {2021-05-16},
	journal = {Nature Medicine},
	author = {Laak, Jeroen van der and Litjens, Geert and Ciompi, Francesco},
	month = may,
	year = {2021},
	pages = {775--784},
}

@book{heumos_mlf-core_2021,
	title = {mlf-core: a framework for deterministic machine learning},
	shorttitle = {mlf-core},
	abstract = {Machine learning has shown extensive growth in recent years. However, previously existing studies highlighted a reproducibility crisis in machine learning. The reasons for irreproducibility are manifold. Major machine learning libraries default to the usage of non-deterministic algorithms based on atomic operations. Solely fixing all random seeds is not sufficient for deterministic machine learning. To overcome this shortcoming, various machine learning libraries released deterministic counterparts to the non-deterministic algorithms. We evaluated the effect of these algorithms on determinism and runtime. Based on these results, we formulated a set of requirements for reproducible machine learning and developed a new software solution, the mlf-core ecosystem, which aids machine learning projects to meet and keep these requirements. We applied mlf-core to develop fully reproducible models in various biomedical fields including a single cell autoencoder with TensorFlow, a PyTorch-based U-Net model for liver-tumor segmentation in CT scans, and a liver cancer classifier based on gene expression profiles with XGBoost.},
	author = {Heumos, Lukas and Ehmele, Philipp and Menden, Kevin and Cuellar, Luis and Miller, Edmund and Lemke, Steffen and Gabernet Garriga, Gisela and Nahnsen, Sven},
	month = apr,
	year = {2021},
}

@article{kleppe_designing_2021,
	title = {Designing deep learning studies in cancer diagnostics},
	volume = {21},
	copyright = {2021 Springer Nature Limited},
	issn = {1474-1768},
	url = {https://www.nature.com/articles/s41568-020-00327-9},
	doi = {10.1038/s41568-020-00327-9},
	abstract = {The number of publications on deep learning for cancer diagnostics is rapidly increasing, and systems are frequently claimed to perform comparable with or better than clinicians. However, few systems have yet demonstrated real-world medical utility. In this Perspective, we discuss reasons for the moderate progress and describe remedies designed to facilitate transition to the clinic. Recent, presumably influential, deep learning studies in cancer diagnostics, of which the vast majority used images as input to the system, are evaluated to reveal the status of the field. By manipulating real data, we then exemplify that much and varied training data facilitate the generalizability of neural networks and thus the ability to use them clinically. To reduce the risk of biased performance estimation of deep learning systems, we advocate evaluation in external cohorts and strongly advise that the planned analyses, including a predefined primary analysis, are described in a protocol preferentially stored in an online repository. Recommended protocol items should be established for the field, and we present our suggestions.},
	language = {en},
	number = {3},
	urldate = {2021-05-13},
	journal = {Nature Reviews Cancer},
	author = {Kleppe, Andreas and Skrede, Ole-Johan and De Raedt, Sepp and Liestøl, Knut and Kerr, David J. and Danielsen, Håvard E.},
	month = mar,
	year = {2021},
	pages = {199--211},
}

@article{kleele_distinct_2021,
	title = {Distinct fission signatures predict mitochondrial degradation or biogenesis},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03510-6},
	doi = {10.1038/s41586-021-03510-6},
	abstract = {Mitochondrial fission is a highly regulated process that, when disrupted, can alter metabolism, proliferation and apoptosis1–3. Dysregulation has been linked to neurodegeneration3,4, cardiovascular disease3 and cancer5. Key components of the fission machinery include the endoplasmic reticulum6 and actin7, which initiate constriction before dynamin-related protein 1 (DRP1)8 binds to the outer mitochondrial membrane via adaptor proteins9–11, to drive scission12. In the mitochondrial life cycle, fission enables both biogenesis of new mitochondria and clearance of dysfunctional mitochondria through mitophagy1,13. Current models of fission regulation cannot explain how those dual fates are decided. However, uncovering fate determinants is challenging, as fission is unpredictable, and mitochondrial morphology is heterogeneous, with ultrastructural features that are below the diffraction limit. Here, we used live-cell structured illumination microscopy to capture mitochondrial dynamics. By analysing hundreds of fissions in African green monkey Cos-7 cells and mouse cardiomyocytes, we discovered two functionally and mechanistically distinct types of fission. Division at the periphery enables damaged material to be shed into smaller mitochondria destined for mitophagy, whereas division at the midzone leads to the proliferation of mitochondria. Both types are mediated by DRP1, but endoplasmic reticulum- and actin-mediated pre-constriction and the adaptor MFF govern only midzone fission. Peripheral fission is preceded by lysosomal contact and is regulated by the mitochondrial outer membrane protein FIS1. These distinct molecular mechanisms explain how cells independently regulate fission, leading to distinct mitochondrial fates.},
	language = {en},
	urldate = {2021-05-06},
	journal = {Nature},
	author = {Kleele, Tatjana and Rey, Timo and Winter, Julius and Zaganelli, Sofia and Mahecic, Dora and Perreten Lambert, Hélène and Ruberto, Francesco Paolo and Nemir, Mohamed and Wai, Timothy and Pedrazzini, Thierry and Manley, Suliana},
	month = may,
	year = {2021},
	pages = {1--5},
}

@article{young_four_2021,
	title = {Four distinct trajectories of tau deposition identified in {Alzheimer}’s disease},
	doi = {10.1038/s41591-021-01309-6},
	abstract = {Alzheimer’s disease (AD) is characterized by the spread of tau pathology throughout the cerebral cortex. This spreading pattern was thought to be fairly consistent across individuals, although recent work has demonstrated substantial variability in the population with AD. Using tau-positron emission tomography scans from 1,612 individuals, we identified 4 distinct spatiotemporal trajectories of tau pathology, ranging in prevalence from 18 to 33\%. We replicated previously described limbic-predominant and medial temporal lobe-sparing patterns, while also discovering posterior and lateral temporal patterns resembling atypical clinical variants of AD. These ‘subtypes’ were stable during longitudinal follow-up and were replicated in a separate sample using a different radiotracer. The subtypes presented with distinct demographic and cognitive profiles and differing longitudinal outcomes. Additionally, network diffusion models implied that pathology originates and spreads through distinct corticolimbic networks in the different subtypes. Together, our results suggest that variation in tau pathology is common and systematic, perhaps warranting a re-examination of the notion of ‘typical AD’ and a revisiting of tau pathological staging. Systematic characterization of longitudinal tau variability in human Alzheimer’s disease using an unbiased subtyping algorithm reveals four trajectories of tau deposition with distinct clinical features.},
	journal = {Nature Medicine},
	author = {Young, Alexandra and Oxtoby, Neil and Smith, Ruben and Ossenkoppele, Rik and Strandberg, Olof and La Joie, Renaud and Aksman, Leon and Grothe, Michel and Iturria, Yasser and Weiner, Michael and Aisen, Paul and Petersen, Ronald and Jack, Clifford and Jagust, William and Trojanowki, John and Toga, Arthur and Beckett, Laurel and Green, Robert},
	month = apr,
	year = {2021},
	pages = {1--11},
}

@article{digan_can_2020,
	title = {Can reproducibility be improved in clinical natural language processing? {A} study of 7 clinical {NLP} suites},
	volume = {28},
	shorttitle = {Can reproducibility be improved in clinical natural language processing?},
	doi = {10.1093/jamia/ocaa261},
	abstract = {Background
The increasing complexity of data streams and computational processes in modern clinical health information systems makes reproducibility challenging. Clinical natural language processing (NLP) pipelines are routinely leveraged for the secondary use of data. Workflow management systems (WMS) have been widely used in bioinformatics to handle the reproducibility bottleneck.

Objective
To evaluate if WMS and other bioinformatics practices could impact the reproducibility of clinical NLP frameworks.

Materials and Methods
Based on the literature across multiple research fields (NLP, bioinformatics and clinical informatics) we selected articles which (1) review reproducibility practices and (2) highlight a set of rules or guidelines to ensure tool or pipeline reproducibility. We aggregate insight from the literature to define reproducibility recommendations. Finally, we assess the compliance of 7 NLP frameworks to the recommendations.

Results
We identified 40 reproducibility features from 8 selected articles. Frameworks based on WMS match more than 50\% of features (26 features for LAPPS Grid, 22 features for OpenMinted) compared to 18 features for current clinical NLP framework (cTakes, CLAMP) and 17 features for GATE, ScispaCy, and Textflows.

Discussion
34 recommendations are endorsed by at least 2 articles from our selection. Overall, 15 features were adopted by every NLP Framework. Nevertheless, frameworks based on WMS had a better compliance with the features.

Conclusion
NLP frameworks could benefit from lessons learned from the bioinformatics field (eg, public repositories of curated tools and workflows or use of containers for shareability) to enhance the reproducibility in a clinical setting.},
	journal = {Journal of the American Medical Informatics Association},
	author = {Digan, William and Névéol, Aurélie and Neuraz, Antoine and Wack, Maxime and Baudoin, David and Burgun, Anita and Rance, Bastien},
	month = dec,
	year = {2020},
}

@article{bronstein_geometric_2021,
	title = {Geometric {Deep} {Learning}: {Grids}, {Groups}, {Graphs}, {Geodesics}, and {Gauges}},
	shorttitle = {Geometric {Deep} {Learning}},
	url = {http://arxiv.org/abs/2104.13478},
	abstract = {The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing Go, or protein folding -- are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation. While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications. Such a 'geometric unification' endeavour, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.},
	language = {en},
	urldate = {2021-04-29},
	journal = {arXiv:2104.13478 [cs, stat]},
	author = {Bronstein, Michael M. and Bruna, Joan and Cohen, Taco and Veličković, Petar},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.13478},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computational Geometry, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{park_axial--lateral_2021,
	title = {Axial-to-lateral super-resolution for {3D} fluorescence microscopy using unsupervised deep learning},
	url = {http://arxiv.org/abs/2104.09435},
	abstract = {Volumetric imaging by fluorescence microscopy is often limited by anisotropic spatial resolution from inferior axial resolution compared to the lateral resolution. To address this problem, here we present a deep-learning-enabled unsupervised super-resolution technique that enhances anisotropic images in volumetric fluorescence microscopy. In contrast to the existing deep learning approaches that require matched high-resolution target volume images, our method greatly reduces the effort to put into practice as the training of a network requires as little as a single 3D image stack, without a priori knowledge of the image formation process, registration of training data, or separate acquisition of target data. This is achieved based on the optimal transport driven cycle-consistent generative adversarial network that learns from an unpaired matching between high-resolution 2D images in lateral image plane and low-resolution 2D images in the other planes. Using fluorescence confocal microscopy and light-sheet microscopy, we demonstrate that the trained network not only enhances axial resolution beyond the diffraction limit, but also enhances suppressed visual details between the imaging planes and removes imaging artifacts.},
	urldate = {2021-04-28},
	journal = {arXiv:2104.09435 [cs, stat]},
	author = {Park, Hyoungjun and Na, Myeongsu and Kim, Bumju and Park, Soohyun and Kim, Ki Hean and Chang, Sunghoe and Ye, Jong Chul},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.09435},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{mozumder_model-based_2021,
	title = {A model-based iterative learning approach for diffuse optical tomography},
	url = {http://arxiv.org/abs/2104.09579},
	abstract = {Diffuse optical tomography (DOT) utilises near-infrared light for imaging spatially distributed optical parameters, typically the absorption and scattering coefficients. The image reconstruction problem of DOT is an ill-posed inverse problem, due to the non-linear light propagation in tissues and limited boundary measurements. The ill-posedness means that the image reconstruction is sensitive to measurement and modelling errors. The Bayesian approach for the inverse problem of DOT offers the possibility of incorporating prior information about the unknowns, rendering the problem less ill-posed. It also allows marginalisation of modelling errors utilising the so-called Bayesian approximation error method. A more recent trend in image reconstruction techniques is the use of deep learning techniques, which have shown promising results in various applications from image processing to tomographic reconstructions. In this work, we study the non-linear DOT inverse problem of estimating the absorption and scattering coefficients utilising a `model-based' learning approach, essentially intertwining learned components with the model equations of DOT. The proposed approach was validated with 2D simulations and 3D experimental data. We demonstrated improved absorption and scattering estimates for targets with a mix of smooth and sharp image features, implying that the proposed approach could learn image features that are difficult to model using standard Gaussian priors. Furthermore, it was shown that the approach can be utilised in compensating for modelling errors due to coarse discretisation enabling computationally efficient solutions. Overall, the approach provided improved computation times compared to a standard Gauss-Newton iteration.},
	urldate = {2021-04-28},
	journal = {arXiv:2104.09579 [physics]},
	author = {Mozumder, Meghdoot and Hauptmann, Andreas and Nissilä, Ilkka and Arridge, Simon R. and Tarvainen, Tanja},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.09579},
	keywords = {Physics - Computational Physics},
}

@book{packhauser_is_2021,
	title = {Is {Medical} {Chest} {X}-ray {Data} {Anonymous}?},
	abstract = {With the rise and ever-increasing potential of deep learning techniques in recent years, publicly available medical data sets became a key factor to enable reproducible development of diagnostic algorithms in the medical domain. Medical data contains sensitive patient-related information and is therefore usually anonymized by removing patient identifiers, e.g., patient names before publication. To the best of our knowledge, we are the first to show that a well-trained deep learning system is able to recover the patient identity from chest X-ray data. We demonstrate this using the publicly available large-scale ChestX-ray14 dataset, a collection of 112,120 frontal-view chest X-ray images from 30,805 unique patients. Our verification system is able to identify whether two frontal chest X-ray images are from the same person with an AUC of 0.9940 and a classification accuracy of 95.55\%. We further highlight that the proposed system is able to reveal the same person even ten and more years after the initial scan. When pursuing a retrieval approach, we observe an mAP@R of 0.9748 and a precision@1 of 0.9963. Based on this high identification rate, a potential attacker may leak patient-related information and additionally cross-reference images to obtain more information. Thus, there is a great risk of sensitive content falling into unauthorized hands or being disseminated against the will of the concerned patients. Especially during the COVID-19 pandemic, numerous chest X-ray datasets have been published to advance research. Therefore, such data may be vulnerable to potential attacks by deep learning-based re-identification algorithms.},
	author = {Packhäuser, Kai and Gündel, Sebastian and Münster, Nicolas and Syben, Christopher and Christlein, Vincent and Maier, Andreas},
	month = mar,
	year = {2021},
	keywords = {deep learning, privacy, xray},
}

@misc{noauthor_histocartographyhistocartography_2021,
	title = {histocartography/histocartography},
	copyright = {AGPL-3.0 License         ,                 AGPL-3.0 License},
	url = {https://github.com/histocartography/histocartography},
	abstract = {Histocartography is a framework bringing together AI and Digital Pathology},
	urldate = {2021-04-22},
	publisher = {histocartography},
	month = apr,
	year = {2021},
	note = {original-date: 2019-11-27T10:10:55Z},
	keywords = {histopathology},
}

@article{manas_seasonal_2021,
	title = {Seasonal {Contrast}: {Unsupervised} {Pre}-{Training} from {Uncurated} {Remote} {Sensing} {Data}},
	shorttitle = {Seasonal {Contrast}},
	url = {http://arxiv.org/abs/2103.16607},
	abstract = {Remote sensing and automatic earth monitoring are key to solve global-scale challenges such as disaster prevention, land use monitoring, or tackling climate change. Although there exist vast amounts of remote sensing data, most of it remains unlabeled and thus inaccessible for supervised learning algorithms. Transfer learning approaches can reduce the data requirements of deep learning algorithms. However, most of these methods are pre-trained on ImageNet and their generalization to remote sensing imagery is not guaranteed due to the domain gap. In this work, we propose Seasonal Contrast (SeCo), an effective pipeline to leverage unlabeled data for in-domain pre-training of remote sensing representations. The SeCo pipeline is composed of two parts. First, a principled procedure to gather large-scale, unlabeled and uncurated remote sensing datasets containing images from multiple Earth locations at different timestamps. Second, a self-supervised algorithm that takes advantage of time and position invariance to learn transferable representations for remote sensing applications. We empirically show that models trained with SeCo achieve better performance than their ImageNet pre-trained counterparts and state-of-the-art self-supervised learning methods on multiple downstream tasks. The datasets and models in SeCo will be made public to facilitate transfer learning and enable rapid progress in remote sensing applications.},
	language = {en},
	urldate = {2021-04-22},
	journal = {arXiv:2103.16607 [cs]},
	author = {Mañas, Oscar and Lacoste, Alexandre and Giro-i-Nieto, Xavier and Vazquez, David and Rodriguez, Pau},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.16607},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{lomakin_spatial_2021,
	title = {Spatial genomics maps the structure, character and evolution of cancer clones},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.04.16.439912v1},
	doi = {10.1101/2021.04.16.439912},
	abstract = {{\textless}p{\textgreater}Subclonality is a universal feature of cancers yet how clones grow, are spatially organised, differ phenotypically or influence clinical outcome is unclear. To address this, we developed base specific in situ sequencing (BaSISS). In fixed tissues, transcripts harbouring clone-defining mutations are detected, converted into quantitative clone maps and characterised through multi-layered data integration. Applied to 8 samples from key stages of breast cancer progression BaSISS localised 1.42 million genotype informative transcripts across 4.9cm2 of tissue. Microscopic clonal topographies are shaped by resident tissue architectures. Distinct transcriptional, histological and immunological features distinguish coexistent genetic clones. Spatial lineage tracing temporally orders clone features associated with the emergence of aggressive clinical traits. These results highlight the pivotal role of spatial genomics in deciphering the mechanisms underlying cancer progression.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-04-18},
	journal = {bioRxiv},
	author = {Lomakin, Artem and Svedlund, Jessica and Strell, Carina and Gataric, Milana and Shmatko, Artem and Park, Jun Sung and Ju, Young Seok and Dentro, Stefan and Kleshchevnikov, Vitalii and Vaskivskyi, Vasyl and Li, Tong and Bayraktar, Omer Ali and Moore, Luiza and Pinder, Sarah and Richardson, Andrea L. and Campbell, Peter J. and Gerstung, Moritz and Nilsson, Mats and Yates, Lucy R.},
	month = apr,
	year = {2021},
	pages = {2021.04.16.439912},
}

@misc{noauthor_acm_nodate,
	title = {{ACM} 2019 {Comorbidity} {Causal} {Network}.pdf},
	url = {https://www.dropbox.com/scl/fi/ryg6guztdeilu9k3p11i5/ACM-2019-Comorbidity-Causal-Network.pdf?dl=0&oref=e&r=ABb6l00AjlyssJo_ij8Mp0Em2Z9qepQAoMgmFs1xWWGTkYB-mQHyMqauXd2waljZ2lIbKNZxCpI5oLe7ttBl_To1cRN1rS0CrbwcWE45reVUQCL0-quEJbAkfn3gAinevN3d9oOlNU3NeVY4z4FAAWBOzBloeUD2mdO-ZmENvWvwf0m7ZGG6BxVN4PRB45L8jio&sm=1},
	abstract = {Shared with Dropbox},
	language = {en},
	urldate = {2021-04-16},
	journal = {Dropbox},
	keywords = {causality, network},
}

@misc{noauthor_self-supervised_nodate,
	title = {Self-supervised learning: {The} dark matter of intelligence},
	shorttitle = {Self-supervised learning},
	url = {https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/},
	abstract = {How can we build machines with human-level intelligence? There’s a limit to how far the field of AI can go with supervised learning alone. Here's why self-supervised learning is one of the most promising ways to make significant progress in AI.},
	language = {en},
	urldate = {2021-04-15},
	keywords = {self-supervised},
}

@article{schilling_quantifying_2021,
	title = {Quantifying the separability of data classes in neural networks},
	doi = {10.1016/j.neunet.2021.03.035},
	abstract = {We introduce the Generalized Discrimination Value (GDV) that measures, in a non-invasive manner, how well different data classes separate in each given layer of an artificial neural network. It turns out that, at the end of the training period, the GDV in each given layer L attains a highly reproducible value, irrespective of the initialization of the network’s connection weights. In the case of multi-layer perceptrons trained with error backpropagation, we find that classification of highly complex data sets requires a temporal reduction of class separability, marked by a characteristic’energy barrier’ in the initial part of the GDV(L) curve. Even more surprisingly, for a given data set, the GDV(L) is running through a fixed’master curve’, independently from the total number of network layers. Finally, due to its invariance with respect to dimensionality, the GDV may serve as a useful tool to compare the internal representational dynamics of artificial neural networks with different architectures for neural architecture search or network compression; or even with brain activity in order to decide between different candidate models of brain function.},
	journal = {Neural Networks},
	author = {Schilling, Achim and Maier, Andreas and Gerum, Richard and Metzner, Claus and Krauss, Patrick},
	month = apr,
	year = {2021},
	keywords = {architecture, neural network, statistics},
}

@article{mathiasen_fast_2020,
	title = {Fast {Fr}{\textbackslash}'echet {Inception} {Distance}},
	url = {http://arxiv.org/abs/2009.14075},
	abstract = {The Fr{\textbackslash}'echet Inception Distance (FID) has been used to evaluate thousands of generative models. We present a novel algorithm, FastFID, which allows fast computation and backpropagation for FID. FastFID can efficiently (1) evaluate generative model *during* training and (2) construct adversarial examples for FID.},
	urldate = {2021-04-08},
	journal = {arXiv:2009.14075 [cs, stat]},
	author = {Mathiasen, Alexander and Hvilshøj, Frederik},
	month = sep,
	year = {2020},
	note = {arXiv: 2009.14075},
	keywords = {Computer Science - Machine Learning, Deep Learning, Frechet, GAN, Statistics, Statistics - Machine Learning},
}

@article{fricker_analyzer_2018,
	title = {{AnalyzER} v1},
	url = {https://ora.ox.ac.uk/objects/uuid:cb0e2845-2a9c-495a-84f0-4dd2c5164463},
	abstract = {The endoplasmic reticulum (ER) is a highly dynamic polygonal membrane network composed of interconnected tubules and sheets (cisternae) that forms the first compartment in the secretory pathway involved in protein translocation, folding, glycosylation, quality control, lipid synthesis, calcium signalling, and metabolon formation. Despite its central role in this plethora of biosynthetic, metabolic and physiological processes, there is little quantitative information on ER structure, morphology or dynamics. Here we describe a software package (AnalyzER) to automatically extract ER tubules and cisternae from multi-dimensional fluorescence images of plant ER. The structure, topology, protein-localisation patterns, and dynamics are automatically quantified using spatial, intensity and graph-theoretic metrics. We validate the method against manually-traced ground-truth networks, and calibrate the sub-resolution width estimates against ER profiles identified in serial block-face SEM images. We apply the approach to quantify the effects on ER morphology of drug treatments, abiotic stress and over-expression of ER tubule-shaping and cisternal-modifying proteins.},
	language = {en},
	urldate = {2021-04-07},
	author = {Fricker, Mark D.},
	year = {2018},
	note = {Publisher: University of Oxford},
	keywords = {ER, graphs, sheets, tubules},
}

@article{thompson_improved_2021,
	title = {Improved {Contrast} in {Images} of {Exoplanets} using {Direct} {SNR} {Optimization}},
	url = {http://arxiv.org/abs/2103.09252},
	abstract = {Direct imaging of exoplanets is usually limited by quasi-static speckles. These uncorrected aberrations in a star's point spread function (PSF) obscure faint companions and limit the sensitivity of high-contrast imaging instruments. Most current approaches to processing differential imaging sequences like angular differential imaging (ADI) and spectral differential imaging (SDI) produce a self-calibrating dataset that are combined in a linear least squares solution to minimize the noise. Due to temporal and chromatic evolution of a telescope's PSF, the best correlated reference images are usually the most contaminated by the planet, leading to self-subtraction and reducing the planet throughput. In this paper, we present an algorithm that directly optimizes the non-linear equation for planet signal to noise ratio (SNR). This new algorithm does not require us to reject adjacent reference images and optimally balances noise reduction with self-subtraction. We then show how this algorithm can be applied to multiple images simultaneously for a further reduction in correlated noise, directly maximizing the SNR of the final combined image. Finally, we demonstrate the technique on an illustrative sequence of HR8799 using the new Julia-based Signal to Noise Analysis Pipeline (SNAP). We show that SNR optimization can provide up to a \$5{\textbackslash}times\$ improvement in contrast close to the star. Applicable to both new and archival data, this technique will allow for the detection of lower mass, and closer in companions, or achieve the same sensitivity with less telescope time.},
	urldate = {2021-04-06},
	journal = {arXiv:2103.09252 [astro-ph]},
	author = {Thompson, William and Marois, Christian},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.09252},
	keywords = {Astrophysics - Earth and Planetary Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, astronomy, imaging, microscopy, psf, snr},
}

@article{rodriguezleyva_parkinson_2016,
	title = {Parkinson disease and progressive supranuclear palsy: protein expression in skin},
	volume = {3},
	copyright = {© 2016 The Authors. Annals of Clinical and Translational Neurology published by Wiley Periodicals, Inc on behalf of American Neurological Association.},
	issn = {2328-9503},
	shorttitle = {Parkinson disease and progressive supranuclear palsy},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/acn3.285},
	doi = {https://doi.org/10.1002/acn3.285},
	abstract = {Objective This study characterizes the expression of tau (p-tau) and α-synuclein (α-syn) by immunohistochemistry in the skin of three different populations: healthy control (HC), Parkinson disease (PD), and progressive supranuclear paralysis (PSP) subjects, with the purpose of finding a biomarker that could differentiate between subjects with PD and PSP. Material and Methods We evaluated the presence of p-tau and α-syn in a pilot study in the skin of three distinct groups of patients: 17 healthy subjects, 17 patients with PD, and 10 patients with PSP. Four millimeters punch biopsies were obtained from the occipital area and analyzed by immunohistochemistry using antibodies against α-syn and phosphorylated species of tau. PHF (paired helical filaments) antibody identifies p-tau in both normal and pathological conditions and AT8 recognizes p-tau characteristic of pathological conditions. Differences between the three groups were assessed by quantification of immunopositive areas in the epidermis. Results The immunopositivity pattern of p-tau and α-syn was significantly different among the three groups. Healthy subjects showed minimal staining using AT8 and α-syn. The PD group showed significantly higher α-syn and AT8 immunopositivity, while the PSP group only expressed higher AT8 immunopositivity than HCs. Conclusion These data suggest that the skin reflects brain pathology. Therefore, immunohistochemical analysis of p-tau and α-syn in the skin can be useful for further characterization of PD and PSP.},
	language = {en},
	number = {3},
	urldate = {2021-04-06},
	journal = {Annals of Clinical and Translational Neurology},
	author = {Rodríguez‐Leyva, Ildefonso and Chi‐Ahumada, Erika G. and Carrizales, Juan and Rodríguez‐Violante, Mayela and Velázquez‐Osuna, Salvador and Medina‐Mier, Verónica and Martel‐Gallegos, María G. and Zarazúa, Sergio and Enríquez‐Macías, Lourdes and Castro, Adriana and Calderón–Garcidueñas, Ana Laura and Jiménez‐Capdeville, María E.},
	year = {2016},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/acn3.285},
	keywords = {palsy, parkinson, skin},
	pages = {191--199},
}

@article{rodriguezleyva_presence_2017,
	title = {The {Presence} of {Alpha}-{Synuclein} in {Skin} from {Melanoma} and {Patients} with {Parkinson}'s {Disease}},
	volume = {4},
	copyright = {© 2017 International Parkinson and Movement Disorder Society},
	issn = {2330-1619},
	url = {https://movementdisorders.onlinelibrary.wiley.com/doi/abs/10.1002/mdc3.12494},
	doi = {https://doi.org/10.1002/mdc3.12494},
	abstract = {Background The misfolding and prion-like propagation of the protein α-synuclein (α-syn) is the leading molecular signature in Parkinson's disease (PD). There is a significant coincidence of PD and melanoma that may suggest a shared pathophysiology. This study compared the presence of α-syn in neural crest-derived tissues, such as nevi, melanoma, skin tags, and skin biopsies from patients with PD and healthy controls. Methods Biopsies from participants with PD were obtained from patients from a tertiary referral center for dermatology and neurology in Mexico and a private dermatopathology center in Florida between January 2015 and March 2016. Biopsies from 7 patients with melanoma, 15 with nevi, 9 with skin tags, 8 with PD, and 9 skin biopsies from healthy volunteers were analyzed for immunohistochemical determination of α-syn and tyrosinase. All analyses were performed by pathologists who were blinded with respect to the clinical diagnosis. Results In healthy controls, positive α-syn status was restricted to scattered cells in the basal layer of the epidermis and accounted for 1 ± 0.8\% of the analyzed area. In patients with PD, there was increased staining for α-syn PD (3.3 ± 2.3\%), with a higher percentage of positive cells in nevi (7.7 ± 5.5\%) and melanoma (13.6 ± 3.5\%). There was no increased staining in skin tags compared with healthy controls. Conclusion Patients with PD and melanoma have increased staining for α-syn in their skin. The authors propose that neurons and melanocytes, both derived from neuroectodermal cells, may share protein synthesis and regulation pathways that become dysfunctional in PD and melanoma.},
	language = {en},
	number = {5},
	urldate = {2021-04-06},
	journal = {Movement Disorders Clinical Practice},
	author = {Rodriguez‐Leyva, Ildefonso and Chi‐Ahumada, Erika and Mejía, Manuel and Castanedo‐Cazares, Juan P. and Eng, William and Saikaly, Sami K. and Carrizales, Juan and Levine, Todd D. and Norman, Robert A. and Jimenez‐Capdeville, Maria E.},
	year = {2017},
	note = {\_eprint: https://movementdisorders.onlinelibrary.wiley.com/doi/pdf/10.1002/mdc3.12494},
	keywords = {Parkinson disease, alzheimer, melanoma, parkinson, proteinopathies, skin, α-synuclein},
	pages = {724--732},
}

@article{betensky_p-value_2019,
	title = {The p-{Value} {Requires} {Context}, {Not} a {Threshold}},
	volume = {73},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2018.1529624},
	doi = {10.1080/00031305.2018.1529624},
	abstract = {It is widely recognized by statisticians, though not as widely by other researchers, that the p-value cannot be interpreted in isolation, but rather must be considered in the context of certain features of the design and substantive application, such as sample size and meaningful effect size. I consider the setting of the normal mean and highlight the information contained in the p-value in conjunction with the sample size and meaningful effect size. The p-value and sample size jointly yield 95\% confidence bounds for the effect of interest, which can be compared to the predetermined meaningful effect size to make inferences about the true effect. I provide simple examples to demonstrate that although the p-value is calculated under the null hypothesis, and thus seemingly may be divorced from the features of the study from which it arises, its interpretation as a measure of evidence requires its contextualization within the study. This implies that any proposal for improved use of the p-value as a measure of the strength of evidence cannot simply be a change to the threshold for significance.},
	number = {sup1},
	urldate = {2021-04-03},
	journal = {The American Statistician},
	author = {Betensky, Rebecca A.},
	month = mar,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2018.1529624},
	keywords = {Effect size, Sample size, Statistical significance, significance, statistics},
	pages = {115--117},
}

@article{krueger_putting_2019,
	title = {Putting the {P}-{Value} in its {Place}},
	volume = {73},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2018.1470033},
	doi = {10.1080/00031305.2018.1470033},
	abstract = {As the debate over best statistical practices continues in academic journals, conferences, and the blogosphere, working researchers (e.g., psychologists) need to figure out how much time and effort to invest in attending to experts' arguments, how to design their next project, and how to craft a sustainable long-term strategy for data analysis and inference. The present special issue of The American Statistician promises help. In this article, we offer a modest proposal for a continued and informed use of the conventional p-value without the pitfalls of statistical rituals. Other statistical indices should complement reporting, and extra-statistical (e.g., theoretical) judgments ought to be made with care and clarity.},
	number = {sup1},
	urldate = {2021-04-03},
	journal = {The American Statistician},
	author = {Krueger, Joachim I. and Heck, Patrick R.},
	month = mar,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2018.1470033},
	keywords = {Bayes' theorem, Inference, Null hypotheses, Statistical significance testing, p-values, significance, statistics},
	pages = {122--128},
}

@article{landy_texture_nodate,
	title = {Texture analysis and perception},
	language = {en},
	author = {Landy, Michael S},
	pages = {26},
}

@article{gaver_what_2012,
	title = {What {Should} {We} {Expect} {From} {Research} {Through} {Design}?},
	doi = {10.1145/2207676.2208538},
	abstract = {In this essay, I explore several facets of research through design in order to contribute to discussions about how the approach should develop. The essay has three parts. In the first, I review two influential theories from the Philosophy of Science to help reflect on the nature of design theory, concluding that research through design is likely to produce theories that are provisional, contingent, and aspirational. In the second part, I discuss three possible interpretations for the diversity of approaches to research through design, and suggest that this variation need not be seen as a sign of inadequate standards or a lack of cumulative progress in the field, but may be natural for a generative endeavour. In the final section, I suggest that, rather than aiming to develop increasingly comprehensive theories of design, practice based research might better view theory as annotation of realised design examples, and particularly portfolios of related pieces. Overall, I suggest that the design research community should be wary of impulses towards convergence and standardisation, and instead take pride in its aptitude for exploring and speculating, particularising and diversifying, and - especially - its ability to manifest the results in the form of new, conceptually rich artefacts.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Gaver, William},
	month = may,
	year = {2012},
	keywords = {HCI, design, philsophy of science},
}

@article{kraus_during_2015,
	title = {During running in place, grid cells integrate elapsed time and distance run},
	volume = {88},
	issn = {0896-6273},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4635558/},
	doi = {10.1016/j.neuron.2015.09.031},
	abstract = {The spatial scale of grid cells may be provided by self-generated motion information or by external sensory information from environmental cues. To determine whether grid cell activity reflects distance traveled or elapsed time independent of external information, we recorded grid cells as animals ran in place on a treadmill. Grid cell activity was only weakly influenced by location but most grid cells and other neurons recorded from the same electrodes strongly signaled a combination of distance and time, with some signaling only distance or time. Grid cells were more sharply tuned to time and distance than non-grid cells. Many grid cells exhibited multiple firing fields during treadmill running, parallel to the periodic firing fields observed in open fields, suggesting a common mode of information processing. These observations indicate that, in the absence of external dynamic cues, grid cells integrate self-generated distance and time information to encode a representation of experience.},
	number = {3},
	urldate = {2021-04-01},
	journal = {Neuron},
	author = {Kraus, Benjamin J. and Brandon, Mark P. and Robinson, Robert J. and Connerney, Michael A. and Hasselmo, Michael E. and Eichenbaum, Howard},
	month = nov,
	year = {2015},
	pmid = {26539893},
	pmcid = {PMC4635558},
	keywords = {memory, neurology},
	pages = {578--589},
}

@article{ho_mitochondrial_2017,
	title = {Mitochondrial {Control} and {Guidance} of {Cellular} {Activities} of {T} {Cells}},
	volume = {8},
	doi = {10.3389/fimmu.2017.00473},
	abstract = {Immune cells protect us against infection and cancer cells, as well as functioning during healing processes to support tissue repairing and regeneration. These behaviors require that upon stimulation from immune activation the appropriate subsets of immune cells are generated. In addition to activation-induced signaling cascades, metabolic reprogramming (profound changes in metabolic pathways) also provides a novel form of regulation to control the formation of desirable immune responses. Immune cells encounter various nutrient compositions by circulating in bloodstream and infiltrating into peripheral tissues; therefore, proper engagement of metabolic pathways is critical to fulfill the metabolic demands of immune cells. Metabolic pathways are tightly regulated mainly via mitochondrial dynamics and the activities of the tricarboxylic acid cycle and the electron transport chain. In this review, we will discuss how metabolic reprogramming influences activation, effector functions, and lineage polarization in T cells, with a particular focus on mitochondria-regulated metabolic checkpoints. Additionally, we will further explore how in various diseases deregulation and manipulation of mitochondrial regulation can occur and be exploited. Furthermore, we will discuss how this knowledge can facilitate the design of immunotherapies.},
	journal = {Frontiers in Immunology},
	author = {Ho, Ping-Chih and Chao, Tung and Haiping, Wang},
	month = apr,
	year = {2017},
	keywords = {mitochondria},
}

@article{heddleston_guide_2021,
	title = {A guide to accurate reporting in digital image acquisition – can anyone replicate your microscopy data?},
	volume = {134},
	issn = {0021-9533, 1477-9137},
	url = {http://jcs.biologists.org/lookup/doi/10.1242/jcs.254144},
	doi = {10.1242/jcs.254144},
	abstract = {Recent technological advances have made microscopy indispensable in life science research. Its ubiquitous use, in turn, underscores the importance of ensuring that microscopy-based experiments are replicable and that the resulting data comparable. While there has been a wealth of review articles, practical guides and conferences devoted to the topic of maintaining standard instrument operating conditions, the paucity of attention dedicated to properly documenting microscopy experiments is undeniable. This lack of emphasis on accurate reporting extends beyond life science researchers themselves, to the review panels and editorial boards of many journals. Such oversight at the final step of communicating a scientific discovery can unfortunately negate the many valiant efforts made to ensure experimental quality control in the name of scientific reproducibility. This Review aims to enumerate the various parameters that should be reported in an imaging experiment by illustrating how their inconsistent application can lead to irreconcilable results.},
	language = {en},
	number = {6},
	urldate = {2021-03-31},
	journal = {Journal of Cell Science},
	author = {Heddleston, John M. and Aaron, Jesse S. and Khuon, Satya and Chew, Teng-Leong},
	month = mar,
	year = {2021},
	pages = {jcs254144},
}

@article{courtiol_deep_2019,
	title = {Deep learning-based classification of mesothelioma improves prediction of patient outcome},
	volume = {25},
	issn = {1078-8956, 1546-170X},
	url = {http://www.nature.com/articles/s41591-019-0583-3},
	doi = {10.1038/s41591-019-0583-3},
	language = {en},
	number = {10},
	urldate = {2021-03-30},
	journal = {Nature Medicine},
	author = {Courtiol, Pierre and Maussion, Charles and Moarii, Matahi and Pronier, Elodie and Pilcer, Samuel and Sefta, Meriem and Manceron, Pierre and Toldo, Sylvain and Zaslavskiy, Mikhail and Le Stang, Nolwenn and Girard, Nicolas and Elemento, Olivier and Nicholson, Andrew G. and Blay, Jean-Yves and Galateau-Sallé, Françoise and Wainrib, Gilles and Clozel, Thomas},
	month = oct,
	year = {2019},
	pages = {1519--1525},
}

@article{ren_mitochondrial_2020,
	title = {Mitochondrial {Dynamics} {Imbalance}: {A} {Strategy} for {Promoting} {Viral} {Infection}},
	volume = {11},
	shorttitle = {Mitochondrial {Dynamics} {Imbalance}},
	doi = {10.3389/fmicb.2020.01992},
	abstract = {Mitochondria are highly dynamic organelles that maintain the dynamic balance of split-fusion via kinetic proteins. This maintains the stability of their morphological functions. This dynamic balance is highly susceptible to various stress environments, including viral infection. After viral infection, the dynamic balance of the host cell mitochondria is disturbed, affecting the processes of energy generation, metabolism, and innate immunity. This creates an intracellular environment that is conducive to viral proliferation and begins the process of its own infection and causes further damage to the body. Herein, we discuss the mechanism of the virus-induced mitochondrial dynamics imbalance and its subsequent effects on the body, which will help to improve our understanding of the relationship between mitochondrial dynamics and viral infection and its importance.},
	journal = {Frontiers in Microbiology},
	author = {Ren, Zhihua and Zhang, Xiaojie and Ding, Ting and Zhong, Zhijun and Hu, Hui and Xu, Zhiwen and Deng, Junliang},
	month = aug,
	year = {2020},
	keywords = {mitochondria},
	pages = {1992},
}

@book{moyer_overview_2020,
	title = {Overview of {Scanner} {Invariant} {Representations}},
	abstract = {Pooled imaging data from multiple sources is subject to bias from each source. Studies that do not correct for these scanner/site biases at best lose statistical power, and at worst leave spurious correlations in their data. Estimation of the bias effects is non-trivial due to the paucity of data with correspondence across sites, so called "traveling phantom" data, which is expensive to collect. Nevertheless, numerous solutions leveraging direct correspondence have been proposed. In contrast to this, Moyer et al. (2019) proposes an unsupervised solution using invariant representations, one which does not require correspondence and thus does not require paired images. By leveraging the data processing inequality, an invariant representation can then be used to create an image reconstruction that is uninformative of its original source, yet still faithful to the underlying structure. In the present abstract we provide an overview of this method.},
	author = {Moyer, Daniel and Ver Steeg, Greg and Thompson, Paul},
	month = may,
	year = {2020},
	keywords = {bias, harmonization, scanner invariance},
}

@incollection{dinsdale_unlearning_2020,
	title = {Unlearning {Scanner} {Bias} for {MRI} {Harmonisation}},
	isbn = {978-3-030-59712-2},
	abstract = {Combining datasets is vital for increased statistical power, especially for neurological conditions where limited data is available. However, variance due to differences in acquisition protocol and hardware limits our ability to combine datasets. We propose an iterative training scheme based on domain adaptation techniques, aiming to create scanner-invariant features while simultaneously maintaining overall performance on the main task. We demonstrate this on age prediction, but expect that our proposed training scheme will be applicable to any feedforward network and classification or regression task. We show that not only can we harmonise three MRI datasets from different studies, but can also successfully adapt the training to work with very biased datasets. The training scheme should, therefore, be applicable to most real-world data scenarios, enabling harmonisation for the task of interest.},
	author = {Dinsdale, Nicola and Jenkinson, Mark and Namburete, Ana},
	month = sep,
	year = {2020},
	doi = {10.1007/978-3-030-59713-9_36},
	keywords = {harmonisation, scanner bias},
	pages = {369--378},
}

@book{moyer_harmonization_2021,
	title = {Harmonization and the {Worst} {Scanner} {Syndrome}},
	abstract = {We show that for a wide class of harmonization/domain-invariance schemes several undesirable properties are unavoidable. If a predictive machine is made invariant to a set of domains, the accuracy of the output predictions (as measured by mutual information) is limited by the domain with the least amount of information to begin with. If a real label value is highly informative about the source domain, it cannot be accurately predicted by an invariant predictor. These results are simple and intuitive, but we believe that it is beneficial to state them for medical imaging harmonization.},
	author = {Moyer, Daniel and Golland, Polina},
	month = jan,
	year = {2021},
	keywords = {harmonization, invariance},
}

@article{grafe_quantitative_2021,
	title = {Quantitative {T1} mapping of the normal brain from early infancy to adulthood},
	volume = {51},
	doi = {10.1007/s00247-020-04842-7},
	abstract = {Background
Quantitative mapping of MRI relaxation times is expected to uncover pathological processes in the brain more subtly than standard MRI techniques with weighted contrasts. So far, however, most mapping techniques suffer from a long measuring time, low spatial resolution or even sensitivity to magnetic field inhomogeneity.

Objective
To obtain T1 relaxation times of the normal brain from early infancy to adulthood using a novel technique for fast and accurate T1 mapping at high spatial resolution.

Materials and methods
We performed whole-brain T1 mapping within less than 3 min in 100 patients between 2 months and 18 years of age with normal brain at a field strength of 3 T. We analyzed T1 relaxation times in several gray-matter nuclei and white matter. Subsequently, we derived regression equations for mean value and confidence interval.

Results
T1 relaxation times of the pediatric brain rapidly decrease in all regions within the first 3 years of age, followed by a significantly weaker decrease until adulthood. These characteristics are more pronounced in white matter than in deep gray matter.

Conclusion
Regardless of age, quantitative T1 mapping of the pediatric brain is feasible in clinical practice. Normal age-dependent values should contribute to improved discrimination of subtle intracerebral alterations.},
	journal = {Pediatric Radiology},
	author = {Gräfe, Daniel and Frahm, Jens and Voit, Dirk and Hirsch, Franz},
	month = mar,
	year = {2021},
	keywords = {MRI, brain, temporal},
	pages = {1--7},
}

@article{hirsch_real-time_2021,
	title = {Real-time magnetic resonance imaging in pediatric radiology — new approach to movement and moving children},
	doi = {10.1007/s00247-020-04828-5},
	abstract = {The recent development of highly undersampled radial gradient echo sequences in combination with nonlinear inverse image reconstruction now allows for MRI examinations in real time. Image acquisition times as short as 20 ms yield MRI videos with rates of up to 50 frames per second with spin density, T1- and T2-type contrast. The addition of an initial 180° inversion pulse achieves accurate T1 mapping within only 4 s. These technical advances promise specific advantages for studies of infants and young children by eliminating the need for sedation or anesthesia. Our preliminary data demonstrate new diagnostic opportunities ranging from dynamic studies of speech and swallowing processes and body movements to a rapid volumetric assessment of brain cerebrospinal fluid spaces in only few seconds. Real-time MRI of the heart and blood flow can be performed without electrocardiogram gating and under free breathing. The present findings support the idea that real-time MRI will complement existing methods by providing long-awaited diagnostic options for patients in early childhood. Major advantages are the avoidance of sedation or anesthesia and the yet unexplored potential to gain insights into arbitrary body functions.},
	journal = {Pediatric Radiology},
	author = {Hirsch, Franz and Frahm, Jens and Sorge, Ina and Roth, Christian and Voit, Dirk and Gräfe, Daniel},
	month = feb,
	year = {2021},
	keywords = {MRI, brain, temporal},
}

@article{changyong_log-transformation_2014,
	title = {Log-transformation and its implications for data analysis},
	volume = {26},
	number = {2},
	journal = {Shanghai archives of psychiatry},
	author = {Changyong, FENG and Hongyue, WANG and Naiji, L. U. and Tian, CHEN and Hua, H. E. and Ying, L. U.},
	year = {2014},
	note = {Publisher: Shanghai Mental Health Center},
	pages = {105},
}

@article{weber_ultrasound_2021,
	title = {Ultrasound differential phase contrast using backscattering and the memory effect},
	volume = {118},
	issn = {0003-6951},
	url = {https://aip.scitation.org/doi/10.1063/5.0048071},
	doi = {10.1063/5.0048071},
	abstract = {We describe a simple and fast technique to perform ultrasound differential phase contrast (DPC) imaging in arbitrarily thick scattering media. Although configured in a reflection geometry, DPC is based on transmission imaging and is a direct analog of optical differential interference contrast. DPC exploits the memory effect and works in combination with standard pulse-echo imaging, with no additional hardware or data requirements, enabling complementary phase contrast (in the transverse direction) without any need for intensive numerical computation. We experimentally demonstrate the principle of DPC using tissue phantoms with calibrated speed-of-sound inclusions.},
	number = {12},
	urldate = {2021-03-28},
	journal = {Applied Physics Letters},
	author = {Weber, Timothy D. and Khetan, Nikunj and Yang, Ruohui and Mertz, Jerome},
	month = mar,
	year = {2021},
	note = {Publisher: American Institute of Physics},
	keywords = {ultrasound},
	pages = {124103},
}

@incollection{ahmed_chapter_2019,
	title = {Chapter 7 - {Pharmacological} {Effects} of {Curcuminoids} in {Neurological} {Disorders}},
	isbn = {978-0-12-815461-8},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128154618000074},
	abstract = {Neurological disorders are major cause of morbidity and mortality. There are very limited therapeutic options available for curing most neurological disorders. This is due to the complex nature of nervous system and its disorders. Medicinal plants have a long history of use for various treatments, and are source of large number of drugs. Curcuminoids (a mixture of curcumin, bisdemethoxycurcumin, and demethoxycurcumin) have been extensively studied and shown a huge therapeutic significance for neurological disorders with limited side effects. Though, curcumin is a vital constituent of the curcuminoids mixture, the other two components (bisdemethoxycurcumin and demethoxycurcumin) which are usually ignored, also play key role in effectiveness of curcuminoids in neurological disorders. Scientific studies have shown the critical, distinctive, and significant role of each component of the curcuminoids in neurological disorders. In conclusion, curcuminoids as a mixture can be a better candidate than individual compound for the treatment of neurological disorders.},
	language = {en},
	urldate = {2021-03-27},
	booktitle = {Curcumin for {Neurological} and {Psychiatric} {Disorders}},
	publisher = {Academic Press},
	author = {Ahmed, Touqeer and Nawaz, Maheen and Iqbal, Waqar},
	editor = {Farooqui, Tahira and Farooqui, Akhlaq A.},
	month = jan,
	year = {2019},
	doi = {10.1016/B978-0-12-815461-8.00007-4},
	keywords = {Curcuminoids, brain, multiple targets, neurological disorders, safety, synergism, treatment},
	pages = {129--154},
}

@book{ellis_essential_2010,
	title = {The essential guide to effect sizes: {Statistical} power, meta-analysis, and the interpretation of research results},
	isbn = {1-139-48815-5},
	publisher = {Cambridge university press},
	author = {Ellis, Paul D.},
	year = {2010},
}

@article{chung_unsupervised_2021,
	title = {Unsupervised {Missing} {Cone} {Deep} {Learning} in {Optical} {Diffraction} {Tomography}},
	url = {http://arxiv.org/abs/2103.09022},
	abstract = {Optical diffraction tomography (ODT) produces three dimensional distribution of refractive index (RI) by measuring scattering fields at various angles. Although the distribution of RI index is highly informative, due to the missing cone problem stemming from the limited-angle acquisition of holograms, reconstructions have very poor resolution along axial direction compared to the horizontal imaging plane. To solve this issue, here we present a novel unsupervised deep learning framework, which learns the probability distribution of missing projection views through optimal transport driven cycleGAN. Experimental results show that missing cone artifact in ODT can be significantly resolved by the proposed method.},
	urldate = {2021-03-26},
	journal = {arXiv:2103.09022 [cs, eess]},
	author = {Chung, Hyungjin and Huh, Jaeyoung and Kim, Geon and Park, Yong Keun and Ye, Jong Chul},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.09022},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, DOT, Deep Learning, Electrical Engineering and Systems Science - Image and Video Processing, reconstruction},
}

@article{huang_belief_2021,
	title = {Belief function-based semi-supervised learning for brain tumor segmentation},
	url = {http://arxiv.org/abs/2102.00097},
	abstract = {Precise segmentation of a lesion area is important for optimizing its treatment. Deep learning makes it possible to detect and segment a lesion field using annotated data. However, obtaining precisely annotated data is very challenging in the medical domain. Moreover, labeling uncertainty and imprecision make segmentation results unreliable. In this paper, we address the uncertain boundary problem by a new evidential neural network with an information fusion strategy, and the scarcity of annotated data by semi-supervised learning. Experimental results show that our proposal has better performance than state-of-the-art methods.},
	urldate = {2021-03-26},
	journal = {arXiv:2102.00097 [cs]},
	author = {Huang, Ling and Ruan, Su and Denoeux, Thierry},
	month = jan,
	year = {2021},
	note = {arXiv: 2102.00097},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, belief theory, semi-supervised},
}

@article{wilson_case_2020,
	title = {The {Case} for {Bayesian} {Deep} {Learning}},
	url = {http://arxiv.org/abs/2001.10995},
	abstract = {The key distinguishing property of a Bayesian approach is marginalization instead of optimization, not the prior, or Bayes rule. Bayesian inference is especially compelling for deep neural networks. (1) Neural networks are typically underspeciﬁed by the data, and can represent many diﬀerent but high performing models corresponding to diﬀerent settings of parameters, which is exactly when marginalization will make the biggest diﬀerence for both calibration and accuracy. (2) Deep ensembles have been mistaken as competing approaches to Bayesian methods, but can be seen as approximate Bayesian marginalization. (3) The structure of neural networks gives rise to a structured prior in function space, which reﬂects the inductive biases of neural networks that help them generalize. (4) The observed correlation between parameters in ﬂat regions of the loss and a diversity of solutions that provide good generalization is further conducive to Bayesian marginalization, as ﬂat regions occupy a large volume in a high dimensional space, and each diﬀerent solution will make a good contribution to a Bayesian model average. (5) Recent practical advances for Bayesian deep learning provide improvements in accuracy and calibration compared to standard training, while retaining scalability.},
	language = {en},
	urldate = {2021-03-26},
	journal = {arXiv:2001.10995 [cs, stat]},
	author = {Wilson, Andrew Gordon},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.10995},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{jensen_correction_2021,
	title = {Correction of multiple-blinking artefacts in photoactivated localisation microscopy},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.03.24.436128v1},
	doi = {10.1101/2021.03.24.436128},
	abstract = {{\textless}p{\textgreater}Photoactivated localisation microscopy (PALM) produces an array of localisation coordinates by means of photoactivatable fluorescent proteins. However, observations are subject to fluorophore multiple-blinking and each protein is included in the dataset an unknown number of times at different positions, due to localisation error. This causes artificial clustering to be observed in the data. We present a workflow using calibration-free estimation of blinking dynamics and model-based clustering, to produce a corrected set of localisation coordinates now representing the true underlying fluorophore locations with enhanced localisation precision. These can be reliably tested for spatial randomness or analysed by other clustering approaches, and previously inestimable descriptors such as the absolute number of fluorophores per cluster are now quantifiable, which we validate with simulated data. Using experimental data, we confirm that the adaptor protein, LAT, is clustered at the T cell immunological synapse, with its nanoscale clustering properties depending on location and intracellular phosphorylatable tyrosine residues.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-03-25},
	journal = {bioRxiv},
	author = {Jensen, Louis G. and Hoh, Tjun Yee and Williamson, David J. and Griffie, Juliette and Sage, Daniel and Rubin-Delanchy, Patrick and Owen, Dylan M.},
	month = mar,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	keywords = {multiple blinking, palm, superresolution},
	pages = {2021.03.24.436128},
}

@book{gu_multi-institutional_2021,
	title = {Multi-institutional {Collaborations} for {Improving} {Deep} {Learning}-based {Magnetic} {Resonance} {Image} {Reconstruction} {Using} {Federated} {Learning}},
	abstract = {Fast and accurate reconstruction of magnetic resonance (MR) images from under-sampled data is important in many clinical applications. In recent years, deep learning-based methods have been shown to produce superior performance on MR image reconstruction. However, these methods require large amounts of data which is difficult to collect and share due to the high cost of acquisition and medical data privacy regulations. In order to overcome this challenge, we propose a federated learning (FL) based solution in which we take advantage of the MR data available at different institutions while preserving patients' privacy. However, the generalizability of models trained with the FL setting can still be suboptimal due to domain shift, which results from the data collected at multiple institutions with different sensors, disease types, and acquisition protocols, etc. With the motivation of circumventing this challenge, we propose a cross-site modeling for MR image reconstruction in which the learned intermediate latent features among different source sites are aligned with the distribution of the latent features at the target site. Extensive experiments are conducted to provide various insights about FL for MR image reconstruction. Experimental results demonstrate that the proposed framework is a promising direction to utilize multi-institutional data without compromising patients' privacy for achieving improved MR image reconstruction. Our code will be available at https://github.com/guopengf/FLMRCM.},
	author = {Gu, Pengfei and Wang, Puyang and Zhou, Jinyuan and Jiang, Shanshan and Patel, Vishal},
	month = mar,
	year = {2021},
	keywords = {FL-MR, federated learning, reconstruction},
}

@article{sanchez-gonzalez_learning_2020,
	title = {Learning to {Simulate} {Complex} {Physics} with {Graph} {Networks}},
	url = {http://arxiv.org/abs/2002.09405},
	abstract = {Here we present a machine learning framework and model implementation that can learn to simulate a wide variety of challenging physical domains, involving fluids, rigid solids, and deformable materials interacting with one another. Our framework---which we term "Graph Network-based Simulators" (GNS)---represents the state of a physical system with particles, expressed as nodes in a graph, and computes dynamics via learned message-passing. Our results show that our model can generalize from single-timestep predictions with thousands of particles during training, to different initial conditions, thousands of timesteps, and at least an order of magnitude more particles at test time. Our model was robust to hyperparameter choices across various evaluation metrics: the main determinants of long-term performance were the number of message-passing steps, and mitigating the accumulation of error by corrupting the training data with noise. Our GNS framework advances the state-of-the-art in learned physical simulation, and holds promise for solving a wide range of complex forward and inverse problems.},
	urldate = {2021-03-24},
	journal = {arXiv:2002.09405 [physics, stat]},
	author = {Sanchez-Gonzalez, Alvaro and Godwin, Jonathan and Pfaff, Tobias and Ying, Rex and Leskovec, Jure and Battaglia, Peter W.},
	month = sep,
	year = {2020},
	note = {arXiv: 2002.09405},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning, deep learning, graphs, physics},
}

@book{xie_joint_2020,
	title = {Joint {Reconstruction} and {Calibration} using {Regularization} by {Denoising}},
	abstract = {Regularization by denoising (RED) is a broadly applicable framework for solving inverse problems by using priors specified as denoisers. While RED has been shown to provide state-of-the-art performance in a number of applications, existing RED algorithms require exact knowledge of the measurement operator characterizing the imaging system, limiting their applicability in problems where the measurement operator has parametric uncertainties. We propose a new method, called Calibrated RED (Cal-RED), that enables joint calibration of the measurement operator along with reconstruction of the unknown image. Cal-RED extends the traditional RED methodology to imaging problems that require the calibration of the measurement operator. We validate Cal-RED on the problem of image reconstruction in computerized tomography (CT) under perturbed projection angles. Our results corroborate the effectiveness of Cal-RED for joint calibration and reconstruction using pre-trained deep denoisers as image priors.},
	author = {Xie, Mingyang and Sun, Yu and Liu, Jiaming and Wohlberg, Brendt and Kamilov, Ulugbek},
	month = nov,
	year = {2020},
}

@article{kim_safe_2021,
	title = {Safe {Learning} and {Optimization} {Techniques}: {Towards} a {Survey} of the {State} of the {Art}},
	shorttitle = {Safe {Learning} and {Optimization} {Techniques}},
	url = {http://arxiv.org/abs/2101.09505},
	abstract = {Safe learning and optimization deals with learning and optimization problems that avoid, as much as possible, the evaluation of non-safe input points, which are solutions, policies, or strategies that cause an irrecoverable loss (e.g., breakage of a machine or equipment, or life threat). Although a comprehensive survey of safe reinforcement learning algorithms was published in 2015, a number of new algorithms have been proposed thereafter, and related works in active learning and in optimization were not considered. This paper reviews those algorithms from a number of domains including reinforcement learning, Gaussian process regression and classiﬁcation, evolutionary algorithms, and active learning. We provide the fundamental concepts on which the reviewed algorithms are based and a characterization of the individual algorithms. We conclude by explaining how the algorithms are connected and suggestions for future research.},
	language = {en},
	urldate = {2021-02-03},
	journal = {arXiv:2101.09505 [cs, math]},
	author = {Kim, Youngmin and Allmendinger, Richard and López-Ibáñez, Manuel},
	month = jan,
	year = {2021},
	note = {arXiv: 2101.09505},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, I.2.8, Mathematics - Optimization and Control},
}

@article{mehta_analytical_2020,
	title = {Analytical review of clustering techniques and proximity measures},
	volume = {53},
	issn = {1573-7462},
	url = {https://doi.org/10.1007/s10462-020-09840-7},
	doi = {10.1007/s10462-020-09840-7},
	abstract = {One of the most fundamental approaches to learn and understand from any type of data is by organizing it into meaningful groups (or clusters) and then analyzing them, which is a process known as cluster analysis. During this process of grouping, proximity measures play a significant role in deciding the similarity level of two objects. Moreover, before applying any learning algorithm on a dataset, different aspects related to preprocessing such as dealing with the sparsity of data, leveraging the correlation among features and normalizing the scales of different features are required to be considered. In this study, various proximity measures have been discussed and analyzed from the aforementioned aspects. In addition, a theoretical procedure for selecting a proximity measure for clustering purpose is proposed. This procedure can also be used in the process of designing a new proximity measure. Second, clustering algorithms of different categories have been overviewed and experimentally compared for various datasets of different domains. The datasets have been chosen in such a way that they range from a very low number of dimensions to a very high number of dimensions. Finally, the effect of using different proximity measures is analyzed in partitional and hierarchical clustering techniques based on experiments.},
	language = {en},
	number = {8},
	urldate = {2020-10-09},
	journal = {Artificial Intelligence Review},
	author = {Mehta, Vivek and Bawa, Seema and Singh, Jasmeet},
	month = dec,
	year = {2020},
	pages = {5995--6023},
}

@article{wu_graph_2020,
	title = {Graph {Learning}-{Based} {Ontology} {Sparse} {Vector} {Computing}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2073-8994/12/9/1562},
	doi = {10.3390/sym12091562},
	abstract = {The ontology sparse vector learning algorithm is essentially a dimensionality reduction trick, i.e., the key components in the p-dimensional vector are taken out, and the remaining components are set to zero, so as to obtain the key information in a certain ontology application background. In the early stage of ontology data processing, the goal of the algorithm is to find the location of key components through the learning of some ontology sample points, if the relevant concepts and structure information of each ontology vertex with p-dimensional vectors are expressed. The ontology sparse vector itself contains a certain structure, such as the symmetry between components and the binding relationship between certain components, and the algorithm can also be used to dig out the correlation and decisive components between the components. In this paper, the graph structure is used to express these components and their interrelationships, and the optimal solution is obtained by using spectral graph theory and graph optimization techniques. The essence of the proposed ontology learning algorithm is to find the decisive vertices in the graph G\&beta;. Finally, two experiments show that the given ontology learning algorithm is effective in similarity calculation and ontology mapping in some specific engineering fields.},
	language = {en},
	number = {9},
	urldate = {2020-09-21},
	journal = {Symmetry},
	author = {Wu, Jianzhang and Sangaiah, Arun Kumar and Gao, Wei},
	month = sep,
	year = {2020},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {graph, graph learning, ontology, sparse vector, spectral graph theory, vector field, vector learning},
	pages = {1562},
}

@article{spahn_whole-cell_2019,
	title = {Whole-{Cell}, {3D}, and {Multicolor} {STED} {Imaging} with {Exchangeable} {Fluorophores}},
	volume = {19},
	issn = {1530-6984},
	url = {https://doi.org/10.1021/acs.nanolett.8b04385},
	doi = {10.1021/acs.nanolett.8b04385},
	abstract = {We demonstrate stimulated emission depletion (STED) microscopy of whole bacterial and eukaryotic cells using fluorogenic labels that reversibly bind to their target structure. A constant exchange of labels guarantees the removal of photobleached fluorophores and their replacement by intact fluorophores, thereby circumventing bleaching-related limitations of STED super-resolution imaging. We achieve a constant labeling density and demonstrate a fluorescence signal for long and theoretically unlimited acquisition times. Using this concept, we demonstrate whole-cell, 3D, multicolor, and live-cell STED microscopy.},
	number = {1},
	urldate = {2020-09-19},
	journal = {Nano Letters},
	author = {Spahn, Christoph and Grimm, Jonathan B. and Lavis, Luke D. and Lampe, Marko and Heilemann, Mike},
	month = jan,
	year = {2019},
	note = {Publisher: American Chemical Society},
	keywords = {STED, fluorescence, mitochondria},
	pages = {500--505},
}

@article{chen_rise_2018,
	title = {The rise of deep learning in drug discovery},
	volume = {23},
	issn = {1359-6446},
	url = {http://www.sciencedirect.com/science/article/pii/S1359644617303598},
	doi = {10.1016/j.drudis.2018.01.039},
	abstract = {Over the past decade, deep learning has achieved remarkable success in various artificial intelligence research areas. Evolved from the previous research on artificial neural networks, this technology has shown superior performance to other machine learning algorithms in areas such as image and voice recognition, natural language processing, among others. The first wave of applications of deep learning in pharmaceutical research has emerged in recent years, and its utility has gone beyond bioactivity predictions and has shown promise in addressing diverse problems in drug discovery. Examples will be discussed covering bioactivity prediction, de novo molecular design, synthesis prediction and biological image analysis.},
	language = {en},
	number = {6},
	urldate = {2020-09-18},
	journal = {Drug Discovery Today},
	author = {Chen, Hongming and Engkvist, Ola and Wang, Yinhai and Olivecrona, Marcus and Blaschke, Thomas},
	month = jun,
	year = {2018},
	keywords = {deep learning, drug, machine learning, review},
	pages = {1241--1250},
}

@article{denham_null-labelling_2020,
	title = {Null-{Labelling}: {A} {Generic} {Approach} for {Learning} in the {Presence} of {Class} {Noise}},
	shorttitle = {Null-{Labelling}},
	url = {/articles/preprint/Null-Labelling_A_Generic_Approach_for_Learning_in_the_Presence_of_Class_Noise/12956918/1},
	doi = {10.36227/techrxiv.12956918.v1},
	abstract = {Datasets containing class noise present significant challenges to accurate classification, thus requiring classifiers that can refuse to classify noisy instances. We demonstrate the inability of the popular confidence-thresholding rejection method to learn from relationships between input features and not-at-random class noise. To take advantage of these relationships, we propose a novel null-labelling scheme based on iterative re-training with relabelled datasets that uses a classifier to learn to reject instances that are likely to be misclassified. We demonstrate the ability of null-labelling to achieve a significantly better tradeoff between classification error and coverage than the confidence-thresholding method. Models generated by the null-labelling scheme have the added advantage of interpretability, in that they are able to identify features correlated with class noise. We also unify prior theories for combining and evaluating sets of rejecting classifiers.},
	language = {en},
	urldate = {2020-09-17},
	author = {Denham, Benjamin and Pears, Russel and Naeem, M. Asif},
	month = sep,
	year = {2020},
	note = {Publisher: TechRxiv},
	keywords = {XAI, classification, interpretable, labelling, learn error},
}

@article{zhang_learning_2018,
	title = {Learning causality and causality-related learning: some recent progress},
	volume = {5},
	issn = {2095-5138},
	shorttitle = {Learning causality and causality-related learning},
	url = {https://academic.oup.com/nsr/article/5/1/26/4638533},
	doi = {10.1093/nsr/nwx137},
	abstract = {Causality is a fundamental notion in science, and plays an important role in explanation, prediction, decision making and control. Recently, with the rapid accu},
	language = {en},
	number = {1},
	urldate = {2020-09-12},
	journal = {National Science Review},
	author = {Zhang, Kun and Schölkopf, Bernhard and Spirtes, Peter and Glymour, Clark},
	month = jan,
	year = {2018},
	note = {Publisher: Oxford Academic},
	keywords = {causality, constrant, learning, score, statistics},
	pages = {26--29},
}

@inproceedings{huang_generalized_2018,
	address = {New York, NY, USA},
	series = {{KDD} '18},
	title = {Generalized {Score} {Functions} for {Causal} {Discovery}},
	isbn = {978-1-4503-5552-0},
	url = {https://doi.org/10.1145/3219819.3220104},
	doi = {10.1145/3219819.3220104},
	abstract = {Discovery of causal relationships from observational data is a fundamental problem. Roughly speaking, there are two types of methods for causal discovery, constraint-based ones and score-based ones. Score-based methods avoid the multiple testing problem and enjoy certain advantages compared to constraint-based ones. However, most of them need strong assumptions on the functional forms of causal mechanisms, as well as on data distributions, which limit their applicability. In practice the precise information of the underlying model class is usually unknown. If the above assumptions are violated, both spurious and missing edges may result. In this paper, we introduce generalized score functions for causal discovery based on the characterization of general (conditional) independence relationships between random variables, without assuming particular model classes. In particular, we exploit regression in RKHS to capture the dependence in a nonparametric way. The resulting causal discovery approach produces asymptotically correct results in rather general cases, which may have nonlinear causal mechanisms, a wide class of data distributions, mixed continuous and discrete data, and multidimensional variables. Experimental results on both synthetic and real-world data demonstrate the efficacy of our proposed approach.},
	urldate = {2020-09-11},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Huang, Biwei and Zhang, Kun and Lin, Yizhu and Schölkopf, Bernhard and Glymour, Clark},
	month = jul,
	year = {2018},
	keywords = {causal, causality, discrete, fcm, graph, score},
	pages = {1551--1560},
}

@article{bau_rewriting_2020,
	title = {Rewriting a {Deep} {Generative} {Model}},
	url = {http://arxiv.org/abs/2007.15646},
	abstract = {A deep generative model such as a GAN learns to model a rich set of semantic and physical rules about the target distribution, but up to now, it has been obscure how such rules are encoded in the network, or how a rule could be changed. In this paper, we introduce a new problem setting: manipulation of specific rules encoded by a deep generative model. To address the problem, we propose a formulation in which the desired rule is changed by manipulating a layer of a deep network as a linear associative memory. We derive an algorithm for modifying one entry of the associative memory, and we demonstrate that several interesting structural rules can be located and modified within the layers of state-of-the-art generative models. We present a user interface to enable users to interactively change the rules of a generative model to achieve desired effects, and we show several proof-of-concept applications. Finally, results on multiple datasets demonstrate the advantage of our method against standard fine-tuning methods and edit transfer algorithms.},
	urldate = {2020-09-09},
	journal = {arXiv:2007.15646 [cs]},
	author = {Bau, David and Liu, Steven and Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.15646},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Machine Learning, GAN, I.2.10, I.2.6, I.3.3, deep learning, editing, generative model, neural search},
}

@article{che_object_2019,
	title = {Object {Recognition}, {Segmentation}, and {Classification} of {Mobile} {Laser} {Scanning} {Point} {Clouds}: {A} {State} of the {Art} {Review}},
	volume = {19},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Object {Recognition}, {Segmentation}, and {Classification} of {Mobile} {Laser} {Scanning} {Point} {Clouds}},
	url = {https://www.mdpi.com/1424-8220/19/4/810},
	doi = {10.3390/s19040810},
	abstract = {Mobile Laser Scanning (MLS) is a versatile remote sensing technology based on Light Detection and Ranging (lidar) technology that has been utilized for a wide range of applications. Several previous reviews focused on applications or characteristics of these systems exist in the literature, however, reviews of the many innovative data processing strategies described in the literature have not been conducted in sufficient depth. To this end, we review and summarize the state of the art for MLS data processing approaches, including feature extraction, segmentation, object recognition, and classification. In this review, we first discuss the impact of the scene type to the development of an MLS data processing method. Then, where appropriate, we describe relevant generalized algorithms for feature extraction and segmentation that are applicable to and implemented in many processing approaches. The methods for object recognition and point cloud classification are further reviewed including both the general concepts as well as technical details. In addition, available benchmark datasets for object recognition and classification are summarized. Further, the current limitations and challenges that a significant portion of point cloud processing techniques face are discussed. This review concludes with our future outlook of the trends and opportunities of MLS data processing algorithms and applications.},
	language = {en},
	number = {4},
	urldate = {2020-09-08},
	journal = {Sensors},
	author = {Che, Erzhuo and Jung, Jaehoon and Olsen, Michael J.},
	month = jan,
	year = {2019},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {3d geometry, classification, feature extraction, lidar, mobile laser scanning, object recognition, point cloud, review, segmentation},
	pages = {810},
}

@article{raefsky_adaptive_2017,
	title = {Adaptive responses of neuronal mitochondria to bioenergetic challenges: {Roles} in neuroplasticity and disease resistance},
	volume = {102},
	issn = {08915849},
	shorttitle = {Adaptive responses of neuronal mitochondria to bioenergetic challenges},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0891584916310814},
	doi = {10.1016/j.freeradbiomed.2016.11.045},
	abstract = {An important concept in neurobiology is “neurons that ﬁre together, wire together” which means that the formation and maintenance of synapses is promoted by activation of those synapses. Very similar to the eﬀects of the stress of exercise on muscle cells, emerging ﬁndings suggest that neurons respond to activity by activating signaling pathways (e.g., Ca2+, CREB, PGC-1α, NF-κB) that stimulate mitochondrial biogenesis and cellular stress resistance. These pathways are also activated by aerobic exercise and food deprivation, two bioenergetic challenges of fundamental importance in the evolution of the brains of all mammals, including humans. The metabolic ‘switch’ in fuel source from liver glycogen store-derived glucose to adipose cell-derived fatty acids and their ketone metabolites during fasting and sustained exercise, appears to be a pivotal trigger of both brainintrinsic and peripheral organ-derived signals that enhance learning and memory and underlying synaptic plasticity and neurogenesis. Brain-intrinsic extracellular signals include the excitatory neurotransmitter glutamate and the neurotrophic factor BDNF, and peripheral signals may include the liver-derived ketone 3hydroxybutyrate and the muscle cell-derived protein irisin. Emerging ﬁndings suggest that fasting, exercise and an intellectually challenging lifestyle can protect neurons against the dysfunction and degeneration that they would otherwise suﬀer in acute brain injuries (stroke and head trauma) and neurodegenerative disorders including Alzheimer’s, Parkinson’s and Huntington’s disease. Among the prominent intracellular responses of neurons to these bioenergetic challenges are up-regulation of antioxidant defenses, autophagy/mitophagy and DNA repair. A better understanding of such fundamental hormesis-based adaptive neuronal response mechanisms is expected to result in the development and implementation of novel interventions to promote optimal brain function and healthy brain aging.},
	language = {en},
	urldate = {2020-09-07},
	journal = {Free Radical Biology and Medicine},
	author = {Raefsky, Sophia M. and Mattson, Mark P.},
	month = jan,
	year = {2017},
	pages = {203--216},
}

@article{Resistance2018a,
	title = {Adaptive responses of neuronal mitochondria to bioenergetic challenges: {Roles} in neuroplasticity and disease resistance},
	doi = {10.1016/j.freeradbiomed.2016.11.045.Adaptive},
	author = {Resistance, Disease},
	year = {2018},
	keywords = {3-hydroxybutyrate, aerobic exercise, autophagy, creb, hormesis, intermittent fasting},
	pages = {203--216},
}

@article{Dall,
	title = {Random geometric graphs},
	doi = {10.1103/PhysRevE.66.016121},
	abstract = {We analyze graphs in which each vertex is assigned random coordinates in a geometric space of arbitrary dimensionality and only edges between adjacent points are present. The critical connectivity is found numeri-cally by examining the size of the largest cluster. We derive an analytical expression for the cluster coefficient, which shows that the graphs are distinctly different from standard random graphs, even for infinite dimension-ality. Insights relevant for graph bipartitioning are included.},
	author = {Dall, Jesper and Christensen, Michael},
}

@article{Gusarov2017,
	title = {Glycogen controls {Caenorhabditis} elegans lifespan and resistance to oxidative stress},
	volume = {8},
	issn = {20411723},
	url = {http://dx.doi.org/10.1038/ncomms15868},
	doi = {10.1038/ncomms15868},
	abstract = {A high-sugar diet has been associated with reduced lifespan in organisms ranging from worms to mammals. However, the mechanisms underlying the harmful effects of glucose are poorly understood. Here we establish a causative relationship between endogenous glucose storage in the form of glycogen, resistance to oxidative stress and organismal aging in Caenorhabditis elegans. We find that glycogen accumulated on high dietary glucose limits C. Elegans longevity. Glucose released from glycogen and used for NADPH/glutathione reduction renders nematodes and human hepatocytes more resistant against oxidative stress. Exposure to low levels of oxidants or genetic inhibition of glycogen synthase depletes glycogen stores and extends the lifespan of animals fed a high glucose diet in an AMPK-dependent manner. Moreover, glycogen interferes with low insulin signalling and accelerates aging of long-lived daf-2 worms fed a high glucose diet. Considering its extensive evolutionary conservation, our results suggest that glycogen metabolism might also have a role in mammalian aging.},
	number = {May 2016},
	journal = {Nature Communications},
	author = {Gusarov, Ivan and Pani, Bibhusita and Gautier, Laurent and Smolentseva, Olga and Eremina, Svetlana and Shamovsky, Ilya and Katkova-Zhukotskaya, Olga and Mironov, Alexander and Nudler, Evgeny},
	year = {2017},
	pmid = {28627510},
	note = {Publisher: Nature Publishing Group},
	pages = {1--12},
}

@article{Kramer2018,
	title = {Our ({Mother}’s) {Mitochondria} and {Our} {Mind}},
	volume = {13},
	issn = {17456924},
	doi = {10.1177/1745691617718356},
	abstract = {Most of the energy we get to spend is furnished by mitochondria, minuscule living structures sitting inside our cells or dispatched back and forth within them to where they are needed. Mitochondria produce energy by burning down what remains of our meal after we have digested it, but at the cost of constantly corroding themselves and us. Here we review how our mitochondria evolved from invading bacteria and have retained a small amount of independence from us; how we inherit them only from our mother; and how they are heavily implicated in learning, memory, cognition, and virtually every mental or neurological affliction. We discuss why counteracting mitochondrial corrosion with antioxidant supplements is often unwise, and why our mitochondria, and therefore we ourselves, benefit instead from exercise, meditation, sleep, sunshine, and particular eating habits. Finally, we describe how malfunctioning mitochondria force rats to become socially subordinate to others, how such disparity can be evened off by a vitamin, and why these findings are relevant to us.},
	number = {1},
	journal = {Perspectives on Psychological Science},
	author = {Kramer, Peter and Bressan, Paola},
	year = {2018},
	pmid = {28937858},
	keywords = {Alzheimer’s disease, Parkinson’s disease, aging, depression, free radicals, ketogenic diet, mitochondria, ★},
	pages = {88--100},
}

@article{Watson2014,
	title = {{MTOR} and the health benefits of exercise},
	volume = {36},
	issn = {10963634},
	url = {http://dx.doi.org/10.1016/j.semcdb.2014.08.013},
	doi = {10.1016/j.semcdb.2014.08.013},
	abstract = {Exercise is the greatest physiological stress that our bodies experience. For example, during maximal endurance exercise in elite athlete's cardiac output can increase up to 8-fold and the working muscles receive 21-times more blood each minute than at rest. Given the physiological stress associated with exercise and the adaptations that occur to handle this stress, it is not surprising that exercise training is known to prevent or effectively treat a multitude of degenerative conditions including cardiovascular disease, cancer, diabetes, depression, Alzheimer's disease, Parkinson's disease, and many others. Many of the health benefits of exercise are mediated by the mammalian/mechanistic target of rapamycin (mTOR), either in complex 1 or 2, not only within the working muscle, but also in distant tissues such as fat, liver, and brain. This review will discuss how exercise activates mTOR in diverse tissues and the ways that mTOR is important in the adaptive response that makes us bigger, stronger, and healthier as a result of exercise.},
	journal = {Seminars in Cell and Developmental Biology},
	author = {Watson, Kurt and Baar, Keith},
	year = {2014},
	note = {Publisher: Elsevier Ltd},
	keywords = {Amino acids, Cancer, Inactivity, Longevity, Quality of life, ★},
	pages = {130--139},
}

@article{Carek2011,
	title = {Exercise for the treatment of depression and anxiety},
	volume = {41},
	issn = {00912174},
	doi = {10.2190/PM.41.1.c},
	abstract = {Depression and anxiety are the most common psychiatric conditions seen in the general medical setting, affecting millions of individuals in the United States. The treatments for depression and anxiety are multiple and have varying degrees of effectiveness. Physical activity has been shown to be associated with decreased symptoms of depression and anxiety. Physical activity has been consistently shown to be associated with improved physical health, life satisfaction, cognitive functioning, and psychological well-being. Conversely, physical inactivity appears to be associated with the development of psychological disorders. Specific studies support the use of exercise as a treatment for depression. Exercise compares favorably to antidepressant medications as a first-line treatment for mild to moderate depression and has also been shown to improve depressive symptoms when used as an adjunct to medications. While not as extensively studied, exercise has been shown to be an effective and cost-efficient treatment alternative for a variety of anxiety disorders. While effective, exercise has not been shown to reduce anxiety to the level achieved by psychopharmaceuticals. © 2011, Baywood Publishing Co., Inc.},
	number = {1},
	journal = {International Journal of Psychiatry in Medicine},
	author = {Carek, Peter J. and Laibstain, Sarah E. and Carek, Stephen M.},
	year = {2011},
	pmid = {21495519},
	keywords = {anxiety, depression, exercise, mood disorder, physical activity, ★},
	pages = {15--28},
}

@article{Filiou2019,
	title = {Anxiety and {Brain} {Mitochondria}: {A} {Bidirectional} {Crosstalk}},
	volume = {42},
	issn = {1878108X},
	url = {https://doi.org/10.1016/j.tins.2019.07.002},
	doi = {10.1016/j.tins.2019.07.002},
	abstract = {Accumulating data highlight the contribution of brain mitochondria and bioenergetics to psychiatric disorders and stress-related pathologies. Although anxiety has not received much attention in this booming literature, a bidirectional interplay between anxiety and brain mitochondria and metabolism has recently started to emerge. Substantial observations indicate alterations in mitochondria and metabolism in highly anxious individuals and, conversely, anxiety symptoms in humans suffering from mitochondrial disorders. Genetic and pharmacological efforts have made substantial progress at advancing the causal involvement of specific mitochondrial and metabolic factors in anxiety. In this review, we discuss this converging evidence and highlight the relevance of developing a research focused on targeting mitochondria as an approach to alleviate anxiety.},
	number = {9},
	journal = {Trends in Neurosciences},
	author = {Filiou, Michaela D. and Sandi, Carmen},
	year = {2019},
	pmid = {31362874},
	note = {Publisher: Elsevier Ltd},
	keywords = {anxiolytic drugs, bioenergetics, neurosteroids, oxidative phosphorylation, psychiatric disorders, stress},
	pages = {573--588},
}

@article{Aguiar2014,
	title = {Effects of exercise on mitochondrial function, neuroplasticity and anxio-depressive behavior of mice},
	volume = {271},
	issn = {18737544},
	url = {http://dx.doi.org/10.1016/j.neuroscience.2014.04.027},
	doi = {10.1016/j.neuroscience.2014.04.027},
	abstract = {The present study was aimed at analyzing the effects of physical exercise on mitochondrial physiology, anxio-depressive-like behaviors and neuroplasticity in mice. Adult C57BL/6J male mice were isolated in home cages equipped or not with free-running wheels. After 6. weeks of exercise, mice were tested in various behavioral paradigms to evaluate anxiety- and depressive-like behaviors. The hippocampi were dissected for neurochemical assays, including mitochondrial activity, monoamines content and the expression of genes involved in energy metabolism and brain-derived neurotrophic factor (BDNF) regulation. Exercise decreased anxiety-like behaviors in the open field and elevated plus maze, and exerted antidepressant-like effects in the tail suspension test. Exercise stimulated brain mitochondrial activity and increased resistance against rotenone, an inhibitor of complex I activity. Furthermore, mRNA expression of Bdnf, Gdnf, Tfam (mitochondrial transcription factor A), and Ndufa6 (mitochondrial I subunit) genes, as well as the phosphorylation of cAMP response element-binding protein were increased after exercise. In summary, exercise appears to engage mitochondrial pathways and to potentiate neuroplasticity and might be associated to mood improvement. © 2014 IBRO.},
	journal = {Neuroscience},
	author = {Aguiar, A. S. and Stragier, E. and da Luz Scheffer, D. and Remor, A. P. and Oliveira, P. A. and Prediger, R. D. and Latini, A. and Raisman-Vozari, R. and Mongeau, R. and Lanfumey, L.},
	year = {2014},
	pmid = {24780767},
	note = {Publisher: IBRO},
	keywords = {Depression, Epigenetic, Hippocampus, Mitochondria, Mood, Neurotrophin},
	pages = {56--63},
}

@article{Sim2014,
	title = {Structural {Studies} on a {Mitochondrial} {Glyoxalase} {II}},
	volume = {281},
	issn = {00219258},
	doi = {10.1074/jbc},
	abstract = {Prion diseases are caused by the aggregation of the native alpha-helical prion protein PrP(C) into its pathological beta-sheet-rich isoform PrP(Sc). In current models of PrP(Sc), helix1 is assumed to be preferentially converted into beta-sheet during aggregation of PrP(C). This was supported by the NMR structure of PrP(C) since, in contrast to the isolated helix1, helix2 and helix3 are connected by a small loop and are additionally stabilized by an interhelical disulfide bond. However, helix1 is extremely hydrophilic and has a high helix propensity. This prompted us to investigate the role of helix1 in prion aggregation using humPrP(23-159) including helix1 (144-156) compared with the C-terminal-truncated isoform humPrP(23-144) corresponding to the pathological human stop mutations Q160Stop and Y145Stop, respectively. Most unexpectedly, humPrP(23-159) aggregated significantly faster compared with the truncated fragment humPrP(23-144), clearly demonstrating that helix1 is involved in the aggregation process. However, helix1 is not resistant to digestion with proteinase K in fibrillar humPrP(23-159), suggesting that helix1 is not converted to beta-sheet. This is confirmed by Fourier transformation infrared spectroscopy since there is almost no difference in beta-sheet content of humPrP(23-159) fibrils compared with humPrP(23-144). In conclusion, we provide strong direct evidence that in contrast to earlier assumptions helix1 is not converted into beta-sheet during aggregation of PrP(C) to PrP(Sc).},
	number = {40},
	journal = {Journal of Biological Chemistry},
	author = {Sim, Robert B and Dodds, Alis W and Mitc, Daniel A and Reid, Kenneth B M and Sc, J},
	year = {2014},
	pmid = {17012240},
	note = {ISBN: 0021-9258 (Print) 0021-9258 (Linking)},
	pages = {1--11},
}

@article{Pushpakom2018,
	title = {Drug repurposing: {Progress}, challenges and recommendations},
	volume = {18},
	issn = {14741784},
	doi = {10.1038/nrd.2018.168},
	abstract = {Given the high attrition rates, substantial costs and slow pace of new drug discovery and development, repurposing of ‘old’ drugs to treat both common and rare diseases is increasingly becoming an attractive proposition because it involves the use of de-risked compounds, with potentially lower overall development costs and shorter development timelines. Various data-driven and experimental approaches have been suggested for the identification of repurposable drug candidates; however, there are also major technological and regulatory challenges that need to be addressed. In this Review, we present approaches used for drug repurposing (also known as drug repositioning), discuss the challenges faced by the repurposing community and recommend innovative ways by which these challenges could be addressed to help realize the full potential of drug repurposing.},
	number = {1},
	journal = {Nature Reviews Drug Discovery},
	author = {Pushpakom, Sudeep and Iorio, Francesco and Eyers, Patrick A. and Escott, K. Jane and Hopper, Shirley and Wells, Andrew and Doig, Andrew and Guilliams, Tim and Latimer, Joanna and McNamee, Christine and Norris, Alan and Sanseau, Philippe and Cavalla, David and Pirmohamed, Munir},
	year = {2018},
	pmid = {30310233},
	note = {Publisher: Nature Publishing Group},
	pages = {41--58},
}

@article{noauthor_optic_nodate,
	title = {The optic nerve: {A} “mito-window” on mitochondrial neurodegeneration},
}

@article{Gurgul2014,
	title = {Hypergraph grammar based linear computational cost solver for three dimensional grids with point singularities},
	volume = {29},
	issn = {18770509},
	doi = {10.1016/j.procs.2014.05.097},
	abstract = {In this paper we present a hypergraph grammar based multi-frontal solver for three dimensional grids with point singularities. We show experimentally that the computational cost of the resulting solver algorithm is linear with respect to the number of degrees of freedom. We also propose a reutilization algorithm that enables to reuse LU factorizations over unrefined parts of the mesh when new local refinements are executed by the hypergraph grammar productions. © The Authors. Published by Elsevier B.V.},
	journal = {Procedia Computer Science},
	author = {Gurgul, Piotr and Paszyńska, Anna and Paszyński, Maciej},
	year = {2014},
	keywords = {Direct solver, H adaptivity, Hypergraph grammar, Reuitlization, ★},
	pages = {1078--1089},
}

@article{Ben-Shachar2017,
	title = {Mitochondrial multifaceted dysfunction in schizophrenia; complex {I} as a possible pathological target},
	volume = {187},
	issn = {15732509},
	url = {http://dx.doi.org/10.1016/j.schres.2016.10.022},
	doi = {10.1016/j.schres.2016.10.022},
	abstract = {Mitochondria are key players in various essential cellular processes beyond being the main energy supplier of the cell. Accordingly, they are involved in neuronal synaptic transmission, neuronal growth and sprouting and consequently neuronal plasticity and connectivity. In addition, mitochondria participate in the modulation of gene transcription and inflammation as well in physiological responses in health and disease. Schizophrenia is currently regarded as a neurodevelopmental disorder associated with impaired immune system, aberrant neuronal differentiation and abnormalities in various neurotransmitter systems mainly the dopaminergic, glutaminergic and GABAergic. Ample evidence has been accumulated over the last decade indicating a multifaceted dysfunction of mitochondria in schizophrenia. Indeed, mitochondrial deficit can be of relevance for the majority of the pathologies observed in this disease. In the present article, we overview specific deficits of the mitochondria in schizophrenia, with a focus on the first complex (complex I) of the mitochondrial electron transport chain (ETC). We argue that complex I, being a major factor in the regulation of mitochondrial ETC, is a possible key modulator of various functions of the mitochondria. We review biochemical, molecular, cellular and functional evidence for mitochondrial impairments and their possible convergence to impact in-vitro neuronal differentiation efficiency in schizophrenia. Mitochondrial function in schizophrenia may advance our knowledge of the disease pathophysiology and open the road for new treatment targets for the benefit of the patients.},
	journal = {Schizophrenia Research},
	author = {Ben-Shachar, Dorit},
	year = {2017},
	note = {Publisher: Elsevier B.V.},
	keywords = {Complex I, Mitochondria, Mitochondrial dynamics, Mitochondrial respiration, Neuronal differentiation, Schizophrenia},
	pages = {3--10},
}

@article{Chou2016,
	title = {Association between the serotonin transporter and cytokines: {Implications} for the pathophysiology of bipolar disorder},
	volume = {191},
	issn = {15732517},
	url = {http://dx.doi.org/10.1016/j.jad.2015.10.056},
	doi = {10.1016/j.jad.2015.10.056},
	abstract = {Background Reduced brain serotonin transporter (SERT) has been demonstrated in bipolar disorder (BD). The aim of this study was to explore the potential role of cytokines on reduced SERT in BD. Methods Twenty-eight BD type I patients and 28 age- and gender-matched healthy controls (HCs) were recruited. Single photon emission computed tomography with the radiotracer 123I ADAM was used for SERT imaging. Regions of interest included the midbrain, thalamus, putamen and caudate. Seven cytokines, including tumor necrosis factor-α (TNF-α), interferon-γ (IFN-γ), interleukin-1α (IL-1α), IL-1β, IL-4, IL-6 and IL-10, were measured using an enzyme linked immune-sorbent assay. Results: SERT availability in the midbrain and caudate was significantly lower in BD compared to HCs. IL-1β was significantly lower, whereas IL-10 was significantly higher in BD compared to HCs. Multiple linear regression analyses revealed that there were associations between cytokines, IL-1α, IL-1β, IL-6 and SERT availability in the midbrain but not in the thalamus, putamen and caudate. Furthermore, linear mixed effect analyses demonstrated that these associations were not different between HCs and BD. Conclusion While many cytokines have been proposed to be important in the pathophysiology of BD, our results demonstrated that significant associations between cytokines and SERT availability may explain the role of cytokines in mood regulation. However, these associations were not different between HCs and BD, which imply the role of these cytokines is not specific for BD.},
	journal = {Journal of Affective Disorders},
	author = {Chou, Yuan Hwa and Hsieh, Wen Chi and Chen, Li Chi and Lirng, Jiing Feng and Wang, Shyh Jen},
	year = {2016},
	note = {Publisher: Elsevier},
	keywords = {Bipolar disorder (BD), Cytokines, Serotonin transporter (SERT), Single photon emission computed tomography (SPECT)},
	pages = {29--35},
}

@misc{noauthor_sciencedirect_articles_15aug2020_23-59-14_nodate,
	title = {{ScienceDirect}\_articles\_15Aug2020\_23-59-14},
}

@article{Karim2016,
	title = {Anticlockwise or clockwise? {A} dynamic {Perception}-{Action}-{Laterality} model for directionality bias in visuospatial functioning},
	volume = {68},
	issn = {18737528},
	url = {http://dx.doi.org/10.1016/j.neubiorev.2016.06.032},
	doi = {10.1016/j.neubiorev.2016.06.032},
	abstract = {Orientation bias and directionality bias are two fundamental functional characteristics of the visual system. Reviewing the relevant literature in visual psychophysics and visual neuroscience we propose here a three-stage model of directionality bias in visuospatial functioning. We call this model the ‘Perception-Action-Laterality’ (PAL) hypothesis. We analyzed the research findings for a wide range of visuospatial tasks, showing that there are two major directionality trends in perceptual preference: clockwise versus anticlockwise. It appears these preferences are combinatorial, such that a majority of people fall in the first category demonstrating a preference for stimuli/objects arranged from left-to-right rather than from right-to-left, while people in the second category show an opposite trend. These perceptual biases can guide sensorimotor integration and action, creating two corresponding turner groups in the population. In support of PAL, we propose another model explaining the origins of the biases – how the neurogenetic factors and the cultural factors interact in a biased competition framework to determine the direction and extent of biases. This dynamic model can explain not only the two major categories of biases in terms of direction and strength, but also the unbiased, unreliably biased or mildly biased cases in visuosptial functioning.},
	journal = {Neuroscience and Biobehavioral Reviews},
	author = {Karim, A. K.M.Rezaul and Proulx, Michael J. and Likova, Lora T.},
	year = {2016},
	note = {Publisher: Elsevier Ltd},
	keywords = {Aesthetics, Anticlockwise, Bisection, Cerebral lateralization, Clockwise, Directionality bias, Dopamine, Dynamic model, Genes, Heritability, Mental number line, Neurogenetic, Orientation, Plasticity, Pseudoneglect, Rotation, Sensorimotor, Space mapping, Turning, Visuospatial perception},
	pages = {669--693},
}

@article{Lavagnino2016,
	title = {Inhibitory control in obesity and binge eating disorder: {A} systematic review and meta-analysis of neurocognitive and neuroimaging studies},
	volume = {68},
	issn = {18737528},
	url = {http://dx.doi.org/10.1016/j.neubiorev.2016.06.041},
	doi = {10.1016/j.neubiorev.2016.06.041},
	abstract = {The ability to exercise appropriate inhibitory control is critical in the regulation of body weight, but the exact mechanisms are not known. In this systematic review, we identified 37 studies that used specific neuropsychological tasks relevant to inhibitory control performance in obese participants with and without binge eating disorder (BED). We performed a meta-analysis of the studies that used the stop signal task (N = 8). We further examined studies on the delay discounting task, the go/no-go task and the Stroop task in a narrative review. We found that inhibitory control is significantly impaired in obese adults and children compared to individuals with body weight within a healthy range (Standardized Mean Difference (SMD): 0.30; CI = 0.00, 0.59, p = 0.007). The presence of BED in obese individuals did not impact on task performance (SMD: 0.05; CI: −0.22, 0.32, p = 0.419). Neuroimaging studies in obesity suggest that lower prefrontal cortex activity affects inhibitory control and BMI. In summary, impairment in inhibitory control is a critical feature associated with obesity and a potential target for clinical interventions.},
	journal = {Neuroscience and Biobehavioral Reviews},
	author = {Lavagnino, Luca and Arnone, Danilo and Cao, Bo and Soares, Jair C. and Selvaraj, Sudhakar},
	year = {2016},
	pmid = {27381956},
	note = {Publisher: Elsevier Ltd},
	keywords = {Binge eating, Go/nogo, Inhibitory control, Obesity, Prefrontal cortex, Stop signal},
	pages = {714--726},
}

@article{Brown2014,
	title = {An updated meta-analysis of oxidative stress markers in bipolar disorder},
	volume = {218},
	issn = {18727123},
	url = {http://dx.doi.org/10.1016/j.psychres.2014.04.005},
	doi = {10.1016/j.psychres.2014.04.005},
	abstract = {Despite its debilitating symptoms, the pathophysiology of bipolar disorder (BD) remains unclear. One consistently compelling finding, however, has been the presence of oxidative stress. In the present investigation, we conducted a meta-analysis of studies that measured oxidative stress markers in BD patients compared to healthy controls. Search terms and selection criteria were determined a priori to identify and include all studies that measured a marker of oxidative stress in BD compared to healthy controls. Eight markers were included: superoxide dismutase, catalase, protein carbonyl, glutathione peroxidase, 3-nitrotyrosine, lipid peroxidation, nitric oxide, and DNA/RNA damage. A meta-analysis of standardized means was conducted using a random-effects model with generic inverse weighting. Between-study heterogeneity, publication bias, and sensitivity analyses were also examined for each marker. Twenty-seven papers were included in the meta-analysis, which comprised a total of 971 unique patients with BD and 886 healthy controls. Lipid peroxidation, DNA/RNA damage, and nitric oxide were significantly increased in BD patients compared to healthy controls. Additionally, the effect size for lipid peroxidation was very high. Publication bias was not detected for any of the markers. The main limitations in this meta-analysis are the high degree of heterogeneity between studies and the small number of studies used in the analysis of some markers. Additionally, the sensitivity analysis indicated that some results are not very robust. The results from this meta-analysis support the role of oxidative stress in bipolar disorder, especially to DNA, RNA, and lipids. © 2014 Elsevier Ireland Ltd.},
	number = {1-2},
	journal = {Psychiatry Research},
	author = {Brown, Nicole C. and Andreazza, Ana C. and Young, L. Trevor},
	year = {2014},
	note = {Publisher: Elsevier},
	keywords = {Antioxidant enzymes, Bipolar disorder, Lipid peroxidation, Oxidative stress, Post-mortem brain},
	pages = {61--68},
}

@article{Fries2016,
	title = {The role of {DNA} methylation in the pathophysiology and treatment of bipolar disorder},
	volume = {68},
	issn = {18737528},
	url = {http://dx.doi.org/10.1016/j.neubiorev.2016.06.010},
	doi = {10.1016/j.neubiorev.2016.06.010},
	abstract = {Bipolar disorder (BD) is a multifactorial illness thought to result from an interaction between genetic susceptibility and environmental stimuli. Epigenetic mechanisms, including DNA methylation, can modulate gene expression in response to the environment, and therefore might account for part of the heritability reported for BD. This paper aims to review evidence of the potential role of DNA methylation in the pathophysiology and treatment of BD. In summary, several studies suggest that alterations in DNA methylation may play an important role in the dysregulation of gene expression in BD, and some actually suggest their potential use as biomarkers to improve diagnosis, prognosis, and assessment of response to treatment. This is also supported by reports of alterations in the levels of DNA methyltransferases in patients and in the mechanism of action of classical mood stabilizers. In this sense, targeting specific alterations in DNA methylation represents exciting new treatment possibilities for BD, and the ‘plastic’ characteristic of DNA methylation accounts for a promising possibility of restoring environment-induced modifications in patients.},
	journal = {Neuroscience and Biobehavioral Reviews},
	author = {Fries, Gabriel R. and Li, Qiongzhen and McAlpin, Blake and Rein, Theo and Walss-Bass, Consuelo and Soares, Jair C. and Quevedo, Joao},
	year = {2016},
	note = {Publisher: Elsevier Ltd},
	keywords = {Bipolar disorder, DNA methylation, DNA methyltransferase, Depression, Epigenetics, Mood disorders, Mood stabilizers},
	pages = {474--488},
}

@article{williams_secret_2020,
	title = {Secret {Book} of {James}},
	author = {Williams, Francis E},
	year = {2020},
	pages = {1--6},
}

@article{Judas2004,
	title = {The {Text} of the {Gospel} of {Thomas}},
	author = {Judas, Didymos},
	year = {2004},
}

@article{Kloke,
	title = {The {R} {Series} {Statistics} {Nonparametric} {Statistical} {Methods} {Using} {R}},
	abstract = {Nonparametric Statistical Methods Using R covers traditional nonparamet-ric methods and rank-based analyses, including estimation and inference for models ranging from simple location models to general linear and nonlinear models for uncorrelated and correlated responses. The authors emphasize applications and statistical computation. They illustrate the methods with many real and simulated data examples using R, including the packages Rfit and npsm. The book first gives an overview of the R language and basic statistical concepts before discussing nonparametrics. It presents rank-based methods for one-and two-sample problems, procedures for regression models, computation for general fixed-effects ANOVA and ANCOVA models, and time-to-event analyses. The last two chapters cover more advanced material, including high breakdown fits for general regression models and rank-based inference for cluster correlated data. Features • Explains how to apply and compute nonparametric methods, such as Wilcoxon procedures and bootstrap methods • Describes various types of rank-based estimates, including linear, nonlinear, time series, and basic mixed effects models • Illustrates the use of diagnostic procedures, including studentized residuals and difference in fits • Provides the R packages on CRAN, enabling you to reproduce all of the analyses • Includes exercises at the end of each chapter for self-study and classroom use John Kloke is a biostatistician and assistant scientist at the University of Wis-consin-Madison. He has held faculty positions at the University of Pittsburgh, Bucknell University, and Pomona College. An R user for more than 15 years, he is an author and maintainer of numerous R packages, including Rfit and npsm. Joseph W. McKean is a professor of statistics at Western Michigan University. He has co-authored several books and published many papers on nonpara-metric and robust statistical procedures. He is a fellow of the American Statistical Association.},
	author = {Kloke, John and Mckean, Joseph W},
	keywords = {★},
}

@article{Steinhaeuser2015,
	title = {A {Survey} on {Unsupervised} {Outlier} {Detection} in {High}-{Dimensional} {Numerical} {Data} {Detection} in {High}-{Dimensional} {Numerical} {Data}},
	volume = {8},
	issn = {19321872},
	doi = {10.1002/sam},
	abstract = {The analysis of climate data has relied heavily on hypothesis-driven statistical methods, while projections of future climate are based primarily on physics-based computational models. However, in recent years a wealth of new datasets has become available. Therefore, we take a more data-centric approach and propose a unified framework for studying climate, with an aim toward characterizing observed phenomena as well as discovering new knowledge in climate science. Specifically, we posit that complex networks are well suited for both descriptive analysis and predictive modeling tasks. We show that the structural properties of 'climate networks' have useful interpretation within the domain. Further, we extract clusters from these networks and demonstrate their predictive power as climate indices. Our experimental results establish that the network clusters are statistically significantly better predictors than clusters derived using a more traditional clustering approach. Using complex networks as data representation thus enables the unique opportunity for descriptive and predictive modeling to inform each other. 2010 Wiley Periodicals, Inc.},
	number = {5},
	journal = {Statistical Analysis and Data Mining},
	author = {Arthur Zimek1∗, Erich Schubert2 {and} Hans-Peter Kriegel2},
	year = {2015},
	pmid = {21824845},
	note = {arXiv: 1206.3552
ISBN: 1932-1872},
	keywords = {climate data, community detection, complex networks, multivariate predictive modeling, network analysis, ★},
	pages = {497--511},
}

@misc{noauthor_george_nodate,
	title = {George {Elliot}-{Middlemarch}},
}

@article{Cai2020,
	title = {Mitophagy in {Alzheimer}’s {Disease} and {Other} {Age}-{Related} {Neurodegenerative} {Diseases}},
	volume = {9},
	issn = {2073-4409},
	doi = {10.3390/cells9010150},
	abstract = {Mitochondrial dysfunction is a central aspect of aging and neurodegenerative diseases, including Alzheimer’s disease, Parkinson’s disease, amyotrophic lateral sclerosis, and Huntington’s disease. Mitochondria are the main cellular energy powerhouses, supplying most of ATP by oxidative phosphorylation, which is required to fuel essential neuronal functions. Efficient removal of aged and dysfunctional mitochondria through mitophagy, a cargo-selective autophagy, is crucial for mitochondrial maintenance and neuronal health. Mechanistic studies into mitophagy have highlighted an integrated and elaborate cellular network that can regulate mitochondrial turnover. In this review, we provide an updated overview of the recent discoveries and advancements on the mitophagy pathways and discuss the molecular mechanisms underlying mitophagy defects in Alzheimer’s disease and other age-related neurodegenerative diseases, as well as the therapeutic potential of mitophagy-enhancing strategies to combat these disorders.},
	number = {1},
	journal = {Cells},
	author = {Cai, Qian and Jeong, Yu Young},
	year = {2020},
	keywords = {alzheimer, amyotrophic lateral, control, huntington, lysosome, mitochondrial dynamics, mitochondrial quality, mitophagosome, mitophagy, parkinson, s disease},
	pages = {150},
}

@article{Jousselme2012a,
	title = {Distances in evidence theory: {Comprehensive} survey and generalizations},
	volume = {53},
	issn = {0888613X},
	url = {http://dx.doi.org/10.1016/j.ijar.2011.07.006},
	doi = {10.1016/j.ijar.2011.07.006},
	abstract = {The purpose of the present work is to survey the dissimilarity measures defined so far in the mathematical framework of evidence theory, and to propose a classification of these measures based on their formal properties. This research is motivated by the fact that while dissimilarity measures have been widely studied and surveyed in the fields of probability theory and fuzzy set theory, no comprehensive survey is yet available for evidence theory. The main results presented herein include a synthesis of the properties of the measures defined so far in the scientific literature; the generalizations proposed naturally lead to additions to the body of the previously known measures, leading to the definition of numerous new measures. Building on this analysis, we have highlighted the fact that Dempster's conflict cannot be considered as a genuine dissimilarity measure between two belief functions and have proposed an alternative based on a cosine function. Other original results include the justification of the use of two-dimensional indexes as (cosine; distance) couples and a general formulation for this class of new indexes. We base our exposition on a geometrical interpretation of evidence theory and show that most of the dissimilarity measures so far published are based on inner products, in some cases degenerated. Experimental results based on Monte Carlo simulations illustrate interesting relationships between existing measures. © 2011 Elsevier Inc. All rights reserved.},
	number = {2},
	journal = {International Journal of Approximate Reasoning},
	author = {Jousselme, Anne Laure and Maupin, Patrick},
	year = {2012},
	note = {Publisher: Elsevier Inc.},
	keywords = {Additive tree, Belief functions, Dissimilarity, Distance, Inner product, Metric},
	pages = {118--145},
}

@article{Hau1989,
	title = {On the robustness of {Dempster}'s rule of combination},
	volume = {48},
	doi = {10.1109/tai.1989.65370},
	abstract = {It is demonstrated by example that Dempster's rule of combination is not robust when combining highly conflicting belief functions. It is that Shafer's discounted belief functions also suffer from this lack of robustness with respect to small perturbations in the discount factor. A modified version of Dempster's rule is proposed to remedy this difficulty.},
	author = {Hau, Hai Yen and Kashyap, R. L.},
	year = {1989},
	note = {ISBN: 0818619848},
	pages = {578--582},
}

@article{Deng2016a,
	title = {Deng entropy},
	volume = {91},
	issn = {09600779},
	doi = {10.1016/j.chaos.2016.07.014},
	abstract = {Dempster Shafer evidence theory has been widely used in many applications due to its advantages to handle uncertainty. However, how to measure uncertainty in evidence theory is still an open issue. The main contribution of this paper is that a new entropy, named as Deng entropy, is presented to measure the uncertainty of a basic probability assignment (BPA). Deng entropy is the generalization of Shannon entropy since the value of Deng entropy is identical to that of Shannon entropy when the BPA defines a probability measure. Numerical examples are illustrated to show the efficiency of Deng entropy.},
	journal = {Chaos, Solitons and Fractals},
	author = {Deng, Yong},
	year = {2016},
	note = {Publisher: Elsevier Ltd},
	keywords = {Dempster-Shafer evidence theory, Deng entropy, Entropy, Shannon entropy, Uncertainty measure},
	pages = {549--553},
}

@article{Yang2013b,
	title = {Evidential reasoning rule for evidence combination},
	volume = {205},
	issn = {00043702},
	url = {http://dx.doi.org/10.1016/j.artint.2013.09.003},
	doi = {10.1016/j.artint.2013.09.003},
	abstract = {This paper aims to establish a unique Evidential Reasoning (ER) rule to combine multiple pieces of independent evidence conjunctively with weights and reliabilities. The novel concept of Weighted Belief Distribution (WBD) is proposed and extended to WBD with Reliability (WBDR) to characterise evidence in complement of Belief Distribution (BD) introduced in Dempster-Shafer (D-S) theory of evidence. The implementation of the orthogonal sum operation on WBDs and WBDRs leads to the establishment of the new ER rule. The most important property of the new ER rule is that it constitutes a generic conjunctive probabilistic reasoning process, or a generalised Bayesian inference process. It is shown that the original ER algorithm is a special case of the ER rule when the reliability of evidence is equal to its weight and the weights of all pieces of evidence are normalised. It is proven that Dempster's rule is also a special case of the ER rule when each piece of evidence is fully reliable. The ER rule completes and enhances Dempster's rule by identifying how to combine pieces of fully reliable evidence that are highly or completely conflicting through a new reliability perturbation analysis. The main properties of the ER rule are explored to facilitate its applications. Several existing rules are discussed and compared with the ER rule. Numerical and simulation studies are conducted to show the features of the ER rule. © 2013 Elsevier B.V. All rights reserved.},
	journal = {Artificial Intelligence},
	author = {Yang, Jian Bo and Xu, Dong Ling},
	year = {2013},
	note = {Publisher: Elsevier B.V.},
	keywords = {Bayesian inference, Belief distribution, Dempster-Shafer theory, Evidential reasoning, Information fusion, Multiple criteria decision analysis, ★},
	pages = {1--29},
}

@article{Yang2016a,
	title = {A new distance-based total uncertainty measure in the theory of belief functions},
	volume = {94},
	issn = {09507051},
	doi = {10.1016/j.knosys.2015.11.014},
	abstract = {The theory of belief functions is a very important and effective tool for uncertainty modeling and reasoning, where measures of uncertainty are very crucial for evaluating the degree of uncertainty in a body of evidence. Several uncertainty measures in the theory of belief functions have been proposed. However, existing measures are generalizations of measures in the probabilistic framework. The inconsistency between different frameworks causes limitations to existing measures. To avoid these limitations, in this paper, a new total uncertainty measure is proposed directly in the framework of belief functions theory without changing the theoretical frameworks. The average distance between the belief interval of each singleton and the most uncertain case is used to represent the total uncertainty degree of the given body of evidence. Numerical examples, simulations, applications and related analyses are provided to verify the rationality of our new measure.},
	journal = {Knowledge-Based Systems},
	author = {Yang, Yi and Han, Deqiang},
	year = {2016},
	note = {Publisher: Elsevier B.V.},
	keywords = {Belief functions, Belief interval, Distance of interval, Evidence theory, Uncertainty measure},
	pages = {114--123},
}

@article{Vaux2012,
	title = {Replicates and repeats-what is the difference and is it significant? {A} brief discussion of statistics and experimental design},
	volume = {13},
	issn = {1469221X},
	url = {http://dx.doi.org/10.1038/embor.2012.36},
	doi = {10.1038/embor.2012.36},
	number = {4},
	journal = {EMBO Reports},
	author = {Vaux, David L. and Fidler, Fiona and Cumming, Geoff},
	year = {2012},
	note = {Publisher: Nature Publishing Group},
	pages = {291--296},
}

@article{Dempster2008,
	title = {The {Dempster}-{Shafer} calculus for statisticians},
	volume = {48},
	issn = {0888613X},
	doi = {10.1016/j.ijar.2007.03.004},
	abstract = {The Dempster-Shafer (DS) theory of probabilistic reasoning is presented in terms of a semantics whereby every meaningful formal assertion is associated with a triple (p, q, r) where p is the probability "for" the assertion, q is the probability "against" the assertion, and r is the probability of "don't know". Arguments are presented for the necessity of "don't know". Elements of the calculus are sketched, including the extension of a DS model from a margin to a full state space, and DS combination of independent DS uncertainty assessments on the full space. The methodology is applied to inference and prediction from Poisson counts, including an introduction to the use of join-tree model structure to simplify and shorten computation. The relation of DS theory to statistical significance testing is elaborated, introducing along the way the new concept of "dull" null hypothesis. © 2007 Elsevier Inc. All rights reserved.},
	number = {2},
	journal = {International Journal of Approximate Reasoning},
	author = {Dempster, A. P.},
	year = {2008},
	keywords = {Belief functions, Dempster-Shafer, Dull null hypothesis, Join-tree computation, Poisson model, State space, Statistical significance},
	pages = {365--377},
}

@article{Chuang2009,
	title = {Hue-preserving color blending},
	volume = {15},
	issn = {10772626},
	doi = {10.1109/TVCG.2009.150},
	abstract = {We propose a new perception-guided compositing operator for color blending. The operator maintains the same rules for achromatic compositing as standard operators (such as the over operator), but it modifies the computation of the chromatic channels. Chromatic compositing aims at preserving the hue of the input colors; color continuity is achieved by reducing the saturation of colors that are to change their hue value. The main benefit of hue preservation is that color can be used for proper visual labeling, even under the constraint of transparency rendering or image overlays. Therefore, the visualization of nominal data is improved. Hue-preserving blending can be used in any existing compositing algorithm, and it is particularly useful for volume rendering. The usefulness of hue-preserving blending and its visual characteristics are shown for several examples of volume visualization. © 2009 IEEE.},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Chuang, Johnson and Weiskopf, Daniel and Möller, Torsten},
	year = {2009},
	keywords = {Image compositing, color blending, illustrative visualization, perceptual transparency, volume rendering},
	pages = {1275--1282},
}

@article{Hotfiel2018,
	title = {Advances in {Delayed}-{Onset} {Muscle} {Soreness} ( {DOMS} ): {Part} {I} : {Pathogenesis} and {Diagnostics} {Delayed} {Onset} {Muscle} {Soreness} – {Teil} {I} : {Pathogenese} und {Diagnostik} {Authors} {Mechanisms} and pathogenesis},
	volume = {32},
	issn = {0932-0555},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/30537791%0Ahttp://www.thieme-connect.de/DOI/DOI?10.1055/a-0753-1884},
	doi = {10.1055/a-0753-1884},
	abstract = {{\textless}p{\textgreater}Delayed-onset muscle soreness (DOMS) is a type of ultrastructural muscle injury. The manifestation of DOMS is caused by eccentric or unfamiliar forms of exercise. Clinical signs include reduced force capacities, increased painful restriction of movement, stiffness, swelling, and dysfunction of adjacent joints. Although DOMS is considered a mild type of injury, it is one of the most common reasons for compromised sportive performance. In the past few decades, many hypotheses have been developed to explain the aetiology of DOMS. Although the exact pathophysiological pathway remains unknown, the primary mechanism is currently considered to be the ultrastructural damage of muscle cells due to unfamiliar sporting activities or eccentric exercise, which leads to further protein degradation, apoptosis and local inflammatory response. The development of clinical symptoms is typically delayed (peak soreness at 48 – 72 h post-exercise) as a result of complex sequences of local and systemic physiological responses. The following narrative review was conducted to present an overview of the current findings regarding the damaging mechanisms as well as the pathophysiology of DOMS and its diagnostic evaluation.{\textless}/p{\textgreater}},
	number = {04},
	journal = {Sportverl Sportschad},
	author = {Hotfiel, Thilo and Freiwald, Jürgen and Hoppe, Matthias Wilhelm and Lutter, Christoph and Forst, Raimund and Grim, Casper and Bloch, Wilhelm and Hüttel, Moritz and Heiss, Rafael},
	year = {2018},
	pmid = {30537791},
	keywords = {eccentric training, eimd, exercise-, induced muscle damage, mri, muscle damage, muscle injury, muscle strain},
	pages = {243--250},
}

@article{Hotfiel2019,
	title = {Accelerating {Recovery} from {Exercise}-{Induced} {Muscle} {Injuries} in {Triathletes}: {Considerations} for {Olympic} {Distance} {Races}},
	volume = {7},
	issn = {2075-4663},
	doi = {10.3390/sports7060143},
	abstract = {The triathlon is one of the fastest developing sports in the world due to expanding participation and media attention. The fundamental change in Olympic triathlon races from a single to a multistart event is highly demanding in terms of recovery from and prevention of exercise-induced muscle injures. In elite and competitive sports, ultrastructural muscle injuries, including delayed onset muscle soreness (DOMS), are responsible for impaired muscle performance capacities. Prevention and treatment of these conditions have become key in regaining muscular performance levels and to guarantee performance and economy of motion in swimming, cycling and running. The aim of this review is to provide an overview of the current findings on the pathophysiology, as well as treatment and prevention of, these conditions in compliance with clinical implications for elite triathletes. In the context of DOMS, the majority of recovery interventions have focused on different protocols of compression, cold or heat therapy, active regeneration, nutritional interventions, or sleep. The authors agree that there is a compelling need for further studies, including high-quality randomized trials, to completely evaluate the effectiveness of existing therapeutic approaches, particularly in triathletes. The given recommendations must be updated and adjusted, as further evidence emerges.},
	number = {6},
	journal = {Sports},
	author = {Hotfiel, Thilo and Mayer, Isabel and Huettel, Moritz and Hoppe, Matthias Wilhelm and Engelhardt, Martin and Lutter, Christoph and Pöttgen, Klaus and Heiss, Rafael and Kastner, Tom and Grim, Casper},
	year = {2019},
	pages = {143},
}

@article{Heiss2019,
	title = {Advances in {Delayed}-{Onset} {Muscle} {Soreness} ( {DOMS} ) – {Part} {II} : {Treatment} and {Prevention} {Delayed} {Onset} {Muscle} {Soreness} – {Teil} {II} : {Therapie} und {Prävention} {Authors}},
	volume = {33},
	issn = {0932-0555},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/30865998%0Ahttp://www.thieme-connect.de/DOI/DOI?10.1055/a-0810-3516},
	doi = {10.1055/a-0810-3516},
	abstract = {{\textless}p{\textgreater}Delayed-onset muscle soreness (DOMS) describes an entity of ultrastructural muscle damage. The manifestation of DOMS is caused by eccentric muscle contractions or unaccustomed forms of exercise. Clinical signs include impaired muscular force capacities, painful restriction of movement, stiffness, swelling, and altered biomechanics in adjacent joints. Although DOMS is categorised as a mild type of muscle damage, it is one of the most common reasons for compromised sportive performance. In the last decade, many hypotheses have been developed to explain the aetiology of DOMS, and there are a wide range of different interventions aiming to prevent or alleviate the symptoms. Many studies have evaluated various types of cold or heat therapy, compression, massage, physical therapy or nutritional interventions. Treatment considerations focus on the primary prevention of ultrastructural lesions during exercise, the treatment of the inflammatory response that leads to DOMS, and recovery strategies for manifest DOMS. This narrative review aims to present an overview of the current treatment and preventive strategies in the field of DOMS.{\textless}/p{\textgreater}},
	number = {01},
	journal = {Sportverl Sportschad},
	author = {Heiss, Rafael and Lutter, Christoph and Freiwald, Jürgen and Hoppe, Matthias W and Grim, Casper and Poettgen, Klaus and Forst, Raimund and Bloch, Wilhelm and Hüttel, Moritz and Hotfiel, Thilo and Huttel, Moritz and Hotfiel, Thilo},
	year = {2019},
	pmid = {30865998},
	keywords = {cold water immersion, compression, cryotherapy, damage, exercise-induced muscle, muscle damage, muscle strain, nutrition, recovery, regeneration},
	pages = {21--29},
}

@article{Rave2018,
	title = {The {Effects} of {Two} {Different} {Resisted} {Swim} {Training} {Load} {Protocols} on {Swimming} {Strength} and {Performance}},
	volume = {64},
	issn = {18997562},
	doi = {10.1515/hukin-2017-0194},
	abstract = {This study used a power rack device to evaluate the effects of 2 different approaches to resisted swim training loads on swimming strength and performance. Sixteen male, youth national-level swimmers (mean age, 16.22 ± 2.63 years; body height, 169 ± 10.20 cm; body mass, 61.33 ± 9.90 kg) completed a 6-week specific strength-training program, and were then randomly assigned to one of the two groups: a standard training group (GS, n = 8) and a flat pyramid-loading pattern group (GP, n = 8). Strength and power tests along with specific swimming tests (50-m crawl and 50-m competition-style time trials) were conducted at baseline (pre-test), before the third week (mid-test), and after 6 weeks of intervention (post-test). Isokinetic swim bench tests were conducted to obtain measurements of force production and power, and 1RM tests with the power rack system were conducted to measure the maximum drag load (MDL) and specific swimming power. Following 6 weeks of intervention, the mean MDL increased (p {\textless} 0.05) by 13.94\%. Scores for the 50-m competition style and 50-m crawl time trials improved by 0.32\% and 0.78\%, respectively, in the GP; however, those changes were not statistically significant. The GS significantly increased their time in the 50-m competition style by 2.59\%, and their isokinetic force production decreased by 14.47\% (p {\textless} 0.05). The 6-week strength-training program performed with the power rack device in a pyramidal organization was more effective than a standard linear load organization in terms of producing improvements in the MDL; however, it did not produce significant improvements in performance. The use of a strength-training program with a pyramidal organization can be recommended for specific strength-training in young swimmers during a preparatory period. However, in our study, that program did not produce significant changes in 50-m crawl and main competition style performance.},
	number = {1},
	journal = {Journal of Human Kinetics},
	author = {Ravé, José María González and Lega-Rrese, Alejandro and González-Mohíno, Fernando and Yustres, Inmaculada and Barragán, Rubén and De Asís Fernández, Francisco and Juárez, Daniel and Arroyo-Toledo, Juan Jaime},
	year = {2018},
	keywords = {load organization, power rack, swimming performance},
	pages = {195--204},
}

@article{DosSantos2018,
	title = {Effects of {Modified} {Pyramid} {System} on {Muscular} {Strength} and {Hypertrophy} in {Older} {Women}},
	volume = {39},
	issn = {14393964},
	doi = {10.1055/a-0634-6454},
	abstract = {This study aimed to analyze the effects of a pyramid system performed with two repetition zones on muscular strength and skeletal muscle mass (SMM) in older women. Thirty-nine physically independent older women (67.8±5.4 years) were randomly assigned into one of two of groups that performed an 8-week resistance training program in an ascending pyramid fashion. Both groups performed 3 sets: a narrow repetition zone (NPR, n=20) with 12/10/8 repetitions, and a wide repetition zone (WPR, n=19) with 15/10/5 repetitions. The program consisted of 8 whole-body exercises, performed 3 times a week. Dual-energy X-ray absorptiometry was used to measure SMM, and muscular strength was evaluated by one-repetition maximum (1RM). Both groups increased (P{\textless}0.05) SMM (NPR=+ 4.7\%, effect size=+ 0.34; WPR=+ 8.4\%, effect size=+ 0.77), and total strength (NPR=+ 11.3\%, effect size=+ 0.80; WPR=+ 13.8\%, effect size=0.84), without statistical differences between them. Results suggest that both zones of repetitions in a pyramid system are effective strategies to improve muscular strength and muscle growth in older women.},
	number = {8},
	journal = {International Journal of Sports Medicine},
	author = {Dos Santos, Leandro and Ribeiro, Alex S. and Cavalcante, Edilaine F. and Nabuco, Hellen C. and Antunes, Melissa and Schoenfeld, Brad J. and Cyrino, Edilson S.},
	year = {2018},
	keywords = {aging, hypertrophy, pyramidal system, resistance exercises, strength training},
	pages = {613--618},
}

@article{Costa2019,
	title = {Acute {Effect} of {Drop}-{Set}, {Traditional}, and {Pyramidal} {Systems} in {Resistance} {Training} on {Neuromuscular} {Performance} in {Trained} {Adults}},
	issn = {1064-8011},
	doi = {10.1519/jsc.0000000000003150},
	abstract = {The aim of this study was to analyze the acute effects of resistance training (RT) systems on lower- and upper-limb performance in trained adults. Eighteen male young adults with experience in RT aged from 18 to 26 years underwent the 3 experimental conditions (drop-set [DS], decrescent pyramid [DP], and traditional [TR]). The participants performed 2 exercises (bench press and leg press 45°). In the DS condition, they underwent 2 sets of 10 repetitions at 12RM, followed by 5 additional repetitions with an intensity of 15RM with 6-minute interval rest between sets. In the DP, it was performed 3 sets of 10 repetitions at 10RM, 12RM, and 15RM, respectively, and the rest interval was 3 minutes between sets. In the TR, the participants performed 3 sets of 10 repetitions at 12RM with 3 minutes of rest between sets. Countermovement jump, peak power (Wpeak), and force (Fpeak) in the bench press were evaluated in the baseline, before, and 30 minutes after the experimental sessions. Countermovement jump performance decreased significantly only after the DS and DP conditions (-6.7 and -1.9\%, respectively). The groups were significantly different in the post-intervention; the DS condition presented lower values when compared with the DP (p = 0.01) and TR (p = 0.001). According to Fpeak and Wpeak, only DS condition significantly decreased the performance (-3.8 and -4.1\%, respectively). The results indicate the DS and DP conditions impair the neuromuscular performance of the lower limbs, whereas for upper limbs, only DS condition negatively affect upper-limb performance.},
	number = {6},
	journal = {Journal of Strength and Conditioning Research},
	author = {Costa, Bruna Daniella de Vasconcelos and Ferreira, Maria Elisa Caputo and Gantois, Petrus and Kassiano, Witalo and Paes, Santiago T. and de Lima-Júnior, Dalton and Cyrino, Edilson S. and Fortes, Leonardo de Souza},
	year = {2019},
	keywords = {countermovement jump, peak force, peak power, strength training},
	pages = {1},
}

@article{Ralston2017,
	title = {The {Effect} of {Weekly} {Set} {Volume} on {Strength} {Gain}: {A} {Meta}-{Analysis}},
	volume = {47},
	issn = {11792035},
	doi = {10.1007/s40279-017-0762-7},
	abstract = {Background: Strength training set organisation and its relationship to the development of muscular strength have yet to be clearly defined. Current meta-analytical research suggests that different population groups have distinctive muscular adaptations, primarily due to the prescription of the strength training set dose. Objectives: We conducted a meta-analysis with restrictive inclusion criteria and examined the potential effects of low (LWS), medium (MWS) or high weekly set (HWS) strength training on muscular strength per exercise. Secondly, we examined strength gain variations when performing multi-joint or isolation exercises, and probed for a potential relationship between weekly set number and stage of subjects’ training (trained versus untrained). Methods: Computerised searches were performed on PubMed, MEDLINE, SWETSWISE, EMBASE and SPORTDiscus™ using the terms ‘strength training’, ‘resistance training’, ‘single sets’, ‘multiple sets’ and ‘volume’. As of September 2016, 6962 potentially relevant studies were identified. After review, nine studies were deemed eligible per pre-set inclusion criteria. Primary data were pooled using a random-effect model. Outcomes for strength gain, strength gain with multi-joint and isolation exercise were analysed for main effects. Sensitivity analyses were calculated for several subgroups by separating the data set and by calculation of separate analyses for each subgroup. Heterogeneity between studies was assessed using the Cochran Q and I2 statistics. Results: Pre- versus post-training strength analysis comprised 61 treatment groups from nine studies. For combined multi-joint and isolation exercises, pre- versus post- training strength gains were greater with HWS compared with LWS [mean effect size (ES) 0.18; 95\% CI 0.06–0.30; p = 0.003]. The mean ES for LWS was 0.82 (95\% CI 0.47–1.17). The mean ES for HWS was 1.01 (95\% CI 0.70–1.32). Separate analysis of the effects of pre- versus post-training strength for LWS or MWS observed marginally greater strength gains with MWS compared with LWS (ES 0.15; 95\% CI 0.01–0.30; p = 0.04). The mean ES for LWS was 0.83 (95\% CI 0.53–1.13). The mean ES for MWS was 0.98 (95\% CI 0.62–1.34). For multi-joint exercises, greater strength gains were observed with HWS compared with LWS (ES 0.18; 95\% CI 0.01–0.34; p = 0.04). The mean ES for LWS was 0.81 (95\% CI 0.65–0.97). The mean ES for HWS was 1.00 (95\% CI 0.77–1.23). For isolation exercises, greater strength gains were observed with HWS compared with LWS (ES 0.23; 95\% CI 0.06–0.40; p = 0.008). The mean ES for LWS was 0.95 (95\% CI 0.30–1.60). The mean ES for HWS was 1.10 (95\% CI 0.26–1.94). For multi-joint and isolation exercise-specific one repetition maximum (1 RM), marginally greater strength gains were observed with HWS compared with LWS (ES 0.14; 95\% CI −0.01 to 0.29; p = 0.06). The mean ES for LWS was 0.80 (95\% CI 0.47–1.13). The mean ES for HWS was 0.97 (95\% CI 0.68–1.26). Conclusion: This meta-analysis presents additional evidence regarding a graded dose–response relationship between weekly sets performed and strength gain. The use of MWS and HWS was more effective than LWS, with LWS producing the smallest pre- to post-training strength difference. For novice and intermediate male trainees, the findings suggest that LWSs do not lead to strength gains compared with MWS or HWS training. For those trainees in the middle ground, not a novice and not advanced, the existing data provide a relationship between weekly sets and strength gain as set configurations produced different pre- to post-training strength increases. For well trained individuals, the use of either MWS or HWS may be an appropriate dose to produce strength gains.},
	number = {12},
	journal = {Sports Medicine},
	author = {Ralston, Grant W. and Kilgore, Lon and Wyatt, Frank B. and Baker, Julien S.},
	year = {2017},
	pmid = {28755103},
	note = {Publisher: Springer International Publishing},
	pages = {2585--2601},
}

@article{Schoenfeld2017,
	title = {Strength and hypertrophy adaptations between low- vs. {High}-load resistance training: {A} systematic review and meta-analysis},
	volume = {31},
	issn = {15334295},
	doi = {10.1519/JSC.0000000000002200},
	abstract = {Schoenfeld, BJ, Grgic, J, Ogborn, D, and Krieger, JW. Strength and hypertrophy adaptations between low- vs. high-load resistance training: a systematic review and meta-analysis. J Strength Cond Res 31(12): 3508–3523, 2017—The purpose of this article was to conduct a systematic review of the current body of literature and a meta-analysis to compare changes in strength and hypertrophy between low- vs. high-load resistance training protocols. Searches of PubMed/MEDLINE, Cochrane Library, and Scopus were conducted for studies that met the following criteria: (a) an experimental trial involving both low-load training [\#60\% 1 repetition maximum (1RM)] and high-load training (.60\% 1RM); (b) with all sets in the training protocols being performed to momentary muscular failure; (c) at least one method of estimating changes in muscle mass or dynamic, isometric, or isokinetic strength was used; (d) the training protocol lasted for a minimum of 6 weeks; (e) the study involved participants with no known medical conditions or injuries impairing training capacity. A total of 21 studies were ultimately included for analysis. Gains in 1RM strength were significantly greater in favor of high- vs. low-load training, whereas no significant differences were found for isometric strength between conditions. Changes in measures of muscle hypertrophy were similar between conditions. The findings indicate that maximal strength benefits are obtained from the use of heavy loads while muscle hypertrophy can be equally achieved across a spectrum of loading ranges.},
	number = {12},
	journal = {Journal of Strength and Conditioning Research},
	author = {Schoenfeld, Brad J. and Grgic, Jozo and Ogborn, Dan and Krieger, James W.},
	year = {2017},
	pmid = {28834797},
	keywords = {Heavy loading, Light loading, Muscle mass, Muscle strength, Repetition maximum continuum},
	pages = {3508--3523},
}

@article{Grgic2018,
	title = {Effect of {Resistance} {Training} {Frequency} on {Gains} in {Muscular} {Strength}: {A} {Systematic} {Review} and {Meta}-{Analysis}},
	volume = {48},
	issn = {11792035},
	url = {https://doi.org/10.1007/s40279-018-0872-x},
	doi = {10.1007/s40279-018-0872-x},
	abstract = {Background: Current recommendations on resistance training (RT) frequency for gains in muscular strength are based on extrapolations from limited evidence on the topic, and thus their practical applicability remains questionable. Objective: To elucidate this issue, we conducted a systematic review and meta-analysis of the studies that compared muscular strength outcomes with different RT frequencies. Methods: To carry out this review, English-language literature searches of the PubMed/MEDLINE, Scopus, and SPORTDiscus databases were conducted. The meta-analysis was performed using a random-effects model. The meta-analysis models were generated with RT frequencies classified as a categorical variable as either 1, 2, 3, or 4+ times/week, or, if there were insufficient data in subgroup analyses, the training frequencies were categorized as 1, 2, or 3 times/week. Subgroup analyses were performed for potential moderators, including (1) training volume; (2) exercise selection for the 1 repetition maximum (RM) test (for both multi-joint and single-joint exercises); (3) upper and lower body strength gains; (4) training to muscular failure (for studies involving and not involving training to muscular failure); (5) age (for both middle-aged/older adults and young adults); and (6) sex (for men and for women). The methodological quality of studies was appraised using the modified Downs and Black checklist. Results: A total of 22 studies were found to meet the inclusion criteria. The average score on the Downs and Black checklist was 18 (range 13–22 points). Four studies were classified as being of good methodological quality, while the rest were classified as being of moderate methodological quality. Results of the meta-analysis showed a significant effect (p = 0.003) of RT frequency on muscular strength gains. Effect sizes increased in magnitude from 0.74, 0.82, 0.93, and 1.08 for training 1, 2, 3, and 4+ times per week, respectively. A subgroup analysis of volume-equated studies showed no significant effect (p = 0.421) of RT frequency on muscular strength gains. The subgroup analysis for exercise selection for the 1RM test suggested a significant effect of RT frequency on multi-joint (p {\textless} 0.001), but not single-joint, 1RM test results (p = 0.324). The subgroup analysis for upper and lower body showed a significant effect of frequency (p = 0.004) for upper body, but not lower body, strength gains (p = 0.070). In the subgroup analysis for studies in which the training was and was not carried out to muscular failure, no significant effect of RT frequency was found. The subgroup analysis for the age groups suggested a significant effect of training frequency among young adults (p = 0.024), but not among middle-aged and older adults (p = 0.093). Finally, the subgroup analysis for sex indicated a significant effect of RT frequency on strength gains in women (p = 0.030), but not men (p = 0.190). Conclusions: The results of the present systematic review and meta-analysis suggest a significant effect of RT frequency as higher training frequencies are translated into greater muscular strength gains. However, these effects seem to be primarily driven by training volume because when the volume is equated, there was no significant effect of RT frequency on muscular strength gains. Thus, from a practical standpoint, greater training frequencies can be used for additional RT volume, which is then likely to result in greater muscular strength gains. However, it remains unclear whether RT frequency on its own has significant effects on strength gain. It seems that higher RT frequencies result in greater gains in muscular strength on multi-joint exercises in the upper body and in women, and, finally, in contrast to older adults, young individuals seem to respond more positively to greater RT frequencies. More evidence among resistance-trained individuals is needed as most of the current studies were performed in untrained participants.},
	number = {5},
	journal = {Sports Medicine},
	author = {Grgic, Jozo and Schoenfeld, Brad J. and Davies, Timothy B. and Lazinica, Bruno and Krieger, James W. and Pedisic, Zeljko},
	year = {2018},
	pmid = {29470825},
	note = {Publisher: Springer International Publishing},
	pages = {1207--1220},
}

@article{Gonzalez2016,
	title = {Acute anabolic response and muscular adaptation after hypertrophy-style and strength-style resistance exercise},
	volume = {30},
	issn = {15334295},
	doi = {10.1519/JSC.0000000000001378},
	abstract = {Resistance training paradigms are often divided into protocols designed to promote an increase in either hypertrophy or strength. Hypertrophy-style protocols (HYPs) typically involve greater volume (3-6 sets; 8-12 repetitions), moderate intensities ({\textless}85\% 1 repetition maximum [1RM]), and short rest intervals (30-90 seconds), whereas strength-style protocols (STRs) typically involve higher intensities (≥85\% 1RM), low volumes (2-6 sets; ≤6 repetitions), and longer rest intervals (3-5 minutes). However, the literature supporting such classifications is surprisingly sparse in trained individuals, and the distinct classifications of such protocols may be an oversimplification. Thus, the purpose of this review was to examine the acute anabolic responses and training-induced muscular adaptations after HYP and STR styles of resistance exercise in trained individuals. Despite the classification of training paradigms, HYP and STR resistance training routines appear to elicit similar magnitudes of muscle growth, although STR routines appear to be more conducive to increasing strength in resistance-Trained individuals. Current evidence suggests that the classification of HYP and STR is an oversimplification, and practitioners are advised to look beyond the classification of resistance exercise protocols when aiming to elicit specific physiological responses.},
	number = {10},
	journal = {Journal of Strength and Conditioning Research},
	author = {Gonzalez, Adam M.},
	year = {2016},
	note = {ISBN: 0000000000},
	keywords = {Intensity, Muscle activation, Muscle growth, Resistance training, Volume},
	pages = {2959--2964},
}

@article{Shephard1993,
	title = {Metabolic {Adaptations} to {Exercise} in the {Cold}: {An} {Update}},
	volume = {16},
	issn = {11792035},
	doi = {10.2165/00007256-199316040-00005},
	abstract = {Metabolic adaptations to exercise in a cold environment include the liberation of heat by vigorous physical activity, shivering and various forms of nonshivering thermogenesis. During a single exposure to cold the main metabolic fuel is glycogen; however, repeated bouts of exercise in the cold also result in an increase in fat metabolism. Potential contributors to fat loss induced by exercise in the cold include: the energy cost of synthesising lean tissue; cold-induced excretion of ketones; stimulation of resting metabolism; and the high energy cost of movement in a cold environment (walking over snow, the weight of heavy boots, hobbling by winter clothing, and decreased mechanical efficiency of dehydrated muscles). Biochemical explanations of fat mobilisation include increased secretion of catecholamines, increased sensitivity of peripheral catecholamine receptors and a decrease in circulating insulin levels. Such fat loss may be helpful in treating moderate obesity, although the response seems less well developed in women than in men. Metabolic changes must be taken into consideration in preparing winter athletes for competition. Glycogen depletion has a negative effect on the performance of endurance competitors, but this can be countered by a combination of diet, training and cold acclimation. © 1993, Adis International Limited. All rights reserved.},
	number = {4},
	journal = {Sports Medicine: An International Journal of Applied Medicine and Science in Sport and Exercise},
	author = {Shephard, Roy J.},
	year = {1993},
	pages = {266--289},
}

@misc{noauthor_the_effects_of_caffeine_and_exercise_on_body11pdf_nodate,
	title = {The\_effects\_of\_caffeine\_and\_exercise\_on\_body.11.pdf},
}

@article{Herren2019,
	title = {A {Microsporidian} blocks {Plasmodium} falciparum transmission in {Anopheles} arabiensis mosquitoes},
	issn = {2041-1723},
	url = {http://dx.doi.org/10.1038/s41467-020-16121-y},
	doi = {10.1101/799445},
	abstract = {Malaria imposes an enormous burden on sub-Saharan Africa, and evidence that incidence could be starting to increase again[1][1] suggests the limits of currently applied control strategies have now been reached. A possible novel control approach involves the dissemination in mosquitoes of inherited symbiotic microbes to block transmission. This strategy is exemplified by the use of transmission-blocking Wolbachia in Aedes aegypti against dengue virus[2][2]–[7][3]. However, in the Anopheles gambiae complex, the primary African vectors of malaria, there limited reports of inherited symbionts with transmission-blocking capacity[8][4]–[10][5]. Here we show that a newly discovered vertically transmitted species of Microsporidia symbiont in the An. gambiae complex blocks Plasmodium transmission. Microsporidia MB is present at moderate prevalence in geographically dispersed populations of An. arabienesis in Kenya, localized to the mosquito midgut and ovaries, and is not associated with significant reductions in adult host fecundity or survival. Field collected Microsporidia MB -infected An. arabiensis were never found to harbor P. falciparum gametocytes and on experimental infection with P. falciparum no sporozoites could be detected in Microsporidia MB- infected mosquitos. As a Plasmodium transmission-blocking microbe that is non-virulent and vertically transmitted, Microsporidia MB could be exploited as a novel malaria control tool.

 [1]: \#ref-1
 [2]: \#ref-2
 [3]: \#ref-7
 [4]: \#ref-8
 [5]: \#ref-10},
	number = {2020},
	journal = {bioRxiv},
	author = {Herren, Jeremy K. and Mbaisi, Lilian and Mararo, Enock and Oundo, Joseph W. and Makhulu, Edward E. and Butungi, Hellen and Mancini, Maria Vittoria and Mobegi, Victor A. and Jabara, Jordan and Sinkins, Steven P.},
	year = {2019},
	note = {Publisher: Springer US},
	pages = {799445},
}

@article{Patterson2017,
	title = {Metabolic {Effects} of {Intermittent} {Fasting}},
	volume = {37},
	issn = {0199-9885},
	doi = {10.1146/annurev-nutr-071816-064634},
	abstract = {The objective of this review is to provide an overview of intermittent fasting regimens, summarize the evidence on the health benefits of intermittent fasting, and discuss physiological mechanisms by which intermittent fasting might lead to improved health outcomes. A MEDLINE search was performed using PubMed and the terms "intermittent fasting," "fasting," "time-restricted feeding," and "food timing." Modified fasting regimens appear to promote weight loss and may improve metabolic health. Several lines of evidence also support the hypothesis that eating patterns that reduce or eliminate nighttime eating and prolong nightly fasting intervals may result in sustained improvements in human health. Intermittent fasting regimens are hypothesized to influence metabolic regulation via effects on (a) circadian biology, (b) the gut microbiome, and (c) modifiable lifestyle behaviors, such as sleep. If proven to be efficacious, these eating regimens offer promising nonpharmacological approaches to improving health at the population level, with multiple public health benefits.},
	number = {1},
	journal = {Annual Review of Nutrition},
	author = {Patterson, Ruth E. and Sears, Dorothy D.},
	year = {2017},
	pmid = {28715993},
	keywords = {circadian rhythm, gut microbiome, modifiable lifestyle, postprandial},
	pages = {371--393},
}

@article{mattson_hhs_2018,
	title = {{HHS} {Public} {Access}},
	doi = {10.1016/j.arr.2016.10.005.Impact},
	author = {Mattson, Mark P and Longo, Valter D and Harvie, Michelle and States, United and States, United and Angeles, Los and States, United and Cancer, Breast and Centre, Prevention and Kingdom, United},
	year = {2018},
	pages = {46--58},
}

@article{White2019,
	title = {Beyond {Bonferroni} revisited: concerns over inflated false positive research findings in the fields of conservation genetics, biology, and medicine},
	volume = {20},
	issn = {15729737},
	url = {https://doi.org/10.1007/s10592-019-01178-0},
	doi = {10.1007/s10592-019-01178-0},
	abstract = {In 2006, Narum published a paper in Conservation Genetics emphasizing that Bonferroni correction for multiple testing can be highly conservative with poor statistical power (high Type II error). He pointed out that other approaches for multiple testing correction can control the false discovery rate (FDR) with a better balance of Type I and Type II errors and suggested that the approach of Benjamini and Yekutieli (BY) 2001 provides the most biologically relevant correction for evaluating the significance of population differentiation in conservation genetics. However, there are crucial differences between the original Benjamini and Yekutieli procedure and that described by Narum. After carefully reviewing both papers, we found an error due to the incorrect implementation of the BY procedure in Narum (Conserv Genet 7:783–787, 2006) such that the approach does not adequately control FDR. Since the incorrect BY approach has been increasingly used, not only in conservation genetics, but also in medicine and biology, it is important that the error is made known to the scientific community. In addition, we provide an overview of FDR approaches for multiple testing correction and encourage authors first and foremost to provide effect sizes for their results; and second, to be transparent in their descriptions of multiple testing correction. Finally, the impact of this error on conservation genetics and other fields will be study-dependent, as it is related to the number of true to false positives for each study.},
	number = {4},
	journal = {Conservation Genetics},
	author = {White, Tonya and van der Ende, Jan and Nichols, Thomas E.},
	year = {2019},
	note = {Publisher: Springer Netherlands
ISBN: 0123456789},
	keywords = {Benjamini Hochberg, Benjamini Yekutieli, False discovery rate, Family-wise error, Multiple testing correction},
	pages = {927--937},
}

@article{johnson_legends_2004,
	title = {{LEGENDS} {OF} {VANCOUVER} {AUTHOR} ' {S} {FOREWORD}},
	author = {Johnson, By E Pauline},
	year = {2004},
	pages = {1--47},
}

@book{vermeer_communications_nodate,
	title = {{COMMUNICATIONS} {COMPUTING} {AGE} {MANAGING} {THE} {RISKS} {TO} {ENCRYPTION} {IN} {THE}},
	isbn = {978-1-977404-61-9},
	author = {Vermeer, Michael J D and Peet, Evan D},
}

@article{Jakobs2020,
	title = {Light {Microscopy} of {Mitochondria} at the {Nanoscale}},
	volume = {49},
	issn = {1936-122X},
	doi = {10.1146/annurev-biophys-121219-081550},
	abstract = {Mitochondria are essential for eukaryotic life. These double-membrane organelles often form highly dynamic tubular networks interacting with many cellular structures. Their highly convoluted contiguous inner membrane compartmentalizes the organelle, which is crucial for mitochondrial function. Since the diameter of the mitochondrial tubules is generally close to the diffraction limit of light microcopy, it is often challenging, if not impossible, to visualize submitochondrial structures or protein distributions using conventional light microscopy. This renders super-resolution microscopy particularly valuable, and attractive, for studying mitochondria. Super-resolution microscopy encompasses a diverse set of approaches that extend resolution, as well as nanoscopy techniques that can even overcome the diffraction limit. In this review, we provide an overview of recent studies using super-resolution microscopy to investigate mitochondria, discuss the strengths and opportunities of the various methods in addressing specific questions in mitochondrial biology, and highlight potential future developments.Expected final online publication date for the Annual Review of Biophysics, Volume 49 is May 6, 2020. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
	number = {1},
	journal = {Annual Review of Biophysics},
	author = {Jakobs, Stefan and Stephan, Till and Ilgen, Peter and Brüser, Christian},
	year = {2020},
	keywords = {live-cell microscopy, mitochondria, nanoscopy, super-resolution},
}

@article{Carter2020,
	title = {Ribosome-associated vesicles: {A} dynamic subcompartment of the endoplasmic reticulum in secretory cells},
	volume = {6},
	issn = {2375-2548},
	doi = {10.1126/sciadv.aay9572},
	abstract = {The endoplasmic reticulum (ER) is a highly dynamic network of membranes. Here, we combine live-cell microscopy with in situ cryo–electron tomography to directly visualize ER dynamics in several secretory cell types including pancreatic β-cells and neurons under near-native conditions. Using these imaging approaches, we identify a novel, mobile form of ER, ribosome-associated vesicles (RAVs), found primarily in the cell periphery, which is conserved across different cell types and species. We show that RAVs exist as distinct, highly dynamic structures separate from the intact ER reticular architecture that interact with mitochondria via direct intermembrane contacts. These findings describe a new ER subcompartment within cells.},
	number = {14},
	journal = {Science Advances},
	author = {Carter, Stephen D. and Hampton, Cheri M. and Langlois, Robert and Melero, Roberto and Farino, Zachary J. and Calderon, Michael J. and Li, Wen and Wallace, Callen T. and Tran, Ngoc Han and Grassucci, Robert A. and Siegmund, Stephanie E. and Pemberton, Joshua and Morgenstern, Travis J. and Eisenman, Leanna and Aguilar, Jenny I. and Greenberg, Nili L. and Levy, Elana S. and Yi, Edward and Mitchell, William G. and Rice, William J. and Wigge, Christoph and Pilli, Jyotsna and George, Emily W. and Aslanoglou, Despoina and Courel, Maïté and Freyberg, Robin J. and Javitch, Jonathan A. and Wills, Zachary P. and Area-Gomez, Estela and Shiva, Sruti and Bartolini, Francesca and Volchuk, Allen and Murray, Sandra A. and Aridor, Meir and Fish, Kenneth N. and Walter, Peter and Balla, Tamas and Fass, Deborah and Wolf, Sharon G. and Watkins, Simon C. and Carazo, José María and Jensen, Grant J. and Frank, Joachim and Freyberg, Zachary},
	year = {2020},
	pages = {eaay9572},
}

@article{of_dhammatalk_nodate,
	title = {A {Dhammatalk} by {Ajahn} {Chah}},
	author = {Of, I S T and Of, Iography},
	pages = {1--3},
}

@article{Morin2015,
	title = {Tsleil-{Waututh} {Nation}'s {History}, {Culture} and {Aboriginal} {Interests} in {Eastern} {Burrard} {Inlet} ({Redacted} {Version})},
	abstract = {Who the Tsleil-Waututh people are as a people historically and today: 
their origins, culture, language, traditions and connection to Eastern 
Burrard Inlet and the watersheds draining therein (the “Study Area”). And 
“whether the Tsleil-Waututh were a distinct Aboriginal group at contact 
and in 1846, and the relationship of the modern Tsleil-Waututh Nation to 
this historic group and its territories.},
	author = {Morin, Jesse},
	year = {2015},
	pages = {477},
}

@article{Chah1994,
	title = {No {Ajahn} {Chah}: {Reflections}},
	abstract = {Introducción Cuando las personas le decían a Ajahn Chah que encontraban imposible practicar en la sociedad, él les preguntaba, "Si yo lo punzara a usted en el pecho con una vara ardiente, sin duda afirmaría que está sufriendo, ¿acaso es debido a que vive en sociedad que no puede deshacerse de ella?" La respuesta de Ajahn Chah aclara el asunto de una manera similar a la parábola de la flecha envenenada del Buda. El Buda cuenta sobre un hombre que había sido alcanzado por una flecha y que no dejaba que nadie se la quitara hasta que sus preguntas acerca de la flecha, el arco y el arquero fuesen respondidas. El único problema era que el hombre herido probablemente moriría antes de que pudiera obtener las respuestas a todas sus preguntas. De lo que el hombre herido tenía que darse cuenta era de que estaba dolorido y agonizante y que tenía que hacer algo acerca de ello inmediatamente.},
	author = {Chah, Ajahn},
	year = {1994},
}

@article{Chah,
	title = {A {Tree} in {A}},
	author = {Chah, Ajahn},
	keywords = {Buddhism, Thailand, Forest Monk, Reflections, medi},
}

@article{TheSangha2007,
	title = {The {Teachings} of {Ajahn} {Chah}: {A} collection of {Ajahn} {Chah}'s {Dhamma} {Talks}},
	author = {The Sangha, Wat Nong Pah Pong},
	year = {2007},
	keywords = {Ajaan Chah, Ajahn Chah, Ajarn Chah, Buddha, Buddhism, Buddhist monk, Dhamma, Dhammatalk, Discipline, Meditation, Morality, Sangha, Thai Forest Tradition, Thailand, Vinaya, Wat Nong Pah Pong, Wat Pa Nanachat, Wat Pah Nanachat, bhikkhu, bhiksu, teaching., ★},
	pages = {715},
}

@article{wiseman_when_nodate,
	title = {When {Do} {Traffic} {Reports} {Make} {Traffic} {Better}?},
	number = {February 2019},
	author = {Wiseman, Jim and Wiseman, Thomas},
	pages = {1--21},
}

@article{Sugaya2018,
	title = {Maintaining privacy in cartels},
	volume = {126},
	issn = {1537534X},
	doi = {10.1086/699975},
	abstract = {It is conventional wisdom that transparency in cartels—monitoring of competitors’ prices, sales, and profits—facilitates collusion. However, in several recent cases cartels have instead worked to preserve the privacy of their participants’ actions and outcomes. Toward explaining this behavior, we show that cartels can sometimes sustain higher profits when actions and outcomes are observed only privately, because better information can hinder collusion by helping firms devise more profitable deviations from the collusive agreement. We provide conditions under which maintaining privacy is optimal for cartels that follow a market-segmentation strategy.},
	number = {6},
	journal = {Journal of Political Economy},
	author = {Sugaya, Takuo and Wolitzky, Alexander},
	year = {2018},
	pages = {2569--2607},
}

@article{whitlad_introduction_1995,
	title = {An introduction to wavelets with applications to {Andrews} ’ plots},
	volume = {0427},
	number = {95},
	author = {Whitlad, J Robertson and Embrechts, Paul and Herzbergb, Agnes M and Kalbfleischb, Heidi K and Travesc, William N},
	year = {1995},
	keywords = {andrews, data analysis, exploratory, fourier functions, haar wavelet, plots, wavelets},
}

@article{fyfe_visualization_2005,
	title = {Visualization of {High}-{Dimensional} {Data} via {Orthogonal} {Curves}},
	volume = {11},
	number = {11},
	author = {Fyfe, Colin},
	year = {2005},
	keywords = {andrews, curves, exploratory data analysis, grand tour methods, visual},
	pages = {1806--1819},
}

@inproceedings{yang_image_2008,
	title = {Image super-resolution as sparse representation of raw image patches},
	isbn = {978-1-4244-2243-2},
	doi = {10.1109/CVPR.2008.4587647},
	abstract = {This paper addresses the problem of generating a super-resolution (SR) image from a single low-resolution input image. We approach this problem from the perspective of compressed sensing. The low-resolution image is viewed as downsampled version of a high-resolution image, whose patches are assumed to have a sparse representation with respect to an over-complete dictionary of prototype signal-atoms. The principle of compressed sensing ensures that under mild conditions, the sparse representation can be correctly recovered from the downsampled signal. We will demonstrate the effectiveness of sparsity as a prior for reg-ularizing the otherwise ill-posed super-resolution problem. We further show that a small set of randomly chosen raw patches from training images of similar statistical nature to the input image generally serve as a good dictionary, in the sense that the computed representation is sparse and the recovered high-resolution image is competitive or even su-perior in quality to images produced by other SR methods.},
	booktitle = {26th {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}, {CVPR}},
	author = {Yang, Jianchao and Wright, John and Huang, Thomas and Ma, Yi},
	year = {2008},
}

@article{gwosch_minflux_2019,
	title = {{MINFLUX} nanoscopy delivers multicolor nanometer {3D}- resolution in ( living ) cells},
	author = {Gwosch, Klaus C and Pape, Jasmin K and Balzarotti, Francisco and Hoess, Philipp and Ellenberg, Jan and Ries, Jonas},
	year = {2019},
	pages = {1--37},
}

@article{Hershko*2018,
	title = {Multicolor localization microscopy by deep learning},
	volume = {5},
	url = {http://arxiv.org/abs/1807.01637},
	abstract = {Deep learning has become an extremely effective tool for image classification and image restoration problems. Here, we apply deep learning to microscopy, and demonstrate how neural networks can exploit the chromatic dependence of the point-spread function to classify the colors of single emitters imaged on a grayscale camera. While existing single-molecule methods for spectral classification require additional optical elements in the emission path, e.g. spectral filters, prisms, or phase masks, our neural net correctly identifies static as well as mobile emitters with high efficiency using a standard, unmodified single-channel configuration. Furthermore, we demonstrate how deep learning can be used to design phase-modulating elements that, when implemented into the imaging path, result in further improved color differentiation between species.},
	number = {4},
	author = {Hershko*, Eran and Weiss*, Lucien E. and Michaeli, Tomer and Shechtman, Yoav},
	year = {2018},
	note = {arXiv: 1807.01637},
}

@article{Nehme2019,
	title = {Dense three dimensional localization microscopy by deep learning},
	url = {http://arxiv.org/abs/1906.09957},
	abstract = {Localization microscopy is an imaging technique in which the positions of individual nanoscale point emitters (e.g. fluorescent molecules) are determined at high precision from their images. This is the key ingredient in single/multiple-particle-tracking and several super-resolution microscopy approaches. Localization in three-dimensions (3D) can be performed by modifying the image that a point-source creates on the camera, namely, the point-spread function (PSF), using additional optical elements. However, localizing multiple adjacent emitters in 3D poses a significant algorithmic challenge, due to the lateral overlap of their PSFs. Here, we train a neural net to receive an image containing densely overlapping PSFs of multiple emitters over a large axial range, and output a list of their 3D positions. Furthermore, we then use the net to design the optimal PSF for the multi-emitter case. We demonstrate our approach numerically as well as experimentally by volumetrically imaging dozens of fluorescently-labeled telomeres occupying a mammalian nucleus in a single snapshot.},
	author = {Nehme, Elias and Freedman, Daniel and Gordon, Racheli and Ferdman, Boris and Michaeli, Tomer and Shechtman, Yoav},
	year = {2019},
	note = {arXiv: 1906.09957},
	pages = {12--14},
}

@article{Hershko2019,
	title = {Multicolor localization microscopy and point-spread-function engineering by deep learning},
	volume = {27},
	doi = {10.1364/oe.27.006158},
	abstract = {Deep learning has become an extremely effective tool for image classification and image restoration problems. Here, we apply deep learning to microscopy, and demonstrate how neural networks can exploit the chromatic dependence of the point-spread function to classify the colors of single emitters imaged on a grayscale camera. While existing single-molecule methods for spectral classification require additional optical elements in the emission path, e.g. spectral filters, prisms, or phase masks, our neural net correctly identifies static as well as mobile emitters with high efficiency using a standard, unmodified single-channel configuration. Furthermore, we demonstrate how deep learning can be used to design phase-modulating elements that, when implemented into the imaging path, result in further improved color differentiation between species.},
	number = {5},
	journal = {Optics Express},
	author = {Hershko, Eran and Weiss, Lucien E. and Michaeli, Tomer and Shechtman, Yoav},
	year = {2019},
	pages = {6158},
}

@article{Khater2018a,
	title = {Super {Resolution} {Network} {Analysis} {Defines} the {Molecular} {Architecture} of {Caveolae} and {Caveolin}-1 {Scaffolds} /631/80/2373/2238 /631/80/313/2026 /14 /14/19 /123 /139 /141 /119 article},
	volume = {8},
	issn = {20452322},
	doi = {10.1038/s41598-018-27216-4},
	abstract = {Quantitative approaches to analyze the large data sets generated by single molecule localization super-resolution microscopy (SMLM) are limited. We developed a computational pipeline and applied it to analyzing 3D point clouds of SMLM localizations (event lists) of the caveolar coat protein, caveolin-1 (Cav1), in prostate cancer cells differentially expressing CAVIN1 (also known as PTRF), that is also required for caveolae formation. High degree (strongly-interacting) points were removed by an iterative blink merging algorithm and Cav1 network properties were compared with randomly generated networks to retain a sub-network of geometric structures (or blobs). Machine-learning based classification extracted 28 quantitative features describing the size, shape, topology and network characteristics of approximately 80,000 blobs. Unsupervised clustering identified small S1A scaffolds corresponding to SDS-resistant Cav1 oligomers, as yet undescribed larger hemi-spherical S2 scaffolds and, only in CAVIN1-expressing cells, spherical, hollow caveolae. Multi-threshold modularity analysis suggests that S1A scaffolds interact to form larger scaffolds and that S1A dimers group together, in the presence of CAVIN1, to form the caveolae coat.},
	number = {1},
	journal = {Scientific Reports},
	author = {Khater, Ismail M. and Meng, Fanrui and Wong, Timothy H. and Nabi, Ivan Robert and Hamarneh, Ghassan},
	year = {2018},
	pages = {1--15},
}

@article{Creech2017,
	title = {Superresolution imaging of clinical formalin fixed paraffin embedded breast cancer with single molecule localization microscopy},
	volume = {7},
	issn = {20452322},
	url = {http://dx.doi.org/10.1038/srep40766},
	doi = {10.1038/srep40766},
	abstract = {Millions of archived formalin-fixed, paraffin-embedded (FFPE) specimens contain valuable molecular insight into healthy and diseased states persevered in their native ultrastructure. To diagnose and treat diseases in tissue on the nanoscopic scale, pathology traditionally employs electron microscopy (EM), but this platform has significant limitations including cost and painstaking sample preparation. The invention of single molecule localization microscopy (SMLM) optically overcame the diffraction limit of light to resolve fluorescently labeled molecules on the nanoscale, leading to many exciting biological discoveries. However, applications of SMLM in preserved tissues has been limited. Through adaptation of the immunofluorescence workflow on FFPE sections milled at histological thickness, cellular architecture can now be visualized on the nanoscale using SMLM including individual mitochondria, undulations in the nuclear lamina, and the HER2 receptor on membrane protrusions in human breast cancer specimens. Using astigmatism imaging, these structures can also be resolved in three dimensions to a depth of {\textasciitilde}800 nm. These results demonstrate the utility of SMLM in efficiently uncovering ultrastructural information of archived clinical samples, which may offer molecular insights into the physiopathology of tissues to assist in disease diagnosis and treatment using conventional sample preparation methods.},
	number = {December 2016},
	journal = {Scientific Reports},
	author = {Creech, Matthew K. and Wang, Jing and Nan, Xiaolin and Gibbs, Summer L.},
	year = {2017},
	note = {Publisher: Nature Publishing Group},
	pages = {1--10},
}

@article{Muller2019,
	title = {A spotlight on viruses—application of click chemistry to visualize virus-cell interactions},
	issn = {14203049},
	doi = {10.3390/molecules24030481},
	abstract = {The replication of a virus within its host cell involves numerous interactions between viral and cellular factors, which have to be tightly controlled in space and time. The intricate interplay between viral exploitation of cellular pathways and the intrinsic host defense mechanisms is difficult to unravel by traditional bulk approaches. In recent years, novel fluorescence microscopy techniques and single virus tracking have transformed the investigation of dynamic virus-host interactions. A prerequisite for the application of these imaging-based methods is the attachment of a fluorescent label to the structure of interest. However, their small size, limited coding capacity and multifunctional proteins render viruses particularly challenging targets for fluorescent labeling approaches. Click chemistry in conjunction with genetic code expansion provides virologists with a novel toolbox for site-specific, minimally invasive labeling of virion components, whose potential has just recently begun to be exploited. Here, we summarize recent achievements, current developments and future challenges for the labeling of viral nucleic acids, proteins, glycoproteins or lipids using click chemistry in order to study dynamic processes in virus-cell interactions.},
	journal = {Molecules},
	author = {Müller, Thorsten G. and Sakin, Volkan and Müller, Barbara},
	year = {2019},
	note = {ISBN: 4962215613245},
	keywords = {Amber suppression, Bioorthogonal, Click chemistry, DNA virus, De novo DNA labeling, De novo RNA labeling, EU, EdU, Fluorescence microscopy, Genetic code expansion, Inclusion bodies, Metabolic labeling, Non-canonical amino acid, Nucleoside analog, RNA virus, Replication compartments, Retrovirus, Reverse transcription, Single virus tracking, Super-resolution microscopy, Uncoating, Unnatural amino acid, Viral factories, Virus},
}

@article{gibson_niftynet:_2018,
	title = {{NiftyNet}: a deep-learning platform for medical imaging},
	issn = {18727565},
	doi = {10.1016/j.cmpb.2018.01.025},
	abstract = {Background and objectives: Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. Established deep-learning platforms are flexible but do not provide specific functionality for medical image analysis and adapting them for this domain of application requires substantial implementation effort. Consequently, there has been substantial duplication of effort and incompatible infrastructure developed across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon. Methods: The NiftyNet infrastructure provides a modular deep-learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications. Components of the NiftyNet pipeline including data loading, data augmentation, network architectures, loss functions and evaluation metrics are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted intervention. NiftyNet is built on the TensorFlow framework and supports features such as TensorBoard visualization of 2D and 3D images and computational graphs by default. Results: We present three illustrative medical image analysis applications built using NiftyNet infrastructure: (1) segmentation of multiple abdominal organs from computed tomography; (2) image regression to predict computed tomography attenuation maps from brain magnetic resonance images; and (3) generation of simulated ultrasound images for specified anatomical poses. Conclusions: The NiftyNet infrastructure enables researchers to rapidly develop and distribute deep learning solutions for segmentation, regression, image generation and representation learning applications, or extend the platform to new applications.},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Gibson, Eli and Li, Wenqi and Sudre, Carole and Fidon, Lucas and Shakir, Dzhoshkun I. and Wang, Guotai and Eaton-Rosen, Zach and Gray, Robert and Doel, Tom and Hu, Yipeng and Whyntie, Tom and Nachev, Parashkev and Modat, Marc and Barratt, Dean C. and Ourselin, Sébastien and Cardoso, M. Jorge and Vercauteren, Tom},
	year = {2018},
	keywords = {Convolutional neural network, Deep learning, Generative adversarial network, Image regression, Medical image analysis, Segmentation},
}

@article{Schierle2016,
	title = {Advanced imaging of tau pathology in {Alzheimer} {Disease}: {New} perspectives from super resolution microscopy and label-free nanoscopy},
	volume = {79},
	issn = {10970029},
	doi = {10.1002/jemt.22698},
	abstract = {© 2016 Wiley Periodicals, Inc. Alzheimer's disease (AD) is the main cause of dementia in the elderly population. Over 30 million people worldwide are living with dementia and AD prevalence is projected to increase dramatically in the next two decades. In terms of neuropathology, AD is characterized by two major cerebral hallmarks: extracellular β-amyloid (Aβ) plaques and intracellular Tau inclusions, which start accumulating in the brain 15-20 years before the onset of symptoms. Within this context, the scientific community worldwide is undertaking a wide research effort to detect AD pathology at its earliest, before symptoms appear. Neuroimaging of Aβ by positron emission tomography (PET) is clinically available and is a promising modality for early detection of Aβ pathology and AD diagnosis. Substantive efforts are ongoing to develop advanced imaging techniques for early detection of Tau pathology. Here, we will briefly describe the key features of Tau pathology and its heterogeneity across various neurodegenerative diseases bearing cerebral Tau inclusions (i.e., tauopathies). We will outline the current status of research on Tau-specific PET tracers and their clinical development. Finally, we will discuss the potential application of novel super-resolution and label-free techniques for investigating Tau pathology at the experimental level and their potential application for AD diagnosis. Microsc. Res. Tech. 79:677–683, 2016. © 2016 Wiley Periodicals, Inc.},
	number = {8},
	journal = {Microscopy Research and Technique},
	author = {Schierle, Gabriele S.Kaminski and Michel, Claire H. and Gasparini, Laura},
	year = {2016},
	keywords = {Alzheimer, label-free imaging, nanoscopy, tauopathy},
	pages = {677--683},
}

@article{Oleksiuk2015,
	title = {Single-{Molecule} {Localization} {Microscopy} allows for the analysis of cancer metastasis-specific {miRNA} distribution on the nanoscale},
	volume = {6},
	doi = {10.18632/oncotarget.6297},
	abstract = {We describe a novel approach for the detection of small non-coding RNAs in single cells by Single-Molecule Localization Microscopy (SMLM). We used a modified SMLM-setup and applied this instrument in a first proof-of-principle concept to human cancer cell lines. Our method is able to visualize single microRNA (miR)-molecules in fixed cells with a localization accuracy of 10-15 nm, and is able to quantify and analyse clustering and localization in particular subcellular sites, including exosomes. We compared the metastasis-site derived (SW620) and primary site derived (SW480) human colorectal cancer (CRC) cell lines, and (as a proof of principle) evaluated the metastasis relevant miR-31 as a first example. We observed that the subcellular distribution of miR-31 molecules in both cell lines was very heterogeneous with the largest subpopulation of optically acquired weakly metastatic cells characterized by a low number of miR-31 molecules, as opposed to a significantly higher number in the majority of the highly metastatic cells. Furthermore, the highly metastatic cells had significantly more miR-31-molecules in the extracellular space, which were visualized to co-localize with exosomes in significantly higher numbers. From this study, we conclude that miRs are not only aberrantly expressed and regulated, but also differentially compartmentalized in cells with different metastatic potential. Taken together, this novel approach, by providing single molecule images of miRNAs in cellulo can be used as a powerful supplementary tool in the analysis of miRNA function and behaviour and has far reaching potential in defining metastasis-critical subpopulations within a given heterogeneous cancer cell population.},
	number = {42},
	journal = {Oncotarget},
	author = {Oleksiuk, Olga and Abba, Mohammed and Tezcan, Kerem Can and Schaufler, Wladimir and Bestvater, Felix and Patil, Nitin and Birk, Udo and Hafner, Mathias and Altevogt, Peter and Cremer, Christoph and Allgayer, Heike},
	year = {2015},
	keywords = {2015, 2015 accepted, 2015 published, localization microscopy, may 19, metastasis, micrornas, mir-31, november 05, october 23, received, super-resolution},
}

@article{Inamdar2019a,
	title = {Monitoring {HIV}-1 assembly in living cells: {Insights} from dynamic and single molecule microscopy},
	volume = {11},
	issn = {19994915},
	doi = {10.3390/v11010072},
	abstract = {The HIV-1 assembly process is a multi-complex mechanism that takes place at the host cell plasma membrane. It requires a spatio-temporal coordination of events to end up with a full mature and infectious virus. The molecular mechanisms of HIV-1 assembly have been extensively studied during the past decades, in order to dissect the respective roles of the structural and non-structural viral proteins of the viral RNA genome and of some host cell factors. Nevertheless, the time course of HIV-1 assembly was observed in living cells only a decade ago. The very recent revolution of optical microscopy, combining high speed and high spatial resolution, in addition to improved fluorescent tags for proteins, now permits study of HIV-1 assembly at the single molecule level within living cells. In this review, after a short description of these new approaches, we will discuss how HIV-1 assembly at the cell plasma membrane has been revisited using advanced super resolution microscopy techniques and how it can bridge the study of viral assembly from the single molecule to the entire host cell.},
	number = {1},
	journal = {Viruses},
	author = {Inamdar, Kaushik and Floderer, Charlotte and Favard, Cyril and Muriaux, Delphine},
	year = {2019},
	keywords = {Dynamics, HIV assembly, SMLM},
	pages = {1--13},
}

@article{Ghorbani2019,
	title = {Data {Shapley}: {Equitable} {Valuation} of {Data} for {Machine} {Learning}},
	url = {http://arxiv.org/abs/1904.02868},
	abstract = {As data becomes the fuel driving technological and economic growth, a fundamental challenge is how to quantify the value of data in algorithmic predictions and decisions. For example, in healthcare and consumer markets, it has been suggested that individuals should be compensated for the data that they generate, but it is not clear what is an equitable valuation for individual data. In this work, we develop a principled framework to address data valuation in the context of supervised machine learning. Given a learning algorithm trained on \$n\$ data points to produce a predictor, we propose data Shapley as a metric to quantify the value of each training datum to the predictor performance. Data Shapley uniquely satisfies several natural properties of equitable data valuation. We develop Monte Carlo and gradient-based methods to efficiently estimate data Shapley values in practical settings where complex learning algorithms, including neural networks, are trained on large datasets. In addition to being equitable, extensive experiments across biomedical, image and synthetic data demonstrate that data Shapley has several other benefits: 1) it is more powerful than the popular leave-one-out or leverage score in providing insight on what data is more valuable for a given learning task; 2) low Shapley value data effectively capture outliers and corruptions; 3) high Shapley value data inform what type of new data to acquire to improve the predictor.},
	author = {Ghorbani, Amirata and Zou, James},
	year = {2019},
	note = {arXiv: 1904.02868},
}

@book{noauthor_https://www.molbiolcell.org/toc/mboc/29/16_nodate,
	title = {https://www.molbiolcell.org/toc/mboc/29/16},
}

@article{Klok2019,
	title = {Statistics with {Julia}: {Fundamentals} for {Data} {Science}, {Machine} {Learning} and {Artificial} {Intelligence}.},
	author = {Klok, Hayden and Nazarathy, Yoni},
	year = {2019},
}

@article{Schwartz1995,
	title = {Space-variant active vision: {Definition}, overview and examples},
	volume = {8},
	issn = {08936080},
	doi = {10.1016/0893-6080(95)00092-5},
	abstract = {The term space-variant vision was introduced in the late 1980s to refer to sensor architectures based on a smooth variation of resolution across the workspace, like that of the human visual system. The use of such sensor architectures is rapidly becoming an important factor in machine vision in which the constraints of size weight, cost and performance must be jointly optimized. The structure of this paper consists of four parts. A review of the four generic architectures for vision will be presented, providing a context for the term " active vision", and a justification for the importance, and the connection between, space-variant architectures and active vision methods. A brief quantitative review of the specific space-variant properties of primate visual cortex topography will be provided, in the cortex of sensor design. The engineering and algorithmic problems that are associated with exploiting space-variant systems will be stated. Examples of several recently constructed miniature space-variant active vision systems will be briefly reviewed, along with a brief discussion of solutions to the basic problem areas in space-variant vision. © 1995.},
	number = {7-8},
	journal = {Neural Networks},
	author = {Schwartz, Eric L. and Greve, Douglas N. and Bonmassar, Giorgio},
	year = {1995},
	keywords = {Active vision, Computer vision, Fovea, Pyramid, Space-variant, Visual cortex},
	pages = {1297--1308},
}

@book{DeGoes2016,
	title = {Vector field processing on triangle meshes},
	isbn = {978-1-4503-4289-6},
	url = {http://dl.acm.org/citation.cfm?doid=2897826.2927303},
	abstract = {While scalar fields on surfaces have been staples of geometry processing, the use of tangent vector fields has steadily grown in geometry processing over the last two decades: they are crucial to encoding directions and sizing on surfaces as commonly required in tasks such as texture synthesis, non-photorealistic rendering, digital grooming, and meshing. There are, however, a variety of discrete representations of tangent vector fields on triangle meshes, and each approach offers different tradeoffs among simplicity, efficiency, and accuracy depending on the targeted application. This course reviews the three main families of discretizations used to design computational tools for vector field processing on triangle meshes: face-based, edge-based, and vertex-based representations. In the process of reviewing the computational tools offered by these representations, we go over a large body of recent developments in vector field processing in the area of discrete differential geometry. We also discuss the theoretical and practical limitations of each type of discretization, and cover increasingly-common extensions such as n-direction and n-vector fields. While the course will focus on explaining the key approaches to practical encoding (including data structures) and manipulation (including discrete operators) of finitedimensional vector fields, important differential geometric notions will also be covered: as often in Discrete Differential Geometry, the discrete picture will be used to illustrate deep continuous concepts such as covariant derivatives, metric connections, or Bochner Laplacians.},
	author = {de Goes, Fernando and Desbrun, Mathieu and Tong, Yiying},
	year = {2016},
	doi = {10.1145/2897826.2927303},
	note = {Publication Title: ACM SIGGRAPH 2016 Courses on - SIGGRAPH '16},
}

@article{PMID:21818365,
	title = {Quantitative photo activated localization microscopy: unraveling the effects of photoblinking},
	volume = {6},
	issn = {1932-6203},
	url = {http://europepmc.org/articles/PMC3144238},
	doi = {10.1371/journal.pone.0022678},
	number = {7},
	journal = {PloS one},
	author = {Annibale, Paolo and Vanni, Stefano and Scarselli, Marco and Rothlisberger, Ursula and Radenovic, Aleksandra},
	year = {2011},
	pages = {e22678},
}

@article{doi:10.1111/j.1740-9713.2015.00827.x,
	title = {The reproducibility crisis in science: {A} statistical counterattack},
	volume = {12},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1740-9713.2015.00827.x},
	doi = {10.1111/j.1740-9713.2015.00827.x},
	abstract = {More people have more access to data than ever before. But a comparative lack of analytical skills has resulted in scientific findings that are neither replicable nor reproducible. It is time to invest in statistics education, says Roger Peng},
	number = {3},
	journal = {Significance},
	author = {Peng, Roger},
	year = {2015},
	pages = {30--32},
}

@incollection{SCHMITZ2017559,
	address = {Boston},
	title = {Chapter 12 - {Classical} {Statistical} {Mechanics}},
	isbn = {978-0-12-800514-9},
	url = {http://www.sciencedirect.com/science/article/pii/B9780128005149000122},
	abstract = {The basic philosophy of statistical representations of microscopic systems stems from the works of Boltzmann and Maxwell. Statistical mechanics is the bridge between the macroscopic properties of matter and the microscopic states of the system. The concepts of phase space and distribution functions provide the scaffold upon which the fundamental structure of statistical mechanics is built. The Liouville Theorem, the Poincaré Recurrence Theorem, and the Ergodic Hypothesis validate the mathematical nature of distribution functions and the use of ensembles to calculate the thermodynamic properties of the microscopic systems. The underlying principles of statistical mechanics are introduced through an analysis of casino games that serve as macroscopic analogues to microscopic processes. Three ensembles and their corresponding partition functions are introduced as follows: the microcanonical ensemble for systems of constant number of particles (N), volume (V), and energy (E); the canonical ensemble for systems of constant N, V, and temperature (T); and the grand canonical ensemble for the description of systems of constant chemical potential (μ), V, and T. The equations that relate the partition functions to thermodynamic variables are derived.},
	booktitle = {Physical {Chemistry}},
	publisher = {Elsevier},
	author = {Schmitz, Kenneth S},
	editor = {Schmitz, Kenneth S},
	year = {2017},
	doi = {https://doi.org/10.1016/B978-0-12-800514-9.00012-2},
	keywords = {Boltzmann's H theorem, Coarse graining, Distribution function, Entropy, Equipartition theorem, Ergodic Hypothesis, Fine graining, Liouville's theorem, Maxwell–Boltzmann distribution, Partition function, Phase space, Poincaré recurrence theorem, Random probability, Statistical thermodynamics},
	pages = {559--632},
}

@article{schmitz_classical_2017,
	title = {Classical {Statistical} {Mechanics}},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128005149000122},
	doi = {10.1016/B978-0-12-800514-9.00012-2},
	abstract = {The basic philosophy of statistical representations of microscopic systems stems from the works of Boltzmann and Maxwell. Statistical mechanics is the bridge between the macroscopic properties of matter and the microscopic states of the system. The concepts of phase space and distribution functions provide the scaffold upon which the fundamental structure of statistical mechanics is built. The Liouville Theorem, the Poincaré Recurrence Theorem, and the Ergodic Hypothesis validate the mathematical nature of distribution functions and the use of ensembles to calculate the thermodynamic properties of the microscopic systems. The underlying principles of statistical mechanics are introduced through an analysis of casino games that serve as macroscopic analogues to microscopic processes. Three ensembles and their corresponding partition functions are introduced as follows: the microcanonical ensemble for systems of constant number of particles (N), volume (V), and energy (E); the canonical ensemble for systems of constant N, V, and temperature (T); and the grand canonical ensemble for the description of systems of constant chemical potential (μ), V, and T. The equations that relate the partition functions to thermodynamic variables are derived.},
	urldate = {2019-07-09},
	journal = {Physical Chemistry},
	author = {Schmitz, Kenneth S. and Schmitz, Kenneth S.},
	month = jan,
	year = {2017},
	note = {Publisher: Elsevier
ISBN: 978-0-12-800514-9},
	pages = {559--632},
}

@article{liu_imaging_2015,
	title = {Imaging {Live}-{Cell} {Dynamics} and {Structure} at the {Single}-{Molecule} {Level}},
	issn = {10974164},
	doi = {10.1016/j.molcel.2015.02.033},
	abstract = {Observation of molecular processes inside living cells is fundamental to a quantitative understanding of how biological systems function. Specifically, decoding the complex behavior of single molecules enables us to measure kinetics, transport, and self-assembly at this fundamental level that is often veiled in ensemble experiments. In the past decade, rapid developments in fluorescence microscopy, fluorescence correlation spectroscopy, and fluorescent labeling techniques have enabled new experiments to investigate the robustness and stochasticity of diverse molecular mechanisms with high spatiotemporal resolution. This review discusses the concepts and strategies of structural and functional imaging in living cells at the single-molecule level with minimal perturbations to the specimen.},
	journal = {Molecular Cell},
	author = {Liu, Zhe and Lavis, Luke D. and Betzig, Eric},
	year = {2015},
}

@article{Duchenne2009,
	title = {{CiteULike}: {A} tensor-based algorithm for high-order graph matching},
	volume = {V},
	url = {http://www.citeulike.org/user/egozi/article/5828320},
	number = {APRIL},
	author = {Duchenne, Olivier},
	year = {2009},
	note = {ISBN: 9781424439911},
	pages = {1980--1987},
}

@article{lerer_p_2019,
	title = {P {Y} {T} {ORCH} -{B} {IG} {G} {RAPH} : {A} {L} {ARGE} - {SCALE} {G} {RAPH} {E} {MBEDDING} {S} {YSTEM}},
	author = {Lerer, Adam and Wu, Ledell and Shen, Jiajun and Lacroix, Timothee and Wehrstedt, Luca and Bose, Abhijit and Peysakhovich, Alex},
	year = {2019},
	keywords = {graph embeddings,representation learning},
}

@article{Newling2016,
	title = {A {Sub}-{Quadratic} {Exact} {Medoid} {Algorithm}},
	volume = {54},
	url = {http://arxiv.org/abs/1605.06950},
	abstract = {We present a new algorithm, trimed, for obtaining the medoid of a set, that is the element of the set which minimises the mean distance to all other elements. The algorithm is shown to have, under certain assumptions, expected run time O(N{\textasciicircum}(3/2)) in R{\textasciicircum}d where N is the set size, making it the first sub-quadratic exact medoid algorithm for d{\textgreater}1. Experiments show that it performs very well on spatial network data, frequently requiring two orders of magnitude fewer distance calculations than state-of-the-art approximate algorithms. As an application, we show how trimed can be used as a component in an accelerated K-medoids algorithm, and then how it can be relaxed to obtain further computational gains with only a minor loss in cluster quality.},
	author = {Newling, James and Fleuret, François},
	year = {2016},
	note = {arXiv: 1605.06950},
}

@article{Veeraraghavan2016,
	title = {Stochastic optical reconstruction microscopy–based relative localization analysis ({STORM}-{RLA}) for quantitative nanoscale assessment of spatial protein organization},
	volume = {27},
	issn = {1059-1524},
	doi = {10.1091/mbc.e16-02-0125},
	abstract = {The spatial association between proteins is crucial to understanding how they function in biological systems. Colocalization analysis of fluorescence microscopy images is widely used to assess this. However, colocalization analysis performed on two-dimensional images with diffraction-limited resolution merely indicates that the proteins are within 200-300 nm of each other in the xy-plane and within 500-700 nm of each other along the z-Axis. Here we demonstrate a novel three-dimensional quantitative analysis applicable to single-molecule positional data: stochastic optical reconstruction microscopy-based relative localization analysis (STORM-RLA). This method offers significant advantages: 1) STORM imaging affords 20-nm resolution in the xy-plane and {\textless}50 nm along the z-Axis; 2) STORM-RLA provides a quantitative assessment of the frequency and degree of overlap between clusters of colabeled proteins; and 3) STORM-RLA also calculates the precise distances between both overlapping and nonoverlapping clusters in three dimensions. Thus STORM-RLA represents a significant advance in the high-Throughput quantitative assessment of the spatial organization of proteins.},
	number = {22},
	journal = {Molecular Biology of the Cell},
	author = {Veeraraghavan, Rengasayee and Gourdie, Robert G.},
	year = {2016},
	pages = {3583--3590},
}

@article{Khalid2012,
	title = {Frameworks for multivariate m-mediods based modeling and classification in {Euclidean} and general feature spaces},
	volume = {45},
	issn = {00313203},
	url = {http://dx.doi.org/10.1016/j.patcog.2011.08.021},
	doi = {10.1016/j.patcog.2011.08.021},
	abstract = {This paper presents an extension of m-mediods based modeling technique to cater for multimodal distributions of sample within a pattern. The classification of new samples and anomaly detection is performed using a novel classification algorithm which can handle patterns with underlying multivariate probability distributions. We have proposed two frameworks, namely MMC-ES and MMC-GFS, to enable our proposed multivarite m-mediods based modeling and classification approach workable for any feature space with a computable distance metric. MMC-ES framework is specialized for finite dimensional features in Euclidean space whereas MMC-GFS works on any feature space with a computable distance metric. Experimental results using simulated and complex real life dataset show that multivariate m-mediods based frameworks are effective and give superior performance than competitive modeling and classification techniques especially when the patterns exhibit multivariate probability density functions. © 2011 Elsevier Ltd. All rights reserved.},
	number = {3},
	journal = {Pattern Recognition},
	author = {Khalid, Shehzad and Razzaq, Shahid},
	year = {2012},
	note = {Publisher: Elsevier},
	keywords = {Anomaly detection, Classification, Data mining, Dynamic modeling, Multivariate m-mediods},
	pages = {1092--1103},
}

@article{Cohen2019,
	title = {Resolution limit of image analysis algorithms},
	volume = {10},
	issn = {20411723},
	doi = {10.1038/s41467-019-08689-x},
	abstract = {Resolution is one of the most important properties of an imaging system, yet it remains difficult to define and apply. Rayleigh's and Abbe's resolution criteria were developed for observations with the human eye and had a major influence on the development of optical instruments. However, no systematic approach is available for the evaluation of the often complex image processing algorithms that have become central to the analysis of the imaging data that today is acquired by highly sensitive cameras. Here, we introduce a novel resolution criterion for image analysis algorithms, which we term algorithmic resolution, based on spatial statistics methods that is independent of both the imaging system that produced the data and the specifics of the objects being analyzed.},
	number = {1},
	journal = {Nature Communications},
	author = {Cohen, Edward A.K. and Abraham, Anish V. and Ramakrishnan, Sreevidhya and Ober, Raimund J.},
	year = {2019},
}

@article{Schmidt2017,
	title = {Bayesian inference for structured additive regression models for large-scale problems with applications to medical imaging},
	abstract = {In applied statistics regression models with high-dimensional coefficients can occur which cannot be estimated using ordinary computers. Amongst others, this applies to the analysis of digital images taking spatio-temporal dependencies into account as they commonly occur within bio-medical research. In this thesis a procedure is formulated which allows to fit regression models with high-dimensional coefficients and non-normal response values requiring only moderate computational equipment. To this end, limitations of different inference strategies for structured additive regression models are demonstrated when applied to high-dimensional problems and possible solutions are discussed. Based thereon an algorithm is formulated whose strengths and weaknesses are subsequently analyzed using simulation studies. Furthermore, the procedure is applied to three different fields of bio-medical imaging from which can be concluded that the algorithm is a promising candidate for answering high-dimensional problems.},
	number = {November},
	author = {Schmidt, Paul},
	year = {2017},
}

@article{Gates2017,
	title = {The {Impact} of {Random} {Models} on {Clustering} {Similarity}},
	volume = {18},
	url = {http://arxiv.org/abs/1701.06508},
	abstract = {Clustering is a central approach for unsupervised learning. After clustering is applied, the most fundamental analysis is to quantitatively compare clusterings. Such comparisons are crucial for the evaluation of clustering methods as well as other tasks such as consensus clustering. It is often argued that, in order to establish a baseline, clustering similarity should be assessed in the context of a random ensemble of clusterings. The prevailing assumption for the random clustering ensemble is the permutation model in which the number and sizes of clusters are fixed. However, this assumption does not necessarily hold in practice; for example, multiple runs of K-means clustering returns clusterings with a fixed number of clusters, while the cluster size distribution varies greatly. Here, we derive corrected variants of two clustering similarity measures (the Rand index and Mutual Information) in the context of two random clustering ensembles in which the number and sizes of clusters vary. In addition, we study the impact of one-sided comparisons in the scenario with a reference clustering. The consequences of different random models are illustrated using synthetic examples, handwriting recognition, and gene expression data. We demonstrate that the choice of random model can have a drastic impact on the ranking of similar clustering pairs, and the evaluation of a clustering method with respect to a random baseline; thus, the choice of random clustering model should be carefully justified.},
	author = {Gates, Alexander J and Ahn, Yong-Yeol},
	year = {2017},
	note = {arXiv: 1701.06508},
	keywords = {adjustment for chance, clustering comparison, clustering evaluation, index, normalized mutual information, rand},
	pages = {1--28},
}

@article{Teachings,
	title = {of {Ajahn} {Chah}},
	journal = {Education},
	author = {Teachings, The and Chah, Ajahn},
}

@article{Li2004,
	title = {A {Syntaxin} 1, {G} o, and {N}-{Type} {Calcium} {Channel} {Complex} at a {Presynaptic} {Nerve} {Terminal}: {Analysis} by {Quantitative} {Immunocolocalization}},
	volume = {24},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0346-04.2004},
	doi = {10.1523/JNEUROSCI.0346-04.2004},
	abstract = {Presynaptic Cav2.2 (N-type) calcium channels are subject to modulation by interaction with syntaxin 1 and by a syntaxin 1-sensitive Gαo G-protein pathway. We used biochemical analysis of neuronal tissue lysates and a new quantitative test of colocalization by intensity correlation analysis at the giant calyx-type presynaptic terminal of the chick ciliary ganglion to explore the association of Cav2.2 with syntaxin 1 and Gαo. Cav2.2 could be localized by immunocytochemistry (antibody Ab571) in puncta on the release site aspect of the presynaptic terminal and close to synaptic vesicle clouds. Syntaxin 1 coimmunoprecipitated with Cav2.2 from chick brain and chick ciliary ganglia and was widely distributed on the presynaptic terminal membrane. A fraction of the total syntaxin 1 colocalized with the Cav2.2 puncta, whereas the bulk colocalized with MUNC18-1. Gαo, whether in its trimeric or monomeric state, did not coimmunoprecipitate with Ca v2.2, MUNC18-1, or syntaxin 1. However, the G-protein exhibited a punctate staining on the calyx membrane with an intensity that varied in synchrony with that for both Ca channels and syntaxin 1 but only weakly with MUNC18-1. Thus, syntaxin 1 appears to be a component of two separate complexes at the presynaptic terminal, a minor one at the transmitter release site with Cav2.2 and Gαo, as well as in large clusters remote from the release site with MUNC18-1. These syntaxin 1 protein complexes may play distinct roles in presynaptic biology.},
	number = {16},
	journal = {Journal of Neuroscience},
	author = {Li, Q.},
	year = {2004},
	keywords = {1, 1b subunit, 2, ca v 2, calcium channel, colocalization, g, g-protein, immunocytochemistry, intensity correlation analysis, intensity correlation quotient, munc18, n-sec-1, n-type, o, presynaptic, syntaxin, transmitter release site},
	pages = {4070--4081},
}

@article{Olivo-Marin2002,
	title = {Extraction of spots in biological images using multiscale products},
	volume = {35},
	issn = {00313203},
	doi = {10.1016/S0031-3203(01)00127-3},
	abstract = {We present a new method to detect and count bright spots in fluorescence images coming from biological immunomicroscopy experiments. It is based on the multiscale product of subband images resulting from the a trous wavelet transform decomposition of the original image, after thresholding of non-significant coefficients. The multiscale correlation of the filtered wavelet coefficients, which allows to enhance multiscale peaks due to spots while reducing noise, combines information coming from different levels of resolution and gives a clear and distinctive chacterization of the spots. Results are presented for the analysis of typical immunofluorescence images. © 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
	number = {9},
	journal = {Pattern Recognition},
	author = {Olivo-Marin, Jean Christophe},
	year = {2002},
	keywords = {Biology, Microscopy, Multiscale analysis, Spot detection, Undecimated wavelet transform},
	pages = {1989--1996},
}

@article{E.M.M1993,
	title = {Measurement of co-localization of objects in dual-colour confocal images},
	volume = {169},
	url = {http://dx.doi.org/10.1111/j.1365-2818.1993.tb03313.x},
	doi = {10.1111/j.1365-2818.1993.tb03313.x},
	number = {January},
	journal = {Journal of Microscopy},
	author = {E. M. M, Manders and F. J, Verbeek and J. A, Aten},
	year = {1993},
	note = {ISBN: 0022-2720},
	keywords = {co-localization, confocal microscopy, correlation, double labelling, image analysis, image reconstruction},
	pages = {375--382},
}

@article{Aaron2018,
	title = {Image co-localization – co-occurrence versus correlation},
	volume = {131},
	issn = {0021-9533},
	doi = {10.1242/jcs.211847},
	abstract = {Fluorescence image co-localization analysis is widely utilized to suggest biomolecular interaction. However, there exists some confusion as to its correct implementation and interpretation. In reality, co-localization analysis consists of at least two distinct sets of methods, termed co-occurrence and correlation. Each approach has inherent and often contrasting strengths and weaknesses. Yet, neither one can be considered to always be preferable for any given application. Rather, each method is most appropriate for answering different types of biological question. This Review discusses the main factors affecting multicolor image co-occurrence and correlation analysis, while giving insight into the types of biological behavior that are better suited to one approach or the other. Further, the limits of pixel-based co-localization analysis are discussed in the context of increasingly popular super-resolution imaging techniques.},
	number = {3},
	journal = {Journal of Cell Science},
	author = {Aaron, Jesse S. and Taylor, Aaron B. and Chew, Teng-Leong},
	year = {2018},
	keywords = {biological system, co-localization, co-localization can be, fluorescence microscopy, image analysis, manders, more strategically employed, pearson, pitfalls of, this review explores how, we outline strengths and},
	pages = {jcs211847},
}

@article{Baddeley2010,
	title = {Visualization of {Localization} {Microscopy} {Data}},
	volume = {16},
	issn = {1431-9276},
	doi = {10.1017/s143192760999122x},
	abstract = {Localization microscopy techniques based on localizing single fluorophore molecules now routinely achieve accuracies better than 30 nm. Unlike conventional optical microscopies, localization microscopy experiments do not generate an image but a list of discrete coordinates of estimated fluorophore positions. Data display and analysis therefore generally require visualization methods that translate the position data into conventional images. Here we investigate the properties of several widely used visualization techniques and show that a commonly used algorithm based on rendering Gaussians may lead to a 1.44-fold loss of resolution. Existing methods typically do not explicitly take sampling considerations into account and thus may produce spurious structures. We present two additional visualization algorithms, an adaptive histogram method based on quad-trees and a Delaunay triangulation based visualization of point data that address some of these deficiencies. The new visualization methods are designed to suppress erroneous detail in poorly sampled image areas but avoid loss of resolution in well-sampled regions. A number of criteria for scoring visualization methods are developed as a guide for choosing among visualization methods and are used to qualitatively compare various algorithms.},
	number = {1},
	journal = {Microscopy and Microanalysis},
	author = {Baddeley, David and Cannell, Mark B. and Soeller, Christian},
	year = {2010},
	note = {Publisher: Simon Fraser University Library},
	keywords = {caveolin, fluorescence, localization microscopy, nanoscopy, single molecules, single molecules, localization microscopy, nanosco, super-resolution},
	pages = {64--72},
}

@article{Riaz2016,
	title = {Optimized localization-analysis for single-molecule tracking and super-resolution microscopy},
	volume = {118},
	doi = {10.1002/cncr.27633.Percutaneous},
	number = {24},
	author = {Riaz, Nadeem and Wolden, Suzanne L and Gelblum, Daphna Y and Eric, J},
	year = {2016},
	pages = {6072--6078},
}

@article{Kusumi2014,
	title = {Tracking single molecules at work in living cells},
	volume = {10},
	issn = {15524469},
	url = {http://dx.doi.org/10.1038/nchembio.1558},
	doi = {10.1038/nchembio.1558},
	abstract = {Methods for imaging and tracking single molecules conjugated with fluorescent probes, called single-molecule tracking (SMT), are now providing researchers with the unprecedented ability to directly observe molecular behaviors and interactions in living cells. Current SMT methods are achieving almost the ultimate spatial precision and time resolution for tracking single molecules, determined by the currently available dyes. In cells, various molecular interactions and reactions occur as stochastic and probabilistic processes. SMT provides an ideal way to directly track these processes by observing individual molecules at work in living cells, leading to totally new views of the biochemical and molecular processes used by cells whether in signal transduction, gene regulation or formation and disintegration of macromolecular complexes. Here we review SMT methods, summarize the recent results obtained by SMT, including related superresolution microscopy data, and describe the special concerns when SMT applications are shifted from the in vitro paradigms to living cells.},
	number = {7},
	journal = {Nature Chemical Biology},
	author = {Kusumi, Akihiro and Tsunoyama, Taka A. and Hirosawa, Kohichiro M. and Kasai, Rinshi S. and Fujiwara, Takahiro K.},
	year = {2014},
	note = {Publisher: Nature Publishing Group},
	pages = {524--532},
}

@article{Scurll2019,
	title = {{StormGraph}: {An} automated graph-based algorithm for quantitative clustering analysis of single-molecule localization microscopy data},
	volume = {0450},
	url = {https://www.biorxiv.org/content/early/2019/01/09/515627?%3Fcollection=},
	doi = {10.1101/515627},
	abstract = {Clustering of proteins is crucial for many cellular processes and can be imaged at nanoscale resolution using single-molecule localization microscopy (SMLM). Existing cluster analysis methods for SMLM data suffer from major limitations, such as unsuitability for heterogeneous datasets, failure to account for uncertainties in localization data, excessive computation time, or inability to analyze three-dimensional data. To address these shortcomings, we developed StormGraph, an algorithm using graph theory and community detection to identify and quantify clusters in heterogeneous 2D and 3D SMLM datasets. StormGraph accounts for localization uncertainties and, by determining thresholds adaptively, it allows many heterogeneous samples to be analyzed using identical parameters. Consequently, StormGraph improves the potential accuracy, objectivity, and throughput of cluster analysis. Furthermore, StormGraph generates a hierarchical clustering, and it quantifies cluster colocalization for two-color SMLM data. We use simulated data to show that StormGraph is superior to existing algorithms. Finally, we demonstrate its application to two-dimensional B-cell antigen receptor clustering and three-dimensional intracellular LAMP-1 clustering.},
	number = {Dc},
	journal = {bioRxiv},
	author = {Scurll, Joshua and Abraham, Libin and Zheng, Da Wei and Tafteh, Reza and Chou, Keng and Gold, Michael R and Coombs, Daniel},
	year = {2019},
	keywords = {b cell receptor, co-localization, detection, dstorm, graph community, heterogeneous clustering, hierarchichal clustering, single-molecule localization microscopy},
	pages = {515627},
}

@article{Andronov2018,
	title = {{3DClusterViSu}: {3D} clustering analysis of super-resolution microscopy data by {3D} {Voronoi} tessellations},
	volume = {34},
	issn = {14602059},
	doi = {10.1093/bioinformatics/bty200},
	abstract = {Single-molecule localization microscopy (SMLM) can play an important role in integrated structural biology approaches for example at the interface of cryo electron microscopy (cryo-EM), X-ray crystallography, NMR and fluorescence imaging to identify, localize and determine the 3D structure of cellular structures. While many tools exist for the 3D analysis and visualisation of crystal or cryo-EM structures little exists for 3D SMLM data which can provide fascinating insights but are particularly challenging to analyze in three dimensions especially in a dense cellular context. We developed 3DClusterViSu, a method based on 3D Voronoi tessellations that allows local density estimation, segmentation \& quantification of 3D SMLM data and visualization of protein clusters within a 3D tool. We show its robust performance on microtubules and histone proteins H2B and CENP-A with distinct spatial distributions. 3DClusterViSu will favor multi-scale and multi-resolution synergies to allow integrating molecular and cellular levels in the analysis of macromolecular complexes.},
	number = {17},
	journal = {Bioinformatics},
	author = {Andronov, Leonid and Michalon, Jonathan and Ouararhni, Khalid and Orlov, Igor and Hamiche, Ali and Vonesch, Jean Luc and Klaholz, Bruno P.},
	year = {2018},
	pages = {3004--3012},
}

@article{wang_solid_nodate,
	title = {Solid immersion microscopy readily and inexpensively enables 12 nm resolution on plunge-frozen cells},
	url = {http://dx.doi.org/10.1101/373647},
	doi = {10.1101/373647},
	abstract = {Super-resolution fluorescence microscopy achieves 20-30 nm resolution by using liquid-immersion objectives to optimize light collection and chemical sample fixation to minimize image blurring. It is known that fluorophore brightness increases substantially under cryogenic conditions and that cryo-fixation is far superior in preserving ultrastructure. However, cryogenic conditions have not been exploited to improve resolution or sample quality because liquid immersion media freezes at the objective, losing its optical properties. Here, simply by replacing the immersion fluid with a low-cost super-hemispherical solid immersion lens (superSIL), we effortlessly achieve {\textless}8 nm localisation precision and 12 nm resolution under cryogenic conditions in a low-cost, low-tech system. This is to our knowledge the best resolution yet attained in biological samples. Furthermore, we demonstrate multicolour imaging and show that the inexpensive setup outperforms 10-fold more costly super-resolution microscopes. By also removing the barrier to total internal reflection fluorescence imaging of mammalian cells under cryogenic conditions, superSIL microscopy delivers a straightforward route to achieve unmatched nanoscale resolution on both bacterial and mammalian cell samples, which any laboratory can effortlessly and inexpensively implement. All rights reserved. No reuse allowed without permission.},
	author = {Wang, Lin and Bateman, Benji and Zanetti-Domingues, Laura C and Moores, Amy N and Astbury, Sam and Spindloe, Christopher and Darrow, Michele C and Romano, Maria and Needham, Sarah R and Beis, Konstantinos and Rolfe, Daniel J and Clarke, David T and Martin-Fernandez, Marisa L},
	keywords = {Cryo-fluorescence microscopy, STORM, cell imaging Running title: Low-cost/tech STORM for 12 nm resolution, solid immersion lens, super-resolution},
}

@incollection{imiya_graph-based_2010,
	title = {Graph-{Based} {Clustering} of {Random} {Point} {Set}},
	author = {Imiya, Atsushi and Tatara, Ken},
	year = {2010},
	doi = {10.1007/978-3-540-27868-9_104},
}

@article{yang_novel_2010,
	title = {A {Novel} {Spatial} {Clustering} {Algorithm} {Based} on {Delaunay} {Triangulation}},
	issn = {1945-3116},
	doi = {10.4236/jsea.2010.32018},
	abstract = {Exploratory data analysis is increasingly more necessary as larger spatial data is managed in electro-magnetic media. Spatial clustering is one of the very important spatial data mining techniques which is the discovery of interesting rela- tionships and characteristics that may exist implicitly in spatial databases. So far, a lot of spatial clustering algorithms have been proposed in many applications such as pattern recognition, data analysis, and image processing and so forth. However most of the well-known clustering algorithms have some drawbacks which will be presented later when ap- plied in large spatial databases. To overcome these limitations, in this paper we propose a robust spatial clustering algorithm named NSCABDT (Novel Spatial Clustering Algorithm Based on Delaunay Triangulation). Delaunay dia- gram is used for determining neighborhoods based on the neighborhood notion, spatial association rules and colloca- tions being defined. NSCABDT demonstrates several important advantages over the previous works. Firstly, it even discovers arbitrary shape of cluster distribution. Secondly, in order to execute NSCABDT, we do not need to know any priori nature of distribution. Third, like DBSCAN, Experiments show that NSCABDT does not require so much CPU processing time. Finally it handles efficiently outliers.},
	journal = {Journal of Software Engineering and Applications},
	author = {Yang, Xiankun and Cui, Weihong},
	year = {2010},
}

@inproceedings{razafindramanana_incremental_2014,
	title = {Incremental delaunay triangulation construction for clustering},
	isbn = {978-1-4799-5208-3},
	doi = {10.1109/ICPR.2014.242},
	abstract = {In this paper, we propose an original solution to the problem of point cloud clustering. The proposed technique is based on a d-dimensional formulated Delaunay Triangulation (DT) construction algorithm and adapts it to the problem of cluster detection. The introduced algorithm allows this detection as along with the DT construction. Precisely, a criterion that detects occurrences of gaps in the simplex perimeter distribution is added during the incremental DT construction. This detection allows to label simplices as being inter - or intra cluster. Experimental results on 2D shape datasets are presented and discussed in terms of cluster detection and topological relationship preservation.},
	booktitle = {Proceedings - {International} {Conference} on {Pattern} {Recognition}},
	author = {Razafindramanana, Octavio and Rayar, Frederic and Venturini, Gilles},
	year = {2014},
	note = {ISSN: 10514651},
}

@techreport{hartuv_clustering_2000,
	title = {A clustering algorithm based on graph connectivity 6},
	abstract = {We have developed a novel algorithm for cluster analysis that is based on graph theoretic techniques. A similarity graph is defined and clusters in that graph correspond to highly connected subgraphs. A polynomial algorithm to compute them efficiently is presented. Our algorithm produces a solution with some provably good properties and performs well on simulated and real data.},
	author = {Hartuv, Erez and Shamir, Ron},
	year = {2000},
	note = {Publication Title: Information Processing Letters
Volume: 76},
	keywords = {Algorithms, Clustering, Diameter, Graph connectivity, Minimum cut},
	pages = {175--181},
}

@article{noauthor_mchugh_ml_interrater_reliability_nodate,
	title = {{McHugh}\_ML\_Interrater\_reliability},
}

@article{pearl_theory_1995,
	title = {A theory of inferred causation},
	issn = {0049237X},
	doi = {10.1016/S0049-237X(06)80074-1},
	abstract = {This chapter discusses the theory of inferred causation. The study of causation is central to the understanding of human reasoning. Inferences involving changing environments require causal theories that make formal distinctions between beliefs based on passive observations and those reflecting intervening actions. In applications such as diagnosis, qualitative physics, and plan recognition, a central task is that of finding a satisfactory explanation to a given set of observations, and the meaning of explanation is intimately related to the notion of causation. In some systems, causal ordering is defined as the ordering at which subsets of variables can be solved independently of others; in other systems, it follows the way a disturbance is propagated from one variable to others. An empirical semantics for causation is important for several reasons. The notion of causation is often associated with those of necessity and functional dependence; causal expressions often tolerate exceptions, primarily because of missing variables and coarse description. Temporal precedence is normally assumed essential for defining causation, and it is one of the most important clues that people use to distinguish causal from other types of associations. © 1995 Elsevier B.V.},
	journal = {Studies in Logic and the Foundations of Mathematics},
	author = {Pearl, Judea and Verma, Thomas S.},
	year = {1995},
}

@article{millstein_disentangling_2009,
	title = {Disentangling molecular relationships with a causal inference test},
	issn = {14712156},
	doi = {10.1186/1471-2156-10-23},
	abstract = {BACKGROUND: There has been intense effort over the past couple of decades to identify loci underlying quantitative traits as a key step in the process of elucidating the etiology of complex diseases. Recently there has been some effort to coalesce non-biased high-throughput data, e.g. high density genotyping and genome wide RNA expression, to drive understanding of the molecular basis of disease. However, a stumbling block has been the difficult question of how to leverage this information to identify molecular mechanisms that explain quantitative trait loci (QTL). We have developed a formal statistical hypothesis test, resulting in a p-value, to quantify uncertainty in a causal inference pertaining to a measured factor, e.g. a molecular species, which potentially mediates a known causal association between a locus and a quantitative trait.{\textbackslash}n{\textbackslash}nRESULTS: We treat the causal inference as a 'chain' of mathematical conditions that must be satisfied to conclude that the potential mediator is causal for the trait, where the inference is only as good as the weakest link in the chain. P-values are computed for the component conditions, which include tests of linkage and conditional independence. The Intersection-Union Test, in which a series of statistical tests are combined to form an omnibus test, is then employed to generate the overall test result. Using computer simulated mouse crosses, we show that type I error is low under a variety of conditions that include hidden variables and reactive pathways. We show that power under a simple causal model is comparable to other model selection techniques as well as Bayesian network reconstruction methods. We further show empirically that this method compares favorably to Bayesian network reconstruction methods for reconstructing transcriptional regulatory networks in yeast, recovering 7 out of 8 experimentally validated regulators.{\textbackslash}n{\textbackslash}nCONCLUSION: Here we propose a novel statistical framework in which existing notions of causal mediation are formalized into a hypothesis test, thus providing a standard quantitative measure of uncertainty in the form of a p-value. The method is theoretically and computationally accessible and with the provided software may prove a useful tool in disentangling molecular relationships.},
	journal = {BMC Genetics},
	author = {Millstein, Joshua and Zhang, Bin and Zhu, Jun and Schadt, Eric E.},
	year = {2009},
	pmid = {19473544},
}

@article{andrews_generalized_2015,
	title = {The {Generalized} {Log}-{Ratio} {Transformation}: {Learning} {Shape} and {Adjacency} {Priors} for {Simultaneous} {Thigh} {Muscle} {Segmentation}},
	issn = {1558254X},
	doi = {10.1109/TMI.2015.2403299},
	abstract = {We present a novel probabilistic shape representation that implicitly includes prior anatomical volume and adjacency information, termed the generalized log-ratio (GLR) representation. We demonstrate the usefulness of this representation in the task of thigh muscle segmentation. Analysis of the shapes and sizes of thigh muscles can lead to a better understanding of the effects of chronic obstructive pulmonary disease (COPD), which often results in skeletal muscle weakness in lower limbs. However, segmenting these muscles from one another is difficult due to a lack of distinctive features and intermuscular boundaries that are difficult to detect. We overcome these difficulties by building a shape model in the space of GLR representations. We remove pose variability from the model by employing a presegmentation-based alignment scheme. We also design a rotationally invariant random forest boundary detector that learns common appearances of the interface between muscles from training data. We combine the shape model and the boundary detector into a fully automatic globally optimal segmentation technique. Our segmentation technique produces a probabilistic segmentation that can be used to generate uncertainty information, which can be used to aid subsequent analysis. Our experiments on challenging 3D magnetic resonance imaging data sets show that the use of the GLR representation improves the segmentation accuracy, and yields an average Dice similarity coefficient of 0:8080:074, comparable to other state-of-the-art thigh segmentation techniques.},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Andrews, Shawn and Hamarneh, Ghassan},
	year = {2015},
	keywords = {COPD, edge Detection, muscle Segmentation, probabilistic Segmentation, statistical Shape Analysis, uncertainty},
}

@article{pereyra_regularizing_2017,
	title = {Regularizing {Neural} {Networks} by {Penalizing} {Confident} {Output} {Distributions}},
	abstract = {We systematically explore regularizing neural networks by penalizing low entropy output distributions. We show that penalizing low entropy output distributions, which has been shown to improve exploration in reinforcement learning, acts as a strong regularizer in supervised learning. Furthermore, we connect a maximum entropy based confidence penalty to label smoothing through the direction of the KL divergence. We exhaustively evaluate the proposed confidence penalty and label smoothing on 6 common benchmarks: image classification (MNIST and Cifar-10), language modeling (Penn Treebank), machine translation (WMT'14 English-to-German), and speech recognition (TIMIT and WSJ). We find that both label smoothing and the confidence penalty improve state-of-the-art models across benchmarks without modifying existing hyperparameters, suggesting the wide applicability of these regularizers.},
	author = {Pereyra, Gabriel and Tucker, George and Chorowski, Jan and Kaiser, Łukasz and Hinton, Geoffrey},
	year = {2017},
	note = {arXiv: 1701.06548},
}

@article{rani_systematic_2018,
	title = {A {Systematic} {Review} of {Compressive} {Sensing}: {Concepts}, {Implementations} and {Applications}},
	issn = {21693536},
	doi = {10.1109/ACCESS.2018.2793851},
	abstract = {Compressive Sensing (CS) is a new sensing modality, which compresses the signal being acquired at the time of sensing. Signals can have sparse or compressible representation either in original domain or in some transform domain. Relying on the sparsity of the signals, CS allows us to sample the signal at a rate much below the Nyquist sampling rate. Also, the varied reconstruction algorithms of CS can faithfully reconstruct the original signal back from fewer compressive measurements. This fact has stimulated research interest toward the use of CS in several fields, such as magnetic resonance imaging, high-speed video acquisition, and ultrawideband communication. This paper reviews the basic theoretical concepts underlying CS. To bridge the gap between theory and practicality of CS, different CS acquisition strategies and reconstruction approaches are elaborated systematically in this paper. The major application areas where CS is currently being used are reviewed here. This paper also highlights some of the challenges and research directions in this field.},
	journal = {IEEE Access},
	author = {Rani, Meenu and Dhok, S. B. and Deshmukh, R. B.},
	year = {2018},
	keywords = {CS acquisition strategies, CS applications, CS reconstruction algorithms, Compressive sensing, OMP, random demodulator, sparsity, ★},
}

@article{murata_cryo-electron_2018,
	title = {Cryo-electron microscopy for structural analysis of dynamic biological macromolecules},
	issn = {18728006},
	doi = {10.1016/j.bbagen.2017.07.020},
	abstract = {Background Since the introduction of what became today's standard for cryo-embedding of biological macromolecules at native conditions more than 30 years ago, techniques and equipment have been drastically improved and the structure of biomolecules can now be studied at near atomic resolution by cryo-electron microscopy (cryo-EM) while capturing multiple dynamic states. Here we review the recent progress in cryo-EM for structural studies of dynamic biological macromolecules. Scope of review We provide an overview of the cryo-EM method and introduce contemporary studies to investigate biomolecular structure and dynamics, including examples from the recent literature. Major conclusions Cryo-EM is a powerful tool for the investigation of biological macromolecular structures including analysis of their dynamics by using advanced image-processing algorithms. The method has become even more widely applicable with present-day single particle analysis and electron tomography. General significance The cryo-EM method can be used to determine the three-dimensional structure of biomacromolecules in near native condition at close to atomic resolution, and has the potential to reveal conformations of dynamic molecular complexes. This article is part of a Special Issue entitled “Biophysical Exploration of Dynamical Ordering of Biomolecular Systems” edited by Dr. Koichi Kato.},
	journal = {Biochimica et Biophysica Acta - General Subjects},
	author = {Murata, Kazuyoshi and Wolf, Matthias},
	year = {2018},
	pmid = {28756276},
	note = {ISBN: 0304-4165},
	keywords = {Cryo-electron tomography, Electron cryomicroscopy, Molecular dynamics, Protein structure, Single particle 3D reconstruction},
}

@article{wu_comprehensive_2019,
	title = {A {Comprehensive} {Survey} on {Graph} {Neural} {Networks}},
	url = {https://arxiv.org/abs/1901.00596},
	urldate = {2019-02-11},
	author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.00596},
}

@article{rubinov_complex_2010,
	title = {Complex network measures of brain connectivity: {Uses} and interpretations},
	volume = {52},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S105381190901074X?via%3Dihub},
	doi = {10.1016/J.NEUROIMAGE.2009.10.003},
	abstract = {Brain connectivity datasets comprise networks of brain regions connected by anatomical tracts or by functional associations. Complex network analysis—a new multidisciplinary approach to the study of complex systems—aims to characterize these brain networks with a small number of neurobiologically meaningful and easily computable measures. In this article, we discuss construction of brain networks from connectivity data and describe the most commonly used network measures of structural and functional connectivity. We describe measures that variously detect functional integration and segregation, quantify centrality of individual brain regions or pathways, characterize patterns of local anatomical circuitry, and test resilience of networks to insult. We discuss the issues surrounding comparison of structural and functional network connectivity, as well as comparison of networks across subjects. Finally, we describe a Matlab toolbox (http://www.brain-connectivity-toolbox.net) accompanying this article and containing a collection of complex network measures and large-scale neuroanatomical connectivity datasets.},
	number = {3},
	urldate = {2019-01-29},
	journal = {NeuroImage},
	author = {Rubinov, Mikail and Sporns, Olaf},
	month = sep,
	year = {2010},
	note = {Publisher: Academic Press},
	pages = {1059--1069},
}

@techreport{vinyals_google_show_nodate,
	title = {Show and {Tell}: {A} {Neural} {Image} {Caption} {Generator}},
	abstract = {Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.},
	urldate = {2019-01-21},
	author = {Vinyals Google, Oriol and Toshev Google, Alexander and Bengio Google, Samy and Erhan Google, Dumitru},
	note = {arXiv: 1411.4555v2},
}

@article{xu_show_2015,
	title = {Show, {Attend} and {Tell}: {Neural} {Image} {Caption} {Generation} with {Visual} {Attention}},
	url = {http://arxiv.org/abs/1502.03044},
	abstract = {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.},
	urldate = {2019-01-21},
	author = {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},
	month = feb,
	year = {2015},
	note = {arXiv: 1502.03044},
}

@techreport{chung_lectures_nodate,
	title = {Lectures on {Spectral} {Graph} {Theory}},
	urldate = {2019-01-15},
	author = {Chung, Fan R K},
}

@article{pontrelli_escherichia_2018,
	title = {Escherichia coli as a host for metabolic engineering},
	volume = {50},
	issn = {1096-7176},
	url = {https://www.sciencedirect.com/science/article/pii/S1096717618300740},
	doi = {10.1016/J.YMBEN.2018.04.008},
	abstract = {Over the past century, Escherichia coli has become one of the best studied organisms on earth. Features such as genetic tractability, favorable growth conditions, well characterized biochemistry and physiology, and availability of versatile genetic manipulation tools make E. coli an ideal platform host for development of industrially viable productions. In this review, we discuss the physiological attributes of E. coli that are most relevant for metabolic engineering, as well as emerging techniques that enable efficient phenotype construction. Further, we summarize the large number of native and non-native products that have been synthesized by E. coli, and address some of the future challenges in broadening substrate range and fighting phage infection.},
	urldate = {2019-01-11},
	journal = {Metabolic Engineering},
	author = {Pontrelli, Sammy and Chiu, Tsan-Yu and Lan, Ethan I. and Chen, Frederic Y.-H. and Chang, Peiching and Liao, James C.},
	month = nov,
	year = {2018},
	note = {Publisher: Academic Press},
	pages = {16--46},
}

@article{author_semi-supervised_nodate,
	title = {Semi-supervised {Learning} for {Quantification} of {Pulmonary} {Edema} in {Chest} {X}-{Ray} {Images}},
	author = {Author, Anonymous},
	keywords = {chest x-ray images, conges-, semi-supervised learning},
}

@article{Hendrick1992,
	title = {"{Breathing}" coal mines and surface asphyxiation from stythe (black damp)},
	volume = {305},
	issn = {09598146},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/1392998},
	number = {6852},
	journal = {Bmj},
	author = {Hendrick, D J and Sizer, K E},
	year = {1992},
	pmid = {1392998},
	note = {ISBN: 0959-8138 (Print){\textbackslash}r0959-535X (Linking)},
	keywords = {*Coal Mining, *Environmental Exposure, Adult, Asphyxia/*etiology, Carbon Dioxide, Female, Geological Phenomena, Geology, Housing, Humans, Oxygen},
	pages = {509--510},
}

@article{yi_moments_2018,
	title = {Moments reconstruction and local dynamic range compression of high order {Superresolution} {Optical} {Fluctuation} {Imaging}},
	url = {https://www.biorxiv.org/content/early/2018/12/28/500819},
	doi = {10.1101/500819},
	abstract = {Super-resolution Optical Fluctuation Imaging (SOFI) offers a simple and affordable alternative to other super-resolution (SR) imaging techniques. The theoretical resolution enhancement of SOFI scales linearly with the cumulants' order, while imaging conditions are less phototoxic to living samples as compared to other SR methods. High order SOFI could, therefore, be a method of choice for dynamic live cell imaging. However, due to cusp-artifacts and to dynamic range expansion of pixel intensities, this promise has not been materialized as of yet. Here we investigated and compared high order moments vs. high order cumulants SOFI reconstructions. We demonstrate that even-order moments reconstructions are intrinsically free of cusp artifacts, allowing for a subsequent deconvolution operation to be performed, hence enhancing the resolution even further. High order moments reconstructions performance was examined for various (simulated) conditions and applied to (experimental) imaging of QD labeled microtubules in fixed cells, and actin stress fiber dynamics in live cells.},
	urldate = {2019-01-03},
	journal = {bioRxiv},
	author = {Yi, Xiyu and Son, Sungho and Ando, Ryoko and Miyawaki, Atsushi and Weiss, Shimon},
	month = dec,
	year = {2018},
	note = {Publisher: Cold Spring Harbor Laboratory},
	pages = {500819},
}

@article{Shivanandan2016b,
	title = {On characterizing protein spatial clusters with correlation approaches},
	volume = {6},
	issn = {20452322},
	url = {----},
	doi = {10.1038/srep31164},
	abstract = {On characterizing protein spatial clusters with correlation approaches},
	number = {August},
	journal = {Scientific Reports},
	author = {Shivanandan, Arun and Unnikrishnan, Jayakrishnan and Radenovic, Aleksandra},
	year = {2016},
	note = {Publisher: Nature Publishing Group},
	pages = {1--12},
}

@article{shivanandan_accounting_2015,
	title = {Accounting for limited detection efficiency and localization precision in cluster analysis in single molecule localization microscopy},
	issn = {19326203},
	doi = {10.1371/journal.pone.0118767},
	abstract = {Single Molecule Localization Microscopy techniques like PhotoActivated Localization Microscopy, with their sub-diffraction limit spatial resolution, have been popularly used to characterize the spatial organization of membrane proteins, by means of quantitative cluster analysis. However, such quantitative studies remain challenged by the techniques' inherent sources of errors such as a limited detection efficiency of less than 60\%, due to incomplete photo-conversion, and a limited localization precision in the range of 10-30 nm, varying across the detected molecules, mainly depending on the number of photons collected from each. We provide analytical methods to estimate the effect of these errors in cluster analysis and to correct for them. These methods, based on the Ripley's L(r) - r or Pair Correlation Function popularly used by the community, can facilitate potentially breakthrough results in quantitative biology by providing a more accurate and precise quantification of protein spatial organization.},
	journal = {PLoS ONE},
	author = {Shivanandan, Arun and Unnikrishnan, Jayakrishnan and Radenovic, Aleksandra},
	year = {2015},
	pmid = {25794150},
	note = {ISBN: 1932-6203 (Electronic){\textbackslash}r1932-6203 (Linking)},
}

@article{Gahlmann2013,
	title = {Quantitative multicolor subdiffraction imaging of bacterial protein ultrastructures in three dimensions},
	volume = {13},
	issn = {15306984},
	doi = {10.1021/nl304071h},
	abstract = {We demonstrate quantitative multicolor three-dimensional (3D) subdiffraction imaging of the structural arrangement of fluorescent protein fusions in living Caulobacter crescentus bacteria. Given single-molecule localization precisions of 20-40 nm, a flexible locally weighted image registration algorithm is critical to accurately combine the super-resolution data with {\textless}10 nm error. Surface-relief dielectric phase masks implement a double-helix response at two wavelengths to distinguish two different fluorescent labels and to quantitatively and precisely localize them relative to each other in 3D.},
	number = {3},
	journal = {Nano Letters},
	author = {Gahlmann, Andreas and Ptacin, Jerod L. and Grover, Ginni and Quirin, Sean and Von Diezmann, Alexander R.S. and Lee, Marissa K. and Backlund, Mikael P. and Shapiro, Lucy and Piestun, Rafael and Moerner, W. E.},
	year = {2013},
	pmid = {23414562},
	note = {ISBN: 1530-6992 (Electronic){\textbackslash}r1530-6984 (Linking)},
	keywords = {3D imaging, Fluorescence, biophysics, image registration, live-cell imaging, super-resolution},
	pages = {987--993},
}

@article{istrate_tapas_nodate,
	title = {{TAPAS} : {Train}-less {Accuracy} {Predictor} for {Architecture} {Search}},
	number = {i},
	author = {Istrate, R and Scheidegger, F and Mariani, G and Nikolopoulos, D and Bekas, C and Malossi, A C I},
	note = {arXiv: 1806.00250v1},
	pages = {1--9},
}

@article{wistuba_deep_nodate,
	title = {Deep {Learning} {Architecture} {Search} by {Neuro}-{Cell}-based {Evolution} with {Function}-{Preserving} {Mutations}},
	author = {Wistuba, Martin},
	keywords = {automated machine learning, evolutionary algorithms, neural architecture search},
}

@article{Seemann2017,
	title = {Deciphering caveolar functions by syndapin {III} {KO}-mediated impairment of caveolar invagination},
	volume = {6},
	issn = {2050084X},
	doi = {10.7554/eLife.29854},
	abstract = {Several human diseases are associated with a lack of caveolae. Yet, the functions of caveolae and the molecular mechanisms critical for shaping them still are debated. We show that muscle cells of syndapin III KO mice show severe reductions of caveolae reminiscent of human caveolinopathies. Yet, different from other mouse models, the levels of the plasma membrane-associated caveolar coat proteins caveolin3 and cavin1 were both not reduced upon syndapin III KO. This allowed for dissecting bona fide caveolar functions from those supported by mere caveolin presence and also demonstrated that neither caveolin3 nor caveolin3 and cavin1 are sufficient to form caveolae. The membrane-shaping protein syndapin III is crucial for caveolar invagination and KO rendered the cells sensitive to membrane tensions. Consistent with this physiological role of caveolae in counterpoising membrane tensions, syndapin III KO skeletal muscles showed pathological parameters upon physical exercise that are also found in CAVEOLIN3 mutation-associated muscle diseases.},
	journal = {eLife},
	author = {Seemann, Eric and Sun, Minxuan and Krueger, Sarah and Tröger, Jessica and Hou, Wenya and Haag, Natja and Schüler, Susann and Westermann, Martin and Huebner, Christian A. and Romeike, Bernd and Kessels, Michael M. and Qualmann, Britta},
	year = {2017},
	pages = {1--37},
}

@techreport{choy_3d-r2n2:_nodate,
	title = {{3D}-{R2N2}: {A} {Unified} {Approach} for {Single} and {Multi}-view {3D} {Object} {Reconstruction}},
	abstract = {Inspired by the recent success of methods that employ shape priors to achieve robust 3D reconstructions, we propose a novel recurrent neural network architecture that we call the 3D Recurrent Reconstruction Neural Network (3D-R2N2). The network learns a mapping from images of objects to their underlying 3D shapes from a large collection of synthetic data [13]. Our network takes in one or more images of an object instance from arbitrary viewpoints and outputs a reconstruction of the object in the form of a 3D occupancy grid. Unlike most of the previous works, our network does not require any image annotations or object class labels for training or testing. Our extensive experimental analysis shows that our reconstruction framework i) outperforms the state-of-the-art methods for single view reconstruction, and ii) enables the 3D reconstruction of objects in situations when traditional SFM/SLAM methods fail (because of lack of texture and/or wide baseline).},
	urldate = {2018-12-17},
	author = {Choy, Christopher B and Xu, Danfei and Gwak, Junyoung and Chen, Kevin and Savarese, Silvio},
	keywords = {multi-view, reconstruction, recurrent neural network},
}

@article{moniz_nested_2018,
	title = {Nested {LSTMs}},
	url = {http://arxiv.org/abs/1801.10308},
	abstract = {We propose Nested LSTMs (NLSTM), a novel RNN architecture with multiple levels of memory. Nested LSTMs add depth to LSTMs via nesting as opposed to stacking. The value of a memory cell in an NLSTM is computed by an LSTM cell, which has its own inner memory cell. Specifically, instead of computing the value of the (outer) memory cell as \$c{\textasciicircum}\{outer\}\_t = f\_t {\textbackslash}odot c\_\{t-1\} + i\_t {\textbackslash}odot g\_t\$, NLSTM memory cells use the concatenation \$(f\_t {\textbackslash}odot c\_\{t-1\}, i\_t {\textbackslash}odot g\_t)\$ as input to an inner LSTM (or NLSTM) memory cell, and set \$c{\textasciicircum}\{outer\}\_t\$ = \$h{\textasciicircum}\{inner\}\_t\$. Nested LSTMs outperform both stacked and single-layer LSTMs with similar numbers of parameters in our experiments on various character-level language modeling tasks, and the inner memories of an LSTM learn longer term dependencies compared with the higher-level units of a stacked LSTM.},
	urldate = {2018-12-17},
	author = {Moniz, Joel Ruben Antony and Krueger, David},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.10308},
}

@article{Li2018a,
	title = {Deep {Learning} on {Graphs} : {A} {Survey}},
	volume = {3},
	author = {Li, Yanjun},
	year = {2018},
	note = {arXiv: 1710.09599},
	pages = {2539},
}

@techreport{bentaieb_predicting_nodate,
	title = {Predicting {Cancer} with a {Recurrent} {Visual} {Attention} {Model} for {Histopathology} {Images}},
	abstract = {Automatically recognizing cancers from multi-gigapixel whole slide histopathology images is one of the challenges facing machine and deep learning based solutions for digital pathology. Currently, most automatic systems for histopathology are not scalable to large images and hence require a patch-based representation; a sub-optimal solution as it results in important additional computational costs but more importantly in the loss of contextual information. We present a novel attention-based model for predicting cancer from histopathology whole slide images. The proposed model is capable of attending to the most discrimi-native regions of an image by adaptively selecting a limited sequence of locations and only processing the selected areas of tissues. We demonstrate the utility of the proposed model on the slide-based prediction of macro and micro metastases in sentinel lymph nodes of breast cancer patients. We achieve competitive results with state-of-the-art convolutional networks while automatically identifying discriminative areas of tissues.},
	urldate = {2018-12-13},
	author = {Bentaieb, Aïcha and Hamarneh, Ghassan},
}

@techreport{you_graphrnn:_2018,
	title = {{GraphRNN}: {Generating} {Realistic} {Graphs} with {Deep} {Auto}-regressive {Models}},
	url = {https://arxiv.org/abs/1802.08773.},
	abstract = {Modeling and generating graphs is fundamental for studying networks in biology, engineering, and social sciences. However, modeling complex distributions over graphs and then efficiently sampling from these distributions is challenging due to the non-unique, high-dimensional nature of graphs and the complex, non-local dependencies that exist between edges in a given graph. Here we propose GraphRNN, a deep autoregressive model that addresses the above challenges and approximates any distribution of graphs with minimal assumptions about their structure. GraphRNN learns to generate graphs by training on a representative set of graphs and decomposes the graph generation process into a sequence of node and edge formations, conditioned on the graph structure generated so far. In order to quantitatively evaluate the performance of GraphRNN, we introduce a benchmark suite of datasets, baselines and novel evaluation metrics based on Maximum Mean Discrepancy , which measure distances between sets of graphs. Our experiments show that GraphRNN significantly outperforms all baselines, learning to generate diverse graphs that match the structural characteristics of a target set, while also scaling to graphs 50× larger than previous deep models.},
	urldate = {2018-12-08},
	author = {You, Jiaxuan and Ying, Rex and Ren, Xiang and Hamilton, William L and Leskovec, Jure},
	year = {2018},
	note = {arXiv: 1802.08773v3},
}

@article{zelger_three-dimensional_2018,
	title = {Three-dimensional localization microscopy using deep learning},
	volume = {26},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/abstract.cfm?URI=oe-26-25-33166},
	doi = {10.1364/OE.26.033166},
	abstract = {Single molecule localization microscopy (SMLM) is one of the fastest evolving and most broadly used super-resolving imaging techniques in the biosciences. While image recordings could take up to hours only ten years ago, scientists are now reaching for real-time imaging in order to follow the dynamics of biology. To this end, it is crucial to have data processing strategies available that are capable of handling the vast amounts of data produced by the microscope. In this article, we report on the use of a deep convolutional neural network (CNN) for localizing particles in three dimensions on the basis of single images. In test experiments conducted on fluorescent microbeads, we show that the precision obtained with a CNN can be comparable to that of maximum likelihood estimation (MLE), which is the accepted gold standard. Regarding speed, the CNN performs with about 22k localizations per second more than three orders of magnitude faster than the MLE algorithm of ThunderSTORM. If only five parameters are estimated (3D position, signal and background), our CNN implementation is currently slower than the fastest, recently published GPU-based MLE algorithm. However, in this comparison the CNN catches up with every additional parameter, with only a few percent extra time required per additional dimension. Thus it may become feasible to estimate further variables such as molecule orientation, aberration functions or color. We experimentally demonstrate that jointly estimating Zernike mode magnitudes for aberration modeling can significantly improve the accuracy of the estimates.},
	number = {25},
	urldate = {2018-12-08},
	journal = {Optics Express},
	author = {Zelger, P. and Kaser, K. and Rossboth, B. and Velas, L. and Schütz, G. J. and Jesacher, A.},
	month = dec,
	year = {2018},
	note = {Publisher: Optical Society of America},
	keywords = {Diode lasers, Image processing, Image restoration, Phase measurement, Phase retrieval, Spatial light modulators},
	pages = {33166},
}

@article{Goodfellow2015,
	title = {Deep {Learning}},
	issn = {14701804},
	url = {005157},
	doi = {10.1016/B978-0-12-801775-3.00001-9},
	author = {Goodfellow, Ian},
	year = {2015},
	pmid = {22109786},
	note = {arXiv: 1011.1669v3
ISBN: 9780128017753},
	pages = {1--9},
}

@misc{noauthor_deep_nodate,
	title = {Deep {Learning}},
	url = {https://www.deeplearningbook.org/},
	urldate = {2018-12-07},
}

@article{vasilache_fast_2014,
	title = {Fast {Convolutional} {Nets} {With} fbfft: {A} {GPU} {Performance} {Evaluation}},
	url = {http://arxiv.org/abs/1412.7580},
	abstract = {We examine the performance profile of Convolutional Neural Network training on the current generation of NVIDIA Graphics Processing Units. We introduce two new Fast Fourier Transform convolution implementations: one based on NVIDIA's cuFFT library, and another based on a Facebook authored FFT implementation, fbfft, that provides significant speedups over cuFFT (over 1.5x) for whole CNNs. Both of these convolution implementations are available in open source, and are faster than NVIDIA's cuDNN implementation for many common convolutional layers (up to 23.5x for some synthetic kernel configurations). We discuss different performance regimes of convolutions, comparing areas where straightforward time domain convolutions outperform Fourier frequency domain convolutions. Details on algorithmic applications of NVIDIA GPU hardware specifics in the implementation of fbfft are also provided.},
	urldate = {2018-12-07},
	author = {Vasilache, Nicolas and Johnson, Jeff and Mathieu, Michael and Chintala, Soumith and Piantino, Serkan and LeCun, Yann},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.7580},
}

@techreport{pratt_fcnn:_nodate,
	title = {{FCNN}: {Fourier} {Convolutional} {Neural} {Networks}},
	abstract = {The Fourier domain is used in computer vision and machine learning as image analysis tasks in the Fourier domain are analogous to spatial domain methods but are achieved using different operations. Convolutional Neu-ral Networks (CNNs) use machine learning to achieve state-of-the-art results with respect to many computer vision tasks. One of the main limiting aspects of CNNs is the computational cost of updating a large number of convolution parameters. Further, in the spatial domain, larger images take exponentially longer than smaller image to train on CNNs due to the operations involved in convolu-tion methods. Consequently, CNNs are often not a viable solution for large image computer vision tasks. In this paper a Fourier Convolution Neural Network (FCNN) is proposed whereby training is conducted entirely within the Fourier domain. The advantage offered is that there is a significant speed up in training time without loss of effectiveness. Using the proposed approach larger images can therefore be processed within viable computation time. The FCNN is fully described and evaluated. The evaluation was conducted using the benchmark Ci-far10 and MNIST datasets, and a bespoke fundus retina image dataset. The results demonstrate that convolution in the Fourier domain gives a significant speed up without adversely affecting accuracy. For simplicity the proposed FCNN concept is presented in the context of a basic CNN architecture, however, the FCNN concept has the potential to improve the speed of any neural network system involving convolution.},
	urldate = {2018-12-07},
	author = {Pratt, Harry and Williams, Bryan and Coenen, Frans and Zheng, Yalin},
}

@article{zhao_loss_2015,
	title = {Loss {Functions} for {Neural} {Networks} for {Image} {Processing}},
	url = {http://arxiv.org/abs/1511.08861},
	abstract = {Neural networks are becoming central in several areas of computer vision and image processing and different architectures have been proposed to solve specific problems. The impact of the loss layer of neural networks, however, has not received much attention in the context of image processing: the default and virtually only choice is L2. In this paper, we bring attention to alternative choices for image restoration. In particular, we show the importance of perceptually-motivated losses when the resulting image is to be evaluated by a human observer. We compare the performance of several losses, and propose a novel, differentiable error function. We show that the quality of the results improves significantly with better loss functions, even when the network architecture is left unchanged.},
	urldate = {2018-12-06},
	author = {Zhao, Hang and Gallo, Orazio and Frosio, Iuri and Kautz, Jan},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.08861},
}

@article{elmokadem_optimal_2015,
	title = {Optimal {Drift} {Correction} for {Superresolution} {Localization} {Microscopy} with {Bayesian} {Inference}},
	issn = {15420086},
	doi = {10.1016/j.bpj.2015.09.017},
	abstract = {Single-molecule-localization-based superresolution microscopy requires accurate sample drift correction to achieve good results. Common approaches for drift compensation include using fiducial markers and direct drift estimation by image correlation. The former increases the experimental complexity and the latter estimates drift at a reduced temporal resolution. Here, we present, to our knowledge, a new approach for drift correction based on the Bayesian statistical framework. The technique has the advantage of being able to calculate the drifts for every image frame of the data set directly from the single-molecule coordinates. We present the theoretical foundation of the algorithm and an implementation that achieves significantly higher accuracy than image-correlation-based estimations.},
	journal = {Biophysical Journal},
	author = {Elmokadem, Ahmed and Yu, Ji},
	year = {2015},
	pmid = {26536254},
	note = {ISBN: 1542-0086 (Electronic){\textbackslash}r0006-3495 (Linking)},
}

@techreport{le_tutorial_2015,
	title = {A {Tutorial} on {Deep} {Learning} {Part} 2: {Autoencoders}, {Convolutional} {Neural} {Networks} and {Recurrent} {Neural} {Networks}},
	urldate = {2018-12-05},
	author = {Le, Quoc V},
	year = {2015},
}

@techreport{salakhutdinov_hugo_larochelle_brain_efficient_nodate,
	title = {Efficient {Learning} of {Deep} {Boltzmann} {Machines}},
	abstract = {We present a new approximate inference algorithm for Deep Boltzmann Machines (DBM's), a generative model with many layers of hidden variables. The algorithm learns a separate "recognition" model that is used to quickly initialize , in a single bottom-up pass, the values of the latent variables in all hidden layers. We show that using such a recognition model, followed by a combined top-down and bottom-up pass, it is possible to efficiently learn a good genera-tive model of high-dimensional highly-structured sensory input. We show that the additional computations required by incorporating a top-down feedback plays a critical role in the performance of a DBM, both as a generative and discrimina-tive model. Moreover, inference is only at most three times slower compared to the approximate inference in a Deep Belief Network (DBN), making large-scale learning of DBM's practical. Finally , we demonstrate that the DBM's trained using the proposed approximate inference algorithm perform well compared to DBN's and SVM's on the MNIST handwritten digit, OCR English letters, and NORB visual object recognition tasks.},
	urldate = {2018-12-05},
	author = {Salakhutdinov Hugo Larochelle Brain, Ruslan and Sciences, Cognitive},
}

@techreport{mnih_conditional_nodate,
	title = {Conditional {Restricted} {Boltzmann} {Machines} for {Structured} {Output} {Prediction}},
	abstract = {Conditional Restricted Boltzmann Machines (CRBMs) are rich probabilistic models that have recently been applied to a wide range of problems, including collaborative filtering, classification, and modeling motion capture data. While much progress has been made in training non-conditional RBMs, these algorithms are not applicable to conditional models and there has been almost no work on training and generating predictions from conditional RBMs for structured output problems. We first argue that standard Con-trastive Divergence-based learning may not be suitable for training CRBMs. We then identify two distinct types of structured output prediction problems and propose an improved learning algorithm for each. The first problem type is one where the output space has arbitrary structure but the set of likely output configurations is relatively small, such as in multi-label classification. The second problem is one where the output space is arbitrarily structured but where the output space variability is much greater, such as in image denoising or pixel labeling. We show that the new learning algorithms can work much better than Contrastive Divergence on both types of problems.},
	urldate = {2018-12-05},
	author = {Mnih, Volodymyr and Larochelle, Hugo and Hinton, Geoffrey E},
}

@article{abstract_caveolin-1_2018,
	title = {Caveolin-1 {Modulates} {Mechanotransduction} {Responses} to {Substrate} {Stiffness} through {Actin}-{Dependent} {Control} of {YAP}},
	volume = {25},
	url = {https://doi.org/10.1016/j.celrep.2018.10.024},
	doi = {10.1016/j.celrep.2018.10.024},
	urldate = {2018-12-05},
	journal = {CellReports},
	author = {Abstract, Graphical},
	year = {2018},
	pages = {1622--1635.e6},
}

@article{sezgin_super-resolution_2017,
	title = {Super-resolution optical microscopy for studying membrane structure and dynamics},
	volume = {29},
	issn = {0953-8984},
	url = {http://stacks.iop.org/0953-8984/29/i=27/a=273001?key=crossref.628afbc8a80015f456cea385052a20d7},
	doi = {10.1088/1361-648X/aa7185},
	number = {27},
	urldate = {2018-12-04},
	journal = {Journal of Physics: Condensed Matter},
	author = {Sezgin, Erdinc},
	month = jul,
	year = {2017},
	note = {Publisher: IOP Publishing},
	pages = {273001},
}

@article{rossboth_tcrs_2018,
	title = {{TCRs} are randomly distributed on the plasma membrane of resting antigen-experienced {T} cells},
	volume = {19},
	issn = {1529-2908},
	url = {http://www.nature.com/articles/s41590-018-0162-7},
	doi = {10.1038/s41590-018-0162-7},
	abstract = {The main function of T cells is to identify harmful antigens as quickly and precisely as possible. Super-resolution microscopy data have indicated that global clustering of T cell antigen receptors (TCRs) occurs before T cell activation. Such pre-activation clustering has been interpreted as representing a potential regulatory mechanism that fine tunes the T cell response. We found here that apparent TCR nanoclustering could be attributed to overcounting artifacts inherent to single-molecule-localization microscopy. Using complementary super-resolution approaches and statistical image analysis, we found no indication of global nanoclustering of TCRs on antigen-experienced CD4+ T cells under non-activating conditions. We also used extensive simulations of super-resolution images to provide quantitative limits for the degree of randomness of the TCR distribution. Together our results suggest that the distribution of TCRs on the plasma membrane is optimized for fast recognition of antigen in the first phase of T cell activation.},
	number = {8},
	urldate = {2018-12-04},
	journal = {Nature Immunology},
	author = {Rossboth, Benedikt and Arnold, Andreas M. and Ta, Haisen and Platzer, René and Kellner, Florian and Huppa, Johannes B. and Brameshuber, Mario and Baumgart, Florian and Schütz, Gerhard J.},
	month = aug,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Microscopy, T cells},
	pages = {821--827},
}

@article{mifsud_gothic_2017,
	title = {{GOTHiC}, a probabilistic model to resolve complex biases and to identify real interactions in {Hi}-{C} data},
	url = {http://www.bioconductor.org/packages/release/bioc/html/GOTHiC.html},
	doi = {10.1371/journal.pone.0174744},
	abstract = {Hi-C is one of the main methods for investigating spatial co-localisation of DNA in the nucleus. However, the raw sequencing data obtained from Hi-C experiments suffer from large biases and spurious contacts, making it difficult to identify true interactions. Existing methods use complex models to account for biases and do not provide a significance threshold for detecting interactions. Here we introduce a simple binomial probabilistic model that resolves complex biases and distinguishes between true and false interactions. The model corrects biases of known and unknown origin and yields a p-value for each interaction, providing a reliable threshold based on significance. We demonstrate this experimentally by testing the method against a random ligation dataset. Our method outperforms previous methods and provides a statistical framework for further data analysis, such as comparisons of Hi-C interactions between different conditions. GOTHiC is available as a BioConductor package},
	urldate = {2018-12-04},
	author = {Mifsud, Borbala and Martincorena, Inigo and Darbo, Elodie and Sugar, Robert and Schoenfelder, Stefan and Fraser, Peter and Luscombe, Nicholas M},
	year = {2017},
	note = {ISBN: 1111111111},
}

@article{jezek_mitochondrial_2019,
	title = {Mitochondrial {Nucleoids}: {Superresolution} microscopy analysis},
	volume = {106},
	issn = {13572725},
	doi = {10.1016/j.biocel.2018.10.012},
	abstract = {The mitochondrion owns an autonomous genome. Double-stranded circular mitochondrial DNA (mtDNA) is organized in complexes with a packing/stabilizing transcription factor TFAM, having multiple roles, and proteins of gene expression machinery in structures called nucleoids. From hundreds to thousands nucleoids exist distributed in the matrix of mitochondrial reticulum network. A single mtDNA molecule contained within the single nucleoid is a currently preferred but questioned model. Nevertheless, mtDNA replication should lead transiently to its doubling within a nucleoid. However, nucleoid division has not yet been documented in detail. A 3D superresolution microscopy is required to resolve nucleoid biology occurring in ∼100 nm space, having an advantage over electron microscopy tomography in resolving the particular protein components. We discuss stochastic vs. stimulated emission depletion microscopy yielding wide vs. narrow nucleoid size distribution, respectively. Nucleoid clustering into spheroids fragmented from the continuous mitochondrial network, likewise possible nucleoid attachment to the inner membrane is reviewed.},
	urldate = {2018-12-04},
	journal = {The International Journal of Biochemistry \& Cell Biology},
	author = {Ježek, Petr and Špaček, Tomáš and Tauber, Jan and Pavluch, Vojtěch},
	year = {2019},
	pages = {21--25},
}

@article{chouchani_mechanisms_2018,
	title = {Mechanisms of {Mitochondria} {Assembly}, {Dynamics} and {Turnover} in {Health} and {Disease}},
	volume = {430},
	issn = {0022-2836},
	url = {https://www.sciencedirect.com/science/article/pii/S0022283618312361?dgcid=raven_sd_via_email},
	doi = {10.1016/J.JMB.2018.11.009},
	number = {24},
	urldate = {2018-12-04},
	journal = {Journal of Molecular Biology},
	author = {Chouchani, Edward T. and Liesa, Marc and Trifunovic, Aleksandra},
	month = dec,
	year = {2018},
	note = {Publisher: Academic Press},
	pages = {4821--4822},
}

@techreport{castrejon_annotating_nodate,
	title = {Annotating {Object} {Instances} with a {Polygon}-{RNN}},
	url = {http://www.cs.toronto.edu/},
	abstract = {We propose an approach for semi-automatic annotation of object instances. While most current methods treat object segmentation as a pixel-labeling problem, we here cast it as a polygon prediction task, mimicking how most current datasets have been annotated. In particular, our approach takes as input an image crop and sequentially produces ver-tices of the polygon outlining the object. This allows a human annotator to interfere at any time and correct a vertex if needed, producing as accurate segmentation as desired by the annotator. We show that our approach speeds up the annotation process by a factor of 4.7 across all classes in Cityscapes, while achieving 78.4\% agreement in IoU with original ground-truth, matching the typical agreement between human annotators. For cars, our speed-up factor is 7.3 for an agreement of 82.2\%. We further show generalization capabilities of our approach to unseen datasets.},
	urldate = {2018-12-03},
	author = {Castrejón, Lluís and Kundu, Kaustav and Urtasun, Raquel and Fidler, Sanja},
}

@article{Parton2018,
	title = {Caveolae: {Structure}, {Function}, and {Relationship} to {Disease}},
	volume = {34},
	issn = {1081-0706},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-cellbio-100617-062737},
	doi = {10.1146/annurev-cellbio-100617-062737},
	abstract = {The plasma membrane of eukaryotic cells is not a simple sheet of lipids and proteins but is differentiated into subdomains with crucial functions. Caveolae, small pits in the plasma membrane, are the most abundant surface subdomains of many mammalian cells. The cellular functions of caveolae have long remained obscure, but a new molecular understanding of caveola formation has led to insights into their workings. Caveolae are formed by the coordinated action of a number of lipid-interacting proteins to produce a microdomain with a specific structure and lipid composition. Caveolae can bud from the plasma membrane to form an endocytic vesicle or can flatten into the membrane to help cells withstand mechanical stress. The role of caveolae as mechanoprotective and signal transduction elements is reviewed in the context of disease conditions associated with caveola dysfunction.},
	number = {1},
	urldate = {2018-12-03},
	journal = {Annual Review of Cell and Developmental Biology},
	author = {Parton, Robert G.},
	month = oct,
	year = {2018},
	note = {Publisher: Annual Reviews},
	keywords = {caveolae, endocytosis, lipid, mechanoprotection, plasma membrane, signal transduction},
	pages = {111--136},
}

@article{levet_sr-tesseler:_2015,
	title = {{SR}-{Tesseler}: a method to segment and quantify localization-based super-resolution microscopy data},
	volume = {12},
	issn = {1548-7091},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26344046},
	doi = {10.1038/nmeth.3579},
	abstract = {Localization-based super-resolution techniques open the door to unprecedented analysis of molecular organization. This task often involves complex image processing adapted to the specific topology and quality of the image to be analyzed. Here we present a segmentation framework based on Voronoï tessellation constructed from the coordinates of localized molecules, implemented in freely available and open-source SR-Tesseler software. This method allows precise, robust and automatic quantification of protein organization at different scales, from the cellular level down to clusters of a few fluorescent markers. We validated our method on simulated data and on various biological experimental data of proteins labeled with genetically encoded fluorescent proteins or organic fluorophores. In addition to providing insight into complex protein organization, this polygon-based method should serve as a reference for the development of new types of quantifications, as well as for the optimization of existing ones.},
	number = {11},
	urldate = {2018-11-30},
	journal = {Nature Methods},
	author = {Levet, Florian and Hosy, Eric and Kechkar, Adel and Butler, Corey and Beghin, Anne and Choquet, Daniel and Sibarita, Jean-Baptiste},
	month = nov,
	year = {2015},
	pmid = {26344046},
	pages = {1065--1071},
}

@article{scriven_super-resolution_2015,
	title = {Super-{Resolution} {Analysis} of the {Distribution} of {RyR}, {Cav1}.2 and {NCX} within the {Mammalian} {Couplon}},
	volume = {108},
	issn = {00063495},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0006349514026770},
	doi = {10.1016/j.bpj.2014.11.1468},
	number = {2},
	urldate = {2018-11-30},
	journal = {Biophysical Journal},
	author = {Scriven, David R.L. and Tafteh, Reza and Chou, Keng C. and Moore, Edwin D.W.},
	month = jan,
	year = {2015},
	note = {Publisher: Elsevier},
	pages = {266a--267a},
}

@article{Wu2010,
	title = {Discrete {Sampling} : {Discrete} {Generalizations} of the {Nyquist}-{Shannon} {Sampling} {Theorem}},
	number = {June},
	author = {Wu, William},
	year = {2010},
}

@article{zimnicka_src-dependent_2016,
	title = {Src-dependent phosphorylation of caveolin-1 {Tyr}-14 promotes swelling and release of caveolae},
	volume = {27},
	issn = {1059-1524},
	url = {https://www.molbiolcell.org/doi/10.1091/mbc.E15-11-0756},
	doi = {10.1091/mbc.E15-11-0756},
	number = {13},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Zimnicka, Adriana M. and Husain, Yawer S. and Shajahan, Ayesha N. and Sverdlov, Maria and Chaga, Oleg and Chen, Zhenlong and Toth, Peter T. and Klomp, Jennifer and Karginov, Andrei V. and Tiruppathi, Chinnaswamy and Malik, Asrar B. and Minshall, Richard D.},
	editor = {Lidke, Diane},
	month = jul,
	year = {2016},
	pages = {2090--2106},
}

@article{chen_nitric_2012,
	title = {Nitric oxide–dependent {Src} activation and resultant caveolin-1 phosphorylation promote {eNOS}/caveolin-1 binding and {eNOS} inhibition},
	volume = {23},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.e11-09-0811},
	doi = {10.1091/mbc.e11-09-0811},
	number = {7},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Chen, Zhenlong and Bakhshi, Farnaz R. and Shajahan, Ayesha N. and Sharma, Tiffany and Mao, Mao and Trane, Andy and Bernatchez, Pascal and van Nieuw Amerongen, Geerten P. and Bonini, Marcelo G. and Skidgel, Randal A. and Malik, Asrar B. and Minshall, Richard D.},
	editor = {Parton, Robert G.},
	month = apr,
	year = {2012},
	pages = {1388--1398},
}

@article{gottlieb-abraham_src-mediated_2013,
	title = {Src-mediated caveolin-1 phosphorylation affects the targeting of active {Src} to specific membrane sites},
	volume = {24},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.e13-03-0163},
	doi = {10.1091/mbc.e13-03-0163},
	number = {24},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Gottlieb-Abraham, Efrat and Shvartsman, Dmitry E. and Donaldson, John C. and Ehrlich, Marcelo and Gutman, Orit and Martin, G. Steven and Henis, Yoav I.},
	editor = {Mostov, Keith E.},
	month = dec,
	year = {2013},
	pages = {3881--3895},
}

@article{predescu_intersectin_2003,
	title = {Intersectin {Regulates} {Fission} and {Internalization} of {Caveolae} in {Endothelial} {Cells}},
	volume = {14},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.e03-01-0041},
	doi = {10.1091/mbc.e03-01-0041},
	number = {12},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Predescu, Sanda A. and Predescu, Dan N. and Timblin, Barbara K. and Stan, Radu V. and Malik, Asrar B.},
	month = dec,
	year = {2003},
	pages = {4997--5010},
}

@article{krueger_dynamincortactinarp2/3_2003,
	title = {A {Dynamin}–{Cortactin}–{Arp2}/3 {Complex} {Mediates} {Actin} {Reorganization} in {Growth} {Factor}-stimulated {Cells}},
	volume = {14},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.e02-08-0466},
	doi = {10.1091/mbc.e02-08-0466},
	number = {3},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Krueger, Eugene W. and Orth, James D. and Cao, Hong and McNiven, Mark A.},
	editor = {Lippincott-Schwartz, Jennifer},
	month = mar,
	year = {2003},
	pages = {1085--1096},
}

@article{moren_ehd2_2012,
	title = {{EHD2} regulates caveolar dynamics via {ATP}-driven targeting and oligomerization},
	volume = {23},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.e11-09-0787},
	doi = {10.1091/mbc.e11-09-0787},
	number = {7},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Morén, Björn and Shah, Claudio and Howes, Mark T. and Schieber, Nicole L. and McMahon, Harvey T. and Parton, Robert G. and Daumke, Oliver and Lundmark, Richard},
	editor = {Lemmon, Sandra},
	month = apr,
	year = {2012},
	pages = {1316--1329},
}

@article{singh_selective_2003,
	title = {Selective {Caveolin}-1–dependent {Endocytosis} of {Glycosphingolipids}},
	volume = {14},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.e02-12-0809},
	doi = {10.1091/mbc.e02-12-0809},
	number = {8},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Singh, Raman Deep and Puri, Vishwajeet and Valiyaveettil, Jacob T. and Marks, David L. and Bittman, Robert and Pagano, Richard E.},
	month = aug,
	year = {2003},
	pages = {3254--3265},
}

@article{sverdlov_filamin_2009,
	title = {Filamin {A} {Regulates} {Caveolae} {Internalization} and {Trafficking} in {Endothelial} {Cells}},
	volume = {20},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.e08-10-0997},
	doi = {10.1091/mbc.e08-10-0997},
	number = {21},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Sverdlov, Maria and Shinin, Vasily and Place, Aaron T. and Castellon, Maricela and Minshall, Richard D.},
	editor = {Munro, Sean},
	month = nov,
	year = {2009},
	pages = {4531--4540},
}

@article{chen_reciprocal_2018,
	title = {Reciprocal regulation of {eNOS} and caveolin-1 functions in endothelial cells},
	volume = {29},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.E17-01-0049},
	doi = {10.1091/mbc.E17-01-0049},
	number = {10},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Chen, Zhenlong and D. S. Oliveira, Suellen and Zimnicka, Adriana M. and Jiang, Ying and Sharma, Tiffany and Chen, Stone and Lazarov, Orly and Bonini, Marcelo G. and Haus, Jacob M. and Minshall, Richard D.},
	editor = {Yap, Alpha},
	month = may,
	year = {2018},
	pages = {1190--1202},
}

@article{osmani_arf6-_2018,
	title = {An {Arf6}- and caveolae-dependent pathway links hemidesmosome remodeling and mechanoresponse},
	volume = {29},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.E17-06-0356},
	doi = {10.1091/mbc.E17-06-0356},
	number = {4},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Osmani, Naël and Pontabry, Julien and Comelles, Jordi and Fekonja, Nina and Goetz, Jacky G. and Riveline, Daniel and Georges-Labouesse, Elisabeth and Labouesse, Michel},
	editor = {Spang, Anne},
	month = feb,
	year = {2018},
	pages = {435--451},
}

@article{marsboom_aberrant_2017,
	title = {Aberrant caveolin-1–mediated {Smad} signaling and proliferation identified by analysis of adenine 474 deletion mutation (c.{474delA}) in patient fibroblasts: a new perspective on the mechanism of pulmonary hypertension},
	volume = {28},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.e16-11-0790},
	doi = {10.1091/mbc.e16-11-0790},
	number = {9},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Marsboom, Glenn and Chen, Zhenlong and Yuan, Yang and Zhang, Yanmin and Tiruppathi, Chinnaswamy and Loyd, James E. and Austin, Eric D. and Machado, Roberto F. and Minshall, Richard D. and Rehman, Jalees and Malik, Asrar B.},
	editor = {Parton, Robert G.},
	month = may,
	year = {2017},
	pages = {1177--1185},
}

@article{orlichenko_caveolae_2009,
	title = {Caveolae {Mediate} {Growth} {Factor}-induced {Disassembly} of {Adherens} {Junctions} to {Support} {Tumor} {Cell} {Dissociation}},
	volume = {20},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.e08-10-1043},
	doi = {10.1091/mbc.e08-10-1043},
	number = {19},
	urldate = {2018-11-29},
	journal = {Molecular Biology of the Cell},
	author = {Orlichenko, Lidiya and Weller, Shaun G. and Cao, Hong and Krueger, Eugene W. and Awoniyi, Muyiwa and Beznoussenko, Galina and Buccione, Roberto and McNiven, Mark A.},
	editor = {Mostov, Keith E.},
	month = oct,
	year = {2009},
	pages = {4140--4152},
}

@techreport{benjamin_redefine_2017,
	title = {Redefine statistical significance {Strength} of evidence from {P} values},
	url = {www.nature.com/nathumbehav},
	abstract = {We propose to change the default P-value threshold for statistical significance from 0.05 to 0.005 for claims of new discoveries. T he lack of reproducibility of scientific studies has caused growing concern over the credibility of claims of new discoveries based on 'statistically significant' findings. There has been much progress toward documenting and addressing several causes of this lack of reproducibility (for example, multiple testing, P-hacking, publication bias and under-powered studies). However, we believe that a leading cause of non-reproducibility has not yet been adequately addressed: statistical standards of evidence for claiming new discoveries in many fields of science are simply too low. Associating statistically significant findings with P {\textless} 0.05 results in a high rate of false positives even in the absence of other experimental, procedural and reporting problems. For fields where the threshold for defining statistical significance for new discoveries is P {\textless} 0.05, we propose a change to P {\textless} 0.005. This simple step would immediately improve the reproducibility of scientific research in many fields. Results that would currently be called significant but do not meet the new threshold should instead be called suggestive. While statisticians have known the relative weakness of using P ≈ 0.05 as a threshold for discovery and the proposal to lower it to 0.005 is not new 1,2 , a critical mass of researchers now endorse this change. We restrict our recommendation to claims of discovery of new effects. We do not address the appropriate threshold for confirmatory or contradictory replications of existing claims. We also do not advocate changes to discovery thresholds in fields that have already adopted more stringent standards (for example, genomics and high-energy physics research; see the 'Potential objections' section below). We also restrict our recommendation to studies that conduct null hypothesis significance tests. We have diverse views about how best to improve reproducibility, and many of us believe that other ways of summarizing the data, such as Bayes factors or other posterior summaries based on clearly articulated model assumptions, are preferable to P values. However, changing the P value threshold is simple, aligns with the training undertaken by many researchers, and might quickly achieve broad acceptance.},
	urldate = {2018-11-29},
	author = {Benjamin, Daniel J and Berger, James O and Johannesson, Magnus and Nosek, Brian A and Wagenmakers, E-j and Berk, Richard and Bollen, Kenneth A and Brembs, Björn and Brown, Lawrence and Camerer, Colin and Cesarini, David and Chambers, Christopher D and Clyde, Merlise and Cook, Thomas D and De Boeck, Paul and Dienes, Zoltan and Dreber, Anna and Easwaran, Kenny and Efferson, Charles and Fehr, Ernst and Fidler, Fiona and Field, Andy P and Forster, Malcolm and George, Edward I and Gonzalez, Richard and Goodman, Steven and Green, Edwin and Green, Donald P and Greenwald, Anthony and Hadfield, Jarrod D and Hedges, Larry V and Held, Leonhard and Hua Ho, Teck and Hoijtink, Herbert and Hruschka, Daniel J and Imai, Kosuke and Imbens, Guido and A Ioannidis, John P and Jeon, Minjeong and Holland Jones, James and Kirchler, Michael and Laibson, David and List, John and Little, Roderick and Lupia, Arthur and Machery, Edouard and Maxwell, Scott E and McCarthy, Michael and Moore, Don and Morgan, Stephen L and Munafó, Marcus and Nakagawa, Shinichi and Nyhan, Brendan and Parker, Timothy H and Pericchi, Luis and Perugini, Marco and Rouder, Jeff and Rousseau, Judith and Savalei, Victoria and Schönbrodt, Felix D and Sellke, Thomas and Sinclair, Betsy and Tingley, Dustin and Van Zandt, Trisha and Vazire, Simine and Watts, Duncan J and Winship, Christopher and Wolpert, Robert L and Xie, Yu and Young, Cristobal and Zinman, Jonathan and Johnson, Valen E},
	year = {2017},
	doi = {10.1038/s41562-017-0189-z},
	note = {Publication Title: Nature Human Behaviour},
}

@article{Spahn2016,
	title = {Temporal accumulation analysis provides simplified artifact-free analysis of membrane-protein nanoclusters},
	volume = {13},
	issn = {15487105},
	url = {http://dx.doi.org/10.1038/nmeth.4065},
	doi = {10.1038/nmeth.4065},
	number = {12},
	journal = {Nature Methods},
	author = {Spahn, Christoph and Herrmannsdörfer, Frank and Kuner, Thomas and Heilemann, Mike},
	year = {2016},
	pmid = {27898062},
	note = {Publisher: Nature Publishing Group
ISBN: 1548-7105 (Electronic){\textbackslash}r1548-7091 (Linking)},
	pages = {963--964},
}

@article{Sauer2017,
	title = {Single-{Molecule} {Localization} {Microscopy} in {Eukaryotes}},
	volume = {117},
	issn = {15206890},
	doi = {++},
	abstract = {Super-resolution fluorescence imaging by photoactivation or photoswitching of single fluorophores and position determination (single-molecule localization microscopy, SMLM) provides microscopic images with subdiffraction spatial resolution. This technology has enabled new insights into how proteins are organized in a cellular context, with a spatial resolution approaching virtually the molecular level. A unique strength of SMLM is that it delivers molecule-resolved information, along with super-resolved images of cellular structures. This allows quantitative access to cellular structures, for example, how proteins are distributed and organized and how they interact with other biomolecules. Ultimately, it is even possible to determine protein numbers in cells and the number of subunits in a protein complex. SMLM thus has the potential to pave the way toward a better understanding of how cells function at the molecular level. In this review, we describe how SMLM has contributed new knowledge in eukaryotic b...},
	number = {11},
	journal = {Chemical Reviews},
	author = {Sauer, Markus and Heilemann, Mike},
	year = {2017},
	pmid = {28287710},
	note = {ISBN: 0009-2665},
	pages = {7478--7509},
}

@article{kim_focal_2013,
	title = {Focal adhesion size uniquely predicts cell migration},
	volume = {27},
	issn = {0892-6638},
	url = {http://www.fasebj.org/doi/10.1096/fj.12-220160},
	doi = {10.1096/fj.12-220160},
	abstract = {Focal adhesions are large protein complexes organized at the basal surface of cells, which physically connect the extracellular matrix to the cytoskeleton and have long been speculated to mediate cell migration. However, whether clustering of these molecular components into focal adhesions is actually required for these proteins to regulate cell motility is unclear. Here we use quantitative microscopy to characterize descriptors of focal adhesion and cell motility for mouse embryonic fibroblasts and human fibrosarcoma cells, across a wide range of matrix compliance and following genetic manipulations of focal adhesion proteins (vinculin, talin, zyxin, FAK, and paxilin). This analysis reveals a tight, biphasic gaussian relationship between mean size of focal adhesions (not their number, surface density, or shape) and cell speed. The predictive power of this relationship is comprehensively validated by disrupting nonfocal adhesion proteins (α-actinin, F-actin, and myosin II) and subcellular organelles (mito...},
	number = {4},
	urldate = {2018-11-28},
	journal = {The FASEB Journal},
	author = {Kim, Dong-Hwee and Wirtz, Denis},
	month = apr,
	year = {2013},
	note = {Publisher:  Federation of American Societies for Experimental Biology Bethesda, MD, USA},
	keywords = {high-throughput phenotyping, mechanosensing, motility, systems biology},
	pages = {1351--1361},
}

@article{boscher_galectin-3_2013,
	title = {Galectin-3– and phospho-caveolin-1–dependent outside-in integrin signaling mediates the {EGF} motogenic response in mammary cancer cells},
	volume = {24},
	issn = {1059-1524},
	url = {http://www.molbiolcell.org/doi/10.1091/mbc.e13-02-0095},
	doi = {10.1091/mbc.e13-02-0095},
	number = {13},
	urldate = {2018-11-28},
	journal = {Molecular Biology of the Cell},
	author = {Boscher, Cecile and Nabi, Ivan R.},
	editor = {Nusrat, Asma},
	month = jul,
	year = {2013},
	pages = {2134--2145},
}

@article{volonte_polymerase_2011,
	title = {Polymerase {I} and {Transcript} {Release} {Factor} ({PTRF})/{Cavin}-1 {Is} a {Novel} {Regulator} of {Stress}-induced {Premature} {Senescence}},
	volume = {286},
	issn = {0021-9258},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21705337},
	doi = {10.1074/jbc.C111.235119},
	abstract = {According to the "free radical theory" of aging, premature senescence induced by oxidative stress contributes to organismal aging. Polymerase I and transcript release factor (PTRF)/cavin-1 is a structural protein component of caveolae, invaginations of the plasma membrane involved in signal transduction. We show that oxidative stress up-regulates PTRF/cavin-1 protein expression and promotes the interaction between PTRF/cavin-1 and caveolin-1, another structural protein component of caveolae. Consistent with these data, the number of caveolae is dramatically increased in cells subjected to oxidative stress. We demonstrate that down-regulation of PTRF/cavin-1 by shRNA significantly inhibits oxidative stress-induced premature senescence. Mechanistically, we found that PTRF/cavin-1 expression is necessary for the oxidant-induced sequestration of Mdm2, a negative regulator of p53, into caveolar membranes, away from p53, and activation of the p53/p21(Waf1/Cip1) pathway. Expression of a mutant form of PTRF/cavin-1, which fails to localize to caveolar membranes after oxidative stress, inhibits oxidative stress-induced activation of p53 and induction of premature senescence. Thus, PTRF/cavin-1 is a novel regulator of oxidative stress-induced premature senescence by acting as a link between free radicals and activation of the p53/p21(Waf1/Cip1) pathway.},
	number = {33},
	urldate = {2018-11-28},
	journal = {Journal of Biological Chemistry},
	author = {Volonte, Daniela and Galbiati, Ferruccio},
	month = aug,
	year = {2011},
	pmid = {21705337},
	pages = {28657--28661},
}

@article{noauthor_polyhedra_nodate,
	title = {Polyhedra},
	urldate = {2018-11-27},
}

@article{oneill_enhanced_2014,
	title = {Enhanced {flowType}/{RchyOptimyx}: a {BioConductor} pipeline for discovery in high-dimensional cytometry data.},
	volume = {30},
	issn = {1367-4811},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24407226},
	doi = {10.1093/bioinformatics/btt770},
	abstract = {We present a significantly improved version of the flowType and RchyOptimyx BioConductor-based pipeline that is both 14 times faster and can accommodate multiple levels of biomarker expression for up to 96 markers. With these improvements, the pipeline is positioned to be an integral part of data analysis for high-throughput experiments on high-dimensional single-cell assay platforms, including flow cytometry, mass cytometry and single-cell RT-qPCR.},
	number = {9},
	urldate = {2018-11-27},
	journal = {Bioinformatics (Oxford, England)},
	author = {O'Neill, Kieran and Jalali, Adrin and Aghaeepour, Nima and Hoos, Holger and Brinkman, Ryan R},
	month = may,
	year = {2014},
	pmid = {24407226},
	note = {Publisher: Oxford University Press},
	pages = {1329--30},
}

@article{bankevich_joint_2018,
	title = {Joint {Analysis} of {Long} and {Short} {Reads} {Enables} {Accurate} {Estimates} of {Microbiome} {Complexity}},
	volume = {7},
	issn = {24054712},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2405471218302497},
	doi = {10.1016/j.cels.2018.06.009},
	number = {2},
	urldate = {2018-11-27},
	journal = {Cell Systems},
	author = {Bankevich, Anton and Pevzner, Pavel A.},
	month = aug,
	year = {2018},
	pages = {192--200.e3},
}

@article{horikoshi_elucidating_2018,
	title = {Elucidating the genetic architecture of reproductive ageing in the {Japanese} population},
	volume = {9},
	issn = {2041-1723},
	url = {http://www.nature.com/articles/s41467-018-04398-z},
	doi = {10.1038/s41467-018-04398-z},
	number = {1},
	urldate = {2018-11-27},
	journal = {Nature Communications},
	author = {Horikoshi, Momoko and Day, Felix R. and Akiyama, Masato and Hirata, Makoto and Kamatani, Yoichiro and Matsuda, Koichi and Ishigaki, Kazuyoshi and Kanai, Masahiro and Wright, Hollis and Toro, Carlos A. and Ojeda, Sergio R. and Lomniczi, Alejandro and Kubo, Michiaki and Ong, Ken K. and Perry, John. R. B.},
	month = dec,
	year = {2018},
	pages = {1977},
}

@article{torabi_moghadam_combinatorial_2016,
	title = {Combinatorial identification of {DNA} methylation patterns over age in the human brain},
	volume = {17},
	issn = {1471-2105},
	url = {http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-1259-3},
	doi = {10.1186/s12859-016-1259-3},
	abstract = {DNA methylation plays a key role in developmental processes, which is reflected in changing methylation patterns at specific CpG sites over the lifetime of an individual. The underlying mechanisms are complex and possibly affect multiple genes or entire pathways. We applied a multivariate approach to identify combinations of CpG sites that undergo modifications when transitioning between developmental stages. Monte Carlo feature selection produced a list of ranked and statistically significant CpG sites, while rule-based models allowed for identifying particular methylation changes in these sites. Our rule-based classifier reports combinations of CpG sites, together with changes in their methylation status in the form of easy-to-read IF-THEN rules, which allows for identification of the genes associated with the underlying sites. We utilized machine learning and statistical methods to discretize decision class (age) values to get a general pattern of methylation changes over the lifespan. The CpG sites present in the significant rules were annotated to genes involved in brain formation, general development, as well as genes linked to cancer and Alzheimer’s disease.},
	number = {1},
	urldate = {2018-11-27},
	journal = {BMC Bioinformatics},
	author = {Torabi Moghadam, Behrooz and Dabrowski, Michal and Kaminska, Bozena and Grabherr, Manfred G. and Komorowski, Jan},
	month = dec,
	year = {2016},
	note = {Publisher: BioMed Central},
	keywords = {Algorithms, Bioinformatics, Computational Biology/Bioinformatics, Computer Appl. in Life Sciences, Microarrays},
	pages = {393},
}

@article{weigert_content-aware_2018,
	title = {Content-aware image restoration: pushing the limits of fluorescence microscopy},
	issn = {1548-7091},
	url = {http://www.nature.com/articles/s41592-018-0216-7},
	doi = {10.1038/s41592-018-0216-7},
	abstract = {Fluorescence microscopy is a key driver of discoveries in the life sciences, with observable phenomena being limited by the optics of the microscope, the chemistry of the fluorophores, and the maximum photon exposure tolerated by the sample. These limits necessitate trade-offs between imaging speed, spatial resolution, light exposure, and imaging depth. In this work we show how content-aware image restoration based on deep learning extends the range of biological phenomena observable by microscopy. We demonstrate on eight concrete examples how microscopy images can be restored even if 60-fold fewer photons are used during acquisition, how near isotropic resolution can be achieved with up to tenfold under-sampling along the axial direction, and how tubular and granular structures smaller than the diffraction limit can be resolved at 20-times-higher frame rates compared to state-of-the-art methods. All developed image restoration methods are freely available as open source software in Python, FIJI, and KNIME.},
	urldate = {2018-11-27},
	journal = {Nature Methods},
	author = {Weigert, Martin and Schmidt, Uwe and Boothe, Tobias and Müller, Andreas and Dibrov, Alexandr and Jain, Akanksha and Wilhelm, Benjamin and Schmidt, Deborah and Broaddus, Coleman and Culley, Siân and Rocha-Martins, Mauricio and Segovia-Miranda, Fabián and Norden, Caren and Henriques, Ricardo and Zerial, Marino and Solimena, Michele and Rink, Jochen and Tomancak, Pavel and Royer, Loic and Jug, Florian and Myers, Eugene W.},
	month = nov,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Image processing, Machine learning, Microscopy, Software},
	pages = {1},
}

@article{qi_structural_2016,
	title = {Structural {Brain} {Network}: {What} is the {Effect} of {LiFE} {Optimization} of {Whole} {Brain} {Tractography}?},
	volume = {10},
	issn = {1662-5188},
	url = {http://journal.frontiersin.org/Article/10.3389/fncom.2016.00012/abstract},
	doi = {10.3389/fncom.2016.00012},
	abstract = {Structural brain networks constructed based on diffusion-weighted MRI (dMRI) have provided a systems perspective to explore the organization of the human brain. Some redundant and nonexistent fibers, however, are inevitably generated in whole brain tractography. We propose to add one critical step while constructing the networks to remove these fibers using the linear fascicle evaluation (LiFE) method, and study the differences between the networks with and without LiFE optimization. For a cohort of 9 healthy adults and for 9 out of the 35 subjects from Human Connectome Project, the T1-weighted images and dMRI data are analyzed. Each brain is parcellated into 90 regions-of-interest, whilst a probabilistic tractography algorithm is applied to generate the original connectome. The elimination of redundant and nonexistent fibers from the original connectome by LiFE creates the optimized connectome, and the random selection of the same number of fibers as the optimized connectome creates the non-optimized connectome. The combination of parcellations and these connectomes leads to the optimized and non-optimized networks, respectively. The optimized networks are constructed with six weighting schemes, and the correlations of different weighting methods are analyzed. The fiber length distributions of the non-optimized and optimized connectomes are compared. The optimized and non-optimized networks are compared with regard to edges, nodes and networks, within a sparsity range of 0.75-0.95. It has been found that relatively more short fibers exist in the optimized connectome. About 24.0\% edges of the optimized network are significantly different from those in the non-optimized network at a sparsity of 0.75. About 13.2\% of edges are classified as false positives or the possible missing edges. The strength and betweenness centrality of some nodes are significantly different for the non-optimized and optimized networks, but not the node efficiency. The normalized clustering coefficient, the normalized characteristic path length and the small-worldness are higher in the optimized network weighted by the fiber number than in the non-optimized network. These observed differences suggest that LiFE optimization can be a crucial step for the construction of more reasonable and more accurate structural brain networks.},
	urldate = {2018-11-26},
	journal = {Frontiers in Computational Neuroscience},
	author = {Qi, Shouliang and Meesters, Stephan and Nicolay, Klaas and ter Haar Romeny, Bart M. and Ossenblok, Pauly},
	month = feb,
	year = {2016},
	note = {Publisher: Frontiers},
	keywords = {brain network, connectome, diffusion-weighted MRI, structural connectivity, tractography},
	pages = {12},
}

@article{Ludwig2013,
	title = {Molecular {Composition} and {Ultrastructure} of the {Caveolar} {Coat} {Complex}},
	volume = {11},
	issn = {1545-7885},
	url = {https://dx.plos.org/10.1371/journal.pbio.1001640},
	doi = {10.1371/journal.pbio.1001640},
	abstract = {The single protein caveolar coat complex comprises only cavins and caveolins, coats the caveolar bulb, and is probably responsible for creating caveolae.},
	number = {8},
	urldate = {2018-11-26},
	journal = {PLoS Biology},
	author = {Ludwig, Alexander and Howard, Gillian and Mendoza-Topaz, Carolina and Deerinck, Thomas and Mackey, Mason and Sandin, Sara and Ellisman, Mark H. and Nichols, Benjamin J.},
	editor = {Hughson, Frederick},
	month = aug,
	year = {2013},
	note = {Publisher: Public Library of Science},
	pages = {e1001640},
}

@article{shvets_news_2014,
	title = {News from the caves: update on the structure and function of caveolae},
	volume = {29},
	issn = {0955-0674},
	url = {https://www.sciencedirect.com/science/article/pii/S0955067414000532},
	doi = {10.1016/J.CEB.2014.04.011},
	abstract = {Recent data from the study of the cell biology of caveolae have provided insights both into how these flask-shaped invaginations of the plasma membrane are formed and how they may function in different contexts. This review discusses experiments that analyse the composition and ultrastructural distribution of protein complexes responsible for generating caveolae, that suggest functions for caveolae in response to mechanical stress or damage to the plasma membrane, that show that caveolae may have an important role during the signalling events for regulation of metabolism, and that imply that caveolae can act as endocytic vesicles at the plasma membrane. We also highlight unexpected roles for caveolar proteins in regulating circadian rhythms and new insights into the way in which caveolae may be involved in fatty acid uptake in the intestine. Current outstanding questions in the field are emphasised.},
	urldate = {2018-11-26},
	journal = {Current Opinion in Cell Biology},
	author = {Shvets, Elena and Ludwig, Alexander and Nichols, Benjamin James},
	month = aug,
	year = {2014},
	note = {Publisher: Elsevier Current Trends},
	pages = {99--106},
}

@article{kovtun_cavin_2015,
	title = {Cavin family proteins and the assembly of caveolae.},
	volume = {128},
	issn = {1477-9137},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25829513},
	doi = {10.1242/jcs.167866},
	abstract = {Caveolae are an abundant feature of the plasma membrane in many cells. Until recently, they were generally considered to be membrane invaginations whose formation primarily driven by integral membrane proteins called caveolins. However, the past decade has seen the emergence of the cavin family of peripheral membrane proteins as essential coat components and regulators of caveola biogenesis. In this Commentary, we summarise recent data on the role of cavins in caveola formation, highlighting structural studies that provide new insights into cavin coat assembly. In mammals, there are four cavin family members that associate through homo- and hetero-oligomerisation to form distinct subcomplexes on caveolae, which can be released into the cell in response to stimuli. Studies from several labs have provided a better understanding of cavin stoichiometry and the molecular basis for their oligomerisation, as well as identifying interactions with membrane phospholipids that may be important for caveola function. We propose a model in which coincident, low-affinity electrostatically controlled protein-protein and protein-lipid interactions allow the formation of caveolae, generating a meta-stable structure that can respond to plasma membrane stress by release of cavins.},
	number = {7},
	urldate = {2018-11-26},
	journal = {Journal of cell science},
	author = {Kovtun, Oleksiy and Tillu, Vikas A and Ariotti, Nicholas and Parton, Robert G and Collins, Brett M},
	month = apr,
	year = {2015},
	pmid = {25829513},
	note = {Publisher: The Company of Biologists Ltd},
	keywords = {Caveolae, Caveolin, Cavin, Coiled coil, Electron microscopy, X-ray crystallography},
	pages = {1269--78},
}

@article{Schlenker2003,
	title = {Self-presentation.},
	url = {http://psycnet.apa.org/psycinfo/2003-02623-025},
	author = {Schlenker, Barry},
	year = {2003},
	pages = {1--42},
}

@techreport{maicas_training_nodate,
	title = {Training {Medical} {Image} {Analysis} {Systems} like {Radiologists}},
	abstract = {The training of medical image analysis systems using machine learning approaches follows a common script: collect and annotate a large dataset, train the classifier on the training set, and test it on a hold-out test set. This process bears no direct resemblance with radiolo-gist training, which is based on solving a series of tasks of increasing difficulty , where each task involves the use of significantly smaller datasets than those used in machine learning. In this paper, we propose a novel training approach inspired by how radiologists are trained. In particular, we explore the use of meta-training that models a classifier based on a series of tasks. Tasks are selected using teacher-student curriculum learning , where each task consists of simple classification problems containing small training sets. We hypothesize that our proposed meta-training approach can be used to pre-train medical image analysis models. This hypothesis is tested on the automatic breast screening classification from DCE-MRI trained with weakly labeled datasets. The classification performance achieved by our approach is shown to be the best in the field for that application, compared to state of art baseline approaches: DenseNet, multiple instance learning and multi-task learning.},
	urldate = {2018-11-25},
	author = {Maicas, Gabriel and Bradley, Andrew P and Nascimento, Jacinto C and Reid, Ian and Carneiro, Gustavo},
	note = {arXiv: 1805.10884v2},
	keywords = {breast image analysis, breast screening, curriculum learning, magnetic resonance imaging, meta-learning, multi-task training},
}

@techreport{brown_machine_2016,
	title = {Machine {Learning} on {Human} {Connectome} {Data} from {MRI}},
	url = {http://connectomelearning.cs.sfu.ca/},
	abstract = {Functional MRI (fMRI) and diffusion MRI (dMRI) are non-invasive imaging modalities that allow in-vivo analysis of a patient's brain network (known as a connectome). Use of these technologies has enabled faster and better diagnoses and treatments of neurological disorders and a deeper understanding of the human brain. Recently, researchers have been exploring the application of machine learning models to connectome data in order to predict clinical outcomes and analyze the importance of subnetworks in the brain. Connectome data has unique properties , which present both special challenges and opportunities when used for machine learning. The purpose of this work is to review the literature on the topic of applying machine learning models to MRI-based connectome data. This field is growing rapidly and now encompasses a large body of research. To summarize the research done to date, we provide a comparative, structured summary of 77 relevant works, tabulated according to different criteria, that represent the majority of the literature on this topic. (We also published a living version of this table online at http://connectomelearning.cs.sfu.ca/ that the community can continue to contribute to.) After giving an overview of how connectomes are constructed from dMRI and fMRI data, we discuss the variety of machine learning tasks that have been explored with connectome data. We then compare the advantages and drawbacks of different machine learning approaches that have been employed, discussing different feature selection and feature extraction schemes, as well as the learning models and regularization penalties themselves. Throughout this discussion , we focus particularly on how the methods are adapted to the unique nature of graphical connectome data. Finally, we conclude by summarizing the current state of the art and by outlining what we believe are strategic directions for future research.},
	urldate = {2018-11-23},
	author = {Brown, Colin J and Hamarneh, Ghassan},
	year = {2016},
	note = {arXiv: 1611.08699v1},
}

@techreport{zelnik-manor_self-tuning_nodate,
	title = {Self-{Tuning} {Spectral} {Clustering}},
	url = {http://www.vision.caltech.edu/lihi/Demos/SelfTuningClustering.html},
	abstract = {We study a number of open issues in spectral clustering: (i) Selecting the appropriate scale of analysis, (ii) Handling multi-scale data, (iii) Clustering with irregular background clutter, and, (iv) Finding automatically the number of groups. We first propose that a 'local' scale should be used to compute the affinity between each pair of points. This local scaling leads to better clustering especially when the data includes multiple scales and when the clusters are placed within a cluttered background. We further suggest exploiting the structure of the eigenvectors to infer automatically the number of groups. This leads to a new algorithm in which the final randomly initialized k-means stage is eliminated.},
	urldate = {2018-11-22},
	author = {Zelnik-Manor, Lihi and Perona, Pietro},
}

@article{Alom,
	title = {The {History} {Began} from {AlexNet}: {A} {Comprehensive} {Survey} on {Deep} {Learning} {Approaches}},
	issn = {00119164},
	doi = {10.1016/S0011-9164(00)80105-8},
	author = {Alom, Zahangir and Taha, Tarek M and Yakopcic, Chris and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Essen, Brian C Van and Awwal, Abdul A S and Asari, Vijayan K},
	note = {arXiv: 1803.01164},
}

@article{li_fast_2017,
	title = {Fast, robust and precise {3D} localization for arbitrary point spread functions},
	url = {https://www.biorxiv.org/content/early/2017/08/10/172643},
	doi = {10.1101/172643},
	abstract = {We present a fitter for 3D single-molecule localization of arbitrary, experimental point spread functions (PSFs) that reaches minimum uncertainty for EMCCD and sCMOS cameras, and achieves more than 105 fits/s. We provide tools to robustly model experimental PSFs and correct for depth induced aberrations, which allowed us to achieve an unprecedented 3D resolution with engineered astigmatic PSFs, and acquire high quality 3D superresolution images even on standard microscopes without 3D optics.},
	urldate = {2018-11-22},
	journal = {bioRxiv},
	author = {Li, Yiming and Mund, Markus and Hoess, Philipp and Matti, Ulf and Nijmeijer, Bianca and Sabinina, Vilma Jimenez and Ellenberg, Jan and Schoen, Ingmar and Ries, Jonas},
	month = aug,
	year = {2017},
	note = {Publisher: Cold Spring Harbor Laboratory},
	pages = {172643},
}

@article{joshi_phosphocaveolin-1_2012,
	title = {Phosphocaveolin-1 is a mechanotransducer that induces caveola biogenesis via {Egr1} transcriptional regulation.},
	volume = {199},
	issn = {1540-8140},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23091071},
	doi = {10.1083/jcb.201207089},
	abstract = {Caveolin-1 (Cav1) is an essential component of caveolae whose Src kinase-dependent phosphorylation on tyrosine 14 (Y14) is associated with regulation of focal adhesion dynamics. However, the relationship between these disparate functions remains to be elucidated. Caveola biogenesis requires expression of both Cav1 and cavin-1, but Cav1Y14 phosphorylation is dispensable. In this paper, we show that Cav1 tyrosine phosphorylation induces caveola biogenesis via actin-dependent mechanotransduction and inactivation of the Egr1 (early growth response-1) transcription factor, relieving inhibition of endogenous Cav1 and cavin-1 genes. Cav1 phosphorylation reduces Egr1 binding to Cav1 and cavin-1 promoters and stimulates their activity. In MDA-231 breast carcinoma cells that express elevated levels of Cav1 and caveolae, Egr1 regulated Cav1, and cavin-1 promoter activity was dependent on actin, Cav1, Src, and Rho-associated kinase as well as downstream protein kinase C (PKC) signaling. pCav1 is therefore a mechanotransducer that acts via PKC to relieve Egr1 transcriptional inhibition of Cav1 and cavin-1, defining a novel feedback regulatory loop to regulate caveola biogenesis.},
	number = {3},
	urldate = {2018-11-20},
	journal = {The Journal of cell biology},
	author = {Joshi, Bharat and Bastiani, Michele and Strugnell, Scott S and Boscher, Cecile and Parton, Robert G and Nabi, Ivan R},
	month = oct,
	year = {2012},
	pmid = {23091071},
	note = {Publisher: The Rockefeller University Press},
	pages = {425--35},
}

@article{margolis_fitness_2018,
	title = {Fitness {Landscape} of the {Immune} {Compromised} {Favors} the {Emergence} of {Antibiotic} {Resistance}},
	volume = {4},
	issn = {2373-8227},
	url = {http://pubs.acs.org/doi/10.1021/acsinfecdis.8b00158},
	doi = {10.1021/acsinfecdis.8b00158},
	abstract = {Antibiotic resistance can come at a high cost, both in terms of fitness for the pathogen and poorer outcomes for patients. The fitness landscape encountered by bacterial pathogens varies greatly throughout patient populations in terms of host immunity as well as the duration and spectrum of antibiotics encountered. Severely immunocompromised patients present a favorable environment for antibiotic resistance to emerge due to lack of immune-mediated competition and increased opportunities to evolve both on-target and compensatory mutations. Such patients may present unique pathways for antibiotic resistance to emerge.},
	number = {9},
	urldate = {2018-11-19},
	journal = {ACS Infectious Diseases},
	author = {Margolis, Elisa and Rosch, Jason W.},
	month = sep,
	year = {2018},
	note = {Publisher: American Chemical Society},
	pages = {1275--1277},
}

@article{bull_transmissible_2018,
	title = {Transmissible {Viral} {Vaccines}},
	volume = {26},
	issn = {0966-842X},
	url = {https://www.sciencedirect.com/science/article/pii/S0966842X17302123},
	doi = {10.1016/J.TIM.2017.09.007},
	abstract = {Genetic engineering now enables the design of live viral vaccines that are potentially transmissible. Some designs merely modify a single viral genome to improve on the age-old method of attenuation whereas other designs create chimeras of viral genomes. Transmission has the benefit of increasing herd immunity above that achieved by direct vaccination alone but also increases the opportunity for vaccine evolution, which typically undermines vaccine utility. Different designs have different epidemiological consequences but also experience different evolution. Approaches that integrate vaccine engineering with an understanding of evolution and epidemiology will reap the greatest benefit from vaccine transmission.},
	number = {1},
	urldate = {2018-11-19},
	journal = {Trends in Microbiology},
	author = {Bull, James J. and Smithson, Mark W. and Nuismer, Scott L.},
	month = jan,
	year = {2018},
	note = {Publisher: Elsevier Current Trends},
	pages = {6--15},
}

@article{levin_phagocytes_2017,
	title = {Phagocytes, {Antibiotics}, and {Self}-{Limiting} {Bacterial} {Infections}},
	volume = {25},
	issn = {0966-842X},
	url = {https://www.sciencedirect.com/science/article/pii/S0966842X17301750},
	doi = {10.1016/J.TIM.2017.07.005},
	abstract = {Most antibiotic use in humans is to reduce the magnitude and term of morbidity of acute, community-acquired infections in immune competent patients, rather than to save lives. Thanks to phagocytic leucocytes and other host defenses, the vast majority of these infections are self-limiting. Nevertheless, there has been a negligible amount of consideration of the contribution of phagocytosis and other host defenses in the research for, and the design of, antibiotic treatment regimens, which hyper-emphasizes antibiotics as if they were the sole mechanism responsible for the clearance of infections. Here, we critically review this approach and its limitations. With the aid of a heuristic mathematical model, we postulate that if the rate of phagocytosis is great enough, for acute, normally self-limiting infections, then (i) antibiotics with different pharmacodynamic properties would be similarly effective, (ii) low doses of antibiotics can be as effective as high doses, and (iii) neither phenotypic nor inherited antibiotic resistance generated during therapy are likely to lead to treatment failure.},
	number = {11},
	urldate = {2018-11-19},
	journal = {Trends in Microbiology},
	author = {Levin, Bruce R. and Baquero, Fernando and Ankomah, Peter (Pierre) and McCall, Ingrid C.},
	month = nov,
	year = {2017},
	note = {Publisher: Elsevier Current Trends},
	pages = {878--892},
}

@book{aguet_super-resolution_2009,
	title = {Super-{Resolution} {Fluorescence} {Microscopy} {Based} on {Physical} {Models}},
	abstract = {This thesis introduces a collection of physics-based methods for super-resolution in optical microscopy. The core of these methods constitute a framework for 3-D localization of single fluorescent molecules. Localization is formulated as a parameter estimation problem relying on a physically accurate model of the system's point spread function (PSF). In a similar approach, methods for fitting PSF models to experimental observations and for extended-depth-of-field imaging are proposed. Imaging of individual fluorophores within densely labeled samples has become possible with the discovery of dyes that can be photo-activated or switched between fluorescent and dark states. A fluorophore can be localized from its image with nanometer-scale accuracy, through fitting with an appropriate image function. This concept forms the basis of fluorescence localization microscopy (FLM) techniques such as photo-activated localization microscopy (PALM) and stochastic optical reconstruction microscopy (STORM), which rely on Gaussian fitting to perform the localization. Whereas the image generated by a single fluorophore corresponds to a section of the microscope's point spread function, only the in-focus section of the latter is well approximated by a Gaussian. Consequently, applications of FLM have for the most part been limited to 2-D imaging of thin specimen layers. In the first section of the thesis, it is shown that localization can be extended to 3-D without loss in accuracy by relying on a physically accurate image formation model in place of a Gaussian approximation. A key aspect of physically realistic models lies in their incorporation of aberrations that arise either as a consequence of mismatched refractive indices between the layers of the sample setup, or as an effect of experimental settings that deviate from the design conditions of the system. Under typical experimental conditions, these aberrations change as a function of sample depth, inducing axial shift-variance in the PSF. This property is exploited in a maximum-likelihood framework for 3-D localization of single fluorophores. Due to the shift-variance of the PSF, the axial position of a fluorophore is uniquely encoded in its diffraction pattern, and can be estimated from a single acquisition with nanometer-scale accuracy. Fluroescent molecules that remain fixed during image acquisition produce a diffraction pattern that is highly characteristic of the orientation of the fluorophore's underlying electromagnetic dipole. The localization is thus extended to incorporate the estimation of this 3-D orientation. It is shown that image formation for dipoles can be represented through a combination of six functions, based on which a 3-D steerable filter for orientation estimation and localization is derived. Experimental results demonstrate the feasibility of joint position and orientation estimation with accuracies of the order of one nanometer and one degree, respectively. Theoretical limits on localization accuracy for these methods are established in a statistical analysis based on Cramér-Rao bounds. A noise model for fluorescence microscopy based on a shifted Poisson distribution is proposed. In these localization methods, the aberration parameters of the PSF are assumed to be known. However, state-of-the-art PSF models depend on a large number of parameters that are generally difficult to determine experimentally with sufficient accuracy, which may limit their use in localization and deconvolution applications. A fitting algorithm analogous to localization is proposed; it is based on a simplified PSF model and shown to accurately reproduce the behavior of shift-variant experimental PSFs. Finally, it is shown that these algorithms can be adapted to more complex experiments, such as imaging of thick samples in brightfield microscopy. An extended-depth-of-field algorithm for the fusion of in-focus information from frames acquired at different focal positions is presented; it relies on a spline representation of the sample surface and as a result yields a continuous and super-resolved topography of the specimen.},
	author = {Aguet, François},
	year = {2009},
	note = {Publication Title: Outlook},
}

@article{babcock_analyzing_2017,
	title = {Analyzing {Single} {Molecule} {Localization} {Microscopy} {Data} {Using} {Cubic} {Splines}},
	volume = {7},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-017-00622-w},
	doi = {10.1038/s41598-017-00622-w},
	abstract = {The resolution of super-resolution microscopy based on single molecule localization is in part determined by the accuracy of the localization algorithm. In most published approaches to date this localization is done by fitting an analytical function that approximates the point spread function (PSF) of the microscope. However, particularly for localization in 3D, analytical functions such as a Gaussian, which are computationally inexpensive, may not accurately capture the PSF shape leading to reduced fitting accuracy. On the other hand, analytical functions that can accurately capture the PSF shape, such as those based on pupil functions, can be computationally expensive. Here we investigate the use of cubic splines as an alternative fitting approach. We demonstrate that cubic splines can capture the shape of any PSF with high accuracy and that they can be used for fitting the PSF with only a 2–3x increase in computation time as compared to Gaussian fitting. We provide an open-source software package that measures the PSF of any microscope and uses the measured PSF to perform 3D single molecule localization microscopy analysis with reasonable accuracy and speed.},
	number = {1},
	urldate = {2018-11-18},
	journal = {Scientific Reports},
	author = {Babcock, Hazen P. and Zhuang, Xiaowei},
	month = dec,
	year = {2017},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biological fluorescence, Computational biophysics},
	pages = {552},
}

@article{tafteh_real-time_2016,
	title = {Real-time {3D} stabilization of a super-resolution microscope using an electrically tunable lens},
	volume = {24},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/abstract.cfm?URI=oe-24-20-22959},
	doi = {10.1364/OE.24.022959},
	abstract = {Single-molecule localization microscopy (SMLM) has become an essential tool for examining a wide variety of biological structures and processes. However, the relatively long acquisition time makes SMLM prone to drift-induced artifacts. Here we report an optical design with an electrically tunable lens (ETL) that actively stabilizes a SMLM in three dimensions and nearly eliminates the mechanical drift (RMS {\textasciitilde}0.7 nm lateral and {\textasciitilde}2.7 nm axial). The bifocal design that employed fiducial markers on the coverslip was able to stabilize the sample regardless of the imaging depth. The effectiveness of the ETL was demonstrated by imaging endosomal transferrin receptors near the apical surface of B-lymphocytes at a depth of 8 \&\#x00B5;m. The drift-free images obtained with the stabilization system showed that the transferrin receptors were present in distinct but heterogeneous clusters with a bimodal size distribution. In contrast, the images obtained without the stabilization system showed a broader unimodal size distribution. Thus, this stabilization system enables a more accurate analysis of cluster topology. Additionally, this ETL-based stabilization system is cost-effective and can be integrated into existing microscopy systems.},
	number = {20},
	urldate = {2018-11-18},
	journal = {Optics Express},
	author = {Tafteh, Reza and Abraham, Libin and Seo, Denny and Lu, Henry Y. and Gold, Michael R. and Chou, Keng C.},
	month = oct,
	year = {2016},
	note = {Publisher: Optical Society of America},
	keywords = {Cylindrical lenses, Diffraction limit, Image processing, Laser beams, Optical design, Tunable lenses},
	pages = {22959},
}

@misc{noauthor_bioengineering_nodate,
	title = {Bioengineering {ZIKV}-like {Exosomes} in the {Treatment} of {Drug}- {Resistant} {Glioblastoma} {\textbar} jemi.microbiology.ubc.ca},
	url = {http://jemi.microbiology.ubc.ca/node/197},
	urldate = {2018-11-16},
}

@article{trapnell_tophat:_2009,
	title = {{TopHat}: discovering splice junctions with {RNA}-{Seq}},
	volume = {25},
	issn = {1460-2059},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btp120},
	doi = {10.1093/bioinformatics/btp120},
	number = {9},
	urldate = {2018-11-16},
	journal = {Bioinformatics},
	author = {Trapnell, Cole and Pachter, Lior and Salzberg, Steven L.},
	month = may,
	year = {2009},
	note = {Publisher: Oxford University Press},
	pages = {1105--1111},
}

@article{liu_computational_2013,
	title = {Computational methods for detecting copy number variations in cancer genome using next generation sequencing: principles and challenges.},
	volume = {4},
	issn = {1949-2553},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24240121},
	doi = {10.18632/oncotarget.1537},
	abstract = {Accurate detection of somatic copy number variations (CNVs) is an essential part of cancer genome analysis, and plays an important role in oncotarget identifications. Next generation sequencing (NGS) holds the promise to revolutionize somatic CNV detection. In this review, we provide an overview of current analytic tools used for CNV detection in NGS-based cancer studies. We summarize the NGS data types used for CNV detection, decipher the principles for data preprocessing, segmentation, and interpretation, and discuss the challenges in somatic CNV detection. This review aims to provide a guide to the analytic tools used in NGS-based cancer CNV studies, and to discuss the important factors that researchers need to consider when analyzing NGS data for somatic CNV detections.},
	number = {11},
	urldate = {2018-11-16},
	journal = {Oncotarget},
	author = {Liu, Biao and Morrison, Carl D and Johnson, Candace S and Trump, Donald L and Qin, Maochun and Conroy, Jeffrey C and Wang, Jianmin and Liu, Song},
	month = nov,
	year = {2013},
	pmid = {24240121},
	note = {Publisher: Impact Journals, LLC},
	pages = {1868--81},
}

@misc{noauthor_gene_nodate,
	title = {Gene {Finding} {Methods} {\textbar} {Broad} {Institute}},
	url = {https://www.broadinstitute.org/fungal-genome-initiative/gene-finding-methods},
	urldate = {2018-11-16},
}

@article{steel_parsimony_2000,
	title = {Parsimony, {Likelihood}, and the {Role} of {Models} in {Molecular} {Phylogenetics}},
	volume = {17},
	issn = {0737-4038},
	url = {http://academic.oup.com/mbe/article/17/6/839/1037773},
	doi = {10.1093/oxfordjournals.molbev.a026364},
	number = {6},
	urldate = {2018-11-16},
	journal = {Molecular Biology and Evolution},
	author = {Steel, Mike and Penny, David},
	month = jun,
	year = {2000},
	note = {Publisher: Oxford University Press},
	pages = {839--850},
}

@article{volz_viral_2013,
	title = {Viral {Phylodynamics}},
	volume = {9},
	issn = {1553-7358},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23555203},
	doi = {10.1371/journal.pcbi.1002947},
	abstract = {Viral phylodynamics is defined as the study of how epidemiological, immunological, and evolutionary processes act and potentially interact to shape viralphylogenies. Since the coining of the term in 2004, research on viral phylodynamics has focused on transmission dynamics in an effort to shed light on how these dynamics impact viral genetic variation. Transmission dynamics can be considered at the level of cells within an infected host, individual hosts within a population, or entire populations of hosts. Many viruses, especially RNA viruses, rapidly accumulate genetic variation because of short generation times and high mutation rates. Patterns of viral genetic variation are therefore heavily influenced by how quickly transmission occurs and by which entities transmit to one another. Patterns of viral genetic variation will also be affected by selection acting on viral phenotypes. Although viruses can differ with respect to many phenotypes, phylodynamic studies have to date tended to focus on a limited number of viral phenotypes. These include virulence phenotypes, phenotypes associated with viral transmissibility, cell or tissue tropism phenotypes, and antigenic phenotypes that can facilitate escape from host immunity. Due to the impact that transmission dynamics and selection can have on viral genetic variation, viral phylogenies can therefore be used to investigate important epidemiological, immunological, and evolutionary processes, such as epidemic spread[2], spatio-temporal dynamics including metapopulation dynamics[3], zoonotic transmission, tissue tropism[4], and antigenic drift[5]. The quantitative investigation of these processes through the consideration of viral phylogenies is the central aim of viral phylodynamics.},
	number = {3},
	urldate = {2018-11-16},
	journal = {PLoS Computational Biology},
	author = {Volz, Erik M. and Koelle, Katia and Bedford, Trevor},
	editor = {Wodak, Shoshana},
	month = mar,
	year = {2013},
	pmid = {23555203},
	pages = {e1002947},
}

@article{knight_best_2018,
	title = {Best practices for analysing microbiomes},
	volume = {16},
	issn = {1740-1526},
	url = {http://www.nature.com/articles/s41579-018-0029-9},
	doi = {10.1038/s41579-018-0029-9},
	abstract = {Complex microbial communities shape the dynamics of various environments, ranging from the mammalian gastrointestinal tract to the soil. Advances in DNA sequencing technologies and data analysis have provided drastic improvements in microbiome analyses, for example, in taxonomic resolution, false discovery rate control and other properties, over earlier methods. In this Review, we discuss the best practices for performing a microbiome study, including experimental design, choice of molecular analysis technology, methods for data analysis and the integration of multiple omics data sets. We focus on recent findings that suggest that operational taxonomic unit-based analyses should be replaced with new methods that are based on exact sequence variants, methods for integrating metagenomic and metabolomic data, and issues surrounding compositional data analysis, where advances have been particularly rapid. We note that although some of these approaches are new, it is important to keep sight of the classic issues that arise during experimental design and relate to research reproducibility. We describe how keeping these issues in mind allows researchers to obtain more insight from their microbiome data sets.},
	number = {7},
	urldate = {2018-11-16},
	journal = {Nature Reviews Microbiology},
	author = {Knight, Rob and Vrbanac, Alison and Taylor, Bryn C. and Aksenov, Alexander and Callewaert, Chris and Debelius, Justine and Gonzalez, Antonio and Kosciolek, Tomasz and McCall, Laura-Isobel and McDonald, Daniel and Melnik, Alexey V. and Morton, James T. and Navas, Jose and Quinn, Robert A. and Sanders, Jon G. and Swafford, Austin D. and Thompson, Luke R. and Tripathi, Anupriya and Xu, Zhenjiang Z. and Zaneveld, Jesse R. and Zhu, Qiyun and Caporaso, J. Gregory and Dorrestein, Pieter C.},
	month = jul,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Bioinformatics, Gene expression analysis, Genomic analysis, Metabolomics, Metagenomics, Microbial ecology, Microbiome, Sequencing},
	pages = {410--422},
}

@article{mandal_analysis_2015,
	title = {Analysis of composition of microbiomes: a novel method for studying microbial composition},
	volume = {26},
	issn = {1651-2235},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26028277},
	doi = {10.3402/mehd.v26.27663},
	abstract = {BACKGROUND Understanding the factors regulating our microbiota is important but requires appropriate statistical methodology. When comparing two or more populations most existing approaches either discount the underlying compositional structure in the microbiome data or use probability models such as the multinomial and Dirichlet-multinomial distributions, which may impose a correlation structure not suitable for microbiome data. OBJECTIVE To develop a methodology that accounts for compositional constraints to reduce false discoveries in detecting differentially abundant taxa at an ecosystem level, while maintaining high statistical power. METHODS We introduced a novel statistical framework called analysis of composition of microbiomes (ANCOM). ANCOM accounts for the underlying structure in the data and can be used for comparing the composition of microbiomes in two or more populations. ANCOM makes no distributional assumptions and can be implemented in a linear model framework to adjust for covariates as well as model longitudinal data. ANCOM also scales well to compare samples involving thousands of taxa. RESULTS We compared the performance of ANCOM to the standard t-test and a recently published methodology called Zero Inflated Gaussian (ZIG) methodology (1) for drawing inferences on the mean taxa abundance in two or more populations. ANCOM controlled the false discovery rate (FDR) at the desired nominal level while also improving power, whereas the t-test and ZIG had inflated FDRs, in some instances as high as 68\% for the t-test and 60\% for ZIG. We illustrate the performance of ANCOM using two publicly available microbial datasets in the human gut, demonstrating its general applicability to testing hypotheses about compositional differences in microbial communities. CONCLUSION Accounting for compositionality using log-ratio analysis results in significantly improved inference in microbiota survey data.},
	number = {0},
	urldate = {2018-11-16},
	journal = {Microbial Ecology in Health \& Disease},
	author = {Mandal, Siddhartha and Van Treuren, Will and White, Richard A. and Eggesbø, Merete and Knight, Rob and Peddada, Shyamal D.},
	month = may,
	year = {2015},
	pmid = {26028277},
	keywords = {constrained, log-ratio, relative abundance},
	pages = {27663},
}

@article{lupski_structural_2015,
	title = {Structural variation mutagenesis of the human genome: {Impact} on disease and evolution},
	volume = {56},
	issn = {08936692},
	url = {http://doi.wiley.com/10.1002/em.21943},
	doi = {10.1002/em.21943},
	number = {5},
	urldate = {2018-11-16},
	journal = {Environmental and Molecular Mutagenesis},
	author = {Lupski, James R.},
	month = jun,
	year = {2015},
	pages = {419--436},
}

@article{weischenfeldt_phenotypic_2013,
	title = {Phenotypic impact of genomic structural variation: insights from and for human disease},
	volume = {14},
	issn = {1471-0056},
	url = {http://www.nature.com/articles/nrg3373},
	doi = {10.1038/nrg3373},
	number = {2},
	urldate = {2018-11-16},
	journal = {Nature Reviews Genetics},
	author = {Weischenfeldt, Joachim and Symmons, Orsolya and Spitz, François and Korbel, Jan O.},
	month = feb,
	year = {2013},
	pages = {125--138},
}

@article{dellicour_phylodynamic_2018,
	title = {Phylodynamic assessment of intervention strategies for the {West} {African} {Ebola} virus outbreak},
	volume = {9},
	issn = {2041-1723},
	url = {http://www.nature.com/articles/s41467-018-03763-2},
	doi = {10.1038/s41467-018-03763-2},
	abstract = {Genetic analyses have provided important insights into Ebola virus spread during the recent West African outbreak, but their implications for specific intervention scenarios remain unclear. Here, we address this issue using a collection of phylodynamic approaches. We show that long-distance dispersal events were not crucial for epidemic expansion and that preventing viral lineage movement to any given administrative area would, in most cases, have had little impact. However, major urban areas were critical in attracting and disseminating the virus: preventing viral lineage movement to all three capitals simultaneously would have contained epidemic size to one-third. We also show that announcements of border closures were followed by a significant but transient effect on international virus dispersal. By quantifying the hypothetical impact of different intervention strategies, as well as the impact of barriers on dispersal frequency, our study illustrates how phylodynamic analyses can help to address specific epidemiological and outbreak control questions.},
	number = {1},
	urldate = {2018-11-16},
	journal = {Nature Communications},
	author = {Dellicour, Simon and Baele, Guy and Dudas, Gytis and Faria, Nuno R. and Pybus, Oliver G. and Suchard, Marc A. and Rambaut, Andrew and Lemey, Philippe},
	month = dec,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Bayesian inference, Ebola virus, Epidemiology, Phylogeny},
	pages = {2222},
}

@article{zhou_research_2018,
	title = {The research on gene-disease association based on text-mining of {PubMed}},
	volume = {19},
	issn = {1471-2105},
	url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2048-y},
	doi = {10.1186/s12859-018-2048-y},
	abstract = {The associations between genes and diseases are of critical significance in aspects of prevention, diagnosis and treatment. Although gene-disease relationships have been investigated extensively, much of the underpinnings of these associations are yet to be elucidated. A novel method integrates MeSH database, term weight (TW), and co-occurrence methods to predict gene-disease associations based on the cosine similarity between gene vectors and disease vectors. Vectors are transformed from the texts of documents in the PubMed database according to the appearance and location of the gene or disease terms. The disease related text data has been optimized during the process of constructing vectors. The overall distribution of cosine similarity value was investigated. By using the gene-disease association data in OMIM database as golden standard, the performance of cosine similarity in predicting gene-disease linkage was evaluated. The effects of applying weight matrix, penalty weights for keywords (PWK), and normalization were also investigated. Finally, we demonstrated that our method outperforms heterogeneous network edge prediction (HNEP) in aspects of precision rate and recall rate. Our method proposed in this paper is easy to be conducted and the results can be integrated with other models to improve the overall performance of gene-disease association predictions.},
	number = {1},
	urldate = {2018-11-16},
	journal = {BMC Bioinformatics},
	author = {Zhou, Jie and Fu, Bo-quan},
	month = dec,
	year = {2018},
	note = {Publisher: BioMed Central},
	keywords = {Algorithms, Bioinformatics, Computational Biology/Bioinformatics, Computer Appl. in Life Sciences, Microarrays},
	pages = {37},
}

@article{cheng_introduction_2018,
	title = {An {Introduction} to {Integrative} {Genomics} and {Systems} {Medicine} in {Cancer}.},
	volume = {9},
	issn = {2073-4425},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/29329216},
	doi = {10.3390/genes9010037},
	abstract = {In this Special Issue (SI), with a theme of "Integrative Genomics and Systems Medicine in Cancer", we have collected a total of 12 research and review articles from researchers in the field of genomics and systems medicine[...].},
	number = {1},
	urldate = {2018-11-16},
	journal = {Genes},
	author = {Cheng, Xiaolong and Jin, Victor X},
	month = jan,
	year = {2018},
	pmid = {29329216},
	note = {Publisher: Multidisciplinary Digital Publishing Institute  (MDPI)},
}

@incollection{hamon_knowledge_2015,
	address = {Berlin, Heidelberg},
	title = {Knowledge {Discovery} in {Bioinformatics}},
	url = {http://link.springer.com/10.1007/978-3-662-43505-2_61},
	urldate = {2018-11-16},
	booktitle = {Springer {Handbook} of {Computational} {Intelligence}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hamon, Julie and Jacques, Julie and Jourdan, Laetitia and Dhaenens, Clarisse},
	year = {2015},
	doi = {10.1007/978-3-662-43505-2_61},
	pages = {1211--1223},
}

@article{ziehm_drug_2017,
	title = {Drug repurposing for aging research using model organisms},
	volume = {16},
	issn = {14749718},
	url = {http://doi.wiley.com/10.1111/acel.12626},
	doi = {10.1111/acel.12626},
	number = {5},
	urldate = {2018-11-16},
	journal = {Aging Cell},
	author = {Ziehm, Matthias and Kaur, Satwant and Ivanov, Dobril K. and Ballester, Pedro J. and Marcus, David and Partridge, Linda and Thornton, Janet M.},
	month = oct,
	year = {2017},
	note = {Publisher: Wiley/Blackwell (10.1111)},
	keywords = {C. elegans, Drosophila, aging, computational predictions, drug repurposing, lifespan},
	pages = {1006--1015},
}

@article{rubin_comparative_2016,
	title = {Comparative genomics reveals convergent rates of evolution in ant–plant mutualisms},
	volume = {7},
	issn = {2041-1723},
	url = {http://www.nature.com/doifinder/10.1038/ncomms12679},
	doi = {10.1038/ncomms12679},
	abstract = {Mutualisms in which ants protect plants in exchange for food and shelter have arisen independently multiple times. Here, Rubin and Moreau sequence the genomes of three mutualistic ant species and four of their non-mutualistic relatives and show that the transition to mutualism is associated with elevated evolutionary rates across the genome},
	urldate = {2018-11-16},
	journal = {Nature Communications},
	author = {Rubin, Benjamin E. R. and Moreau, Corrie S.},
	month = aug,
	year = {2016},
	note = {Publisher: Nature Publishing Group},
	keywords = {Comparative genomics, Evolutionary ecology, Evolutionary genetics, Molecular evolution},
	pages = {12679},
}

@article{hughes_principles_2011,
	title = {Principles of early drug discovery.},
	volume = {162},
	issn = {1476-5381},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21091654},
	doi = {10.1111/j.1476-5381.2010.01127.x},
	abstract = {Developing a new drug from original idea to the launch of a finished product is a complex process which can take 12-15 years and cost in excess of \$1 billion. The idea for a target can come from a variety of sources including academic and clinical research and from the commercial sector. It may take many years to build up a body of supporting evidence before selecting a target for a costly drug discovery programme. Once a target has been chosen, the pharmaceutical industry and more recently some academic centres have streamlined a number of early processes to identify molecules which possess suitable characteristics to make acceptable drugs. This review will look at key preclinical stages of the drug discovery process, from initial target identification and validation, through assay development, high throughput screening, hit identification, lead optimization and finally the selection of a candidate molecule for clinical development.},
	number = {6},
	urldate = {2018-11-16},
	journal = {British journal of pharmacology},
	author = {Hughes, J P and Rees, S and Kalindjian, S B and Philpott, K L},
	month = mar,
	year = {2011},
	pmid = {21091654},
	note = {Publisher: Wiley-Blackwell},
	pages = {1239--49},
}

@article{muda_model_2004,
	title = {Model organisms and target discovery},
	volume = {1},
	issn = {1740-6749},
	url = {https://www.sciencedirect.com/science/article/pii/S1740674904000113},
	doi = {10.1016/J.DDTEC.2004.08.001},
	abstract = {The wealth of information harvested from full genomic sequencing projects has not generated a parallel increase in the number of novel targets for therapeutic intervention. Several pharmaceutical companies have realized that novel drug targets can be identified and validated using simple model organisms. After decades of service in basic research laboratories, yeasts, worms, flies, fishes, and mice are now the cornerstones of modern drug discovery programs.},
	number = {1},
	urldate = {2018-11-16},
	journal = {Drug Discovery Today: Technologies},
	author = {Muda, Marco and McKenna, Sean},
	month = sep,
	year = {2004},
	note = {Publisher: Elsevier},
	pages = {55--59},
}

@article{wicklund_clinical_2018,
	title = {Clinical genetic counselors: {An} asset in the era of precision medicine},
	volume = {178},
	issn = {15524868},
	url = {http://doi.wiley.com/10.1002/ajmg.c.31605},
	doi = {10.1002/ajmg.c.31605},
	number = {1},
	urldate = {2018-11-16},
	journal = {American Journal of Medical Genetics Part C: Seminars in Medical Genetics},
	author = {Wicklund, Catherine A. L. and Duquette, Debra A. and Swanson, Amy L.},
	month = mar,
	year = {2018},
	note = {Publisher: Wiley-Blackwell},
	pages = {63--67},
}

@article{fountzilas_overview_2018,
	title = {Overview of precision oncology trials: challenges and opportunities},
	volume = {11},
	issn = {1751-2433},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/30044653},
	doi = {10.1080/17512433.2018.1504677},
	abstract = {INTRODUCTION In recent years, the therapeutic management of selected patients with cancer has shifted toward the 'precision medicine' approach based on patient's mechanisms of tumorigenesis, and their baseline characteristics and comorbidities. Complete tumor and cell-free DNA profiling using next-generation sequencing, proteomic and RNA analysis, and immune mechanisms should to be taken into consideration and accurate bioinformatic analysis is essential to optimize patient's treatment. Areas covered: The challenges and opportunities of conducting clinical trials in precision oncology are summarized. Expert commentary: Precision medicine has significantly changed the diagnostic and therapeutic landscape of cancer. Successful implementation of precision medicine requires translational and bioinformatics infrastructure to support optimization of treatment selection. Targeted therapy, immunotherapy, T-cell therapy alone or in combination with cytotoxic or other effective therapeutic strategies and innovative clinical trials with adaptive design should be offered to all patients. Data sharing and 'N-of-1' models hold the promise to optimize the treatment of individual patients and expedite drug approval for rare alterations and tumor types. Artificial intelligence will facilitate accurate utilization of sequencing data to perform algorithm analysis. Collaboration of healthcare providers with pharmaceutical and biotechnical companies, scientific organizations, and governmental regulatory agencies have a crucial role in curing cancer.},
	number = {8},
	urldate = {2018-11-16},
	journal = {Expert Review of Clinical Pharmacology},
	author = {Fountzilas, Elena and Tsimberidou, Apostolia M.},
	month = aug,
	year = {2018},
	pmid = {30044653},
	keywords = {N-of-1, ctDNA, immunotherapy, molecular, mutation, personalized, precision, targeted, trial},
	pages = {797--804},
}

@article{gatenby_evolution_2018,
	title = {The {Evolution} and {Ecology} of {Resistance} in {Cancer} {Therapy}},
	volume = {8},
	issn = {2157-1422},
	url = {http://perspectivesinmedicine.cshlp.org/lookup/doi/10.1101/cshperspect.a033415},
	doi = {10.1101/cshperspect.a033415},
	number = {3},
	urldate = {2018-11-16},
	journal = {Cold Spring Harbor Perspectives in Medicine},
	author = {Gatenby, Robert and Brown, Joel},
	month = mar,
	year = {2018},
	pages = {a033415},
}

@article{gatenby_adaptive_2009,
	title = {Adaptive {Therapy}},
	volume = {69},
	issn = {0008-5472},
	url = {http://cancerres.aacrjournals.org/cgi/doi/10.1158/0008-5472.CAN-08-3658},
	doi = {10.1158/0008-5472.CAN-08-3658},
	number = {11},
	urldate = {2018-11-16},
	journal = {Cancer Research},
	author = {Gatenby, R. A. and Silva, A. S. and Gillies, R. J. and Frieden, B. R.},
	month = jun,
	year = {2009},
	pages = {4894--4903},
}

@article{laskin_lessons_2015,
	title = {Lessons learned from the application of whole-genome analysis to the treatment of patients with advanced cancers},
	volume = {1},
	issn = {2373-2865},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27148575},
	doi = {10.1101/mcs.a000570},
	abstract = {Given the success of targeted agents in specific populations it is expected that some degree of molecular biomarker testing will become standard of care for many, if not all, cancers. To facilitate this, cancer centers worldwide are experimenting with targeted "panel" sequencing of selected mutations. Recent advances in genomic technology enable the generation of genome-scale data sets for individual patients. Recognizing the risk, inherent in panel sequencing, of failing to detect meaningful somatic alterations, we sought to establish processes to integrate data from whole-genome analysis (WGA) into routine cancer care. Between June 2012 and August 2014, 100 adult patients with incurable cancers consented to participate in the Personalized OncoGenomics (POG) study. Fresh tumor and blood samples were obtained and used for whole-genome and RNA sequencing. Computational approaches were used to identify candidate driver mutations, genes, and pathways. Diagnostic and drug information were then sought based on these candidate "drivers." Reports were generated and discussed weekly in a multidisciplinary team setting. Other multidisciplinary working groups were assembled to establish guidelines on the interpretation, communication, and integration of individual genomic findings into patient care. Of 78 patients for whom WGA was possible, results were considered actionable in 55 cases. In 23 of these 55 cases, the patients received treatments motivated by WGA. Our experience indicates that a multidisciplinary team of clinicians and scientists can implement a paradigm in which WGA is integrated into the care of late stage cancer patients to inform systemic therapy decisions.},
	number = {1},
	urldate = {2018-11-16},
	journal = {Molecular Case Studies},
	author = {Laskin, Janessa and Jones, Steven and Aparicio, Samuel and Chia, Stephen and Ch'ng, Carolyn and Deyell, Rebecca and Eirew, Peter and Fok, Alexandra and Gelmon, Karen and Ho, Cheryl and Huntsman, David and Jones, Martin and Kasaian, Katayoon and Karsan, Aly and Leelakumari, Sreeja and Li, Yvonne and Lim, Howard and Ma, Yussanne and Mar, Colin and Martin, Monty and Moore, Richard and Mungall, Andrew and Mungall, Karen and Pleasance, Erin and Rassekh, S. Rod and Renouf, Daniel and Shen, Yaoqing and Schein, Jacqueline and Schrader, Kasmintan and Sun, Sophie and Tinker, Anna and Zhao, Eric and Yip, Stephen and Marra, Marco A.},
	month = oct,
	year = {2015},
	pmid = {27148575},
	pages = {a000570},
}

@article{V.A.PATEL2009,
	title = {Performance {Evaluation} of {Treated} – {Untreated} {Jute} – {Carbon} and {Glass} – {Carbon} {Hybrid} {Composites} of {Bisphenol}-{C} based {Mixed} {Epoxy} – {Phenolic} {Resins}},
	volume = {28},
	doi = {10.1177/0731684408093973},
	abstract = {Results from physical mapping projects have recently been reported for the genomes of Escherichia coli, Saccharomyces cerevisiae, and Caenorhabditis elegans, and similar projects are currently being planned for other organisms. In such projects, the physical map is assembled by first "fingerprinting" a large number of clones chosen at random from a recombinant library and then inferring overlaps between clones with sufficiently similar fingerprints. Although the basic approach is the same, there are many possible choices for the fingerprint used to characterize the clones and the rules for declaring overlap. In this paper, we derive simple formulas showing how the progress of a physical mapping project is affected by the nature of the fingerprinting scheme. Using these formulas, we discuss the analytic considerations involved in selecting an appropriate fingerprinting scheme for a particular project.},
	number = {20},
	journal = {Water},
	author = {V. A. PATEL, B.D.BHUVA},
	year = {2009},
	keywords = {diffusivity, hybrid composites, mechanical and electrical properties, water uptake},
	pages = {2549--2556},
}

@article{Badal2018,
	title = {Natural language processing in text mining for structural modeling of protein complexes},
	volume = {19},
	issn = {14712105},
	doi = {10.1186/s12859-018-2079-4},
	abstract = {Structural modeling of protein-protein interactions produces a large number of putative configurations of the protein complexes. Identification of the near-native models among them is a serious challenge. Publicly available results of biomedical research may provide constraints on the binding mode, which can be essential for the docking. Our text-mining (TM) tool, which extracts binding site residues from the PubMed abstracts, was successfully applied to protein docking (Badal et al., PLoS Comput Biol, 2015; 11: e1004630). Still, many extracted residues were not relevant to the docking. We present an extension of the TM tool, which utilizes natural language processing (NLP) for analyzing the context of the residue occurrence. The procedure was tested using generic and specialized dictionaries. The results showed that the keyword dictionaries designed for identification of protein interactions are not adequate for the TM prediction of the binding mode. However, our dictionary designed to distinguish keywords relevant to the protein binding sites led to considerable improvement in the TM performance. We investigated the utility of several methods of context analysis, based on dissection of the sentence parse trees. The machine learning-based NLP filtered the pool of the mined residues significantly more efficiently than the rule-based NLP. Constraints generated by NLP were tested in docking of unbound proteins from the DOCKGROUND X-ray benchmark set 4. The output of the global low-resolution docking scan was post-processed, separately, by constraints from the basic TM, constraints re-ranked by NLP, and the reference constraints. The quality of a match was assessed by the interface root-mean-square deviation. The results showed significant improvement of the docking output when using the constraints generated by the advanced TM with NLP. The basic TM procedure for extracting protein-protein binding site residues from the PubMed abstracts was significantly advanced by the deep parsing (NLP techniques for contextual analysis) in purging of the initial pool of the extracted residues. Benchmarking showed a substantial increase of the docking success rate based on the constraints generated by the advanced TM with NLP.},
	number = {1},
	journal = {BMC Bioinformatics},
	author = {Badal, Varsha D. and Kundrotas, Petras J. and Vakser, Ilya A.},
	year = {2018},
	note = {Publisher: BMC Bioinformatics},
	keywords = {Binding site prediction, Dependency parser, Protein docking, Protein interactions, Rule-based system, Supervised learning},
	pages = {1--10},
}

@article{Urtasun2017a,
	title = {Annotating {Object} {Instances} with a {Polygon}- {Annotating} {Object} {Instances} with a {Polygon}-{RNN}},
	number = {June},
	author = {Urtasun, Raquel and Urtasun, Raquel},
	year = {2017},
	note = {arXiv: 1704.05548v1},
	pages = {22},
}

@phdthesis{de_zitter_correlating_nodate,
	title = {Correlating spectroscopic properties of fluorescent proteins ({FPs}) to their crystal structure: towards the rational design of {FPs} for superresolution microscopy - {KU} {Leuven}},
	url = {https://limo.libis.be/primo-explore/fulldisplay?docid=LIRIAS2123542&context=L&vid=Lirias&search_scope=Lirias&tab=default_tab&lang=en_US&fromSitemap=1},
	abstract = {Superresolution microscopy consists of several techniques, which are often used for the visualization of subcellular systems. Because most of these techniques are based on the specific dynamic behavior of the dynamic fluorescent label, they all have their own advantages and disadvantages and the obtained results will therefore be different. Therefore, the combination of different techniques (multimodal superresolution microscopy) would allow researchers to increase the information content of their experiments and allow them to validate their superresolution results. A good example is the combination of “PhotoActivated Localization Microscopy” (PALM) and “Photochromic Stochastic fluctuation imaging” (pcSOFI). However, multimodal suerresolution microscopy demands for specific dynamic fluorescent proteins and introducing the desired dynamic characteristics into fluorescent proteins using random mutagenesis and directed evolution is a costly and time-consuming process. For a more efficient rational design of these dynamic fluorescent proteins, more knowledge about them is necessary. Therefore, the relationship between molecular structureand function of dynamic fluorescent proteins will be investigated. During this project, different cycles of mutagenesis, characterization, crystallization, structure determination and statistical analysis will be performed. Finally, we will be able to design dynamic fluorescent proteinssuitable for multimodal microscopy.},
	urldate = {2018-11-15},
	author = {De Zitter, E},
}

@article{brechun_selection_2018,
	title = {Selection of {Protein}–{Protein} {Interactions} of {Desired} {Affinities} with a {Bandpass} {Circuit}},
	issn = {0022-2836},
	url = {https://www.sciencedirect.com/science/article/pii/S0022283618311227?dgcid=raven_sd_aip_email},
	doi = {10.1016/J.JMB.2018.11.011},
	abstract = {We have developed a genetic circuit in Escherichia coli that can be used to select for protein–protein interactions of different strengths by changing antibiotic concentrations in the media. The genetic circuit links protein–protein interaction strength to β-lactamase activity, while simultaneously imposing tuneable positive and negative selection pressure for β-lactamase activity. Cells only survive if they express interacting proteins with affinities that fall within set high- and low-pass thresholds, i.e. the circuit acts as a bandpass filter for protein–protein interactions. We show that the circuit can be used to recover protein–protein interactions of desired affinity from a mixed population with a range of affinities. The circuit can also be used to select for inhibitors of protein–protein interactions of defined strength.},
	urldate = {2018-11-15},
	journal = {Journal of Molecular Biology},
	author = {Brechun, Katherine E. and Arndt, Katja M. and Andrew Woolley, G.},
	month = nov,
	year = {2018},
	note = {Publisher: Academic Press},
}

@article{Rees2012,
	title = {Blind assessment of localisation microscope image resolution},
	volume = {1},
	issn = {21922853},
	doi = {10.1186/2192-2853-1-12},
	abstract = {BACKGROUND:This paper analyses the resolution achieved in localisation microscopy experiments. The resolution is an essential metric for the correct interpretation of super-resolution images, but it varies between specimens due to different localisation precisions and densities.METHODS:By analysing localisation microscopy as a statistical method of Density Estimation, we present a method that produces a blind estimate of the resolution in a super-resolved image. This estimate is derived directly from the raw image data without the need for comparisons with known calibration specimens. It is corroborated with simulated and experimental data.RESULTS AND DISCUSSION:Localisation microscopy has a resolution limit equal to 2sigma, where sigma is the r.m.s. localisation precision, evaluated as an average Thompson precision, Cramer Rao bound, or otherwise. Further, for a limited-sampling case in which there is only one localisation per fluorophore, the expected resolution of an optimised super-resolution image is worsened to approximately 3sigma, due to smoothing processes that are necessarily involved in visualising the specimen with limited data. This 2sigma or 3sigma resolution can be estimated for any localisation microscopy specimen, and this metric can corroborate or replace empirical estimates of resolution. Other quantifiable resolution losses arise from sparse labelling, fluorescent label size, and motion blur.},
	number = {1},
	journal = {Optical Nanoscopy},
	author = {Rees, Eric J. and Erdelyi, Miklos and Pinotsi, Dorothea and Knight, Alex and Metcalf, Daniel and Kaminski, Clemens F.},
	year = {2012},
	note = {ISBN: 2192-2853},
	keywords = {Density estimation, Localisation microscopy, Resolution, Super-resolution},
	pages = {1--10},
}

@article{adli_biology_2018,
	title = {The {Biology} and {Application} {Areas} of {CRISPR} {Technologies}},
	issn = {0022-2836},
	url = {https://www.sciencedirect.com/science/article/pii/S0022283618312373?dgcid=raven_sd_aip_email},
	doi = {10.1016/J.JMB.2018.11.012},
	urldate = {2018-11-14},
	journal = {Journal of Molecular Biology},
	author = {Adli, Mazhar},
	month = nov,
	year = {2018},
	note = {Publisher: Academic Press},
}

@article{west_capitalizing_2018,
	title = {Capitalizing on competition: {An} evolutionary model of competitive release in metastatic castration resistant prostate cancer treatment},
	issn = {10958541},
	doi = {10.1016/j.jtbi.2018.07.028},
	abstract = {The development of chemotherapeutic resistance resulting in tumor relapse is largely the consequence of the mechanism of competitive release of pre-existing resistant tumor cells selected for regrowth after chemotherapeutic agents attack the previously dominant chemo-sensitive population. We introduce a prisoner's dilemma game theoretic mathematical model based on the replicator of three competing cell populations: healthy (cooperators), sensitive (defectors), and resistant (defectors) cells. The model is shown to recapitulate prostate-specific antigen measurement data from three clinical trials for metastatic castration-resistant prostate cancer patients treated with 1) prednisone, 2) mitoxantrone and prednisone and 3) docetaxel and prednisone. Continuous maximum tolerated dose schedules reduce the sensitive cell population, initially shrinking tumor burden, but subsequently “release” the resistant cells from competition to re-populate and re-grow the tumor in a resistant form. The evolutionary model allows us to quantify responses to conventional (continuous) therapeutic strategies as well as to design adaptive strategies.These novel adaptive strategies are robust to small perturbations in timing and extend simulated time to relapse from continuous therapy administration.},
	journal = {Journal of Theoretical Biology},
	author = {West, Jeffrey and Ma, Yongqian and Newton, Paul K.},
	year = {2018},
	keywords = {Adaptive control, Adaptive therapy, Chemotherapeutic resistance, Competitive release, Evolutionary dynamics, Evolutionary game theory, Metastatic castration-resistant prostate cancer, Prisoner's dilemma, Replicator dynamics},
}

@article{jin_nanoparticles_2018,
	title = {Nanoparticles for super-resolution microscopy and single-molecule tracking},
	volume = {15},
	issn = {1548-7091},
	url = {http://www.nature.com/articles/s41592-018-0012-4},
	doi = {10.1038/s41592-018-0012-4},
	number = {6},
	urldate = {2018-11-08},
	journal = {Nature Methods},
	author = {Jin, Dayong and Xi, Peng and Wang, Baoming and Zhang, Le and Enderlein, Jörg and van Oijen, Antoine M.},
	month = jun,
	year = {2018},
	pages = {415--423},
}

@misc{noauthor_asap:_nodate,
	title = {{ASAP}: {Fast}, {Approximate} {Graph} {Pattern} {Mining} at {Scale} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/osdi18/presentation/iyer},
	urldate = {2018-11-07},
}

@article{li_so-net:_2018,
	title = {{SO}-{Net}: {Self}-{Organizing} {Network} for {Point} {Cloud} {Analysis}},
	url = {https://arxiv.org/abs/1803.04249},
	urldate = {2018-11-07},
	author = {Li, Jiaxin and Chen, Ben M. and Lee, Gim Hee},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.04249},
}

@article{bezanson_julia:_2018,
	title = {Julia: dynamism and performance reconciled by design},
	volume = {2},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3288538.3276490},
	doi = {10.1145/3276490},
	number = {OOPSLA},
	urldate = {2018-11-06},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Bezanson, Jeff and Chen, Jiahao and Chung, Benjamin and Karpinski, Stefan and Shah, Viral B. and Vitek, Jan and Zoubritzky, Lionel},
	month = oct,
	year = {2018},
	note = {Publisher: ACM},
	keywords = {dynamic languages, just-in-time compilation, multiple dispatch},
	pages = {1--23},
}

@article{erdelyi_correcting_2013,
	title = {Correcting chromatic offset in multicolor super-resolution localization microscopy},
	volume = {21},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-21-9-10978},
	doi = {10.1364/OE.21.010978},
	abstract = {Localization based super-resolution microscopy techniques require precise drift correction methods because the achieved spatial resolution is close to both the mechanical and optical performance limits of modern light microscopes. Multi-color imaging methods require corrections in addition to those dealing with drift due to the static, but spatially-dependent, chromatic offset between images. We present computer simulations to quantify this effect, which is primarily caused by the high-NA objectives used in super-resolution microscopy. Although the chromatic offset in well corrected systems is only a fraction of an optical wavelength in magnitude (\&lt;50 nm) and thus negligible in traditional diffraction limited imaging, we show that object colocalization by multi-color super-resolution methods is impossible without appropriate image correction. The simulated data are in excellent agreement with experiments using fluorescent beads excited and localized at multiple wavelengths. Finally we present a rigorous and practical calibration protocol to correct for chromatic optical offset, and demonstrate its efficacy for the imaging of transferrin receptor protein colocalization in HeLa cells using two-color direct stochastic optical reconstruction microscopy (dSTORM).},
	number = {9},
	urldate = {2018-11-04},
	journal = {Optics Express},
	author = {Erdelyi, Miklos and Rees, Eric and Metcalf, Daniel and Schierle, Gabriele S. Kaminski and Dudas, Laszlo and Sinko, Jozsef and Knight, Alex E. and Kaminski, Clemens F.},
	month = may,
	year = {2013},
	note = {Publisher: Optical Society of America},
	keywords = {Diffraction limit, Image metrics, Image quality, Imaging techniques, Optical components, Optical transfer functions},
	pages = {10978},
}

@article{nurse_regulatory_1980,
	title = {Regulatory genes controlling mitosis in the fission yeast {Schizosaccharomyces} pombe.},
	volume = {96},
	issn = {0016-6731},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/7262540},
	abstract = {Fifty-two wee mutants that undergo mitosis and cell division at a reduced size compared with wild type have been genetically analyzed. The mutants define two genes, wee1 and cdc2, which control the timing of mitosis. Fifty-one of the mutants map at the wee1 locus, which is unlinked to any known cdc gene. One of the wee1 alleles has been shown to be nonsense suppressible. The 52nd were mutant maps within cdc2. Previously, only temperature-sensitive mutants that become blocked at mitosis have been found at the cdc2 locus. The simplest interpretation of these observations is that wee1+ codes for a negative element or inhibitor, and cdc2+ codes for a positive element or activator in the mitotic control. The gene dosage of wee1+ plays some role in determining the timing of mitosis, but the gene dosage of cdc2+ has little effect. However, some aspect of the cdc2 gene product activity is important for determining when mitosis takes place. The possible roles of wee1 and cdc2 in the mitotic control are discussed, with particular reference to the part they may play in the monitoring of cell growth rate, both of which influence the timing of mitosis.},
	number = {3},
	urldate = {2018-11-04},
	journal = {Genetics},
	author = {Nurse, P and Thuriaux, P},
	month = nov,
	year = {1980},
	pmid = {7262540},
	pages = {627--37},
}

@article{mungall_monarch_2017,
	title = {The {Monarch} {Initiative}: an integrative data and analytic platform connecting phenotypes to genotypes across species.},
	volume = {45},
	issn = {1362-4962},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27899636},
	doi = {10.1093/nar/gkw1128},
	abstract = {The correlation of phenotypic outcomes with genetic variation and environmental factors is a core pursuit in biology and biomedicine. Numerous challenges impede our progress: patient phenotypes may not match known diseases, candidate variants may be in genes that have not been characterized, model organisms may not recapitulate human or veterinary diseases, filling evolutionary gaps is difficult, and many resources must be queried to find potentially significant genotype-phenotype associations. Non-human organisms have proven instrumental in revealing biological mechanisms. Advanced informatics tools can identify phenotypically relevant disease models in research and diagnostic contexts. Large-scale integration of model organism and clinical research data can provide a breadth of knowledge not available from individual sources and can provide contextualization of data back to these sources. The Monarch Initiative (monarchinitiative.org) is a collaborative, open science effort that aims to semantically integrate genotype-phenotype data from many species and sources in order to support precision medicine, disease modeling, and mechanistic exploration. Our integrated knowledge graph, analytic tools, and web services enable diverse users to explore relationships between phenotypes and genotypes across species.},
	number = {D1},
	urldate = {2018-11-04},
	journal = {Nucleic acids research},
	author = {Mungall, Christopher J and McMurry, Julie A and Köhler, Sebastian and Balhoff, James P and Borromeo, Charles and Brush, Matthew and Carbon, Seth and Conlin, Tom and Dunn, Nathan and Engelstad, Mark and Foster, Erin and Gourdine, J P and Jacobsen, Julius O B and Keith, Dan and Laraway, Bryan and Lewis, Suzanna E and NguyenXuan, Jeremy and Shefchek, Kent and Vasilevsky, Nicole and Yuan, Zhou and Washington, Nicole and Hochheiser, Harry and Groza, Tudor and Smedley, Damian and Robinson, Peter N and Haendel, Melissa A},
	year = {2017},
	pmid = {27899636},
	note = {Publisher: Oxford University Press},
	pages = {D712--D722},
}

@misc{noauthor_computing_nodate,
	title = {Computing a fractal dimension with {Matlab}: {1D}, {2D} and {3D} {Box}-counting},
	url = {https://www.mathworks.com/examples/matlab/community/36051-computing-a-fractal-dimension-with-matlab-1d-2d-and-3d-box-counting},
	urldate = {2018-11-04},
}

@article{strobelt_seq2seq-vis:_2018,
	title = {{Seq2Seq}-{Vis}: {A} {Visual} {Debugging} {Tool} for {Sequence}-to-{Sequence} {Models}},
	url = {http://arxiv.org/abs/1804.09299},
	abstract = {Neural Sequence-to-Sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work in a five stage blackbox process that involves encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction with a trained sequence-to-sequence model through each stage of the translation process. The aim is to identify which patterns have been learned and to detect model errors. We demonstrate the utility of our tool through several real-world large-scale sequence-to-sequence use cases.},
	urldate = {2018-11-04},
	author = {Strobelt, Hendrik and Gehrmann, Sebastian and Behrisch, Michael and Perer, Adam and Pfister, Hanspeter and Rush, Alexander M.},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.09299},
}

@article{jiang_graph_2018,
	title = {Graph {Convolutional} {Reinforcement} {Learning} for {Multi}-{Agent} {Cooperation}},
	url = {http://arxiv.org/abs/1810.09202},
	abstract = {Learning to cooperate is crucially important in multi-agent reinforcement learning. The key is to take the influence of other agents into consideration when performing distributed decision making. However, multi-agent environment is highly dynamic, which makes it hard to learn abstract representations of influences between agents by only low-order features that existing methods exploit. In this paper, we propose a graph convolutional model for multi-agent cooperation. The graph convolution architecture adapts to the dynamics of the underlying graph of the multi-agent environment, where the influence among agents is captured by their abstract relation representations. High-order features extracted by relation kernels of convolutional layers from gradually increased receptive fields are exploited to learn cooperative strategies. The gradient of an agent not only backpropagates to itself but also to other agents in its receptive fields to reinforce the learned cooperative strategies. Moreover, the relation representations are temporally regularized to make the cooperation more consistent. Empirically, we show that our model enables agents to develop more cooperative and sophisticated strategies than existing methods in jungle and battle games and routing in packet switching networks.},
	urldate = {2018-11-04},
	author = {Jiang, Jiechuan and Dun, Chen and Lu, Zongqing},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.09202},
}

@article{west_3d_2011,
	title = {A {3D} analysis of yeast {ER} structure reveals how {ER} domains are organized by membrane curvature.},
	volume = {193},
	issn = {1540-8140},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21502358},
	doi = {10.1083/jcb.201011039},
	abstract = {We analyzed the structure of yeast endoplasmic reticulum (ER) during six sequential stages of budding by electron tomography to reveal a three-dimensional portrait of ER organization during inheritance at a nanometer resolution. We have determined the distribution, dimensions, and ribosome densities of structurally distinct but continuous ER domains during multiple stages of budding with and without the tubule-shaping proteins, reticulons (Rtns) and Yop1. In wild-type cells, the peripheral ER contains cytoplasmic cisternae, many tubules, and a large plasma membrane (PM)-associated ER domain that consists of both tubules and fenestrated cisternae. In the absence of Rtn/Yop1, all three domains lose membrane curvature, ER ribosome density changes, and the amount of PM-associated ER increases dramatically. Deletion of Rtns/Yop1 does not, however, prevent bloated ER tubules from being pulled from the mother cisterna into the bud and strongly suggests that Rtns/Yop1 stabilize/maintain rather than generate membrane curvature at all peripheral ER domains in yeast.},
	number = {2},
	urldate = {2018-11-02},
	journal = {The Journal of cell biology},
	author = {West, Matt and Zurek, Nesia and Hoenger, Andreas and Voeltz, Gia K},
	month = apr,
	year = {2011},
	pmid = {21502358},
	note = {Publisher: Rockefeller University Press},
	pages = {333--46},
}

@incollection{fricker_quantitation_2018,
	title = {Quantitation of {ER} {Structure} and {Function}},
	url = {http://link.springer.com/10.1007/978-1-4939-7389-7_5},
	urldate = {2018-11-02},
	publisher = {Humana Press, New York, NY},
	author = {Fricker, Mark and Heaton, Luke and Jones, Nick and Obara, Boguslaw and Müller, Stefanie J. and Meyer, Andreas J.},
	year = {2018},
	doi = {10.1007/978-1-4939-7389-7_5},
	pages = {43--66},
}

@incollection{griffing_dancing_2018,
	title = {Dancing with the {Stars}: {Using} {Image} {Analysis} to {Study} the {Choreography} of the {Endoplasmic} {Reticulum} and {Its} {Partners} and of {Movement} {Within} {Its} {Tubules}},
	url = {http://link.springer.com/10.1007/978-1-4939-7389-7_7},
	urldate = {2018-11-02},
	publisher = {Humana Press, New York, NY},
	author = {Griffing, Lawrence R.},
	year = {2018},
	doi = {10.1007/978-1-4939-7389-7_7},
	pages = {75--102},
}

@article{noauthor_analyzeer_nodate,
	title = {{AnalyzeER}},
	url = {https://ora.ox.ac.uk/objects/uuid:cb0e2845-2a9c-495a-84f0-4dd2c5164463},
}

@article{malkusch_extracting_2016,
	title = {Extracting quantitative information from single-molecule super-resolution imaging data with {LAMA} – {LocAlization} {Microscopy} {Analyzer}},
	volume = {6},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep34486},
	doi = {10.1038/srep34486},
	abstract = {Extracting quantitative information from single-molecule super-resolution imaging data with LAMA – LocAlization Microscopy Analyzer},
	number = {1},
	urldate = {2018-10-31},
	journal = {Scientific Reports},
	author = {Malkusch, Sebastian and Heilemann, Mike},
	month = dec,
	year = {2016},
	note = {Publisher: Nature Publishing Group},
	keywords = {Nanoscale biophysics, Super, resolution microscopy},
	pages = {34486},
}

@inproceedings{zhou_deep_2018,
	title = {Deep learning for super-resolution localization microscopy},
	volume = {10820},
	isbn = {978-1-5106-2238-8},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10820/2500832/Deep-learning-for-super-resolution-localization-microscopy/10.1117/12.2500832.full},
	doi = {10.1117/12.2500832},
	abstract = {Super-resolution localization microscopy techniques (e.g., STORM or PALM), breaks the optics diffraction limit, making possible the observation of sub-cellular structures in vivo. However, long acquisition time is required to maintain a desired high spatial resolution. To overcome the limitation, an effective method is to increase the density of activated emitters in each frame. The high-density emitters will cause them to overlap, which makes it difficult to accurately resolve each emitter location. Although some methods have been proposed to identify the overlapped emitters, these methods are computationally intensive and parameter dependent. To address these problems, in this paper, we proposed a novel method based on convolutional neural networks (CNN) for super-resolution localization microscopy, termed as DL-SRLM. DL-SRLM is capable of learning the nonlinear mapping between a camera frame (i.e., the experimentally acquired low-resolution image) and the true locations of emitters in the corresponding image region (i.e., the recovered super-resolution image). As a result, the method provides the possibility to faster resolve the high-density emitters, without requiring the parameters. To evaluate the performance of DL-SRLM, a series of simulations with varying emitter densities, signal-to-noise ratios (SNRs), and point spread functions (PSFs) were performed. The results show that DL-SRLM can accurately resolve the locations of high-density emitters, even if when the raw measurement data contained noise or was generated by using inaccurate PSF. In addition, DL-SRLM greatly improve the computational speed ({\textasciitilde} 15 ms/frame) compared with the current methods while avoiding the effect of the parameters on the super-resolution imaging performance.},
	urldate = {2018-10-31},
	booktitle = {Optics in {Health} {Care} and {Biomedical} {Optics} {VIII}},
	publisher = {SPIE},
	author = {Zhou, Tianyang and Luo, Jianwen and Liu, Xin},
	editor = {Luo, Qingming and Li, Xingde and Tang, Yuguo and Gu, Ying},
	month = oct,
	year = {2018},
	keywords = {convolutional neural networks, deep learning, super-resolution localization microscopy},
	pages = {75},
}

@article{Rubin-Delanchy2015,
	title = {Bayesian cluster identification in single-molecule localization microscopy data},
	volume = {12},
	issn = {1548-7091},
	url = {http://www.nature.com/articles/nmeth.3612},
	doi = {10.1038/nmeth.3612},
	abstract = {This paper reports a Bayesian approach for the automatic identification of the optimal clustering proposal in the analysis of single-molecule localization-based super-resolution data.},
	number = {11},
	urldate = {2018-10-30},
	journal = {Nature Methods},
	author = {Rubin-Delanchy, Patrick and Burn, Garth L and Griffié, Juliette and Williamson, David J and Heard, Nicholas A and Cope, Andrew P and Owen, Dylan M},
	month = nov,
	year = {2015},
	note = {Publisher: Nature Publishing Group},
	keywords = {Fluorescence imaging, Image processing, Single, Super, molecule biophysics, resolution microscopy},
	pages = {1072--1076},
}

@article{Salman2016,
	title = {Spontaneous tumor regression},
	volume = {2},
	issn = {2452-3364},
	url = {https://www.sciencedirect.com/science/article/pii/S2452336416300255},
	doi = {10.1016/J.JONS.2016.04.008},
	abstract = {Spontaneous tumor regression is defined as spontaneous remission or disappearance of a tumor in the absence of any treatment. Activation of immune system has been found important in its pathogenesis. Further, spontaneous tumor regression appears to be associated with apoptosis, tumor microenvironment, and DNA oncogenic suppression. It can be observed in all types of tumors, most frequently in renal cell cancer, germ cell tumors, malignant melanoma, and neuroblastoma. It is crucial to understand this phenomenon in order to improve the immune treatments which are effective in neoplastic diseases.},
	number = {1},
	urldate = {2018-10-30},
	journal = {Journal of Oncological Science},
	author = {Salman, Tarik},
	month = apr,
	year = {2016},
	note = {Publisher: Elsevier},
	pages = {1--4},
}

@misc{noauthor_scannet_nodate,
	title = {{ScanNet}},
	url = {https://github.com/ScanNet/ScanNet},
}

@article{tchapmi_segcloud:_2017,
	title = {{SEGCloud}: {Semantic} {Segmentation} of {3D} {Point} {Clouds}},
	url = {http://arxiv.org/abs/1710.07563},
	abstract = {3D semantic scene labeling is fundamental to agents operating in the real world. In particular, labeling raw 3D point sets from sensors provides fine-grained semantics. Recent works leverage the capabilities of Neural Networks (NNs), but are limited to coarse voxel predictions and do not explicitly enforce global consistency. We present SEGCloud, an end-to-end framework to obtain 3D point-level segmentation that combines the advantages of NNs, trilinear interpolation(TI) and fully connected Conditional Random Fields (FC-CRF). Coarse voxel predictions from a 3D Fully Convolutional NN are transferred back to the raw 3D points via trilinear interpolation. Then the FC-CRF enforces global consistency and provides fine-grained semantics on the points. We implement the latter as a differentiable Recurrent NN to allow joint optimization. We evaluate the framework on two indoor and two outdoor 3D datasets (NYU V2, S3DIS, KITTI, Semantic3D.net), and show performance comparable or superior to the state-of-the-art on all datasets.},
	urldate = {2018-10-29},
	author = {Tchapmi, Lyne P. and Choy, Christopher B. and Armeni, Iro and Gwak, JunYoung and Savarese, Silvio},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.07563},
}

@article{koh_understanding_2017,
	title = {Understanding {Black}-box {Predictions} via {Influence} {Functions}},
	url = {http://arxiv.org/abs/1703.04730},
	abstract = {How can we explain the predictions of a black-box model? In this paper, we use influence functions -- a classic technique from robust statistics -- to trace a model's prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.},
	urldate = {2018-10-29},
	author = {Koh, Pang Wei and Liang, Percy},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.04730},
}

@article{ribeiro_&quot;why_2016,
	title = {\&quot;{Why} {Should} {I} {Trust} {You}?\&quot;: {Explaining} the {Predictions} of {Any} {Classifier}},
	url = {http://arxiv.org/abs/1602.04938},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	urldate = {2018-10-29},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.04938},
}

@article{abid_autowarp:_2018,
	title = {Autowarp: {Learning} a {Warping} {Distance} from {Unlabeled} {Time} {Series} {Using} {Sequence} {Autoencoders}},
	url = {http://arxiv.org/abs/1810.10107},
	abstract = {Measuring similarities between unlabeled time series trajectories is an important problem in domains as diverse as medicine, astronomy, finance, and computer vision. It is often unclear what is the appropriate metric to use because of the complex nature of noise in the trajectories (e.g. different sampling rates or outliers). Domain experts typically hand-craft or manually select a specific metric, such as dynamic time warping (DTW), to apply on their data. In this paper, we propose Autowarp, an end-to-end algorithm that optimizes and learns a good metric given unlabeled trajectories. We define a flexible and differentiable family of warping metrics, which encompasses common metrics such as DTW, Euclidean, and edit distance. Autowarp then leverages the representation power of sequence autoencoders to optimize for a member of this warping distance family. The output is a metric which is easy to interpret and can be robustly learned from relatively few trajectories. In systematic experiments across different domains, we show that Autowarp often outperforms hand-crafted trajectory similarity metrics.},
	urldate = {2018-10-25},
	author = {Abid, Abubakar and Zou, James},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.10107},
}

@misc{noauthor_multi-view_nodate,
	title = {Multi-view {Convolutional} {Neural} {Networks} for {3D} {Shape} {Recognition}},
	url = {http://vis-www.cs.umass.edu/mvcnn/},
	urldate = {2018-10-25},
}

@article{shen_mining_2017,
	title = {Mining {Point} {Cloud} {Local} {Structures} by {Kernel} {Correlation} and {Graph} {Pooling}},
	url = {http://arxiv.org/abs/1712.06760},
	abstract = {Unlike on images, semantic learning on 3D point clouds using a deep network is challenging due to the naturally unordered data structure. Among existing works, PointNet has achieved promising results by directly learning on point sets. However, it does not take full advantage of a point's local neighborhood that contains fine-grained structural information which turns out to be helpful towards better semantic learning. In this regard, we present two new operations to improve PointNet with a more efficient exploitation of local structures. The first one focuses on local 3D geometric structures. In analogy to a convolution kernel for images, we define a point-set kernel as a set of learnable 3D points that jointly respond to a set of neighboring data points according to their geometric affinities measured by kernel correlation, adapted from a similar technique for point cloud registration. The second one exploits local high-dimensional feature structures by recursive feature aggregation on a nearest-neighbor-graph computed from 3D positions. Experiments show that our network can efficiently capture local information and robustly achieve better performances on major datasets. Our code is available at http://www.merl.com/research/license\#KCNet},
	urldate = {2018-10-25},
	author = {Shen, Yiru and Feng, Chen and Yang, Yaoqing and Tian, Dong},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.06760},
}

@article{han_phylogenetic_2018,
	title = {Phylogenetic {Clustering} by {Linear} {Integer} {Programming} ({PhyCLIP})},
	url = {https://www.biorxiv.org/content/early/2018/10/23/446716},
	doi = {10.1101/446716},
	abstract = {Sub-species nomenclature systems of pathogens are increasingly based on sequence data. The use of phylogenetics to identify and differentiate between clusters of genetically similar pathogens is particularly prevalent in virology from the nomenclature of human papillomaviruses to highly pathogenic avian influenza (HPAI) H5Nx viruses. These nomenclature systems rely on absolute genetic distance thresholds to define the maximum genetic divergence tolerated between viruses designated as closely related. However, the phylogenetic clustering methods used in these nomenclature systems are limited by the arbitrariness of setting intra- and inter-cluster diversity thresholds. The lack of a consensus ground truth to define well-delineated, meaningful phylogenetic subpopulations amplifies the difficulties in identifying an informative distance threshold. Consequently, phylogenetic clustering often becomes an exploratory, ad-hoc exercise. Phylogenetic Clustering by Linear Integer Programming (PhyCLIP) was developed to provide a statistically-principled phylogenetic clustering framework that negates the need for an arbitrarily-defined distance threshold. Using the pairwise patristic distance distributions of an input phylogeny, PhyCLIP parameterises the intra- and inter-cluster divergence limits as statistical bounds in an integer linear programming model which is subsequently optimised to cluster as many sequences as possible. When applied to the hemagglutinin phylogeny of HPAI H5Nx viruses, PhyCLIP was not only able to recapitulate the current WHO/OIE/FAO H5 nomenclature system but also further delineated informative higher resolution clusters that capture geographically-distinct subpopulations of viruses. PhyCLIP is pathogen-agnostic and can be generalised to a wide variety of research questions concerning the identification of biologically informative clusters in pathogen phylogenies. PhyCLIP is freely available at http://github.com/alvinxhan/PhyCLIP.},
	urldate = {2018-10-23},
	journal = {bioRxiv},
	author = {Han, Alvin Xiaochuan and Parker, Edyth and Scholer, Frits and Maurer-Stroh, Sebastian and Russell, Colin},
	month = oct,
	year = {2018},
	note = {Publisher: Cold Spring Harbor Laboratory},
	pages = {446716},
}

@article{tran_deep_2017,
	title = {Deep {Probabilistic} {Programming}},
	url = {http://arxiv.org/abs/1701.03757},
	abstract = {We propose Edward, a Turing-complete probabilistic programming language. Edward defines two compositional representations---random variables and inference. By treating inference as a first class citizen, on a par with modeling, we show that probabilistic programming can be as flexible and computationally efficient as traditional deep learning. For flexibility, Edward makes it easy to fit the same model using a variety of composable inference methods, ranging from point estimation to variational inference to MCMC. In addition, Edward can reuse the modeling representation as part of inference, facilitating the design of rich variational models and generative adversarial networks. For efficiency, Edward is integrated into TensorFlow, providing significant speedups over existing probabilistic systems. For example, we show on a benchmark logistic regression task that Edward is at least 35x faster than Stan and 6x faster than PyMC3. Further, Edward incurs no runtime overhead: it is as fast as handwritten TensorFlow.},
	urldate = {2018-10-22},
	author = {Tran, Dustin and Hoffman, Matthew D. and Saurous, Rif A. and Brevdo, Eugene and Murphy, Kevin and Blei, David M.},
	month = jan,
	year = {2017},
	note = {arXiv: 1701.03757},
}

@article{Saff1997,
	title = {Distributing many points on a sphere},
	volume = {19},
	issn = {0343-6993},
	url = {http://link.springer.com/10.1007/BF03024331},
	doi = {10.1007/BF03024331},
	number = {1},
	urldate = {2018-10-17},
	journal = {The Mathematical Intelligencer},
	author = {Saff, E. B. and Kuijlaars, A. B. J.},
	month = dec,
	year = {1997},
	note = {Publisher: Springer-Verlag},
	pages = {5--11},
}

@article{bermudez-hernandez_method_2017,
	title = {A {Method} for {Quantifying} {Molecular} {Interactions} {Using} {Stochastic} {Modelling} and {Super}-{Resolution} {Microscopy}.},
	volume = {7},
	issn = {2045-2322},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/29093506},
	doi = {10.1038/s41598-017-14922-8},
	abstract = {We introduce the Interaction Factor (IF), a measure for quantifying the interaction of molecular clusters in super-resolution microscopy images. The IF is robust in the sense that it is independent of cluster density, and it only depends on the extent of the pair-wise interaction between different types of molecular clusters in the image. The IF for a single or a collection of images is estimated by first using stochastic modelling where the locations of clusters in the images are repeatedly randomized to estimate the distribution of the overlaps between the clusters in the absence of interaction (IF = 0). Second, an analytical form of the relationship between IF and the overlap (which has the random overlap as its only parameter) is used to estimate the IF for the experimentally observed overlap. The advantage of IF compared to conventional methods to quantify interaction in microscopy images is that it is insensitive to changing cluster density and is an absolute measure of interaction, making the interpretation of experiments easier. We validate the IF method by using both simulated and experimental data and provide an ImageJ plugin for determining the IF of an image.},
	number = {1},
	urldate = {2018-10-17},
	journal = {Scientific reports},
	author = {Bermudez-Hernandez, Keria and Keegan, Sarah and Whelan, Donna R and Reid, Dylan A and Zagelbaum, Jennifer and Yin, Yandong and Ma, Sisi and Rothenberg, Eli and Fenyö, David},
	month = nov,
	year = {2017},
	pmid = {29093506},
	note = {Publisher: Nature Publishing Group},
	pages = {14882},
}

@article{Laine2018,
	title = {{NanoJ}: a high-performance open-source super-resolution microscopy toolbox},
	doi = {10.1101/432674},
	abstract = {Super-resolution microscopy has become essential for the study of nanoscale biological processes. This type of imaging often requires the use of specialised image analysis tools to process a large volume of recorded data and extract quantitative information. In recent years, our team has built an open-source image analysis framework for super-resolution microscopy designed to combine high performance and ease of use. We named it NanoJ - a reference to the popular ImageJ software it was developed for. In this paper, we highlight the current capabilities of NanoJ for several essential processing steps: spatio-temporal alignment of raw data (NanoJ-Core), super-resolution image reconstruction (NanoJ-SRRF), image quality assessment (NanoJ-SQUIRREL), structural modelling (NanoJ-VirusMapper) and control of the sample environment (NanoJ-Fluidics). We expect to expand NanoJ in the future through the development of new tools designed to improve quantitative data analysis and measure the reliability of fluorescent microscopy studies.},
	urldate = {2018-10-16},
	journal = {bioRxiv},
	author = {Laine, Romain and Tosheva, Kalina and Gustafsson, Nils and Gray, Robert D. M. and Almada, Pedro and Albrecht, David and Risa, Gabriel T. and Hurtig, Fredrik and Lindås, Ann-Christin and Baum, Buzz and Mercer, Jason and Leterrier, Christophe and Pereira, Pedro M. and Culley, Siân and Henriques, Ricardo},
	month = oct,
	year = {2018},
	note = {Publisher: Cold Spring Harbor Laboratory},
	pages = {432674},
}

@incollection{frangi_multiscale_1998,
	title = {Multiscale vessel enhancement filtering},
	url = {http://link.springer.com/10.1007/BFb0056195},
	urldate = {2018-10-16},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Frangi, Alejandro F. and Niessen, Wiro J. and Vincken, Koen L. and Viergever, Max A.},
	month = oct,
	year = {1998},
	doi = {10.1007/BFb0056195},
	pages = {130--137},
}

@article{Frangi2001,
	title = {Three-dimensional model-based analysis of vascular and cardiac images},
	url = {https://dspace.library.uu.nl/handle/1874/377},
	abstract = {Universiteit Utrecht},
	urldate = {2018-10-16},
	author = {Frangi, A.F.},
	month = apr,
	year = {2001},
	keywords = {Geneeskunde, based image analysis, dimensional, left ventricle, magnetic resonance, model, nucleus caudate, segmentation, statistical shape models, three, vessels, wrist},
}

@article{Fujimoto2000,
	title = {Ion-{Sensitive} {Field} {Effect} {Transistors} and {Related} {Devices}},
	volume = {47},
	issn = {15206882},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/10984441},
	doi = {10.1021/ac60352a020},
	abstract = {The relationship between caveolin-1 isoforms alpha and beta and caveolar ultrastructure was studied. By immunofluorescence microscopy of human fibroblasts, caveolae were observed as dots positive for caveolin-1, but many dots labeled by an antibody recognizing both isoforms (anti-alphabeta) were not labeled by another antibody specific for the alpha isoform (anti-alpha). Immunogold electron microscopy of freeze-fracture replicas revealed caveolae of different depths, and indicated that anti-alpha labeled deep caveolae preferentially over shallow ones, whereas anti-alphabeta labeled both forms with an equivalent frequency and intensity. The presence of the beta isoform in deep caveolae was confirmed by labeling epitope-tagged beta-caveolin. When made to be expressed in HepG2 cells lacking endogenous caveolins, the alpha isoform formed caveolar depressions efficiently, but the beta isoform hardly did so. Caveolae were also formed in cells expressing the two isoforms, but their frequency was variable among cells of the same clone. Coexpression of caveolin-1 and caveolin-2 caused more efficient formation of deep caveolae than caveolin-1 alone. The result indicates that the two isoforms of caveolin-1 have a different potential for forming caveolae structure, and more importantly, that deep and shallow caveolae may be diversified in their molecular composition.},
	number = {2},
	urldate = {2018-10-15},
	journal = {Analytical Chemistry},
	author = {Zemel, J. N.},
	month = oct,
	year = {1975},
	pmid = {10984441},
	note = {ISBN: 0021-9533 (Print){\textbackslash}n0021-9533 (Linking)},
	pages = {255A--268a},
}

@article{Biphenyls2015,
	title = {{HHS} {Public} {Access}},
	volume = {91},
	issn = {1527-5418},
	doi = {10.1016/j.chemosphere.2012.12.037.Reactivity},
	number = {2},
	author = {Biphenyls, Coplanar Polychlorinated},
	year = {2015},
	pmid = {26928661},
	note = {arXiv: 15334406
ISBN: 0000000000000},
	keywords = {bimetallic nanotubes, dechlorination, iron, palladium, polychlorinated biphenyls},
	pages = {165--171},
}

@article{Bagci1993,
	title = {Monoclonal anti-biotin antibodies simulate avidin m the recognition of biotin},
	volume = {322},
	issn = {00145793},
	doi = {10.1016/0014-5793(93)81108-C},
	abstract = {The sequence of the VHgene of a monoclonal anti-biotin antibody was determined. Biotin-binding motifs, similar to those in avidin and streptavidin, were identified in complementarity determining regions 2 and 3, suggesting that natural selection of functional motifs may occur in unrelated protein types. © 1993.},
	number = {1},
	journal = {FEBS Letters},
	author = {Bagçi, Hasan and Kohen, Fortune and Kusçuoglu, Unsal and Bayer, Edward A. and Wilchek, Meir},
	year = {1993},
	pmid = {8482366},
	note = {ISBN: 0014-5793},
	keywords = {Anti-biotin antibody, Antibody combining site, Antibody gene, Binding motif, Biotin binding site},
	pages = {47--50},
}

@article{Efron1979,
	title = {Bootstrap {Methods}: {Another} {Look} at the {Jackknife}},
	volume = {7},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1176344552},
	doi = {10.1214/aos/1176344552},
	number = {1},
	urldate = {2018-10-11},
	journal = {The Annals of Statistics},
	author = {Efron, B.},
	month = jan,
	year = {1979},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Jackknife, bootstrap, discriminant analysis, error rate estimation, nonlinear regression, nonparametric variance estimation, resampling, subsample values},
	pages = {1--26},
}

@article{Brameshuber2018,
	title = {Monomeric {TCRs} drive {T} cell antigen recognition},
	volume = {19},
	issn = {1529-2908},
	url = {http://www.nature.com/articles/s41590-018-0092-4},
	doi = {10.1038/s41590-018-0092-4},
	abstract = {T cell antigen recognition requires T cell antigen receptors (TCRs) engaging MHC-embedded antigenic peptides (pMHCs) within the contact region of a T cell with its conjugated antigen-presenting cell. Despite micromolar TCR:pMHC affinities, T cells respond to even a single antigenic pMHC, and higher-order TCRs have been postulated to maintain high antigen sensitivity and trigger signaling. We interrogated the stoichiometry of TCRs and their associated CD3 subunits on the surface of living T cells through single-molecule brightness and single-molecule coincidence analysis, photon-antibunching-based fluorescence correlation spectroscopy and Förster resonance energy transfer measurements. We found exclusively monomeric TCR–CD3 complexes driving the recognition of antigenic pMHCs, which underscores the exceptional capacity of single TCR–CD3 complexes to elicit robust intracellular signaling.},
	number = {5},
	urldate = {2018-10-11},
	journal = {Nature Immunology},
	author = {Brameshuber, Mario and Kellner, Florian and Rossboth, Benedikt K. and Ta, Haisen and Alge, Kevin and Sevcsik, Eva and Göhring, Janett and Axmann, Markus and Baumgart, Florian and Gascoigne, Nicholas R. J. and Davis, Simon J. and Stockinger, Hannes and Schütz, Gerhard J. and Huppa, Johannes B.},
	month = may,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biomedicine, Immunology, Infectious Diseases, general},
	pages = {487--496},
}

@misc{noauthor_cv_fall18_nodate,
	title = {cv\_Fall18 (1).pdf},
}

@article{yin_detection_2018,
	title = {Detection of {Velocity} and {Diffusion} {Coefficient} {Change} {Points} in {Single}-{Particle} {Trajectories}},
	volume = {115},
	issn = {15420086},
	doi = {10.1016/j.bpj.2017.11.008},
	abstract = {The position-time trajectory of a biological subject moving in a complex environment contains rich information about how it interacts with the local setting. Whether the subject be an animal or an intracellular endosomal vesicle, the two primary modes of biological locomotion are directional movement and random walk, respectively characterized by velocity and diffusion coefficient. This contribution introduces a method to quantitatively divide a single-particle trajectory into segments that exhibit changes in the diffusion coefficient, velocity, or both. With the determination of these two physical parameters given by the maximum likelihood estimators, the relative precisions are given as explicit functions of the number of data points and total trajectory time. The method is based on rigorous statistical tests and does not require any presumed kinetics scheme. Results of extensive characterizations, extensions to 2D and 3D trajectories, and applications to common scenarios are also discussed.},
	number = {2},
	journal = {Biophysical Journal},
	author = {Yin, Shuhui and Song, Nancy and Yang, Haw},
	year = {2018},
	pmid = {29241585},
}

@article{Anthony2009,
	title = {Image {Analysis} with {Rapid} and {Accurate} {Two}-{Dimensional} {Gaussian} {Fitting}},
	volume = {25},
	issn = {0743-7463},
	url = {http://pubs.acs.org/doi/abs/10.1021/la900393v},
	doi = {10.1021/la900393v},
	abstract = {A computationally rapid image analysis method, weighted overdetermined regression, is presented for two-dimensional (2D) Gaussian fitting of particle location with subpixel resolution from a pixelized image of light intensity. Compared to least-squares Gaussian iterative fitting, which is most exact but prohibitively slow for large data sets, the precision of this new method is equivalent when the signal-to-noise ratio is high and approaches it when the signal-to-noise ratio is low, while enjoying a more than 100-fold improvement in computational time. Compared to another widely used approximation method, nine-point regression, we show that precision and speed are both improved. Additionally, weighted regression runs nearly as fast and with greatly improved precision compared to the simplest method, the moment method, which, despite its limited precision, is frequently employed because of its speed. Quantitative comparisons are presented for both circular and elliptical Gaussian intensity distributions. T...},
	number = {14},
	urldate = {2018-10-05},
	journal = {Langmuir},
	author = {Anthony, Stephen M. and Granick, Steve},
	month = jul,
	year = {2009},
	note = {Publisher: American Chemical Society},
	pages = {8152--8160},
}

@article{Ahmed2017,
	title = {Graphlet decomposition: framework, algorithms, and applications},
	volume = {50},
	issn = {0219-1377},
	url = {http://link.springer.com/10.1007/s10115-016-0965-5},
	doi = {10.1007/s10115-016-0965-5},
	number = {3},
	urldate = {2018-10-03},
	journal = {Knowledge and Information Systems},
	author = {Ahmed, Nesreen K. and Neville, Jennifer and Rossi, Ryan A. and Duffield, Nick G. and Willke, Theodore L.},
	month = mar,
	year = {2017},
	note = {Publisher: Springer-Verlag New York, Inc.},
	keywords = {Biological networks, Classification, Graph features, Graph kernel, Graph mining, Graphlet, Higher-order graph statistics, Motif, Visual graph analytics},
	pages = {689--722},
}

@article{We2019a,
	title = {Graph {UNET}},
	author = {We, Bstract and Convolutional, Ntroduction},
	year = {2019},
	pages = {1--10},
}

@article{agrawal_thicweed:_2017,
	title = {{THiCweed}: fast, sensitive detection of sequence features by clustering big data sets},
	url = {https://www.biorxiv.org/content/early/2017/11/30/104109},
	doi = {10.1101/104109},
	abstract = {We present THiCweed, a new approach to analyzing transcription factor binding data from high-throughput chromatin-immunoprecipitation-sequencing (ChIP-seq) experiments. THiCweed clusters bound regions based on sequence similarity using a divisive hierarchical clustering approach based on sequence similarity within sliding windows, while exploring both strands. ThiCweed is specially geared towards data containing mixtures of motifs, which present a challenge to traditional motif-finders. Our implementation is significantly faster than standard motif-finding programs, able to process 30,000 peaks in 1-2 hours, on a single CPU core of a desktop computer. On synthetic data containing mixtures of motifs it is as accurate or more accurate than all other tested programs. THiCweed performs best with large "window" sizes (≥ 50bp), much longer than typical binding sites (7-15 base pairs). On real data it successfully recovers literature motifs, but also uncovers complex sequence characteristics in flanking DNA, variant motifs, and secondary motifs even when they occur in {\textless} 5\% of the input, all of which appear biologically relevant. We also find recurring sequence patterns across diverse ChIP-seq data sets, possibly related to chromatin architecture and looping. THiCweed thus goes beyond traditional motif-finding to give new insights into genomic TF binding complexity.},
	urldate = {2018-09-26},
	journal = {bioRxiv},
	author = {Agrawal, Ankit and Sambare, Snehal V and Narlikar, Leelavati and Siddharthan, Rahul},
	month = nov,
	year = {2017},
	note = {Publisher: Cold Spring Harbor Laboratory},
	pages = {104109},
}

@inproceedings{saha_fast_2017,
	title = {Fast \&amp; {Space}-{Efficient} {Approximations} of {Language} {Edit} {Distance} and {RNA} {Folding}: {An} {Amnesic} {Dynamic} {Programming} {Approach}},
	isbn = {978-1-5386-3464-6},
	url = {http://ieeexplore.ieee.org/document/8104067/},
	doi = {10.1109/FOCS.2017.35},
	urldate = {2018-09-25},
	booktitle = {2017 {IEEE} 58th {Annual} {Symposium} on {Foundations} of {Computer} {Science} ({FOCS})},
	publisher = {IEEE},
	author = {Saha, Barna},
	month = oct,
	year = {2017},
	pages = {295--306},
}

@article{knudsen_rna_1999,
	title = {{RNA} secondary structure prediction using stochastic context-free grammars and evolutionary history},
	volume = {15},
	issn = {1367-4803},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/15.6.446},
	doi = {10.1093/bioinformatics/15.6.446},
	number = {6},
	urldate = {2018-09-25},
	journal = {Bioinformatics},
	author = {Knudsen, B. and Hein, J.},
	month = jun,
	year = {1999},
	note = {Publisher: Oxford University Press},
	pages = {446--454},
}

@article{Le1989,
	title = {Tree graphs of {RNA} secondary structures and their comparisons},
	volume = {22},
	issn = {0010-4809},
	url = {https://www.sciencedirect.com/science/article/pii/0010480989900396},
	doi = {10.1016/0010-4809(89)90039-6},
	abstract = {To facilitate comparison of RNA secondary structures each structure is represented as an ordered labeled tree. Several alternate secondary structures yielding a set of trees can be computed for any given RNA molecule (sequence). Frequently recurring subtrees are searched in this set of trees. The consensus structure motifs are then selected and used to construct a secondary structure model of the RNA. Given the difficulties involved in RNA secondary structure calculations, this procedure may significantly improve our predictive capabilities. In addition, the change of secondary structures between two different RNA sequences is described as a transformation of ordered trees. The transferable ratio of tree A from tree B is defined as a proportion of the largest common subtrees in trees A and B occurring in tree A. The method is applied to the study of the mechanism of human α1 globin pre-mRNA splicing. In the study, two tentative splicing mechanisms, A and B, with different orders of intron excision from α1 globin pre-mRNA have been simulated. A possible relationship between the structural features of the secondary structures and the order of intron excision in the pathway of precursor splicing of human α1 globin is discussed.},
	number = {5},
	urldate = {2018-09-25},
	journal = {Computers and Biomedical Research},
	author = {Le, Shu-Yun and Nussinov, Ruth and Maizel, Jacob V.},
	month = oct,
	year = {1989},
	note = {Publisher: Academic Press},
	pages = {461--473},
}

@article{Staple2005,
	title = {Pseudoknots: {RNA} {Structures} with {Diverse} {Functions}},
	volume = {3},
	issn = {1545-7885},
	url = {http://dx.plos.org/10.1371/journal.pbio.0030213},
	doi = {10.1371/journal.pbio.0030213},
	abstract = {Just as proteins form distinct structural motifs, certain structures are commonly adopted by RNA molecules. Amongst the most prevalent is the RNA pseudoknot.},
	number = {6},
	urldate = {2018-09-24},
	journal = {PLoS Biology},
	author = {Staple, David W and Butcher, Samuel E},
	month = jun,
	year = {2005},
	note = {Publisher: Public Library of Science},
	pages = {e213},
}

@incollection{gray_mitochondrial_2001,
	title = {Mitochondrial {Genome}},
	isbn = {978-0-12-227080-2},
	urldate = {2018-09-24},
	booktitle = {Encyclopedia of {Genetics}},
	author = {Gray, M.W.},
	year = {2001},
	doi = {10.1006/rwgn.2001.0837},
	pages = {1220--1222},
}

@article{Gagnidze2018,
	title = {A {New} {Chapter} in {Genetic} {Medicine}: {RNA} {Editing} and its {Role} in {Disease} {Pathogenesis}},
	volume = {24},
	issn = {14714914},
	doi = {10.1016/j.molmed.2018.01.002},
	abstract = {The transfer of genomic information from DNA to mRNA to protein usually occurs with high fidelity, but can also be subverted by a programmed RNA sequence alteration termed ‘RNA editing’, involving deamination of adenosine to inosine (decoded as guanosine), or of cytosine to uracil. These sequence changes can lead to cellular heterogeneity by generating variable sets of transcripts within otherwise identical cells. Recent studies have demonstrated that editing is most prevalent in cells and tissues with high propensity for plasticity. Within those, RNA editing reproducibly targets transcripts of related function, altering the outcomes of entire pathways at once. In ongoing work, changes in patterns of editing have been correlated with neuronal disease pathogenesis, suggesting that RNA editing harbors diagnostic potential.},
	number = {3},
	urldate = {2018-09-24},
	journal = {Trends in Molecular Medicine},
	author = {Gagnidze, Khatuna and Rayon-Estrada, Violeta and Harroch, Sheila and Bulloch, Karen and Papavasiliou, F. Nina},
	year = {2018},
	pages = {294--303},
}

@incollection{Brenner2001,
	title = {Genetic {Code}},
	isbn = {978-0-12-227080-2},
	urldate = {2018-09-24},
	booktitle = {Encyclopedia of {Genetics}},
	author = {Brenner, S.},
	year = {2001},
	doi = {10.1006/rwgn.2001.0528},
	pages = {821--822},
}

@incollection{Xia2013,
	title = {Wobble {Hypothesis}},
	isbn = {978-0-08-096156-9},
	abstract = {The original wobble hypothesis with its extended codon–anticodon base pairs played a crucial role in understanding the working of the messenger RNA (mRNA) translation machinery. Wobble pairing reduces the number of transfer RNAs (tRNAs) needed for mRNA translation, but also tends to reduce translation efficiency and accuracy. Many nucleotide modifications have been discovered that either increase or decrease the wobble versatility of nucleotides, leading to increased decoding capacity without serious reduction in translation efficiency and accuracy. Recent studies on tRNA have led to the expanded wobble hypothesis that extends the wobble hypothesis by invoking wobble pairing between the third anticodon site (NIII) and the first codon site (N1), conditional on a CII/G2 or GII/C2 with three hydrogen bonds. This hypothesis implies that the anticodon UCG would wobble pair with stop codon UGA through a wobble UIII/G1 pair, and should therefore be strongly selected against. The hypothesis explains not only the avoidance of tRNAArg/UCG in diverse evolutionary lineages, but in particular why tRNAArg/UCG should be avoided in most eubacterial species and ancestral mitochondrial lineages where UGA is used as a stop codon, and why it is present in derived mitochondrial lineages such as vertebrate mitochondrial genomes, where UGA is no longer used as a stop codon. Wobble pairing implies the theoretical possibility of adding new base pairs of novel nucleotides to protein-coding genes to increase the coding capacity.},
	urldate = {2018-09-24},
	booktitle = {Brenner's {Encyclopedia} of {Genetics}},
	author = {Xia, X.},
	year = {2013},
	doi = {10.1016/B978-0-12-374984-0.01648-X},
	pages = {347--349},
}

@article{Nguyen2015,
	title = {Continuous hydrolysis of carboxymethyl cellulose with cellulase aggregates trapped inside membranes},
	volume = {78},
	issn = {01410229},
	doi = {10.1016/j.enzmictec.2015.06.005},
	abstract = {Enzymatic hydrolysis of cellulose is often conducted in batch processes in which hydrolytic products tend to inhibit enzyme activity. In this study, we report a method for continuous hydrolysis of carboxymethyl cellulose (CMC) by using cross-linked cellulase aggregate (XCA) trapped inside a membrane. XCA particles prepared by using a millifluidic reactor have a uniform size distribution around 350nm. Because of their large size, XCA particles in solutions can be filtered through a polyethersulfone membrane to collect 87.1±0.9\% of XCA particles. The membrane with impregnated XCA can be used as a catalyst for hydrolysis of CMC in a continuous mode. When the CMC concentration is 1.0g/l and the flow rate is 2μl/min, 53.9\% of CMC is hydrolyzed to reducing sugars. The membrane with XCA is very stable under continuously flowing solutions. After 72h of reaction, 97.5\% of XCA remains inside the membrane.},
	urldate = {2018-09-24},
	journal = {Enzyme and Microbial Technology},
	author = {Nguyen, Le Truc and Neo, Kristyn Rui Shan and Yang, Kun-Lin},
	year = {2015},
	pages = {34--39},
}

@article{Alexander2001,
	title = {Wobble {Hypothesis}},
	url = {https://www.sciencedirect.com/science/article/pii/B0122270800013914},
	doi = {10.1006/RWGN.2001.1391},
	urldate = {2018-09-24},
	journal = {Encyclopedia of Genetics},
	author = {Alexander, R.W. and Schimmel, P.},
	month = jan,
	year = {2001},
	note = {Publisher: Academic Press
ISBN: 9780122270802},
	pages = {2140--2141},
}

@article{Marraffini2010,
	title = {{CRISPR} interference: {RNA}-directed adaptive immunity in bacteria and archaea.},
	volume = {11},
	issn = {1471-0064},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20125085},
	doi = {10.1038/nrg2749},
	abstract = {Sequence-directed genetic interference pathways control gene expression and preserve genome integrity in all kingdoms of life. The importance of such pathways is highlighted by the extensive study of RNA interference (RNAi) and related processes in eukaryotes. In many bacteria and most archaea, clustered, regularly interspaced short palindromic repeats (CRISPRs) are involved in a more recently discovered interference pathway that protects cells from bacteriophages and conjugative plasmids. CRISPR sequences provide an adaptive, heritable record of past infections and express CRISPR RNAs - small RNAs that target invasive nucleic acids. Here, we review the mechanisms of CRISPR interference and its roles in microbial physiology and evolution. We also discuss potential applications of this novel interference pathway.},
	number = {3},
	urldate = {2018-09-23},
	journal = {Nature reviews. Genetics},
	author = {Marraffini, Luciano A and Sontheimer, Erik J},
	month = mar,
	year = {2010},
	pmid = {20125085},
	note = {Publisher: NIH Public Access},
	pages = {181--90},
}

@article{Wilkinson2006,
	title = {Selective 2′-hydroxyl acylation analyzed by primer extension ({SHAPE}): quantitative {RNA} structure analysis at single nucleotide resolution},
	volume = {1},
	issn = {1754-2189},
	url = {http://www.nature.com/doifinder/10.1038/nprot.2006.249},
	doi = {10.1038/nprot.2006.249},
	abstract = {Selective 2′-hydroxyl acylation analyzed by primer extension (SHAPE): quantitative RNA structure analysis at single nucleotide resolution},
	number = {3},
	urldate = {2018-09-23},
	journal = {Nature Protocols},
	author = {Wilkinson, Kevin A and Merino, Edward J and Weeks, Kevin M},
	month = nov,
	year = {2006},
	note = {Publisher: Nature Publishing Group},
	pages = {1610--1616},
}

@article{Yonemoto2015,
	title = {A semi-supervised learning approach for {RNA} secondary structure prediction.},
	volume = {57},
	issn = {1476-928X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1476927115000195},
	doi = {10.1016/j.compbiolchem.2015.02.002},
	abstract = {RNA secondary structure prediction is a key technology in RNA bioinformatics. Most algorithms for RNA secondary structure prediction use probabilistic models, in which the model parameters are trained with reliable RNA secondary structures. Because of the difficulty of determining RNA secondary structures by experimental procedures, such as NMR or X-ray crystal structural analyses, there are still many RNA sequences that could be useful for training whose secondary structures have not been experimentally determined. In this paper, we introduce a novel semi-supervised learning approach for training parameters in a probabilistic model of RNA secondary structures in which we employ not only RNA sequences with annotated secondary structures but also ones with unknown secondary structures. Our model is based on a hybrid of generative (stochastic context-free grammars) and discriminative models (conditional random fields) that has been successfully applied to natural language processing. Computational experiments indicate that the accuracy of secondary structure prediction is improved by incorporating RNA sequences with unknown secondary structures into training. To our knowledge, this is the first study of a semi-supervised learning approach for RNA secondary structure prediction. This technique will be useful when the number of reliable structures is limited.},
	urldate = {2018-09-23},
	journal = {Computational biology and chemistry},
	author = {Yonemoto, Haruka and Asai, Kiyoshi and Hamada, Michiaki},
	month = aug,
	year = {2015},
	pmid = {25748534},
	keywords = {Parameter learning, RNA secondary structure, Semi-supervised learning},
	pages = {72--9},
}

@article{Zuker1984,
	title = {{RNA} secondary structures and their prediction},
	volume = {46},
	issn = {0092-8240},
	url = {http://link.springer.com/10.1007/BF02459506},
	doi = {10.1007/BF02459506},
	number = {4},
	urldate = {2018-09-23},
	journal = {Bulletin of Mathematical Biology},
	author = {Zuker, Michael and Sankoff, David},
	month = jul,
	year = {1984},
	note = {Publisher: Kluwer Academic Publishers},
	pages = {591--621},
}

@article{Washietl2005,
	title = {Mapping of conserved {RNA} secondary structures predicts thousands of functional noncoding {RNAs} in the human genome},
	volume = {23},
	issn = {1087-0156},
	url = {http://www.nature.com/articles/nbt1144},
	doi = {10.1038/nbt1144},
	abstract = {Mapping of conserved RNA secondary structures predicts thousands of functional noncoding RNAs in the human genome},
	number = {11},
	urldate = {2018-09-23},
	journal = {Nature Biotechnology},
	author = {Washietl, Stefan and Hofacker, Ivo L and Lukasser, Melanie and Hüttenhofer, Alexander and Stadler, Peter F},
	month = nov,
	year = {2005},
	note = {Publisher: Nature Publishing Group},
	pages = {1383--1390},
}

@article{Will2012,
	title = {{LocARNA}-{P}: accurate boundary prediction and improved detection of structural {RNAs}.},
	volume = {18},
	issn = {1469-9001},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22450757},
	doi = {10.1261/rna.029041.111},
	abstract = {Current genomic screens for noncoding RNAs (ncRNAs) predict a large number of genomic regions containing potential structural ncRNAs. The analysis of these data requires highly accurate prediction of ncRNA boundaries and discrimination of promising candidate ncRNAs from weak predictions. Existing methods struggle with these goals because they rely on sequence-based multiple sequence alignments, which regularly misalign RNA structure and therefore do not support identification of structural similarities. To overcome this limitation, we compute columnwise and global reliabilities of alignments based on sequence and structure similarity; we refer to these structure-based alignment reliabilities as STARs. The columnwise STARs of alignments, or STAR profiles, provide a versatile tool for the manual and automatic analysis of ncRNAs. In particular, we improve the boundary prediction of the widely used ncRNA gene finder RNAz by a factor of 3 from a median deviation of 47 to 13 nt. Post-processing RNAz predictions, LocARNA-P's STAR score allows much stronger discrimination between true- and false-positive predictions than RNAz's own evaluation. The improved accuracy, in this scenario increased from AUC 0.71 to AUC 0.87, significantly reduces the cost of successive analysis steps. The ready-to-use software tool LocARNA-P produces structure-based multiple RNA alignments with associated columnwise STARs and predicts ncRNA boundaries. We provide additional results, a web server for LocARNA/LocARNA-P, and the software package, including documentation and a pipeline for refining screens for structural ncRNA, at http://www.bioinf.uni-freiburg.de/Supplements/LocARNA-P/.},
	number = {5},
	urldate = {2018-09-23},
	journal = {RNA (New York, N.Y.)},
	author = {Will, Sebastian and Joshi, Tejal and Hofacker, Ivo L and Stadler, Peter F and Backofen, Rolf},
	month = may,
	year = {2012},
	pmid = {22450757},
	note = {Publisher: Cold Spring Harbor Laboratory Press},
	pages = {900--14},
}

@book{science_essential_2013,
	title = {{ESSENTIAL} {CELL} {BIOLOGY} {ESSENTIAL} {CELL} {BIOLOGY} {ESSENTIAL} {CELL} {BIOLOGY} {FOURTH} {EDITION} 13:25},
	isbn = {978-0-8153-4455-1},
	author = {Science, Garland and Lewis, Johnson},
	year = {2013},
}

@article{Wick2017,
	title = {Unicycler: {Resolving} bacterial genome assemblies from short and long sequencing reads},
	volume = {13},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1005595},
	doi = {10.1371/journal.pcbi.1005595},
	abstract = {The Illumina DNA sequencing platform generates accurate but short reads, which can be used to produce accurate but fragmented genome assemblies. Pacific Biosciences and Oxford Nanopore Technologies DNA sequencing platforms generate long reads that can produce complete genome assemblies, but the sequencing is more expensive and error-prone. There is significant interest in combining data from these complementary sequencing technologies to generate more accurate “hybrid” assemblies. However, few tools exist that truly leverage the benefits of both types of data, namely the accuracy of short reads and the structural resolving power of long reads. Here we present Unicycler, a new tool for assembling bacterial genomes from a combination of short and long reads, which produces assemblies that are accurate, complete and cost-effective. Unicycler builds an initial assembly graph from short reads using the de novo assembler SPAdes and then simplifies the graph using information from short and long reads. Unicycler uses a novel semi-global aligner to align long reads to the assembly graph. Tests on both synthetic and real reads show Unicycler can assemble larger contigs with fewer misassemblies than other hybrid assemblers, even when long-read depth and accuracy are low. Unicycler is open source (GPLv3) and available at github.com/rrwick/Unicycler.},
	number = {6},
	urldate = {2018-09-20},
	journal = {PLOS Computational Biology},
	author = {Wick, Ryan R. and Judd, Louise M. and Gorrie, Claire L. and Holt, Kathryn E.},
	editor = {Phillippy, Adam M.},
	month = jun,
	year = {2017},
	note = {Publisher: Public Library of Science},
	pages = {e1005595},
}

@article{Koren2016,
	title = {Canu: scalable and accurate long-read assembly via adaptive k-mer weighting and repeat separation},
	url = {https://www.biorxiv.org/content/early/2016/08/24/071282},
	doi = {10.1101/071282},
	abstract = {Long-read single-molecule sequencing has revolutionized de novo genome assembly and enabled the automated reconstruction of reference-quality genomes. However, given the relatively high error rates of such technologies, efficient and accurate assembly of large repeats and closely related haplotypes remains challenging. We address these issues with Canu, a complete reworking of Celera Assembler that is specifically designed for noisy single-molecule sequences. Canu introduces support for nanopore sequencing, halves depth-of-coverage requirements, and improves assembly continuity while simultaneously reducing runtime by an order of magnitude on large genomes. These advances result from new overlapping and assembly algorithms, including an adaptive overlapping strategy based on tf-idf weighted MinHash and a sparse assembly graph construction that avoids collapsing diverged repeats and haplotypes. We demonstrate that Canu can reliably assemble complete microbial genomes and near-complete eukaryotic chromosomes using either PacBio or Oxford Nanopore technologies, and achieves a contig NG50 of greater than 21 Mbp on both human and Drosophila melanogaster PacBio datasets. For assembly structures that cannot be linearly represented, Canu provides graph-based assembly outputs for analysis or integration with complementary phasing and scaffolding techniques. Canu source code and pre-compiled binaries are freely available under a GPLv2 license from https://github.com/marbl/canu.},
	urldate = {2018-09-20},
	journal = {bioRxiv},
	author = {Koren, Sergey and Walenz, Brian P. and Berlin, Konstantin and Miller, Jason R. and Phillippy, Adam M.},
	month = aug,
	year = {2016},
	note = {Publisher: Cold Spring Harbor Laboratory},
	pages = {071282},
}

@article{yang_molecular_2012,
	title = {Molecular phylogenetics: principles and practice},
	volume = {13},
	issn = {1471-0056},
	url = {http://www.nature.com/articles/nrg3186},
	doi = {10.1038/nrg3186},
	abstract = {Phylogenetic analysis is pervading every field of biological study. The authors review and assess the main methods of phylogenetic analysis — including parsimony, distance, likelihood and Bayesian methods — and provide guidance for selecting the most appropriate approach and software package.},
	number = {5},
	urldate = {2018-09-20},
	journal = {Nature Reviews Genetics},
	author = {Yang, Ziheng and Rannala, Bruce},
	month = may,
	year = {2012},
	note = {Publisher: Nature Publishing Group},
	keywords = {Bioinformatics, Evolutionary biology, Phylogenetics, Phylogenomics, Population genetics},
	pages = {303--314},
}

@article{Flicek2007,
	title = {Gene prediction: compare and {CONTRAST}.},
	volume = {8},
	issn = {1474-760X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18096089},
	doi = {10.1186/gb-2007-8-12-233},
	abstract = {CONTRAST, a new gene-prediction algorithm that uses sophisticated machine-learning techniques, has pushed de novo prediction accuracy to new heights, and has significantly closed the gap between de novo and evidence-based methods for human genome annotation.},
	number = {12},
	urldate = {2018-09-20},
	journal = {Genome biology},
	author = {Flicek, Paul},
	year = {2007},
	pmid = {18096089},
	note = {Publisher: BioMed Central},
	pages = {233},
}

@article{bailey_meme_2009,
	title = {{MEME} {SUITE}: tools for motif discovery and searching.},
	volume = {37},
	issn = {1362-4962},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19458158},
	doi = {10.1093/nar/gkp335},
	abstract = {The MEME Suite web server provides a unified portal for online discovery and analysis of sequence motifs representing features such as DNA binding sites and protein interaction domains. The popular MEME motif discovery algorithm is now complemented by the GLAM2 algorithm which allows discovery of motifs containing gaps. Three sequence scanning algorithms--MAST, FIMO and GLAM2SCAN--allow scanning numerous DNA and protein sequence databases for motifs discovered by MEME and GLAM2. Transcription factor motifs (including those discovered using MEME) can be compared with motifs in many popular motif databases using the motif database scanning algorithm TOMTOM. Transcription factor motifs can be further analyzed for putative function by association with Gene Ontology (GO) terms using the motif-GO term association tool GOMO. MEME output now contains sequence LOGOS for each discovered motif, as well as buttons to allow motifs to be conveniently submitted to the sequence and motif database scanning algorithms (MAST, FIMO and TOMTOM), or to GOMO, for further analysis. GLAM2 output similarly contains buttons for further analysis using GLAM2SCAN and for rerunning GLAM2 with different parameters. All of the motif-based tools are now implemented as web services via Opal. Source code, binaries and a web server are freely available for noncommercial use at http://meme.nbcr.net.},
	number = {Web Server issue},
	urldate = {2018-09-20},
	journal = {Nucleic acids research},
	author = {Bailey, Timothy L and Boden, Mikael and Buske, Fabian A and Frith, Martin and Grant, Charles E and Clementi, Luca and Ren, Jingyuan and Li, Wilfred W and Noble, William S},
	month = jul,
	year = {2009},
	pmid = {19458158},
	note = {Publisher: Oxford University Press},
	pages = {W202--8},
}

@article{Small2014,
	title = {Fluorophore localization algorithms for super-resolution microscopy.},
	volume = {11},
	issn = {1548-7105},
	url = {http://www.nature.com/articles/nmeth.2844},
	doi = {10.1038/nmeth.2844},
	abstract = {Super-resolution localization microscopy methods provide powerful new capabilities for probing biology at the nanometer scale via fluorescence. These methods rely on two key innovations: switchable fluorophores (which blink on and off and can be sequentially imaged) and powerful localization algorithms (which estimate the positions of the fluorophores in the images). These techniques have spurred a flurry of innovation in algorithm development over the last several years. In this Review, we survey the fundamental issues for single-fluorophore fitting routines, localization algorithms based on principles other than fitting, three-dimensional imaging, dipole imaging and techniques for estimating fluorophore positions from images of multiple activated fluorophores. We offer practical advice for users and adopters of algorithms, and we identify areas for further development.},
	number = {3},
	urldate = {2018-09-20},
	journal = {Nature methods},
	author = {Small, Alex and Stahlheber, Shane},
	month = mar,
	year = {2014},
	pmid = {24577277},
	pages = {267--79},
}

@article{Mai2018,
	title = {{ADCN}: {An} anisotropic density-based clustering algorithm for discovering spatial point patterns with noise},
	volume = {22},
	issn = {13611682},
	url = {http://doi.wiley.com/10.1111/tgis.12313},
	doi = {10.1111/tgis.12313},
	number = {1},
	urldate = {2018-09-18},
	journal = {Transactions in GIS},
	author = {Mai, Gengchen and Janowicz, Krzysztof and Hu, Yingjie and Gao, Song},
	month = feb,
	year = {2018},
	note = {Publisher: Wiley/Blackwell (10.1111)},
	pages = {348--369},
}

@article{Cortese2017,
	title = {Ultrastructural {Characterization} of {Zika} {Virus} {Replication} {Factories}},
	volume = {18},
	issn = {22111247},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/28249158},
	doi = {10.1016/j.celrep.2017.02.014},
	abstract = {A global concern has emerged with the pandemic spread of Zika virus (ZIKV) infections that can cause severe neurological symptoms in adults and newborns. ZIKV is a positive-strand RNA virus replicating in virus-induced membranous replication factories (RFs). Here we used various imaging techniques to investigate the ultrastructural details of ZIKV RFs and their relationship with host cell organelles. Analyses of human hepatic cells and neural progenitor cells infected with ZIKV revealed endoplasmic reticulum (ER) membrane invaginations containing pore-like openings toward the cytosol, reminiscent to RFs in Dengue virus-infected cells. Both the MR766 African strain and the H/PF/2013 Asian strain, the latter linked to neurological diseases, induce RFs of similar architecture. Importantly, ZIKV infection causes a drastic reorganization of microtubules and intermediate filaments forming cage-like structures surrounding the viral RF. Consistently, ZIKV replication is suppressed by cytoskeleton-targeting drugs. Thus, ZIKV RFs are tightly linked to rearrangements of the host cell cytoskeleton.},
	number = {9},
	urldate = {2018-09-17},
	journal = {Cell Reports},
	author = {Cortese, Mirko and Goellner, Sarah and Acosta, Eliana Gisela and Neufeldt, Christopher John and Oleksiuk, Olga and Lampe, Marko and Haselmann, Uta and Funaya, Charlotta and Schieber, Nicole and Ronchi, Paolo and Schorb, Martin and Pruunsild, Priit and Schwab, Yannick and Chatel-Chaix, Laurent and Ruggieri, Alessia and Bartenschlager, Ralf},
	year = {2017},
	pmid = {28249158},
	note = {Publisher: Elsevier
ISBN: 2211-1247},
	keywords = {Zika virus, electron microscopy, electron tomography, flavivirus, human neural progenitor cells, intermediate filaments, live-cell imaging, microtubules, replication factories, replication organelles},
	pages = {2113--2123},
}

@article{Khan2018,
	title = {A {Comprehensive} {Study} of {De} {Novo} {Genome} {Assemblers}: {Current} {Challenges} and {Future} {Prospective}},
	volume = {14},
	issn = {1176-9343},
	url = {http://journals.sagepub.com/doi/10.1177/1176934318758650},
	doi = {10.1177/1176934318758650},
	abstract = {Background:Current advancements in next-generation sequencing technology have made possible to sequence whole genome but assembling a large number of short sequence reads is still a big challenge. In this article, we present the comparative study of seven assemblers, namely, ABySS, Velvet, Edena, SGA, Ray, SSAKE, and Perga, using prokaryotic and eukaryotic paired-end as well as single-end data sets from Illumina platform.Results:Results showed that in case of single-end data sets, Velvet and ABySS outperformed in all the seven assemblers with comparatively low assembling time and high genome fraction. Velvet consumed the least amount of memory than any other assembler. In case of paired-end data sets, Velvet consumed least amount of time and produced high genome fraction after ABySS and Ray. In terms of low memory usage, SGA and Edena outperformed in all the assemblers. Ray also showed good genome fraction; however, extremely high assembling time consumed by the Ray might make it prohibitively slow on lar...},
	urldate = {2018-09-12},
	journal = {Evolutionary Bioinformatics},
	author = {Khan, Abdul Rafay and Pervez, Muhammad Tariq and Babar, Masroor Ellahi and Naveed, Nasir and Shoaib, Muhammad},
	month = jan,
	year = {2018},
	note = {Publisher: SAGE PublicationsSage UK: London, England},
	keywords = {DBG (de Bruijn graph), ENA (European Nucleotide Archive), NGS (next-generation sequencing), OLC (overlap layout consensus), bps (base pairs)},
	pages = {117693431875865},
}

@article{Stegle2015,
	title = {Computational and analytical challenges in single-cell transcriptomics},
	volume = {16},
	issn = {1471-0056},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25628217},
	doi = {10.1038/nrg3833},
	abstract = {The development of high-throughput RNA sequencing (RNA-seq) at the single-cell level has already led to profound new discoveries in biology, ranging from the identification of novel cell types to the study of global patterns of stochastic gene expression. Alongside the technological breakthroughs that have facilitated the large-scale generation of single-cell transcriptomic data, it is important to consider the specific computational and analytical challenges that still have to be overcome. Although some tools for analysing RNA-seq data from bulk cell populations can be readily applied to single-cell RNA-seq data, many new computational strategies are required to fully exploit this data type and to enable a comprehensive yet detailed study of gene expression at the single-cell level.},
	number = {3},
	urldate = {2018-09-12},
	journal = {Nature Reviews Genetics},
	author = {Stegle, Oliver and Teichmann, Sarah A. and Marioni, John C.},
	month = mar,
	year = {2015},
	pmid = {25628217},
	pages = {133--145},
}

@article{Schnitzbauer2018,
	title = {Correlation analysis framework for localization-based superresolution microscopy},
	volume = {115},
	issn = {0027-8424},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/29531072},
	doi = {10.1073/pnas.1711314115},
	abstract = {Superresolution images reconstructed from single-molecule localizations can reveal cellular structures close to the macromolecular scale and are now being used routinely in many biomedical research applications. However, because of their coordinate-based representation, a widely applicable and unified analysis platform that can extract a quantitative description and biophysical parameters from these images is yet to be established. Here, we propose a conceptual framework for correlation analysis of coordinate-based superresolution images using distance histograms. We demonstrate the application of this concept in multiple scenarios, including image alignment, tracking of diffusing molecules, as well as for quantification of colocalization, showing its superior performance over existing approaches.},
	number = {13},
	urldate = {2018-09-12},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Schnitzbauer, Joerg and Wang, Yina and Zhao, Shijie and Bakalar, Matthew and Nuwal, Tulip and Chen, Baohui and Huang, Bo},
	month = mar,
	year = {2018},
	pmid = {29531072},
	keywords = {diffusion, image analysis, single-molecule imaging, superresolution microscopy},
	pages = {3219--3224},
}

@article{Mailfert2018,
	title = {A {Theoretical} {High}-{Density} {Nanoscopy} {Study} {Leads} to the {Design} of {UNLOC}, a {Parameter}-free {Algorithm}},
	volume = {115},
	issn = {00063495},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/30029772},
	doi = {10.1016/j.bpj.2018.06.024},
	abstract = {Single-molecule localization microscopy (SMLM) enables the production of high-resolution images by imaging spatially isolated fluorescent particles. Although challenging, the result of SMLM analysis lists the position of individual molecules, leading to a valuable quantification of the stoichiometry and spatial organization of molecular actors. Both the signal/noise ratio and the density (Dframe), i.e., the number of fluorescent particles per μm2 per frame, have previously been identified as determining factors for reaching a given SMLM precision. Establishing a comprehensive theoretical study relying on these two parameters is therefore of central interest to delineate the achievable limits for accurate SMLM observations. Our study reports that in absence of prior knowledge of the signal intensity α, the density effect on particle localization is more prominent than that anticipated from theoretical studies performed at known α. A first limit appears when, under a low-density hypothesis (i.e., one-Gaussian fitting hypothesis), any fluorescent particle distant by less than ∼600 nm from the particle of interest biases its localization. In fact, all particles should be accounted for, even those dimly fluorescent, to ascertain unbiased localization of any surrounding particles. Moreover, even under a high-density hypothesis (i.e., multi-Gaussian fitting hypothesis), a second limit arises because of the impossible distinction of particles located too closely. An increase in Dframe is thus likely to deteriorate the localization precision, the image reconstruction, and more generally the quantification accuracy. Our study firstly provides a density-signal/noise ratio space diagram for use as a guide in data recording toward reaching an achievable SMLM resolution. Additionally, it leads to the identification of the essential requirements for implementing UNLOC, a parameter-free and fast computing algorithm approaching the Cramér-Rao bound for particles at high-density per frame and without any prior knowledge of their intensity. UNLOC is available as an ImageJ plugin.},
	number = {3},
	urldate = {2018-09-12},
	journal = {Biophysical Journal},
	author = {Mailfert, Sébastien and Touvier, Jérôme and Benyoussef, Lamia and Fabre, Roxane and Rabaoui, Asma and Blache, Marie-Claire and Hamon, Yannick and Brustlein, Sophie and Monneret, Serge and Marguet, Didier and Bertaux, Nicolas},
	month = aug,
	year = {2018},
	pmid = {30029772},
	pages = {565--576},
}

@article{Altschul1990,
	title = {Basic local alignment search tool},
	volume = {215},
	issn = {0022-2836},
	url = {https://www.sciencedirect.com/science/article/pii/S0022283605803602?via%3Dihub},
	doi = {10.1016/S0022-2836(05)80360-2},
	abstract = {A new approach to rapid sequence comparison, basic local alignment search tool (BLAST), directly approximates alignments that optimize a measure of local similarity, the maximal segment pair (MSP) score. Recent mathematical results on the stochastic properties of MSP scores allow an analysis of the performance of this method as well as the statistical significance of alignments it generates. The basic algorithm is simple and robust; it can be implemented in a number of ways and applied in a variety of contexts including straight-forward DNA and protein sequence database searches, motif searches, gene identification searches, and in the analysis of multiple regions of similarity in long DNA sequences. In addition to its flexibility and tractability to mathematical analysis, BLAST is an order of magnitude faster than existing sequence comparison tools of comparable sensitivity.},
	number = {3},
	urldate = {2018-09-09},
	journal = {Journal of Molecular Biology},
	author = {Altschul, Stephen F. and Gish, Warren and Miller, Webb and Myers, Eugene W. and Lipman, David J.},
	month = oct,
	year = {1990},
	note = {Publisher: Academic Press},
	pages = {403--410},
}

@article{Shechtman2016,
	title = {Multicolour localization microscopy by point-spread-function engineering},
	issn = {17494893},
	doi = {10.1038/nphoton.2016.137},
	abstract = {Super-resolution microscopy has revolutionized cellular imaging in recent years1, 2, 3, 4. Methods that rely on sequential localization of single point emitters enable spatial tracking at a resolution of ∼10–40 nm. Moreover, tracking and imaging in three dimensions is made possible by various techniques, including point-spread-function (PSF) engineering5, 6, 7, 8, 9—namely, encoding the axial (z) position of a point source in the shape that it creates in the image plane. However, efficient multicolour imaging remains a challenge for localization microscopy—a task of the utmost importance for contextualizing biological data. Normally, multicolour imaging requires sequential imaging10, 11, multiple cameras12 or segmented dedicated fields of view13, 14. Here, we demonstrate an alternate strategy: directly encoding the spectral information (colour), in addition to three-dimensional position, in the image. By exploiting chromatic dispersion we design a new class of optical phase masks that simultaneously yield controllably different PSFs for different wavelengths, enabling simultaneous multicolour tracking or super-resolution imaging in a single optical path.},
	journal = {Nature Photonics},
	author = {Shechtman, Yoav and Weiss, Lucien E. and Backer, Adam S. and Lee, Maurice Y. and Moerner, W. E.},
	year = {2016},
	pmid = {28413434},
	note = {ISBN: 1749-4893},
}

@article{Dai2016,
	title = {Optical imaging of individual biomolecules in densely packed clusters},
	issn = {17483395},
	doi = {10.1038/nnano.2016.95},
	abstract = {Recent advances in fluorescence super-resolution microscopy have allowed subcellular features and synthetic nanostructures down to 10-20 nm in size to be imaged. However, the direct optical observation of individual molecular targets (∼5 nm) in a densely packed biomolecular cluster remains a challenge. Here, we show that such discrete molecular imaging is possible using DNA-PAINT (points accumulation for imaging in nanoscale topography)—a super-resolution fluorescence microscopy technique that exploits programmable transient oligonucleotide hybridization—on synthetic DNA nanostructures. We examined the effects of a high photon count, high blinking statistics and an appropriate blinking duty cycle on imaging quality, and developed a software-based drift correction method that achieves {\textless}1 nm residual drift (root mean squared) over hours. This allowed us to image a densely packed triangular lattice pattern with ∼5 nm point-to-point distance and to analyse the DNA origami structural offset with ångström-level precision (2 Å) from single-molecule studies. By combining the approach with multiplexed exchange-PAINT imaging, we further demonstrated an optical nanodisplay with 5 × 5 nm pixel size and three distinct colours with {\textless}1 nm cross-channel registration accuracy.},
	journal = {Nature Nanotechnology},
	author = {Dai, Mingjie and Jungmann, Ralf and Yin, Peng},
	year = {2016},
	pmid = {27376244},
	note = {arXiv: 15334406
ISBN: 1748-3395 (Electronic){\textbackslash}r1748-3387 (Linking)},
}

@article{Bourg2015,
	title = {Direct optical nanoscopy with axially localized detection},
	issn = {17494893},
	doi = {10.1038/nphoton.2015.132},
	abstract = {Evanescent light excitation is widely used in super-resolution fluorescence microscopy to confine light and reduce background noise. Herein we propose a method of exploiting evanescent light in the context of emission. When a fluorophore is located in close proximity to a medium with a higher refractive index, its near-field component is converted into light that propagates beyond the critical angle. This so-called Supercritical Angle Fluorescence (SAF) can be captured using a hig-NA objective and used to determine the axial position of the fluorophore with nanometer precision. We introduce a new technique for 3D nanoscopy that combines direct STochastic Optical Reconstruction Microscopy (dSTORM) imaging with dedicated detection of SAF emission. We demonstrate that our approach of a Direct Optical Nanoscopy with Axially Localized Detection (DONALD) yields a typical isotropic 3D localization precision of 20 nm.},
	journal = {Nature Photonics},
	author = {Bourg, N. and Mayet, C. and Dupuis, G. and Barroca, T. and Bon, P. and Lécart, S. and Fort, E. and Lévêque-Fort, S.},
	year = {2015},
	note = {arXiv: 1410.1563
ISBN: 1749-4885},
}

@article{evans_fever_2015,
	title = {Fever and the thermal regulation of immunity: the immune system feels the heat.},
	volume = {15},
	issn = {1474-1741},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25976513},
	doi = {10.1038/nri3843},
	abstract = {Fever is a cardinal response to infection that has been conserved in warm-blooded and cold-blooded vertebrates for more than 600 million years of evolution. The fever response is executed by integrated physiological and neuronal circuitry and confers a survival benefit during infection. In this Review, we discuss our current understanding of how the inflammatory cues delivered by the thermal element of fever stimulate innate and adaptive immune responses. We further highlight the unexpected multiplicity of roles of the pyrogenic cytokine interleukin-6 (IL-6), both during fever induction and during the mobilization of lymphocytes to the lymphoid organs that are the staging ground for immune defence. We also discuss the emerging evidence suggesting that the adrenergic signalling pathways associated with thermogenesis shape immune cell function.},
	number = {6},
	urldate = {2018-09-02},
	journal = {Nature reviews. Immunology},
	author = {Evans, Sharon S and Repasky, Elizabeth A and Fisher, Daniel T},
	month = jun,
	year = {2015},
	pmid = {25976513},
	note = {Publisher: NIH Public Access},
	pages = {335--49},
}

@article{Ober2015,
	title = {Quantitative {Aspects} of {Single} {Molecule} {Microscopy}.},
	volume = {32},
	issn = {1053-5888},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26167102},
	doi = {10.1109/MSP.2014.2353664},
	abstract = {Single molecule microscopy is a relatively new optical microscopy technique that allows the detection of individual molecules such as proteins in a cellular context. This technique has generated significant interest among biologists, biophysicists and biochemists, as it holds the promise to provide novel insights into subcellular processes and structures that otherwise cannot be gained through traditional experimental approaches. Single molecule experiments place stringent demands on experimental and algorithmic tools due to the low signal levels and the presence of significant extraneous noise sources. Consequently, this has necessitated the use of advanced statistical signal and image processing techniques for the design and analysis of single molecule experiments. In this tutorial paper, we provide an overview of single molecule microscopy from early works to current applications and challenges. Specific emphasis will be on the quantitative aspects of this imaging modality, in particular single molecule localization and resolvability, which will be discussed from an information theoretic perspective. We review the stochastic framework for image formation, different types of estimation techniques and expressions for the Fisher information matrix. We also discuss several open problems in the field that demand highly non-trivial signal processing algorithms.},
	number = {1},
	urldate = {2018-08-30},
	journal = {IEEE signal processing magazine},
	author = {Ober, Raimund J and Tahmasbi, Amir and Ram, Sripad and Lin, Zhiping and Ward, E Sally},
	month = jan,
	year = {2015},
	pmid = {26167102},
	note = {Publisher: NIH Public Access},
	pages = {58--69},
}

@inproceedings{Chao2009,
	title = {A {3D} resolution measure for optical microscopy},
	isbn = {978-1-4244-3931-7},
	url = {http://ieeexplore.ieee.org/document/5193252/},
	doi = {10.1109/ISBI.2009.5193252},
	urldate = {2018-08-30},
	booktitle = {2009 {IEEE} {International} {Symposium} on {Biomedical} {Imaging}: {From} {Nano} to {Macro}},
	publisher = {IEEE},
	author = {Chao, Jerry and Ram, Sripad and Ward, E. Sally and Ober, Raimund J.},
	month = jun,
	year = {2009},
	pages = {1115--1118},
}

@article{Luxburg2006,
	title = {A {Tutorial} on {Spectral} {Clustering} {A} {Tutorial} on {Spectral} {Clustering}},
	volume = {17},
	issn = {09603174},
	url = {http://www.springerlink.com/index/10.1007/s11222-007-9033-z},
	doi = {10.1007/s11222-007-9033-z},
	abstract = {In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. Nevertheless, on the first glance spectral clustering looks a bit mysterious, and it is not obvious to see why it works at all and what it really does. This article is a tutorial introduction to spectral clustering. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.},
	number = {March},
	journal = {Statistics and Computing},
	author = {Luxburg, Ulrike Von},
	year = {2006},
	pmid = {19784854},
	note = {arXiv: 0711.0189v1
ISBN: 0960-3174},
	keywords = {graph laplacian, spectral clustering},
	pages = {395--416},
}

@article{soubies_continuous_2015,
	title = {A {Continuous} {Exact} \${\textbackslash}ell\_0\$ {Penalty} ({CEL0}) for {Least} {Squares} {Regularized} {Problem}},
	volume = {8},
	issn = {1936-4954},
	url = {http://epubs.siam.org/doi/10.1137/151003714},
	doi = {10.1137/151003714},
	number = {3},
	urldate = {2018-08-30},
	journal = {SIAM Journal on Imaging Sciences},
	author = {Soubies, Emmanuel and Blanc-Féraud, Laure and Aubert, Gilles},
	month = jan,
	year = {2015},
	pages = {1607--1639},
}

@inproceedings{Gazagnes2017,
	title = {High density molecule localization for super-resolution microscopy using {CEL0} based sparse approximation},
	isbn = {978-1-5090-1172-8},
	url = {http://ieeexplore.ieee.org/document/7950460/},
	doi = {10.1109/ISBI.2017.7950460},
	urldate = {2018-08-30},
	booktitle = {2017 {IEEE} 14th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI} 2017)},
	publisher = {IEEE},
	author = {Gazagnes, Simon and Soubies, Emmanuel and Blanc-Feraud, Laure},
	month = apr,
	year = {2017},
	pages = {28--31},
}

@article{Min2015,
	title = {{FALCON}: fast and unbiased reconstruction of high-density super-resolution microscopy data},
	volume = {4},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep04577},
	doi = {10.1038/srep04577},
	abstract = {FALCON: fast and unbiased reconstruction of high-density super-resolution microscopy data},
	number = {1},
	urldate = {2018-08-30},
	journal = {Scientific Reports},
	author = {Min, Junhong and Vonesch, Cédric and Kirshner, Hagai and Carlini, Lina and Olivier, Nicolas and Holden, Seamus and Manley, Suliana and Ye, Jong Chul and Unser, Michael},
	month = may,
	year = {2015},
	note = {Publisher: Nature Publishing Group},
	keywords = {Mathematics and computing, Molecular biology, Nanoscience and technology},
	pages = {4577},
}

@article{Ashdown2017,
	title = {Live-{Cell} {Super}-resolution {Reveals} {F}-{Actin} and {Plasma} {Membrane} {Dynamics} at the {T} {Cell} {Synapse}},
	volume = {112},
	issn = {00063495},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/28445761},
	doi = {10.1016/j.bpj.2017.01.038},
	abstract = {The cortical actin cytoskeleton has been shown to be critical for the reorganization and heterogeneity of plasma membrane components of many cells, including T cells. Building on previous studies at the T cell immunological synapse, we quantitatively assess the structure and dynamics of this meshwork using live-cell superresolution fluorescence microscopy and spatio-temporal image correlation spectroscopy. We show for the first time, to our knowledge, that not only does the dense actin cortex flow in a retrograde fashion toward the synapse center, but the plasma membrane itself shows similar behavior. Furthermore, using two-color, live-cell superresolution cross-correlation spectroscopy, we demonstrate that the two flows are correlated and, in addition, we show that coupling may extend to the outer leaflet of the plasma membrane by examining the flow of GPI-anchored proteins. Finally, we demonstrate that the actin flow is correlated with a third component, α-actinin, which upon CRISPR knockout led to reduced plasma membrane flow directionality despite increased actin flow velocity. We hypothesize that this apparent cytoskeletal-membrane coupling could provide a mechanism for driving the observed retrograde flow of signaling molecules such as the TCR, Lck, ZAP70, LAT, and SLP76.},
	number = {8},
	urldate = {2018-08-29},
	journal = {Biophysical Journal},
	author = {Ashdown, George W. and Burn, Garth L. and Williamson, David J. and Pandžić, Elvis and Peters, Ruby and Holden, Michael and Ewers, Helge and Shao, Lin and Wiseman, Paul W. and Owen, Dylan M.},
	month = apr,
	year = {2017},
	pmid = {28445761},
	pages = {1703--1713},
}

@article{Li2016,
	title = {Learning to {Optimize}},
	url = {http://arxiv.org/abs/1606.01885},
	abstract = {Algorithm design is a laborious process and often requires many iterations of ideation and validation. In this paper, we explore automating algorithm design and present a method to learn an optimization algorithm, which we believe to be the first method that can automatically discover a better algorithm. We approach this problem from a reinforcement learning perspective and represent any particular optimization algorithm as a policy. We learn an optimization algorithm using guided policy search and demonstrate that the resulting algorithm outperforms existing hand-engineered algorithms in terms of convergence speed and/or the final objective value.},
	urldate = {2018-08-28},
	author = {Li, Ke and Malik, Jitendra},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.01885},
}

@article{wang_3d_2010,
	title = {{3D} knowledge-based segmentation using pose-invariant higher-order graphs.},
	volume = {13},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20879399},
	abstract = {Segmentation is a fundamental problem in medical image analysis. The use of prior knowledge is often considered to address the ill-posedness of the process. Such a process consists in bringing all training examples in the same reference pose, and then building statistics. During inference, pose parameters are usually estimated first, and then one seeks a compromise between data-attraction and model-fitness with the prior model. In this paper, we propose a novel higher-order Markov Random Field (MRF) model to encode pose-invariant priors and perform 3D segmentation of challenging data. The approach encodes data support in the singleton terms that are obtained using machine learning, and prior constraints in the higher-order terms. A dual-decomposition-based inference method is used to recover the optimal solution. Promising results on challenging data involving segmentation of tissue classes of the human skeletal muscle demonstrate the potentials of the method.},
	number = {Pt 3},
	urldate = {2018-08-26},
	journal = {Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
	author = {Wang, Chaohui and Teboul, Olivier and Michel, Fabrice and Essafi, Salma and Paragios, Nikos},
	year = {2010},
	pmid = {20879399},
	pages = {189--96},
}

@article{Miolane2018,
	title = {geomstats: a {Python} {Package} for {Riemannian} {Geometry} in {Machine} {Learning}},
	url = {http://arxiv.org/abs/1805.08308},
	abstract = {We introduce geomstats, a python package that performs computations on manifolds such as hyperspheres, hyperbolic spaces, spaces of symmetric positive definite matrices and Lie groups of transformations. We provide efficient and extensively unit-tested implementations of these manifolds, together with useful Riemannian metrics and associated Exponential and Logarithm maps. The corresponding geodesic distances provide a range of intuitive choices of Machine Learning loss functions. We also give the corresponding Riemannian gradients. The operations implemented in geomstats are available with different computing backends such as numpy, tensorflow and keras. We have enabled GPU implementation and integrated geomstats manifold computations into keras deep learning framework. This paper also presents a review of manifolds in machine learning and an overview of the geomstats package with examples demonstrating its use for efficient and user-friendly Riemannian geometry.},
	urldate = {2018-08-25},
	author = {Miolane, Nina and Mathe, Johan and Donnat, Claire and Jorda, Mikael and Pennec, Xavier},
	month = may,
	year = {2018},
	note = {arXiv: 1805.08308},
}

@article{Budowski-Tal2018,
	title = {A {Novel} {Geometry}-{Based} {Approach} to {Infer} {Protein} {Interface} {Similarity}},
	volume = {8},
	issn = {2045-2322},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/29844500},
	doi = {10.1038/s41598-018-26497-z},
	abstract = {The protein interface is key to understand protein function, providing a vital insight on how proteins interact with each other and with other molecules. Over the years, many computational methods to compare protein structures were developed, yet evaluating interface similarity remains a very difficult task. Here, we present PatchBag - a geometry based method for efficient comparison of protein surfaces and interfaces. PatchBag is a Bag-Of-Words approach, which represents complex objects as vectors, enabling to search interface similarity in a highly efficient manner. Using a novel framework for evaluating interface similarity, we show that PatchBag performance is comparable to state-of-the-art alignment-based structural comparison methods. The great advantage of PatchBag is that it does not rely on sequence or fold information, thus enabling to detect similarities between interfaces in unrelated proteins. We propose that PatchBag can contribute to reveal novel evolutionary and functional relationships between protein interfaces.},
	number = {1},
	urldate = {2018-08-15},
	journal = {Scientific Reports},
	author = {Budowski-Tal, Inbal and Kolodny, Rachel and Mandel-Gutfreund, Yael},
	month = dec,
	year = {2018},
	pmid = {29844500},
	pages = {8192},
}

@article{Mandal1997,
	title = {Selection of alpha for alpha-hull in {R2}},
	volume = {30},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320396001768},
	doi = {10.1016/S0031-3203(96)00176-8},
	abstract = {For finding the shape of a planar set, Edelsbrunner, Kirkpatrick and Seidel introduced the concept of α-hulls as a natural generalization of convex hulls. While the α-hull is elegant and efficient to compute, it still suffers from a major drawback, i.e. the single parameter, namely α, must nevertheless be tuned. This paper deals with finding a way to overcome this drawback, i.e. we proposed here a selection criterion of α for α-hulls corresponding to a point set in R2. The selection criterion of α is based on the concept of minimum spanning trees and certain existing results. The effectiveness of the proposed selection criterion is demonstrated on some artificially generated data sets. The convergence (with sample size) of the α-hull, based on the proposed selection criterion for α, to the original pattern class has also been verified using symmetric difference, the Hausdorff metric, and a similarity metric.},
	number = {10},
	urldate = {2018-08-06},
	journal = {Pattern Recognition},
	author = {Mandal, Deba Prasad and Murthy, C.A},
	month = oct,
	year = {1997},
	note = {Publisher: Pergamon},
	pages = {1759--1767},
}

@article{joe_delaunay_1991,
	title = {Delaunay versus max-min solid angle triangulations for three-dimensional mesh generation},
	volume = {31},
	issn = {0029-5981},
	url = {http://doi.wiley.com/10.1002/nme.1620310511},
	doi = {10.1002/nme.1620310511},
	number = {5},
	urldate = {2018-08-06},
	journal = {International Journal for Numerical Methods in Engineering},
	author = {Joe, Barry},
	month = apr,
	year = {1991},
	note = {Publisher: Wiley-Blackwell},
	pages = {987--997},
}

@incollection{ota_principal_2016,
	title = {Principal {Component} {Analysis} of {Two}-{Dimensional} {Flow} {Vector} {Fields} on {Human} {Facial} {Skin} for {Efficient} {Robot} {Face} {Design}},
	url = {http://link.springer.com/10.1007/978-3-319-42417-0_19},
	urldate = {2018-07-31},
	publisher = {Springer, Cham},
	author = {Ota, Nobuyuki and Ishihara, Hisashi and Asada, Minoru},
	year = {2016},
	doi = {10.1007/978-3-319-42417-0_19},
	pages = {203--213},
}

@article{Osada2002,
	title = {Shape distributions},
	volume = {21},
	issn = {07300301},
	url = {http://portal.acm.org/citation.cfm?doid=571647.571648},
	doi = {10.1145/571647.571648},
	number = {4},
	urldate = {2018-07-29},
	journal = {ACM Transactions on Graphics},
	author = {Osada, Robert and Funkhouser, Thomas and Chazelle, Bernard and Dobkin, David},
	month = oct,
	year = {2002},
	note = {Publisher: ACM},
	keywords = {Shape analysis, shape representation},
	pages = {807--832},
}

@article{Roweis2000,
	title = {Nonlinear {Dimensionality} {Reduction} by {Locally} {Linear} {Embedding}},
	volume = {290},
	issn = {00368075},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/11125150},
	doi = {10.1126/science.290.5500.2323},
	abstract = {Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.},
	number = {5500},
	urldate = {2018-07-29},
	journal = {Science},
	author = {Roweis, S. T. and Saul, L K},
	month = dec,
	year = {2000},
	pmid = {11125150},
	pages = {2323--2326},
}

@incollection{Dinh2008,
	title = {Measuring the {Similarity} of {Vector} {Fields} {Using} {Global} {Distributions}},
	isbn = {978-3-540-89688-3},
	url = {http://link.springer.com/10.1007/978-3-540-89689-0_23},
	urldate = {2018-07-29},
	booktitle = {Proceedings of the 2008 {Joint} {IAPR} {International} {Workshop} on {Structural}, {Syntactic}, and {Statistical} {Pattern} {Recognition}},
	publisher = {Springer-Verlag},
	author = {Dinh, H. Quynh and Xu, Liefei},
	year = {2008},
	doi = {10.1007/978-3-540-89689-0_23},
	keywords = {geometric histogram, shape distribution, vector field matching},
	pages = {187--196},
}

@incollection{Li2006a,
	title = {Manifold {Learning} of {Vector} {Fields}},
	url = {http://link.springer.com/10.1007/11759966_64},
	urldate = {2018-07-29},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Li, Hongyu and Shen, I-Fan},
	year = {2006},
	doi = {10.1007/11759966_64},
	pages = {430--435},
}

@article{Aarti1999,
	title = {Data clustering},
	author = {Aarti, Spectral Clustering},
	year = {1999},
	pages = {1--8},
}

@incollection{Li2006,
	title = {Similarity {Measure} for {Vector} {Field} {Learning}},
	url = {http://link.springer.com/10.1007/11759966_65},
	urldate = {2018-07-29},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Li, Hongyu and Shen, I-Fan},
	year = {2006},
	doi = {10.1007/11759966_65},
	pages = {436--441},
}

@inproceedings{Sahillioglu2010,
	title = {{3D} {Shape} correspondence by isometry-driven greedy optimization},
	isbn = {978-1-4244-6984-0},
	url = {http://ieeexplore.ieee.org/document/5540178/},
	doi = {10.1109/CVPR.2010.5540178},
	urldate = {2018-07-25},
	booktitle = {2010 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Sahillioglu, Yusuf and Yemez, Yiicel},
	month = jun,
	year = {2010},
	pages = {453--458},
}

@article{Lai2011,
	title = {Laplace-{Beltrami} {Eigen}-geometry and {Applications} on {3D} {Medical} {Imaging}},
	author = {Lai, Rongjie},
	year = {2011},
	pages = {1--36},
}

@inproceedings{levy_spectral_2010,
	address = {New York, New York, USA},
	title = {Spectral mesh processing},
	isbn = {978-1-4503-0395-8},
	url = {http://portal.acm.org/citation.cfm?doid=1837101.1837109},
	doi = {10.1145/1837101.1837109},
	urldate = {2018-07-24},
	booktitle = {{ACM} {SIGGRAPH} 2010 {Courses} on - {SIGGRAPH} '10},
	publisher = {ACM Press},
	author = {Lévy, Bruno and Zhang, Hao (Richard)},
	year = {2010},
	pages = {1--312},
}

@inproceedings{Zass2008,
	title = {Probabilistic graph and hypergraph matching},
	isbn = {978-1-4244-2242-5},
	url = {http://ieeexplore.ieee.org/document/4587500/},
	doi = {10.1109/CVPR.2008.4587500},
	urldate = {2018-07-24},
	booktitle = {2008 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Zass, Ron and Shashua, Amnon},
	month = jun,
	year = {2008},
	pages = {1--8},
}

@incollection{drost_graph-based_2015,
	title = {Graph-{Based} {Deformable} {3D} {Object} {Matching}},
	url = {http://link.springer.com/10.1007/978-3-319-24947-6_18},
	urldate = {2018-07-24},
	author = {Drost, Bertram and Ilic, Slobodan},
	year = {2015},
	doi = {10.1007/978-3-319-24947-6_18},
	pages = {222--233},
}

@incollection{Aboudib2016,
	title = {A {Neural} {Network} {Model} for {Solving} the {Feature} {Correspondence} {Problem}},
	url = {http://link.springer.com/10.1007/978-3-319-44781-0_52},
	urldate = {2018-07-24},
	author = {Aboudib, Ala and Gripon, Vincent and Coppin, Gilles},
	year = {2016},
	doi = {10.1007/978-3-319-44781-0_52},
	pages = {439--446},
}

@incollection{park_multi-attributed_2016,
	title = {Multi-attributed {Graph} {Matching} with {Multi}-layer {Random} {Walks}},
	url = {http://link.springer.com/10.1007/978-3-319-46487-9_12},
	urldate = {2018-07-24},
	author = {Park, Han-Mu and Yoon, Kuk-Jin},
	year = {2016},
	doi = {10.1007/978-3-319-46487-9_12},
	pages = {189--204},
}

@article{Dey2010,
	title = {Convergence , {Stability} , and {Discrete} {Approximation} of {Laplace} {Spectra}},
	abstract = {Spectral methods have been widely used in a broad range of applications fields. One important object involved in such methods is the Laplace-Beltrami operator of a manifold. Indeed, a variety of work in graphics and geometric optimization uses the eigen-structures (i.e, the eigenvalues and eigenfunctions) of the Laplace operator. Applications include mesh smoothing, compression, editing, shape segmentation, matching, parameterization, and so on. While the Laplace operator is defined (mathematically) for a smooth domain, these applications often approximate a smooth manifold by a discrete mesh. The spectral structure of the manifold Laplacian is estimated from some discrete Laplace operator constructed from this mesh. In this paper, we study the important question of how well the spectrum computed from the discrete mesh approximates the true spectrum of the manifold Laplacian. We exploit a recent result on mesh Laplacian and provide the first convergence result to relate the spectrum constructed from a general mesh (approximating an m-manifold embedded in IRd) with the true spectrum. We also study how stable these eigenvalues and their discrete approximations are when the underlying manifold is perturbed, and provide explicit bounds for the Laplacian spectra of two “close” manifolds, as well as a convergence result for their discrete approximations. Finally, we present various experimental results to demonstrate that these discrete spectra are both accurate and robust in practice.},
	journal = {Society for Industrial and Applied Mathematics},
	author = {Dey, Tamal K and Ranjan, Pawas and Wang, Yusu},
	year = {2010},
	note = {ISBN: 9780898717013},
}

@article{Baddeley2018,
	title = {Biological {Insight} from {Super}-{Resolution} {Microscopy}: {What} {We} {Can} {Learn} from {Localization}-{Based} {Images}},
	volume = {87},
	issn = {0066-4154},
	doi = {10.1146/annurev-biochem-060815-014801},
	abstract = {Super-resolution optical imaging based on the switching and localization of individual fluorescent molecules [photoactivated localization microscopy (PALM), stochastic optical reconstruction microscopy (STORM), etc.] has evolved remarkably over the last decade. Originally driven by pushing technological limits, it has become a tool of biological discovery. The initial demand for impressive pictures showing well-studied biological structures has been replaced by a need for quantitative, reliable data providing dependable evidence for specific unresolved biological hypotheses. In this review, we highlight applications that showcase this development, identify the features that led to their success, and discuss remaining challenges and difficulties. In this context, we consider the complex topic of defining resolution for this imaging modality and address some of the more common analytical methods used with this data. Expected final online publication date for the Annual Review of Biochemistry Volume 87 is June 20, 2018. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
	number = {1},
	journal = {Annual Review of Biochemistry},
	author = {Baddeley, David and Bewersdorf, Joerg},
	year = {2018},
	pmid = {29272143},
	note = {ISBN: 1545-4509 (Electronic) 0066-4154 (Linking)},
}

@article{Smith2016,
	title = {Simultaneous measurement of emission color and {3D} position of single molecules},
	volume = {24},
	issn = {1094-4087},
	doi = {10.1364/OE.24.004996},
	abstract = {We show that the position of single molecules in all three spatial dimensions can be estimated alongside its emission color by diffractive optics based design of the Point Spread Function (PSF). The phase in a plane conjugate to the aperture stop of the objective lens is modified by a diffractive structure that splits the spot on the camera into closely spaced diffraction orders. The distance between and the size of these sub-spots are a measure of the emission color. Estimation of the axial position is enabled by imprinting aberrations such as astigmatism and defocus onto the orders. The overall spot shape is fitted with a fully vectorial PSF model. Proof-of-principle experiments on quantum dots indicate that a spectral precision of 10 to 20 nm, an axial localization precision of 25 to 50 nm, and a lateral localization precision of 10 to 30 nm can be achieved over a 1 μm range of axial positions for on average 800 signal photons and 17 background photons/pixel. The method appears to be rather sensitive to PSF model errors such as aberrations, giving in particular rise to biases in the fitted wavelength of up to 15 nm.},
	number = {5},
	journal = {Optics Express},
	author = {Smith, Carlas and Huisman, Max and Siemons, Marijn and Grünwald, David and Stallinga, Sjoerd},
	year = {2016},
}

@article{Chen2017,
	title = {Optical {Super}-{Resolution} {Imaging} of {Surface} {Reactions}},
	volume = {117},
	issn = {15206890},
	doi = {10.1021/acs.chemrev.6b00673},
	abstract = {Optical super-resolution imaging has gained momentum in investigations of heterogeneous and homogeneous chemical reactions at the single-molecule level. Thanks to its exceptional spatial resolution and ability to monitor dynamic systems, much detailed information on single-molecule reaction/adsorption processes and single-particle catalytic processes has been revealed, including chemical kinetics and reaction dynamics; active-site distributions on single-particle surfaces; and size-, shape-, and facet-dependent catalytic activities of individual nanocatalysts. In this review, we provide an overview of recent advances in super-resolution chemical imaging of surface reactions.},
	number = {11},
	journal = {Chemical Reviews},
	author = {Chen, Tao and Dong, Bin and Chen, Kuangcai and Zhao, Fei and Cheng, Xiaodong and Ma, Changbei and Lee, Seungah and Zhang, Peng and Kang, Seong Ho and Ha, Ji Won and Xu, Weilin and Fang, Ning},
	year = {2017},
	pmid = {28306243},
	note = {ISBN: 0009-2665},
}

@article{Nahidiazar2016,
	title = {Optimizing imaging conditions for demanding multi-color super resolution localization microscopy},
	volume = {11},
	issn = {19326203},
	doi = {10.1371/journal.pone.0158884},
	abstract = {Single Molecule Localization super-resolution Microscopy (SMLM) has become a powerful tool to study cellular architecture at the nanometer scale. In SMLM, single fluorophore labels are made to repeatedly switch on and off ("blink"), and their exact locations are determined by mathematically finding the centers of individual blinks. The image quality obtainable by SMLM critically depends on efficacy of blinking (brightness, fraction of molecules in the on-state) and on preparation longevity and labeling density. Recent work has identified several combinations of bright dyes and imaging buffers that work well together. Unfortunately, different dyes blink optimally in different imaging buffers, and acquisition of good quality 2- and 3-color images has therefore remained challenging. In this study we describe a new imaging buffer, OxEA, that supports 3-color imaging of the popular Alexa dyes. We also describe incremental improvements in preparation technique that significantly decrease lateral- and axial drift, as well as increase preparation longevity. We show that these improvements allow us to collect very large series of images from the same cell, enabling image stitching, extended 3D imaging as well as multi-color recording.},
	number = {7},
	journal = {PLoS ONE},
	author = {Nahidiazar, Leila and Agronskaia, Alexandra V. and Broertjes, Jorrit and Van Broek, Bram Den and Jalink, Kees},
	year = {2016},
	pmid = {27391487},
}

@article{Myronenko2009,
	title = {Point {Set} {Registration}: {Coherent} {Point} {Drift}},
	abstract = {Point set registration is a key component in many computer vision tasks. The goal of point set registration is to assign correspondences between two sets of points and to recover the transformation that maps one point set to the other. Multiple factors, including an unknown non-rigid spatial transformation, large dimensionality of point set, noise and outliers, make the point set registration a challenging problem. We introduce a probabilistic method, called the Coherent Point Drift (CPD) algorithm, for both rigid and non-rigid point set registration. We consider the alignment of two point sets as a probability density estimation problem. We fit the GMM centroids (representing the first point set) to the data (the second point set) by maximizing the likelihood. We force the GMM centroids to move coherently as a group to preserve the topological structure of the point sets. In the rigid case, we impose the coherence constraint by re-parametrization of GMM centroid locations with rigid parameters and derive a closed form solution of the maximization step of the EM algorithm in arbitrary dimensions. In the non-rigid case, we impose the coherence constraint by regularizing the displacement field and using the variational calculus to derive the optimal transformation. We also introduce a fast algorithm that reduces the method computation complexity to linear. We test the CPD algorithm for both rigid and non-rigid transformations in the presence of noise, outliers and missing points, where CPD shows accurate results and outperforms current state-of-the-art methods.},
	author = {Myronenko, Andriy and Song, Xubo},
	year = {2009},
	note = {arXiv: 0905.2635v1},
	keywords = {()},
}

@article{VanKaick,
	title = {A {Survey} on {Shape} {Correspondence}},
	volume = {xx},
	abstract = {We review methods designed to compute correspondences between geometric shapes represented by triangle meshes, contours, or point sets. This survey is motivated in part by recent developments in space-time registration, where one seeks a correspondence between non-rigid and time-varying surfaces, and semantic shape analysis, which underlines a recent trend to incorporate shape understanding into the analysis pipeline. Establishing a meaningful correspondence between shapes is often difficult since it generally requires an understanding of the structure of the shapes at both the local and global levels, and sometimes the functionality of the shape parts as well. Despite its inherent complexity, shape correspondence is a recurrent problem and an essential component of numerous geometry processing applications. In this survey, we discuss the different forms of the correspondence problem and review the main solution methods, aided by several classification criteria arising from the problem definition. The main categories of classification are defined in terms of the input and output representation, objective function, and solution approach. We conclude the survey by discussing open problems and future perspectives.},
	author = {Van Kaick, Oliver and Zhang, Hao and Hamarneh, Ghassan and Cohen-Or, Daniel},
	pages = {1--24},
}

@inproceedings{Andreux2015,
	title = {Anisotropic laplace-beltrami operators for shape analysis},
	isbn = {978-3-319-16219-5},
	doi = {10.1007/978-3-319-16220-1_21},
	abstract = {This paper introduces an anisotropic Laplace-Beltrami op-erator for shape analysis. While keeping useful properties of the stan-dard Laplace-Beltrami operator, it introduces variability in the directions of principal curvature, giving rise to a more intuitive and semantically meaningful diffusion process. Although the benefits of anisotropic diffu-sion have already been noted in the area of mesh processing (e.g. surface regularization), focusing on the Laplacian itself, rather than on the dif-fusion process it induces, opens the possibility to effectively replace the omnipresent Laplace-Beltrami operator in many shape analysis meth-ods. After providing a mathematical formulation and analysis of this new operator, we derive a practical implementation on discrete meshes. Further, we demonstrate the effectiveness of our new operator when em-ployed in conjunction with different methods for shape segmentation and matching.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Andreux, Mathieu and Rodolá, Emanuele and Aubry, Mathieu and Cremers, Daniel},
	year = {2015},
	note = {ISSN: 16113349},
	keywords = {Anisotropic diffusion, Curvature, Laplace-Beltrami operator, Non-rigid matching, Segmentation, Shape analysis},
}

@inproceedings{Reuter2005,
	address = {New York, New York, USA},
	title = {Laplace-spectra as fingerprints for shape matching},
	isbn = {1-59593-015-9},
	url = {http://portal.acm.org/citation.cfm?doid=1060244.1060256},
	doi = {10.1145/1060244.1060256},
	urldate = {2018-07-23},
	booktitle = {Proceedings of the 2005 {ACM} symposium on {Solid} and physical modeling  - {SPM} '05},
	publisher = {ACM Press},
	author = {Reuter, Martin and Wolter, Franz-Erich and Peinecke, Niklas},
	year = {2005},
	keywords = {NURBS, copyright protection, database retrieval, fingerprints, laplace-beltrami operator, parameterized surfaces and bodies, polyhedra, shape invariants, shape matching},
	pages = {101--106},
}

@article{Masoumi2016,
	title = {A spectral graph wavelet approach for nonrigid {3D} shape retrieval},
	volume = {83},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865516300617},
	doi = {10.1016/J.PATREC.2016.04.009},
	abstract = {In this paper, we propose a spectral graph wavelet approach for 3D shape retrieval using the bag-of-features paradigm. In an effort to capture both local and global characteristics of a 3D shape, we present a three-step feature description framework. Local descriptors are first extracted via the spectral graph wavelet transform having the Mexican hat wavelet as a generating kernel. Then, mid-level features are obtained by embedding local descriptors into the visual vocabulary space using the soft-assignment coding step of the bag-of-features model. A global descriptor is subsequently constructed by aggregating mid-level features weighted by a geodesic exponential kernel, resulting in a matrix representation that describes the frequency of appearance of nearby codewords in the vocabulary. Then, we compare the global descriptor of a query to all global descriptors of the shapes in the dataset using a dissimilarity measure and find the closest shape. Experimental results on two standard 3D shape benchmarks demonstrate the effectiveness of the proposed shape retrieval approach in comparison with state-of-the-art methods.},
	urldate = {2018-07-23},
	journal = {Pattern Recognition Letters},
	author = {Masoumi, Majid and Li, Chunyuan and Ben Hamza, A.},
	month = nov,
	year = {2016},
	note = {Publisher: North-Holland},
	pages = {339--348},
}

@article{Lau2007,
	title = {Complex {N}-{Glycan} {Number} and {Degree} of {Branching} {Cooperate} to {Regulate} {Cell} {Proliferation} and {Differentiation}},
	volume = {129},
	issn = {00928674},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17418791},
	doi = {10.1016/j.cell.2007.01.049},
	abstract = {The number of N-glycans (n) is a distinct feature of each glycoprotein sequence and cooperates with the physical properties of the Golgi N-glycan-branching pathway to regulate surface glycoprotein levels. The Golgi pathway is ultrasensitive to hexosamine flux for the production of tri- and tetra-antennary N-glycans, which bind to galectins and form a molecular lattice that opposes glycoprotein endocytosis. Glycoproteins with few N-glycans (e.g., TbetaR, CTLA-4, and GLUT4) exhibit enhanced cell-surface expression with switch-like responses to increasing hexosamine concentration, whereas glycoproteins with high numbers of N-glycans (e.g., EGFR, IGFR, FGFR, and PDGFR) exhibit hyperbolic responses. Computational and experimental data reveal that these features allow nutrient flux stimulated by growth-promoting high-n receptors to drive arrest/differentiation programs by increasing surface levels of low-n glycoproteins. We have identified a mechanism for metabolic regulation of cellular transition between growth and arrest in mammals arising from apparent coevolution of N-glycan number and branching.},
	number = {1},
	urldate = {2018-07-20},
	journal = {Cell},
	author = {Lau, Ken S. and Partridge, Emily A. and Grigorian, Ani and Silvescu, Cristina I. and Reinhold, Vernon N. and Demetriou, Michael and Dennis, James W.},
	month = apr,
	year = {2007},
	pmid = {17418791},
	pages = {123--134},
}

@article{Nabi2015,
	title = {The galectin lattice at a glance},
	volume = {128},
	issn = {0021-9533},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26092931},
	doi = {10.1242/jcs.151159},
	abstract = {Galectins are a family of widely expressed β-galactoside-binding lectins in metazoans. The 15 mammalian galectins have either one or two conserved carbohydrate recognition domains (CRDs), with galectin-3 being able to pentamerize; they form complexes that crosslink glycosylated ligands to form a dynamic lattice. The galectin lattice regulates the diffusion, compartmentalization and endocytosis of plasma membrane glycoproteins and glycolipids. The galectin lattice also regulates the selection, activation and arrest of T cells, receptor kinase signaling and the functionality of membrane receptors, including the glucagon receptor, glucose and amino acid transporters, cadherins and integrins. The affinity of transmembrane glycoproteins to the galectin lattice is proportional to the number and branching of their N-glycans; with branching being mediated by Golgi N-acetylglucosaminyltransferase-branching enzymes and the supply of UDP-GlcNAc through metabolite flux through the hexosamine biosynthesis pathway. The relative affinities of glycoproteins for the galectin lattice depend on the activities of the Golgi enzymes that generate the epitopes of their ligands and, thus, provide a means to analyze biological function of lectins and of the 'glycome' more broadly.},
	number = {13},
	urldate = {2018-07-20},
	journal = {Journal of Cell Science},
	author = {Nabi, I. R. and Shankar, J. and Dennis, J. W.},
	month = jul,
	year = {2015},
	pmid = {26092931},
	keywords = {Endocytosis, Galectin, Glycolipid, Glycosylation, MGATs, Receptor},
	pages = {2213--2219},
}

@article{caron_deep_2018,
	title = {Deep {Clustering} for {Unsupervised} {Learning} of {Visual} {Features}},
	url = {http://arxiv.org/abs/1807.05520},
	abstract = {Clustering is a class of unsupervised learning methods that has been extensively applied and studied in computer vision. Little work has been done to adapt it to the end-to-end training of visual features on large scale datasets. In this work, we present DeepCluster, a clustering method that jointly learns the parameters of a neural network and the cluster assignments of the resulting features. DeepCluster iteratively groups the features with a standard clustering algorithm, k-means, and uses the subsequent assignments as supervision to update the weights of the network. We apply DeepCluster to the unsupervised training of convolutional neural networks on large datasets like ImageNet and YFCC100M. The resulting model outperforms the current state of the art by a significant margin on all the standard benchmarks.},
	urldate = {2018-07-20},
	author = {Caron, Mathilde and Bojanowski, Piotr and Joulin, Armand and Douze, Matthijs},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.05520},
}

@article{Pal2016,
	title = {A complete review of computational methods for human and {HIV}-1 protein interaction prediction},
	volume = {12},
	issn = {1744-5485},
	url = {http://www.inderscience.com/link.php?id=75396},
	doi = {10.1504/IJBRA.2016.075396},
	number = {1},
	urldate = {2018-07-19},
	journal = {International Journal of Bioinformatics Research and Applications},
	author = {Pal, Debasmita and Mondal, Kartick Chandra},
	year = {2016},
	pages = {19},
}

@article{wang_supervised_2007,
	title = {Supervised classification of protein structures based on convex hull representation},
	volume = {3},
	issn = {1744-5485},
	url = {http://www.inderscience.com/link.php?id=13598},
	doi = {10.1504/IJBRA.2007.013598},
	number = {2},
	urldate = {2018-07-19},
	journal = {International Journal of Bioinformatics Research and Applications},
	author = {Wang, Yong and Wu, Ling Yun and Chen, Luonan and Zhang, Xiang Sun},
	year = {2007},
	pages = {123},
}

@article{Berlo2013,
	title = {Efficient calculation of compound similarity based on maximum common subgraphs and its application to prediction of gene transcript levels},
	volume = {9},
	issn = {1744-5485},
	url = {http://www.inderscience.com/link.php?id=54688},
	doi = {10.1504/IJBRA.2013.054688},
	number = {4},
	urldate = {2018-07-19},
	journal = {International Journal of Bioinformatics Research and Applications},
	author = {Berlo, Rogier J.P. Van and Winterbach, Wynand and Groot, Marco J.L. De and Bender, Andreas and Verheijen, Peter J.T. and Reinders, Marcel J.T. and Ridder, Dick De},
	year = {2013},
	pages = {407},
}

@inproceedings{kattenborn_automatic_2014,
	title = {Automatic single palm tree detection in plantations using {UAV}-based photogrammetric point clouds},
	isbn = {16821750 (ISSN)},
	doi = {10.5194/isprsarchives-XL-3-139-2014},
	abstract = {{\textless}p{\textgreater}For reasons of documentation, management and certification there is a high interest in efficient inventories of palm plantations on the single plant level. Recent developments in unmanned aerial vehicle (UAV) technology facilitate spatial and temporal flexible acquisition of high resolution 3D data. Common single tree detection approaches are based on Very High Resolution (VHR) satellite or Airborne Laser Scanning (ALS) data. However, VHR data is often limited to clouds and does commonly not allow for height measurements. VHR and in particualar ALS data are characterized by high relatively high acquisition costs. Sperlich et al. (2013) already demonstrated the high potential of UAV-based photogrammetric point clouds for single tree detection using pouring algorithms. This approach was adjusted and improved for an application on palm plantation. The 9.4ha test site on Tarawa, Kiribati, comprised densely scattered growing palms, as well as abundant undergrowth and trees. Using a standard consumer grade camera mounted on an octocopter two flight campaigns at 70m and 100m altitude were performed to evaluate the effect Ground Sampling Distance (GSD) and image overlap. To avoid comission errors and improve the terrain interpolation the point clouds were classified based on the geometric characteristics of the classes, i.e. (1) palm, (2) other vegetation (3) and ground. The mapping accuracy amounts for 86.1 \% for the entire study area and 98.2 \% for dense growing palm stands. We conclude that this flexible and automatic approach has high capabilities for operational use.{\textless}/p{\textgreater}},
	booktitle = {International {Archives} of the {Photogrammetry}, {Remote} {Sensing} and {Spatial} {Information} {Sciences} - {ISPRS} {Archives}},
	author = {Kattenborn, T. and Sperlich, M. and Bataua, K. and Koch, B.},
	year = {2014},
	note = {ISSN: 16821750},
	keywords = {Palm plantation, Point clouds, Segmentation, Single tree detection, Structure from motion, Terrain models, UAV},
}

@inproceedings{becker_classification_2017,
	title = {{CLASSIFICATION} of {AERIAL} {PHOTOGRAMMETRIC} {3D} {POINT} {CLOUDS}},
	doi = {10.5194/isprs-annals-IV-1-W1-3-2017},
	abstract = {We present a powerful method to extract per-point semantic class labels from aerialphotogrammetry data. Labeling this kind of data is important for tasks such as environmental modelling, object classification and scene understanding. Unlike previous point cloud classification methods that rely exclusively on geometric features, we show that incorporating color information yields a significant increase in accuracy in detecting semantic classes. We test our classification method on three real-world photogrammetry datasets that were generated with Pix4Dmapper Pro, and with varying point densities. We show that off-the-shelf machine learning techniques coupled with our new features allow us to train highly accurate classifiers that generalize well to unseen data, processing point clouds containing 10 million points in less than 3 minutes on a desktop computer.},
	booktitle = {{ISPRS} {Annals} of the {Photogrammetry}, {Remote} {Sensing} and {Spatial} {Information} {Sciences}},
	author = {Becker, C. and Häni, N. and Rosinskaya, E. and D'Angelo, E. and Strecha, C.},
	year = {2017},
	note = {arXiv: 1705.08374
ISSN: 21949050},
	keywords = {Aerial Photogrammetry, LiDAR, Photogrammetry, Point Clouds, Semantic Classification},
}

@article{freire_many-objective_2015,
	title = {Many-objective optimization with corner-based search},
	issn = {18659292},
	doi = {10.1007/s12293-015-0151-4},
	abstract = {Theperformance of multi-objective evolutionary algorithms can severely deterioratewhenapplied to problems with 4 or more objectives, called many-objective problems. For Pareto dominance based techniques, available informa- tion about some optimal solutions can be used to improve their performance. This is the case of corner solutions. This work considers the behaviour of three multi-objective algo- rithms [Non-dominated sorting genetic algorithm (NSGA- II), Speed-constrained multi-objective particle swarm opti- mization (SMPSO) and generalized differential evolution (GDE3)] when corner solutions are inserted into the pop- ulation at different evolutionary stages. The problem of find- ing corner solutions is addressed by proposing a new algo- rithm based in multi-objective particle swarm optimization (MOPSO). Results concerning the behaviour of the afore- mentioned algorithms in five benchmark problems (DTLZ1- 5) and respective analysis are presented. Keywords},
	journal = {Memetic Computing},
	author = {Freire, Hélio and de Moura Oliveira, P. B. and Solteiro Pires, E. J. and Bessa, Maximino},
	year = {2015},
	note = {ISBN: 1229301501514},
	keywords = {Corner solutions, Evolutionary computation, Many-objective algorithm, Particle swarm optimization},
}

@article{singh_pareto_2011,
	title = {A {Pareto} corner search evolutionary algorithm and dimensionality reduction in many-objective optimization problems},
	issn = {1089778X},
	doi = {10.1109/TEVC.2010.2093579},
	abstract = {Many-objective optimization refers to the optimization problems containing large number of objectives, typically more than four. Non-dominance is an inadequate strategy for convergence to the Pareto front for such problems, as almost all solutions in the population become non-dominated, resulting in loss of convergence pressure. However, for some problems, it may be possible to generate the Pareto front using only a few of the objectives, rendering the rest of the objectives redundant. Such problems may be reducible to a manageable number of relevant objectives, which can be optimized using conventional multiobjective evolutionary algorithms (MOEAs). For dimensionality reduction, most proposals in the paper rely on analysis of a representative set of solutions obtained by running a conventional MOEA for a large number of generations, which is computationally overbearing. A novel algorithm, Pareto corner search evolutionary algorithm (PCSEA), is introduced in this paper, which searches for the corners of the Pareto front instead of searching for the complete Pareto front. The solutions obtained using PCSEA are then used for dimensionality reduction to identify the relevant objectives. The potential of the proposed approach is demonstrated by studying its performance on a set of benchmark test problems and two engineering examples. While the preliminary results obtained using PCSEA are promising, there are a number of areas that need further investigation. This paper provides a number of useful insights into dimensionality reduction and, in particular, highlights some of the roadblocks that need to be cleared for future development of algorithms attempting to use few selected solutions for identifying relevant objectives.},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Singh, Hemant Kumar and Isaacs, Amitay and Ray, Tapabrata},
	year = {2011},
	note = {ISBN: 1089-778X},
	keywords = {Dimensionality reduction, Pareto corner search, many-objective optimization},
}

@article{cai_locating_2018,
	title = {Locating the boundaries of {Pareto} fronts: {A} {Many}-{Objective} {Evolutionary} {Algorithm} {Based} on {Corner} {Solution} {Search}},
	url = {http://arxiv.org/abs/1806.02967},
	abstract = {In this paper, an evolutionary many-objective optimization algorithm based on corner solution search (MaOEA-CS) was proposed. MaOEA-CS implicitly contains two phases: the exploitative search for the most important boundary optimal solutions - corner solutions, at the first phase, and the use of angle-based selection [1] with the explorative search for the extension of PF approximation at the second phase. Due to its high efficiency and robustness to the shapes of PFs, it has won the CEC'2017 Competition on Evolutionary Many-Objective Optimization. In addition, MaOEA-CS has also been applied on two real-world engineering optimization problems with very irregular PFs. The experimental results show that MaOEA-CS outperforms other six state-of-the-art compared algorithms, which indicates it has the ability to handle real-world complex optimization problems with irregular PFs.},
	urldate = {2018-07-11},
	author = {Cai, Xinye and Sun, Haoran and Zhu, Chunyang and Li, Zhenyu and Zhang, Qingfu},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.02967},
}

@article{Xu2018,
	title = {Use of active learning for earthquake damage mapping from {UAV} photogrammetric point clouds},
	issn = {0143-1161},
	url = {https://www.tandfonline.com/doi/full/10.1080/01431161.2018.1466083},
	doi = {10.1080/01431161.2018.1466083},
	abstract = {ABSTRACTThis article presents an effective classification method for earthquake damage mapping from unmanned aerial vehicles (UAV) photogrammetric point clouds. The classification method consists of three main components: (a) construction of a point feature descriptor regarding to spectral, textural, and geometrical features, (b) optimization of collecting informative training samples through an active learning (AL) method, and (c) fine-tuning the point-based classification results with contextual information. Besides using existing spectral and geometrical features, we design a textural feature based on fractal theory to construct a point feature descriptor through linear combination. A batch-model AL method called Margin Sampling and Multiclass Level Uncertainty (MS-MCLU) is proposed based on classification uncertainty using a Support Vector Machine classifier. We use a multi-label Markov random fields to fine-tune the point-based classification results with a pairwise model. The proposed method was tes...},
	urldate = {2018-07-11},
	journal = {International Journal of Remote Sensing},
	author = {Xu, Zhihua and Wu, Lixin and Zhang, Zhenxin},
	month = apr,
	year = {2018},
	note = {Publisher: Taylor \& Francis},
	pages = {1--28},
}

@article{VonLuxburg2007,
	title = {A {Tutorial} on {Spectral} {Clustering}},
	volume = {17},
	url = {www.springer.com.},
	abstract = {In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.},
	number = {4},
	urldate = {2018-07-06},
	journal = {Statistics and Computing},
	author = {Von Luxburg, Ulrike},
	year = {2007},
	note = {arXiv: 0711.0189v1},
	keywords = {graph Laplacian, spectral clustering},
}

@article{Colomer2018,
	title = {A transient self-assembling self-replicator},
	volume = {9},
	issn = {2041-1723},
	url = {http://www.nature.com/articles/s41467-018-04670-2},
	doi = {10.1038/s41467-018-04670-2},
	number = {1},
	urldate = {2018-07-03},
	journal = {Nature Communications},
	author = {Colomer, Ignacio and Morrow, Sarah M. and Fletcher, Stephen P.},
	month = dec,
	year = {2018},
	pages = {2239},
}

@article{noauthor_morihei_nodate,
	title = {Morihei {Ueshiba}},
	urldate = {2018-06-28},
}

@article{marcais_asymptotically_2018,
	title = {Asymptotically optimal minimizers schemes},
	volume = {34},
	issn = {1367-4803},
	url = {https://academic.oup.com/bioinformatics/article/34/13/i13/5045769},
	doi = {10.1093/bioinformatics/bty258},
	number = {13},
	urldate = {2018-06-27},
	journal = {Bioinformatics},
	author = {Marçais, Guillaume and DeBlasio, Dan and Kingsford, Carl},
	month = jul,
	year = {2018},
	note = {Publisher: Oxford University Press},
	pages = {i13--i22},
}

@article{noauthor_novel_nodate,
	title = {A {Novel} {Framework} for {3D}-{2D} vertebra {Matching}},
}

@article{Whelan2015,
	title = {Image artifacts in single molecule localization microscopy: {Why} optimization of sample preparation protocols matters},
	volume = {5},
	issn = {20452322},
	doi = {10.1038/srep07924},
	abstract = {Single molecule localization microscopy (SMLM) techniques allow for sub-diffraction imaging with spatial resolutions better than 10 nm reported. Much has been discussed relating to different variations of SMLM and all-inclusive microscopes can now be purchased, removing the need for in-house software or hardware development. However, little discussion has occurred examining the reliability and quality of the images being produced, as well as the potential for overlooked preparative artifacts. As a result of the up to an order-of-magnitude improvement in spatial resolution, substantially more detail is observed, including changes in distribution and ultrastructure caused by the many steps required to fix, permeabilize, and stain a sample. Here we systematically investigate many of these steps including different fixatives, fixative concentration, permeabilization concentration and timing, antibody concentration, and buffering. We present three well-optimized fixation protocols for staining microtubules, mitochondria and actin in a mammalian cell line and then discuss various artifacts in relation to images obtained from samples prepared using the protocols. The potential for such errors to go undetected in SMLM images and the complications in defining a 'good' image using previous parameters applied to confocal microscopy are also discussed.},
	journal = {Scientific Reports},
	author = {Whelan, Donna R. and Bell, Toby D.M.},
	year = {2015},
	pmid = {25603780},
	note = {ISBN: 2045-2322 (Electronic) 2045-2322 (Linking)},
}

@article{Sieben2018,
	title = {Super-resolution microscopy to decipher multi-molecular assemblies},
	volume = {49},
	issn = {1879033X},
	doi = {10.1016/j.sbi.2018.03.017},
	abstract = {Super-resolution fluorescence microscopy (SRM) is increasingly being applied as a complementary method to resolve the organization of large biomolecular assemblies. One of its main advantages is that it provides information on protein organization and identity simultaneously, within the native cellular milieu. It also extends the accessible range of structures up to the micrometer scale, offering complementary information relative to classical structural biology methods. Furthermore, SRM is capable of resolving the organization of some biomolecular assemblies not accessible to other methods. We highlight these advantages within the context of deciphering the structure of the centrosome and chromatin, and discuss how computational data post-processing has been adapted for SRM data. We also outline current limitations and potential approaches to overcome them.},
	journal = {Current Opinion in Structural Biology},
	author = {Sieben, Christian and Douglass, Kyle M. and Guichard, Paul and Manley, Suliana},
	year = {2018},
	pmid = {29621666},
}

@article{VanDeLinde2014,
	title = {How to switch a fluorophore: {From} undesired blinking to controlled photoswitching},
	volume = {43},
	issn = {03060012},
	doi = {10.1039/c3cs60195a},
	abstract = {Molecular optical photoswitches based on fluorescent proteins and organic dyes are fundamental for super-resolution fluorescence imaging and tracking methods. Precise control of switching, bio-labeling compatibility, and high brightness make photoswitches broadly applicable. This review emphasizes the design and development of photoswitches and the requirements they need to fulfill for their successful application in single-molecule localization microscopy. Furthermore, we discuss recent developments in improving the photoswitching performance with a special focus on organic dyes.},
	number = {4},
	journal = {Chemical Society Reviews},
	author = {Van De Linde, Sebastian and Sauer, Markus},
	year = {2014},
	pmid = {23942584},
	note = {ISBN: 1460-4744 (Electronic){\textbackslash}r0306-0012 (Linking)},
}

@article{aouchiche_distance_2014,
	title = {Distance spectra of graphs: {A} survey},
	volume = {458},
	issn = {0024-3795},
	url = {https://www.sciencedirect.com/science/article/pii/S0024379514003759},
	doi = {10.1016/J.LAA.2014.06.010},
	abstract = {In 1971, Graham and Pollack established a relationship between the number of negative eigenvalues of the distance matrix and the addressing problem in data communication systems. They also proved that the determinant of the distance matrix of a tree is a function of the number of vertices only. Since then several mathematicians were interested in studying the spectral properties of the distance matrix of a connected graph. Computing the distance characteristic polynomial and its coefficients was the first research subject of interest. Thereafter, the eigenvalues attracted much more attention. In the present paper, we report on the results related to the distance matrix of a graph and its spectral properties.},
	urldate = {2018-06-11},
	journal = {Linear Algebra and its Applications},
	author = {Aouchiche, Mustapha and Hansen, Pierre},
	month = oct,
	year = {2014},
	note = {Publisher: North-Holland},
	pages = {301--386},
}

@article{lin_distance_2017,
	title = {Distance between distance spectra of graphs},
	volume = {65},
	issn = {0308-1087},
	url = {https://www.tandfonline.com/doi/full/10.1080/03081087.2017.1278737},
	doi = {10.1080/03081087.2017.1278737},
	abstract = {AbstractLet be a connected graph with vertex set and edge set E(G). Let D(G) be the distance matrix of G and be its distance spectrum. The distance between distance spectra of G and is defined byDefine the cospectrality of G byLet . In the paper, we obtain lower bounds on and for . Furthermore, we give an upper bound on .},
	number = {12},
	urldate = {2018-06-11},
	journal = {Linear and Multilinear Algebra},
	author = {Lin, Huiqiu and Li, Dan and Das, Kinkar Ch.},
	month = dec,
	year = {2017},
	note = {Publisher: Taylor \& Francis},
	keywords = {05C50, Distance spectra, cospectral, distance, distance matrix},
	pages = {2538--2550},
}

@article{dehmer_networks_2011,
	title = {Networks for systems biology: conceptual connection of data and function},
	volume = {5},
	issn = {1751-8849},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21639592},
	doi = {10.1049/iet-syb.2010.0025},
	abstract = {The purpose of this study is to survey the use of networks and network-based methods in systems biology. This study starts with an introduction to graph theory and basic measures allowing to quantify structural properties of networks. Then, the authors present important network classes and gene networks as well as methods for their analysis. In the last part of this study, the authors review approaches that aim at analysing the functional organisation of gene networks and the use of networks in medicine. In addition to this, the authors advocate networks as a systematic approach to general problems in systems biology, because networks are capable of assuming multiple roles that are very beneficial connecting experimental data with a functional interpretation in biological terms.},
	number = {3},
	urldate = {2018-06-11},
	journal = {IET Systems Biology},
	author = {Dehmer, M. and Emmert-Streib, F.},
	month = may,
	year = {2011},
	pmid = {21639592},
	pages = {185--207},
}

@article{noauthor_manuscript_nodate,
	title = {Manuscript {Number}: {SIMPAT}-{D}-18--408},
}

@book{corder_nonparametric_2009,
	address = {Hoboken, NJ, USA},
	title = {Nonparametric {Statistics} for {Non}-{Statisticians}},
	isbn = {978-1-118-16588-1},
	url = {http://doi.wiley.com/10.1002/9781118165881},
	urldate = {2018-06-10},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Corder, Gregory W. and Foreman, Dale I.},
	month = may,
	year = {2009},
	doi = {10.1002/9781118165881},
	note = {Publication Title: Nonparametric Statistics for Non-Statisticians: A Step-by-Step Approach
ISSN: 0009-4978},
}

@article{lambert_zero-inflated_1992,
	title = {Zero-{Inflated} {Poisson} {Regression}, with an {Application} to {Defects} in {Manufacturing}},
	volume = {34},
	issn = {00401706},
	url = {https://www.jstor.org/stable/1269547?origin=crossref},
	doi = {10.2307/1269547},
	number = {1},
	urldate = {2018-06-05},
	journal = {Technometrics},
	author = {Lambert, Diane and {Diane}},
	month = feb,
	year = {1992},
	note = {Publisher: American Society for Quality Control and American Statistical Association},
	pages = {1},
}

@misc{hartigan_dip_nodate,
	title = {The {Dip} {Test} of {Unimodality}},
	url = {https://www.jstor.org/stable/2241144},
	abstract = {The dip test measures multimodality in a sample by the maximum difference, over all sample points, between the empirical distribution function, and the unimodal distribution function that minimizes that maximum difference. The uniform distribution is the asymptotically least favorable unimodal distribution, and the distribution of the test statistic is determined asymptotically and empirically when sampling from the uniform.},
	urldate = {2018-06-05},
	publisher = {Institute of Mathematical Statistics},
	author = {Hartigan, J. A. and Hartigan, P. M.},
	doi = {10.2307/2241144},
	note = {Pages: 70-84
Publication Title: The Annals of Statistics
Volume: 13},
}

@article{Ghasemi2012,
	title = {Normality tests for statistical analysis: a guide for non-statisticians.},
	volume = {10},
	issn = {1726-913X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23843808},
	doi = {10.5812/ijem.3505},
	abstract = {Statistical errors are common in scientific literature and about 50\% of the published articles have at least one error. The assumption of normality needs to be checked for many statistical procedures, namely parametric tests, because their validity depends on it. The aim of this commentary is to overview checking for normality in statistical analysis using SPSS.},
	number = {2},
	urldate = {2018-06-05},
	journal = {International journal of endocrinology and metabolism},
	author = {Ghasemi, Asghar and Zahediasl, Saleh},
	year = {2012},
	pmid = {23843808},
	note = {Publisher: Kowsar Medical Institute},
	keywords = {Normality, Statistical Analysis},
	pages = {486--9},
}

@article{fraley_how_nodate,
	title = {How {Many} {Clusters}? {Which} {Clustering} {Method}? {Answers} {Via} {Model}-{Based} {Cluster} {Analysis}},
	abstract = {We consider the problem of determining the structure of clustered data, without prior knowledge of the number of clusters or any other information about their composition. Data are represented by a mixture model in which each component corresponds to a different cluster. Models with varying geometric properties are obtained through Gaussian components with different parametrizations and cross-cluster constraints. Noise and outliers can be modelled by adding a Poisson process component. Partitions are determined by the expectation-maximization (EM) algorithm for maximum likelihood, with initial values from agglomerative hierarchical clustering. Models are compared using an approximation to the Bayes factor based on the Bayesian information criterion (BIC); unlike significance tests, this allows comparison of more than two models at the same time, and removes the restriction that the models compared be nested. The problems of determining the number of clusters and the clustering method are solved simultaneously by choosing the best model. Moreover, the EM result provides a measure of uncertainty about the associated classification of each data point. Examples are given, showing that this approach can give performance that is much better than standard procedures, which often fail to identify groups that are either overlapping or of varying sizes and shapes.},
	urldate = {2018-06-05},
	author = {Fraley, Chris and Raftery, Adrian E},
}

@article{freedman_histogram_1981,
	title = {On the histogram as a density estimator:{L} 2 theory},
	volume = {57},
	issn = {0044-3719},
	url = {http://link.springer.com/10.1007/BF01025868},
	doi = {10.1007/BF01025868},
	number = {4},
	urldate = {2018-05-29},
	journal = {Zeitschrift f�r Wahrscheinlichkeitstheorie und Verwandte Gebiete},
	author = {Freedman, David and Diaconis, Persi},
	month = dec,
	year = {1981},
	note = {Publisher: Springer-Verlag},
	pages = {453--476},
}

@misc{noauthor_spectral_nodate,
	title = {Spectral {Clustering}: {A} quick overview},
	url = {https://calculatedcontent.com/2012/10/09/spectral-clustering/},
	urldate = {2018-05-23},
}

@article{ning_incremental_2010,
	title = {Incremental spectral clustering by efficiently updating the eigen-system},
	volume = {43},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320309002209},
	doi = {10.1016/J.PATCOG.2009.06.001},
	abstract = {In recent years, the spectral clustering method has gained attentions because of its superior performance. To the best of our knowledge, the existing spectral clustering algorithms cannot incrementally update the clustering results given a small change of the data set. However, the capability of incrementally updating is essential to some applications such as websphere or blogsphere. Unlike the traditional stream data, these applications require incremental algorithms to handle not only insertion/deletion of data points but also similarity changes between existing points. In this paper, we extend the standard spectral clustering to such evolving data, by introducing the incidence vector/matrix to represent two kinds of dynamics in the same framework and by incrementally updating the eigen-system. Our incremental algorithm, initialized by a standard spectral clustering, continuously and efficiently updates the eigenvalue system and generates instant cluster labels, as the data set is evolving. The algorithm is applied to a blog data set. Compared with recomputation of the solution by the standard spectral clustering, it achieves similar accuracy but with much lower computational cost. It can discover not only the stable blog communities but also the evolution of the individual multi-topic blogs. The core technique of incrementally updating the eigenvalue system is a general algorithm and has a wide range of applications—as well as incremental spectral clustering—where dynamic graphs are involved. This demonstrates the wide applicability of our incremental algorithm.},
	number = {1},
	urldate = {2018-05-23},
	journal = {Pattern Recognition},
	author = {Ning, Huazhong and Xu, Wei and Chi, Yun and Gong, Yihong and Huang, Thomas S.},
	month = jan,
	year = {2010},
	note = {Publisher: Pergamon},
	pages = {113--127},
}

@book{Parlett1998,
	title = {The symmetric eigenvalue problem},
	isbn = {978-1-61197-116-3},
	abstract = {Title from title screen, viewed 04/05/2011. "This SIAM edition is an unabridged, corrected republication of the work first published by Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1980"--Title page verso. According to Parlett, "Vibrations are everywhere, and so too are the eigenvalues associated with them. As mathematical models invade more and more disciplines, we can anticipate a demand for eigenvalue calculations in an ever richer variety of contexts." Anyone who performs these calculations will welcome the reprinting of Parlett's book (originally published in 1980). In this unabridged, amended version, Parlett covers aspects of the problem that are not easily found elsewhere. The chapter titles convey the scope of the material succinctly. The aim of the book is to present mathematical knowledge that is needed in order to understand the art of computing eigenvalues of real symmetric matrices, either all of them or only a few. The author explains why the selected information really matters and he is not shy about making judgments. The commentary is lively but the proofs are terse. The first nine chapters are based on a matrix on which it is possible to make similarity transformations explicitly. The only source of error is inexact arithmetic. The last five chapters turn to large sparse matrices and the task of making approximations and judging them. Convergence theory for the Rayleigh quotient iteration -- Eigenvectors of tridiagonals -- Convergence theory, simpler than Wilkinson's, for Wilkinson's shift strategy in QL and QR -- New proofs and sharper results for error bounds -- Optimal properties of Rayleigh-Ritz approximations -- Approximation theory from Krylov subspaces, Paige's theorem for noisy Lanczos algorithms, and semiorthogonality among Lanczos vectors -- Four flavors of subspace iteration.},
	urldate = {2018-05-23},
	publisher = {Society for Industrial and Applied Mathematics (SIAM, 3600 Market Street, Floor 6, Philadelphia, PA 19104)},
	author = {Parlett, Beresford N. and {Society for Industrial and Applied Mathematics.}},
	year = {1998},
}

@article{zitnik_predicting_2017,
	title = {Predicting multicellular function through multi-layer tissue networks},
	volume = {33},
	issn = {1367-4803},
	url = {https://academic.oup.com/bioinformatics/article/33/14/i190/3953967},
	doi = {10.1093/bioinformatics/btx252},
	number = {14},
	urldate = {2018-05-22},
	journal = {Bioinformatics},
	author = {Zitnik, Marinka and Leskovec, Jure},
	month = jul,
	year = {2017},
	note = {Publisher: Oxford University Press},
	pages = {i190--i198},
}

@book{Malmberg2011,
	title = {Graph-based {Methods} for {Interactive} {Image} {Segmentation}},
	isbn = {978-91-554-8037-0},
	abstract = {Härtill 7 uppsatser. Diss. (sammanfattning)--Uppsala: Uppsala universitet, 2011.},
	urldate = {2018-05-17},
	publisher = {Acta Universitatis Upsaliensis},
	author = {Malmberg, Filip},
	year = {2011},
}

@article{andrews_fully_2014,
	title = {Fully {Automated} {Medical} {Image} {Analysis} {Facilitating} {Subsequent} {User} {Analysis}},
	url = {http://summit.sfu.ca/item/14338},
	urldate = {2018-05-17},
	author = {Andrews, Shawn David},
	month = jul,
	year = {2014},
}

@article{grady_random_2006,
	title = {Random {Walks} for {Image} {Segmentation}},
	volume = {28},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/1704833/},
	doi = {10.1109/TPAMI.2006.233},
	number = {11},
	urldate = {2018-05-17},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Grady, L.},
	month = nov,
	year = {2006},
	pages = {1768--1783},
}

@article{Nassar2013,
	title = {Caveola-forming proteins caveolin-1 and {PTRF} in prostate cancer},
	volume = {10},
	issn = {1759-4812},
	url = {http://www.nature.com/articles/nrurol.2013.168},
	doi = {10.1038/nrurol.2013.168},
	abstract = {Caveolae are flask-shaped invaginations of the plasma membrane involved in membrane trafficking and cell signalling. Here, Parat et al. discuss the roles of caveolin 1 and PTRF in prostate cancer, summarizing the available data on the expression and function of these caveola-forming proteins and asking whether they might be targeted for future therapeutic strategies.},
	number = {9},
	urldate = {2018-05-16},
	journal = {Nature Reviews Urology},
	author = {Nassar, Zeyad D. and Hill, Michelle M. and Parton, Robert G. and Parat, Marie-Odile},
	month = sep,
	year = {2013},
	note = {Publisher: Nature Publishing Group},
	keywords = {Prostate cancer},
	pages = {529--536},
}

@article{grady_minimal_2010,
	title = {Minimal {Surfaces} {Extend} {Shortest} {Path} {Segmentation} {Methods} to {3D}},
	volume = {32},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/4711052/},
	doi = {10.1109/TPAMI.2008.289},
	number = {2},
	urldate = {2018-05-15},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Grady, L.},
	month = feb,
	year = {2010},
	pages = {321--334},
}

@article{wan_variational_2011,
	title = {Variational surface reconstruction based on {Delaunay} triangulation and graph cut},
	volume = {85},
	issn = {00295981},
	url = {http://doi.wiley.com/10.1002/nme.2965},
	doi = {10.1002/nme.2965},
	number = {2},
	urldate = {2018-05-15},
	journal = {International Journal for Numerical Methods in Engineering},
	author = {Wan, Min and Wang, Yu and Wang, Desheng},
	month = jan,
	year = {2011},
	note = {Publisher: Wiley-Blackwell},
	keywords = {Delaunay triangulation, graph cut, multi‐phase, reverse engineering, surface reconstruction},
	pages = {206--229},
}

@article{Felzenszwalb2004,
	title = {Efficient graph-based image segmentation},
	volume = {59},
	issn = {09205691},
	url = {http://link.springer.com/10.1023/B:VISI.0000022288.19776.77},
	doi = {10.1023/B:VISI.0000022288.19776.77},
	abstract = {This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm},
	number = {2},
	urldate = {2018-05-15},
	journal = {International Journal of Computer Vision},
	author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
	month = sep,
	year = {2004},
	pmid = {1000198747},
	note = {Publisher: Kluwer Academic Publishers
ISBN: 0920-5691},
	keywords = {Clustering, Graph algorithm, Image segmentation, Perceptual organization},
	pages = {167--181},
}

@article{Peng2013,
	title = {A survey of graph theoretical approaches to image segmentation},
	volume = {46},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320312004219},
	doi = {10.1016/J.PATCOG.2012.09.015},
	abstract = {Image segmentation is a fundamental problem in computer vision. Despite many years of research, general purpose image segmentation is still a very challenging task because segmentation is inherently ill-posed. Among different segmentation schemes, graph theoretical ones have several good features in practical applications. It explicitly organizes the image elements into mathematically sound structures, and makes the formulation of the problem more flexible and the computation more efficient. In this paper, we conduct a systematic survey of graph theoretical methods for image segmentation, where the problem is modeled in terms of partitioning a graph into several sub-graphs such that each of them represents a meaningful object of interest in the image. These methods are categorized into five classes under a uniform notation: the minimal spanning tree based methods, graph cut based methods with cost functions, graph cut based methods on Markov random field models, the shortest path based methods and the other methods that do not belong to any of these classes. We present motivations and detailed technical descriptions for each category of methods. The quantitative evaluation is carried by using five indices – Probabilistic Rand (PR) index, Normalized Probabilistic Rand (NPR) index, Variation of Information (VI), Global Consistency Error (GCE) and Boundary Displacement Error (BDE) – on some representative automatic and interactive segmentation methods.},
	number = {3},
	urldate = {2018-05-12},
	journal = {Pattern Recognition},
	author = {Peng, Bo and Zhang, Lei and Zhang, David},
	month = mar,
	year = {2013},
	note = {Publisher: Pergamon},
	pages = {1020--1038},
}

@article{Shivanandan2014,
	title = {Challenges in quantitative single molecule localization microscopy},
	volume = {588},
	issn = {0014-5793},
	url = {https://www.sciencedirect.com/science/article/pii/S0014579314004724},
	doi = {10.1016/J.FEBSLET.2014.06.014},
	abstract = {Single molecule localization microscopy (SMLM), which can provide up to an order of magnitude improvement in spatial resolution over conventional fluorescence microscopy, has the potential to be a highly useful tool for quantitative biological experiments. It has already been used for this purpose in varied fields in biology, ranging from molecular biology to neuroscience. In this review article, we briefly review the applications of SMLM in quantitative biology, and also the challenges involved and some of the solutions that have been proposed. Due to its advantages in labeling specificity and the relatively low overcounting caused by photoblinking when photo-activable fluorescent proteins (PA-FPs) are used as labels, we focus specifically on Photo-Activated Localization Microscopy (PALM), even though the ideas presented might be applicable to SMLM in general. Also, we focus on the following three quantitative measurements: single molecule counting, analysis of protein spatial distribution heterogeneity and co-localization analysis.},
	number = {19},
	urldate = {2018-05-11},
	journal = {FEBS Letters},
	author = {Shivanandan, A. and Deschout, H. and Scarselli, M. and Radenovic, A.},
	month = oct,
	year = {2014},
	note = {Publisher: No longer published by Elsevier},
	pages = {3595--3602},
}

@incollection{Kumar2008,
	title = {What {Is} a {Good} {Nearest} {Neighbors} {Algorithm} for {Finding} {Similar} {Patches} in {Images}?},
	isbn = {978-3-540-88685-3},
	url = {http://link.springer.com/10.1007/978-3-540-88688-4_27},
	urldate = {2018-05-11},
	booktitle = {Proceedings of the 10th {European} {Conference} on {Computer} {Vision}: {Part} {II}},
	publisher = {Springer-Verlag},
	author = {Kumar, Neeraj and Zhang, Li and Nayar, Shree},
	year = {2008},
	doi = {10.1007/978-3-540-88688-4_27},
	pages = {364--378},
}

@article{Descloux2018,
	title = {Combined multi-plane phase retrieval and super-resolution optical fluctuation imaging for {4D} cell microscopy},
	volume = {12},
	issn = {1749-4885},
	url = {http://www.nature.com/articles/s41566-018-0109-4},
	doi = {10.1038/s41566-018-0109-4},
	number = {3},
	urldate = {2018-05-10},
	journal = {Nature Photonics},
	author = {Descloux, A. and Grußmayer, K. S. and Bostan, E. and Lukes, T. and Bouwens, A. and Sharipov, A. and Geissbuehler, S. and Mahul-Mellier, A.-L. and Lashuel, H. A. and Leutenegger, M. and Lasser, T.},
	month = mar,
	year = {2018},
	pages = {165--172},
}

@article{wu_group_2018,
	title = {Group {Normalization}},
	url = {http://arxiv.org/abs/1803.08494},
	abstract = {Batch Normalization (BN) is a milestone technique in the development of deep learning, enabling various networks to train. However, normalizing along the batch dimension introduces problems --- BN's error increases rapidly when the batch size becomes smaller, caused by inaccurate batch statistics estimation. This limits BN's usage for training larger models and transferring features to computer vision tasks including detection, segmentation, and video, which require small batches constrained by memory consumption. In this paper, we present Group Normalization (GN) as a simple alternative to BN. GN divides the channels into groups and computes within each group the mean and variance for normalization. GN's computation is independent of batch sizes, and its accuracy is stable in a wide range of batch sizes. On ResNet-50 trained in ImageNet, GN has 10.6\% lower error than its BN counterpart when using a batch size of 2; when using typical batch sizes, GN is comparably good with BN and outperforms other normalization variants. Moreover, GN can be naturally transferred from pre-training to fine-tuning. GN can outperform its BN-based counterparts for object detection and segmentation in COCO, and for video classification in Kinetics, showing that GN can effectively replace the powerful BN in a variety of tasks. GN can be easily implemented by a few lines of code in modern libraries.},
	urldate = {2018-05-10},
	author = {Wu, Yuxin and He, Kaiming},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.08494},
}

@article{yizong_cheng_mean_1995,
	title = {Mean shift, mode seeking, and clustering},
	volume = {17},
	issn = {01628828},
	url = {http://ieeexplore.ieee.org/document/400568/},
	doi = {10.1109/34.400568},
	number = {8},
	urldate = {2018-05-09},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {{Yizong Cheng}},
	year = {1995},
	pages = {790--799},
}

@article{lakhani_hello_2018,
	title = {Hello {World} {Deep} {Learning} in {Medical} {Imaging}},
	issn = {0897-1889},
	url = {http://link.springer.com/10.1007/s10278-018-0079-6},
	doi = {10.1007/s10278-018-0079-6},
	urldate = {2018-05-09},
	journal = {Journal of Digital Imaging},
	author = {Lakhani, Paras and Gray, Daniel L. and Pett, Carl R. and Nagy, Paul and Shih, George},
	month = may,
	year = {2018},
	note = {Publisher: Springer International Publishing},
	pages = {1--7},
}

@article{Grady,
	title = {Discrete {Calculus}},
	doi = {10.1007/978-1-84996-290-2},
	urldate = {2018-04-30},
	journal = {Discrete Calculus},
	author = {Grady, Leo J. and Polimeni, Jonathan R.},
	year = {2010},
}

@article{Spielman,
	title = {Spectral {Graph} {Theory} and its {Applications}},
	urldate = {2018-04-30},
	author = {Spielman, Daniel A},
}

@article{graps_introduction_nodate,
	title = {An {Introduction} to {Wavelets}},
	abstract = {Wavelets are mathematical functions that cut up data into different frequency com-ponents, and then study each component with a resolution matched to its scale. They have ad-vantages over traditional Fourier methods in analyzing physical situations where the signal contains discontinuities and sharp spikes. Wavelets were developed independently in the fields of mathemat-ics, quantum physics, electrical engineering, and seismic geology. Interchanges between these fields during the last ten years have led to many new wavelet applications such as image compression, turbulence, human vision, radar, and earthquake prediction. This paper introduces wavelets to the interested technical person outside of the digital signal processing field. I describe the history of wavelets beginning with Fourier, compare wavelet transforms with Fourier transforms, state prop-erties and other special aspects of wavelets, and finish with some interesting applications such as image compression, musical tones, and de-noising noisy data.},
	urldate = {2018-04-30},
	author = {Graps, Amara},
}

@book{cvetkovic_selected_2011,
	title = {Selected topics on applications of graph spectra},
	isbn = {86-80593-44-3},
	url = {https://books.google.ca/books/about/Selected_Topics_on_Applications_of_Graph.html?id=apkmKQEACAAJ&redir_esc=y},
	urldate = {2018-04-30},
	publisher = {Matematički Inst. SANU},
	author = {Cvetković, Dragoš. and Gutman, Ivan.},
	year = {2011},
}

@article{noauthor_biological_nodate,
	title = {{BIOLOGICAL} {IMAGING} {BY} {SUPERRESOLUTION} {LIGHT} {MICROSCOPY}},
}

@article{Gaietta2002,
	title = {Multicolor and {Electron} {Microscopic} {Imaging} of {Connexin} {Trafficking}},
	volume = {296},
	issn = {00368075},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/11964472},
	doi = {10.1126/science.1068793},
	abstract = {Recombinant proteins containing tetracysteine tags can be successively labeled in living cells with different colors of biarsenical fluorophores so that older and younger protein molecules can be sharply distinguished by both fluorescence and electron microscopy. Here we used this approach to show that newly synthesized connexin43 was transported predominantly in 100- to 150-nanometer vesicles to the plasma membrane and incorporated at the periphery of existing gap junctions, whereas older connexins were removed from the center of the plaques into pleiomorphic vesicles of widely varying sizes. Selective imaging by correlated optical and electron microscopy of protein molecules of known ages will clarify fundamental processes of protein trafficking in situ.},
	number = {5567},
	urldate = {2018-04-29},
	journal = {Science},
	author = {Gaietta, G. and Deerinck, Thomas J and Adams, Stephen R and Bouwer, James and Tour, Oded and Laird, Dale W and Sosinsky, Gina E and Tsien, Roger Y and Ellisman, Mark H},
	month = apr,
	year = {2002},
	pmid = {11964472},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {503--507},
}

@article{Shaner2014,
	title = {Fluorescent proteins for quantitative microscopy: {Important} properties and practical evaluation},
	volume = {123},
	issn = {0091-679X},
	url = {https://www.sciencedirect.com/science/article/pii/B9780124201385000069},
	doi = {10.1016/B978-0-12-420138-5.00006-9},
	abstract = {More than 20 years after their discovery, fluorescent proteins (FPs) continue to be the subject of massive engineering efforts yielding continued improvements. Among these efforts are many aspects that should be of great interest to quantitative imaging users. With new variants frequently introduced into the research community, “tried and true” FPs that have been relied on for many years may now be due for upgrades to more modern variants. However, the dizzying array of FPs now available can make the initial act of narrowing down the potential choices an intimidating prospect. This chapter describes the FP properties that most strongly impact their performance in quantitative imaging experiments, along with their physical origins as they are currently understood. A workflow for evaluating a given FP in the researcher's chosen experimental system (e.g., a specific cell line) is described.},
	urldate = {2018-04-29},
	journal = {Methods in Cell Biology},
	author = {Shaner, Nathan Christopher},
	month = jan,
	year = {2014},
	note = {Publisher: Academic Press
ISBN: 9780124201385},
	pages = {95--111},
}

@article{Cordelieres2014,
	title = {Experimenters' guide to colocalization studies: {Finding} a way through indicators and quantifiers, in practice},
	volume = {123},
	issn = {0091-679X},
	url = {https://www.sciencedirect.com/science/article/pii/B9780124201385000215},
	doi = {10.1016/B978-0-12-420138-5.00021-5},
	abstract = {Multicolor fluorescence microscopy helps to define the local interplay of subcellular components in cell biological experiments. The analysis of spatial coincidence of two or more markers is a first step in investigating the potential interactions of molecular actors. Colocalization studies rely on image preprocessing and further analysis; however, they are limited by optical resolution. Once those limitations are taken into account, characterization might be performed. In this review, we discuss two types of parameters that are aimed at evaluating colocalization, which are indicators and quantifiers. Indicators evaluate signal coincidence over a predefined scale, while quantifiers provide an absolute measurement. As the image is both a collection of intensities and a collection of objects, both approaches are applicable. Most of the available image processing software include various colocalization options; however, guidance for the choice of the appropriate method is rarely proposed. In this review, we provide the reader with a basic description of the available colocalization approaches, proposing a guideline for their use, either alone or in combination.},
	urldate = {2018-04-29},
	journal = {Methods in Cell Biology},
	author = {Cordelières, Fabrice P. and Bolte, Susanne},
	month = jan,
	year = {2014},
	note = {Publisher: Academic Press
ISBN: 9780124201385},
	pages = {395--408},
}

@article{Shtengel2014,
	title = {Imaging cellular ultrastructure by {PALM}, {iPALM}, and correlative {iPALM}-{EM}},
	volume = {123},
	issn = {0091-679X},
	url = {https://www.sciencedirect.com/science/article/pii/B978012420138500015X},
	doi = {10.1016/B978-0-12-420138-5.00015-X},
	abstract = {Many biomolecules in cells can be visualized with high sensitivity and specificity by fluorescence microscopy. However, the resolution of conventional light microscopy is limited by diffraction to {\textasciitilde}200–250nm laterally and {\textgreater}500nm axially. Here, we describe superresolution methods based on single-molecule localization analysis of photoswitchable fluorophores (PALM: photoactivated localization microscopy) as well as our recent three-dimensional (3D) method (iPALM: interferometric PALM) that allows imaging with a resolution better than 20nm in all three dimensions. Considerations for their implementations, applications to multicolor imaging, and a recent development that extend the imaging depth of iPALM to {\textasciitilde}750nm are discussed. As the spatial resolution of superresolution fluorescence microscopy converges with that of electron microscopy (EM), direct imaging of the same specimen using both approaches becomes feasible. This could be particularly useful for cross validation of experiments, and thus, we also describe recent methods that were developed for correlative superresolution fluorescence and EM.},
	urldate = {2018-04-29},
	journal = {Methods in Cell Biology},
	author = {Shtengel, Gleb and Wang, Yilin and Zhang, Zhen and Goh, Wah Ing and Hess, Harald F. and Kanchanawong, Pakorn},
	month = jan,
	year = {2014},
	note = {Publisher: Academic Press
ISBN: 9780124201385},
	pages = {273--294},
}

@article{DuFort2014,
	title = {Nanoscale cellular imaging with scanning angle interference microscopy},
	volume = {123},
	issn = {0091-679X},
	url = {https://www.sciencedirect.com/science/article/pii/B9780124201385000136},
	doi = {10.1016/B978-0-12-420138-5.00013-6},
	abstract = {Fluorescence microscopy is among the most widely utilized tools in cell and molecular biology due to its ability to noninvasively obtain time-resolved images of live cells with molecule-specific contrast. In this chapter, we describe a simple high-resolution technique, scanning angle interference microscopy (SAIM), for the imaging and localization of fluorescent molecules with nanometer precision along the optical axis. In SAIM, samples above a reflective surface are sequentially scanned with an excitation laser at varying angles of incidence. Interference patterns generated between the incident and reflected lights result in an emission intensity that depends on the height of a fluorophore above the silicon surface and the angle of the incident radiation. The measured fluorescence intensities are then fit to an optical model to localize the labeled molecules along the z-axis with 5–10nm precision and diffraction-limited lateral resolution. SAIM is easily implemented on widely available commercial total internal reflection fluorescence microscopes, offering potential for widespread use in cell biology. Here, we describe the setup of SAIM and its application for imaging cellular structures near ({\textless}1μm) the sample substrate.},
	urldate = {2018-04-29},
	journal = {Methods in Cell Biology},
	author = {DuFort, Christopher and Paszek, Matthew},
	month = jan,
	year = {2014},
	note = {Publisher: Academic Press
ISBN: 9780124201385},
	pages = {235--252},
}

@article{Majlof2002,
	title = {Confocal {Microscopy}: {Important} {Considerations} for {Accurate} {Imaging}},
	volume = {70},
	issn = {0091-679X},
	url = {https://www.sciencedirect.com/science/article/pii/S0091679X02700058},
	doi = {10.1016/S0091-679X(02)70005-8},
	urldate = {2018-04-29},
	journal = {Methods in Cell Biology},
	author = {Majlof, Lars and Forsgren, Per-Ola},
	month = jan,
	year = {2002},
	note = {Publisher: Academic Press
ISBN: 9780124802773},
	pages = {149--164},
}

@article{Yi2018,
	title = {Fast {Super} {Resolved} {Imaging} of {Live} {Cells} {Using} {Superresolution} {Optical} {Fluctuation} {Imaging} 2.0 ({SOFI}-2.0)},
	volume = {114},
	issn = {00063495},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0006349517313504},
	doi = {10.1016/j.bpj.2017.11.118},
	number = {3},
	urldate = {2018-04-24},
	journal = {Biophysical Journal},
	author = {Yi, Xiyu and Son, Sungho and Weiss, Shimon},
	month = feb,
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {13a--14a},
}

@incollection{Buchin2015,
	address = {Philadelphia, PA},
	title = {Region-based {Approximation} {Algorithms} for {Visibility} between {Imprecise} {Locations}},
	url = {http://epubs.siam.org/doi/10.1137/1.9781611973754.9},
	urldate = {2018-04-24},
	booktitle = {2015 {Proceedings} of the {Seventeenth} {Workshop} on {Algorithm} {Engineering} and {Experiments} ({ALENEX})},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Buchin, Kevin and Kostitsyna, Irina and Löffler, Maarten and Silveira, Rodrigo I.},
	month = jan,
	year = {2015},
	doi = {10.1137/1.9781611973754.9},
	pages = {94--103},
}

@article{VanKreveld2010,
	title = {Preprocessing {Imprecise} {Points} and {Splitting} {Triangulations}},
	volume = {39},
	issn = {0097-5397},
	url = {http://epubs.siam.org/doi/10.1137/090753620},
	doi = {10.1137/090753620},
	number = {7},
	urldate = {2018-04-24},
	journal = {SIAM Journal on Computing},
	author = {van Kreveld, Marc and Löffler, Maarten and Mitchell, Joseph S. B.},
	month = jan,
	year = {2010},
	pages = {2990--3000},
}

@article{Zhang2014,
	title = {Interferometric three-dimensional single molecule localization microscopy using a single high-numerical-aperture objective},
	volume = {53},
	issn = {0003-6935},
	url = {https://www.osapublishing.org/abstract.cfm?URI=ao-53-31-7415},
	doi = {10.1364/AO.53.007415},
	abstract = {Interferometric detection of the fluorescence emission from a single molecule [interferometric photoactivated localization microscopy (iPALM)] enables a localization accuracy of nanometers in axial localization for 3D superresolution imaging. However, iPALM uses two high-numerical-aperture (NA) objectives in juxtaposition for fluorescence collection (a 4Pi microscope geometry), increasing expense and limiting samples that can be studied. Here, we propose an interferometric single molecule localization microscopy method using a single high-NA objective. The axial position of single molecules can be unambiguously determined from the phase-shifted interference signals with nanometer precision and over a range of 2\&\#x3BB;. The use of only one objective simplifies the system configuration and sample mounting. In addition, due to the use of wavefront-splitting interference in our approach, the two parts of the wavefront that eventually merge and interfere with each other travel along nearly equivalent optical paths, which should minimize the effect of drift for long-term 3D superresolution imaging.},
	number = {31},
	urldate = {2018-04-24},
	journal = {Applied Optics},
	author = {Zhang, P. and Goodwin, P. M. and Werner, J. H.},
	month = nov,
	year = {2014},
	note = {Publisher: Optical Society of America},
	keywords = {Fluorescence microscopy, Superresolution, Three, dimensional microscopy},
	pages = {7415},
}

@article{kendall_what_2017,
	title = {What {Uncertainties} {Do} {We} {Need} in {Bayesian} {Deep} {Learning} for {Computer} {Vision}?},
	url = {https://arxiv.org/abs/1703.04977},
	urldate = {2018-04-23},
	author = {Kendall, Alex and Gal, Yarin},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.04977},
}

@article{Shroff2008,
	title = {Live-cell photoactivated localization microscopy of nanoscale adhesion dynamics.},
	volume = {5},
	issn = {1548-7105},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18408726},
	doi = {10.1038/nmeth.1202},
	abstract = {We demonstrate live-cell super-resolution imaging using photoactivated localization microscopy (PALM). The use of photon-tolerant cell lines in combination with the high resolution and molecular sensitivity of PALM permitted us to investigate the nanoscale dynamics within individual adhesion complexes (ACs) in living cells under physiological conditions for as long as 25 min, with half of the time spent collecting the PALM images at spatial resolutions down to approximately 60 nm and frame rates as short as 25 s. We visualized the formation of ACs and measured the fractional gain and loss of individual paxillin molecules as each AC evolved. By allowing observation of a wide variety of nanoscale dynamics, live-cell PALM provides insights into molecular assembly during the initiation, maturation and dissolution of cellular processes.},
	number = {5},
	urldate = {2018-04-23},
	journal = {Nature methods},
	author = {Shroff, Hari and Galbraith, Catherine G and Galbraith, James A and Betzig, Eric},
	month = may,
	year = {2008},
	pmid = {18408726},
	note = {Publisher: NIH Public Access},
	pages = {417--23},
}

@article{Sauer2013,
	title = {Localization microscopy coming of age: from concepts to biological impact},
	volume = {126},
	issn = {0021-9533},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23950110},
	doi = {10.1242/jcs.123612},
	abstract = {Super-resolution fluorescence imaging by single-molecule photoactivation or photoswitching and position determination (localization microscopy) has the potential to fundamentally revolutionize our understanding of how cellular function is encoded at the molecular level. Among all powerful, high-resolution imaging techniques introduced in recent years, localization microscopy excels because it delivers single-molecule information about molecular distributions, even giving absolute numbers of proteins present in subcellular compartments. This provides insight into biological systems at a molecular level that can yield direct experimental feedback for modeling the complexity of biological interactions. In addition, efficient new labeling methods and strategies to improve localization are emerging that promise to achieve true molecular resolution. This raises localization microscopy as a powerful complementary method for correlative light and electron microscopy experiments.},
	number = {16},
	urldate = {2018-04-23},
	journal = {Journal of Cell Science},
	author = {Sauer, M.},
	month = aug,
	year = {2013},
	pmid = {23950110},
	keywords = {Localization microscopy, Quantitative imaging, Single-molecule fluorescence detection, Super-resolution fluorescence imaging},
	pages = {3505--3513},
}

@article{Legant2016,
	title = {High-density three-dimensional localization microscopy across large volumes},
	volume = {13},
	issn = {15487105},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26950745},
	doi = {10.1038/nmeth.3797},
	abstract = {Extending three-dimensional (3D) single-molecule localization microscopy away from the coverslip and into thicker specimens will greatly broaden its biological utility. However, because of the limitations of both conventional imaging modalities and conventional labeling techniques, it is a challenge to localize molecules in three dimensions with high precision in such samples while simultaneously achieving the labeling densities required for high resolution of densely crowded structures. Here we combined lattice light-sheet microscopy with newly developed, freely diffusing, cell-permeable chemical probes with targeted affinity for DNA, intracellular membranes or the plasma membrane. We used this combination to perform high-localization precision, ultrahigh-labeling density, multicolor localization microscopy in samples up to 20 μm thick, including dividing cells and the neuromast organ of a zebrafish embryo. We also demonstrate super-resolution correlative imaging with protein-specific photoactivable fluorophores, providing a mutually compatible, single-platform alternative to correlative light-electron microscopy over large volumes.},
	number = {4},
	urldate = {2018-04-23},
	journal = {Nature Methods},
	author = {Legant, Wesley R and Shao, Lin and Grimm, Jonathan B and Brown, Timothy A and Milkie, Daniel E and Avants, Brian B and Lavis, Luke D and Betzig, Eric},
	month = apr,
	year = {2016},
	pmid = {26950745},
	note = {arXiv: 1602.03837
ISBN: 1548-7105 (Electronic){\textbackslash}r1548-7091 (Linking)},
	pages = {359--365},
}

@inproceedings{Wanga,
	title = {Multiscale structural similarity for image quality assessment},
	isbn = {0-7803-8104-1},
	url = {http://ieeexplore.ieee.org/document/1292216/},
	doi = {10.1109/ACSSC.2003.1292216},
	urldate = {2018-04-23},
	booktitle = {The {Thrity}-{Seventh} {Asilomar} {Conference} on {Signals}, {Systems} \& {Computers}, 2003},
	publisher = {IEEE},
	author = {Wang, Z. and Simoncelli, E.P. and Bovik, A.C.},
	pages = {1398--1402},
}

@article{Ouyang2018,
	title = {Deep learning massively accelerates super-resolution localization microscopy},
	issn = {1087-0156},
	url = {http://www.nature.com/doifinder/10.1038/nbt.4106},
	doi = {10.1038/nbt.4106},
	abstract = {Accelerating PALM/STORM microscopy with deep learning allows super-resolution imaging of {\textgreater}1,000 cells in a few hours.},
	urldate = {2018-04-23},
	journal = {Nature Biotechnology},
	author = {Ouyang, Wei and Aristov, Andrey and Lelek, Mickaël and Hao, Xian and Zimmer, Christophe},
	month = apr,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Fluorescence imaging, Image processing, Machine learning, Microscopy, Super, resolution microscopy},
}

@article{wehinger_phosphorylation_2015,
	title = {Phosphorylation of caveolin-1 on tyrosine-14 induced by {ROS} enhances palmitate-induced death of beta-pancreatic cells},
	volume = {1852},
	issn = {0925-4439},
	url = {https://www.sciencedirect.com/science/article/pii/S0925443914004153},
	doi = {10.1016/J.BBADIS.2014.12.021},
	abstract = {A considerable body of evidence exists implicating high levels of free saturated fatty acids in beta pancreatic cell death, although the molecular mechanisms and the signaling pathways involved have not been clearly defined. The membrane protein caveolin-1 has long been implicated in cell death, either by sensitizing to or directly inducing apoptosis and it is normally expressed in beta cells. Here, we tested whether the presence of caveolin-1 modulates free fatty acid-induced beta cell death by reexpressing this protein in MIN6 murine beta cells lacking caveolin-1. Incubation of MIN6 with palmitate, but not oleate, induced apoptotic cell death that was enhanced by the presence of caveolin-1. Moreover, palmitate induced de novo ceramide synthesis, loss of mitochondrial transmembrane potential and reactive oxygen species (ROS) formation in MIN6 cells. ROS generation promoted caveolin-1 phosphorylation on tyrosine-14 that was abrogated by the anti-oxidant N-acetylcysteine or the incubation with the Src-family kinase inhibitor, PP2 (4-amino-5-(4-chlorophenyl)-7(dimethylethyl)pyrazolo[3,4-d]pyrimidine). The expression of a non-phosphorylatable caveolin-1 tyrosine-14 to phenylalanine mutant failed to enhance palmitate-induced apoptosis while for MIN6 cells expressing the phospho-mimetic tyrosine-14 to glutamic acid mutant caveolin-1 palmitate sensitivity was comparable to that observed for MIN6 cells expressing wild type caveolin-1. Thus, caveolin-1 expression promotes palmitate-induced ROS-dependent apoptosis in MIN6 cells in a manner requiring Src family kinase mediated tyrosine-14 phosphorylation.},
	number = {5},
	urldate = {2018-04-20},
	journal = {Biochimica et Biophysica Acta (BBA) - Molecular Basis of Disease},
	author = {Wehinger, Sergio and Ortiz, Rina and Díaz, María Inés and Aguirre, Adam and Valenzuela, Manuel and Llanos, Paola and Mc Master, Christopher and Leyton, Lisette and Quest, Andrew F.G.},
	month = may,
	year = {2015},
	note = {Publisher: Elsevier},
	pages = {693--708},
}

@article{Gould2010,
	title = {Changes in caveolae, caveolin, and polymerase 1 and transcript release factor ({PTRF}) expression in prostate cancer progression},
	volume = {70},
	issn = {02704137},
	url = {http://doi.wiley.com/10.1002/pros.21195},
	doi = {10.1002/pros.21195},
	number = {15},
	urldate = {2018-04-19},
	journal = {The Prostate},
	author = {Gould, M.L. and Williams, G. and Nicholson, H.D.},
	month = nov,
	year = {2010},
	note = {Publisher: Wiley-Blackwell},
	keywords = {benign prostatic hyperplasia, caveolin‐1, caveolin‐2},
	pages = {1609--1621},
}

@inproceedings{Xie2015,
	title = {Dynamic interaction graphs with probabilistic edge decay},
	volume = {2015-May},
	isbn = {978-1-4799-7963-9},
	doi = {10.1109/ICDE.2015.7113363},
	abstract = {A large scale network of social interactions, such as mentions in Twitter, can often be modeled as a “dynamic interaction graph” in which new interactions (edges) are continually added over time. Existing systems for extracting timely insights from such graphs are based on either a cumulative “snapshot” model or a “sliding window” model. The former model does not sufficiently emphasize recent interactions. The latter model abruptly forgets past interactions, leading to discontinuities in which, e.g., the graph analysis completely ignores historically important influencers who have temporarily gone dormant. We introduce TIDE, a distributed system for analyzing dynamic graphs that employs a new “probabilistic edge decay” (PED) model. In this model, the graph analysis algorithm of interest is applied at each time step to one or more graphs obtained as samples from the current “snapshot” graph that comprises all interactions that have occurred so far. The probability that a given edge of the snapshot graph is included in a sample decays over time according to a user specified decay function. The PED model allows controlled trade-offs between recency and continuity, and allows existing analysis algorithms for static graphs to be applied to dynamic graphs essentially without change. For the important class of exponential decay functions, we provide efficient methods that leverage past samples to incrementally generate new samples as time advances. We also exploit the large degree of overlap between samples to reduce memory consumption from O(N) to O(logN) when maintaining N sample graphs. Finally, we provide bulk-execution methods for applying graph algorithms to multiple sample graphs simultaneously without requiring any changes to existing graph-processing APIs. Experiments on a real Twitter dataset demonstrate the effectiveness and efficiency of our TIDE prototype, which is built on top of- the Spark distributed computing framework.},
	booktitle = {Proceedings - {International} {Conference} on {Data} {Engineering}},
	author = {Xie, Wenlei and Tian, Yuanyuan and Sismanis, Yannis and Balmin, Andrey and Haas, Peter J.},
	year = {2015},
	note = {ISSN: 10844627},
}

@article{doi:10.1002/cmdc.201700482,
	title = {Comparison of {Maximum} {Common} {Subgraph} {Isomorphism} {Algorithms} for the {Alignment} of {2D} {Chemical} {Structures}},
	volume = {13},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cmdc.201700482},
	doi = {10.1002/cmdc.201700482},
	abstract = {Abstract The identification of the largest substructure in common when two (or more) molecules are overlaid is important for several applications in chemoinformatics, and can be implemented using a maximum common subgraph (MCS) algorithm. Many such algorithms have been reported, and it is important to know which are likely to be the useful in operation. A detailed comparison was hence conducted of the efficiency (in terms of CPU time) and the effectiveness (in terms of the size of the MCS identified) of eleven MCS algorithms, some of which were exact and some of which were approximate in character. The algorithms were used to identify both connected and disconnected MCSs on a range of pairs of molecules. The fastest exact algorithms for the connected and disconnected problems were found to be the fMCS and MaxCliqueSeq algorithms, respectively, while the ChemAxon\_MCS algorithm was the fastest approximate algorithm for both types of problem.},
	number = {6},
	journal = {ChemMedChem},
	author = {Duesbury, Edmund and Holliday, John and Willett, Peter},
	keywords = {chemoinformatics, drug discovery, maximum common subgraph, maximum common substructure, molecular alignment},
	pages = {588--598},
}

@inproceedings{Salesin1989,
	address = {New York, New York, USA},
	title = {Epsilon geometry: building robust algorithms from imprecise computations},
	isbn = {0-89791-318-3},
	url = {http://portal.acm.org/citation.cfm?doid=73833.73857},
	doi = {10.1145/73833.73857},
	urldate = {2018-04-18},
	booktitle = {Proceedings of the fifth annual symposium on {Computational} geometry  - {SCG} '89},
	publisher = {ACM Press},
	author = {Salesin, D. and Stolfi, J and Guibas, L.},
	year = {1989},
	pages = {208--217},
}

@article{doi:10.1002/net.3230110104,
	title = {An {O}(n log n) heuristic for steiner minimal tree problems on the euclidean metric},
	volume = {11},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/net.3230110104},
	doi = {10.1002/net.3230110104},
	abstract = {Abstract An O(n log n) heuristic for the Euclidean Steiner Minimal Tree (ESMT) problem is presented. The algorithm is based on a decomposition approach which first partitions the vertex set into triangles via the Delaunay triangulation, then “recomposes” the suboptimal Steiner Minimal Tree (SMT) according to the Voronoi diagram and Minimum Spanning Tree (MST) of the point set. The ESMT algorithm was implemented in FORTRAN‐IV and tested on a number of randomly generated point sets in the plane drawn from a uniform distribution. Comparison of the O(n log n) algorithm with an O(n4) algorithm clearly indicates that the O(n log n) algorithm is as good as the previous O(n4) algorithm in achieving reductions in the ratio SMT/MST of the given vertex set. This is somewhat surprising since the O(n4) algorithm considers more potential Steiner points and alternative tree configurations.},
	number = {1},
	journal = {Networks},
	author = {Smith, J Macgregor and Lee, D T and Liebman, Judith S},
	pages = {23--39},
}

@article{eppstein_subgraph_1999,
	title = {Subgraph {Isomorphism} in {Planar} {Graphs} and {Related} {Problems}},
	url = {http://arxiv.org/abs/cs/9911003},
	abstract = {We solve the subgraph isomorphism problem in planar graphs in linear time, for any pattern of constant size. Our results are based on a technique of partitioning the planar graph into pieces of small tree-width, and applying dynamic programming within each piece. The same methods can be used to solve other planar graph problems including connectivity, diameter, girth, induced subgraph isomorphism, and shortest paths.},
	urldate = {2018-04-17},
	author = {Eppstein, David},
	month = nov,
	year = {1999},
	note = {arXiv: cs/9911003},
}

@article{u_v_r_e_s_good_nodate,
	title = {Good approximation for the relative neighbourhood graph},
	urldate = {2018-04-15},
	author = {U V R è S, R T and Â, Ã and Ç H, Å AE and Î, Ã and µ, á H and µ, H and Ð, Ï W and Ò, Y and Õ, Á and Å Ù Ç, Ø Y and Å Þ Ç, Ý and Ê Ä, Ï and á, â},
}

@article{maass_mosaic:_2017,
	title = {{MOSAIC}: {Processing} a {Trillion}-{Edge} {Graph} on a {Single} {Machine}},
	doi = {10.1145/3064176.3064191},
	abstract = {Processing a one trillion-edge graph has recently been demon-strated by distributed graph engines running on clusters of tens to hundreds of nodes. In this paper, we employ a single heterogeneous machine with fast storage media (e.g., NVMe SSD) and massively parallel coprocessors (e.g., Xeon Phi) to reach similar dimensions. By fully exploiting the hetero-geneous devices, we design a new graph processing engine, named MOSAIC, for a single machine. We propose a new locality-optimizing, space-efficient graph representation— Hilbert-ordered tiles, and a hybrid execution model that en-ables vertex-centric operations in fast host processors and edge-centric operations in massively parallel coprocessors. Our evaluation shows that for smaller graphs, MOSAIC consistently outperforms other state-of-the-art out-of-core engines by 3.2–58.6× and shows comparable performance to distributed graph engines. Furthermore, MOSAIC can complete one iteration of the Pagerank algorithm on a trillion-edge graph in 21 minutes, outperforming a distributed disk-based engine by 9.2×.},
	journal = {EuroSys},
	author = {Maass, Steffen and Min, Changwoo and Kashyap, Sanidhya and Kang, Woonhak and Kumar, Mohan and Kim, Taesoo},
	year = {2017},
	note = {ISBN: 9781450349383},
}

@book{kao_encyclopedia_2008,
	title = {Encyclopedia of algorithms},
	isbn = {0-387-30162-3},
	url = {https://dl.acm.org/citation.cfm?id=1479716},
	abstract = {The Encyclopedia of Algorithms provides a comprehensive set of solutions to important algorithmic problems for students and researchers, including high-impact solutions from the most recent decade. A must-have for computer scientists, this encyclopedic reference has been edited by Ming Yang Kao, Editor-in-Chief of the top journal in the field, Algorithmica. All of the entries have been written and peer-reviewed by experts in the field. Nearly 400 entries are organized alphabetically by problem, with subentries for distinct solutions. Extensive cross-references support efficient, user-friendly searches for immediate access to useful information. This defining reference is published both in print and online. The print publication includes an index of subjects and authors as well as a chronology for locating recent solutions. The online edition supplements this index with hyperlinks as well as including internal hyperlinks to related entries in the text, CrossRef citations, and links to additional significant research. Open problems, links to downloadable code, experimental results, data sets, and illustrations are included. VLSI -- Distributed Computing -- Parallel Processing -- Automated Design -- Robotics -- Graphics -- Data Base Design -- Software Tools -- Sorting -- Searching -- Data Structures -- Computational Geometry -- Linear Programming.},
	urldate = {2018-04-09},
	publisher = {Springer},
	author = {Kao, Ming-Yang. and Yang, Ming},
	year = {2008},
}

@article{henzinger_dynamic_2013,
	title = {Dynamic {Approximate} {All}-{Pairs} {Shortest} {Paths}: {Breaking} the {O}(mn) {Barrier} and {Derandomization}},
	url = {http://arxiv.org/abs/1308.0776},
	doi = {10.1137/140957299},
	abstract = {We study dynamic \$(1+{\textbackslash}epsilon)\$-approximation algorithms for the all-pairs shortest paths problem in unweighted undirected \$n\$-node \$m\$-edge graphs under edge deletions. The fastest algorithm for this problem is a randomized algorithm with a total update time of \${\textbackslash}tilde O(mn/{\textbackslash}epsilon)\$ and constant query time by Roditty and Zwick [FOCS 2004]. The fastest deterministic algorithm is from a 1981 paper by Even and Shiloach [JACM 1981]; it has a total update time of \$O(mn{\textasciicircum}2)\$ and constant query time. We improve these results as follows: (1) We present an algorithm with a total update time of \${\textbackslash}tilde O(n{\textasciicircum}\{5/2\}/{\textbackslash}epsilon)\$ and constant query time that has an additive error of \$2\$ in addition to the \$1+{\textbackslash}epsilon\$ multiplicative error. This beats the previous \${\textbackslash}tilde O(mn/{\textbackslash}epsilon)\$ time when \$m={\textbackslash}Omega(n{\textasciicircum}\{3/2\})\$. Note that the additive error is unavoidable since, even in the static case, an \$O(n{\textasciicircum}\{3-{\textbackslash}delta\})\$-time (a so-called truly subcubic) combinatorial algorithm with \$1+{\textbackslash}epsilon\$ multiplicative error cannot have an additive error less than \$2-{\textbackslash}epsilon\$, unless we make a major breakthrough for Boolean matrix multiplication [Dor et al. FOCS 1996] and many other long-standing problems [Vassilevska Williams and Williams FOCS 2010]. The algorithm can also be turned into a \$(2+{\textbackslash}epsilon)\$-approximation algorithm (without an additive error) with the same time guarantees, improving the recent \$(3+{\textbackslash}epsilon)\$-approximation algorithm with \${\textbackslash}tilde O(n{\textasciicircum}\{5/2+O({\textbackslash}sqrt\{{\textbackslash}log\{(1/{\textbackslash}epsilon)\}/{\textbackslash}log n\})\})\$ running time of Bernstein and Roditty [SODA 2011] in terms of both approximation and time guarantees. (2) We present a deterministic algorithm with a total update time of \${\textbackslash}tilde O(mn/{\textbackslash}epsilon)\$ and a query time of \$O({\textbackslash}log{\textbackslash}log n)\$. The algorithm has a multiplicative error of \$1+{\textbackslash}epsilon\$ and gives the first improved deterministic algorithm since 1981. It also answers an open question raised by Bernstein [STOC 2013].},
	urldate = {2018-04-09},
	author = {Henzinger, Monika and Krinninger, Sebastian and Nanongkai, Danupon},
	month = aug,
	year = {2013},
	note = {arXiv: 1308.0776},
}

@incollection{demetrescu_decremental_2008,
	address = {Boston, MA},
	title = {Decremental {All}-{Pairs} {Shortest} {Paths}},
	url = {http://link.springer.com/10.1007/978-0-387-30162-4_102},
	urldate = {2018-04-09},
	booktitle = {Encyclopedia of {Algorithms}},
	publisher = {Springer US},
	author = {Demetrescu, Camil and Italiano, Giuseppe F.},
	year = {2008},
	doi = {10.1007/978-0-387-30162-4_102},
	pages = {226--227},
}

@article{Defferrard2016,
	title = {Convolutional {Neural} {Networks} on {Graphs} with {Fast} {Localized} {Spectral} {Filtering}},
	issn = {10495258},
	abstract = {In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs.},
	author = {Defferrard, Michaël and Bresson, Xavier and Vandergheynst, Pierre},
	year = {2016},
	note = {arXiv: 1606.09375
ISBN: 978-1-5108-3881-9},
}

@article{Pennacchietti2017,
	title = {The {Role} of {Probe} {Photophysics} in {Localization}-{Based} {Superresolution} {Microscopy}},
	volume = {113},
	issn = {15420086},
	doi = {10.1016/j.bpj.2017.08.054},
	abstract = {Fluorescent proteins are used extensively for biological imaging applications; photoactivatable and photoconvertible fluorescent proteins (PAFPs) are used widely in superresolution localization microscopy methods such as fluorescence photoactivation localization microscopy and photoactivated localization microscopy. However, their optimal use depends on knowledge of not only their bulk fluorescence properties, but also their photophysical properties at the single molecule level. We have used fluorescence correlation spectroscopy and cross-correlation spectroscopy to quantify the diffusion, photobleaching, fluorescence intermittency, and photoconversion dynamics of Dendra2, a well-known PAFP used in localization microscopy. Numerous dark states of Dendra2 are observed both in inactive (green fluorescent) and active (orange fluorescent) forms; the interconversion rates are both light- and pH-dependent, as observed for other PAFPs. The dark states limit the detected count rate per molecule, which is a crucial parameter for localization microscopy. We then developed, to our knowledge, a new mathematical estimate for the resolution in localization microscopy as a function of the measured photophysical parameters of the probe such as photobleaching quantum yield, count rate per molecule, and intensity of saturation. The model was used to predict the dependence of resolution on acquisition parameters such as illumination intensity and time per frame, demonstrating an optimal set of acquisition parameters for a given probe for a variety of measures of resolution. The best possible resolution was then compared for Dendra2 and other widely used probes, including Alexa dyes and quantum dots. This work establishes a framework for determination of the best possible resolution using a localization microscope to image a particular fluorophore, and suggests that development of probes for use in superresolution localization microscopy must consider the count rate per molecule, the saturation intensity, the photobleaching yield, and, crucially, management of bright/dark state transitions, to optimize image resolution.},
	number = {9},
	journal = {Biophysical Journal},
	author = {Pennacchietti, Francesca and Gould, Travis J. and Hess, Samuel T.},
	year = {2017},
	pmid = {29117527},
}

@inproceedings{guerraoui_optimistic_2016,
	title = {Optimistic concurrency with {OPTIK}},
	isbn = {978-1-4503-4092-2},
	doi = {10.1145/2851141.2851146},
	abstract = {Abstract Authors References Cited By Index Terms Publication Reviews Comments Table of Contents We introduce OPTIK, a new practical design pattern for designing and implementing fast and scalable concurrent data structures. OPTIK relies on the commonly-used technique of version numbers for detecting conflicting concurrent operations. We show how to implement the OPTIK pattern using the novel concept of OPTIK locks. These locks enable the use of version numbers for implementing very efficient optimistic concurrent data structures. Existing state-of-the-art lock-based data structures acquire the lock and then check for conflicts. In contrast, with OPTIK locks, we merge the lock acquisition with the detection of conflicting concurrency in a single atomic step, similarly to lock-free algorithms. We illustrate the power of our OPTIK pattern and its implementation by introducing four new algorithms and by optimizing four state-of-the-art algorithms for linked lists, skip lists, hash tables, and queues. Our results show that concurrent data structures built using OPTIK are more scalable than the state of the art.},
	booktitle = {Proceedings of the 21st {ACM} {SIGPLAN} {Symposium} on {Principles} and {Practice} of {Parallel} {Programming} - {PPoPP} '16},
	author = {Guerraoui, Rachid and Trigonakis, Vasileios},
	year = {2016},
}

@article{makreshanski_lock_2015,
	title = {To {Lock} , {Swap} , or {Elide} : {On} the {Interplay} of {Hardware} {Transactional} {Memory} and {Lock}-{Free} {Indexing}},
	issn = {21508097},
	doi = {10.14778/2809974.2809990},
	abstract = {The release of hardware transactional memory (HTM) in commod- ity CPUs has major implications on the design and implementation of main-memory databases, especially on the architecture of high- performance lock-free indexing methods at the core of several of these systems. This paper studies the interplay of HTM and lock- free indexing methods. First, we evaluate whether HTM will ob- viate the need for crafty lock-free index designs by integrating it in a traditional B-tree architecture. HTM performs well for simple data sets with small fixed-length keys and payloads, but its benefits disappear for more complex scenarios (e.g., larger variable-length keys and payloads), making it unattractive as a general solution for achieving high performance. Second, we explore fundamen- tal differences between HTM-based and lock-free B-tree designs. While lock-freedom entails design complexity and extra mecha- nism, it has performance advantages in several scenarios, especially high-contention cases where readers proceed uncontested (whereas HTM aborts readers). Finally, we explore the use of HTM as a method to simplify lock-free design. We find that using HTM to implement a multi-word compare-and-swap greatly reduces lock- free programming complexity at the cost of only a 10-15\% per- formance degradation. Our study uses two state-of-the-art index implementations: a memory-optimized B-tree extended with HTM to provide multi-threaded concurrency and the Bw-tree lock-free B-tree used in several Microsoft production environments.},
	journal = {Proceedings of the 41st International Conference on Very Large Data Bases},
	author = {Makreshanski, Darko and Zurich, E T H},
	year = {2015},
}

@inproceedings{Brown2017,
	address = {New York, New York, USA},
	title = {A {Template} for {Implementing} {Fast} {Lock}-free {Trees} {Using} {HTM}},
	isbn = {978-1-4503-4992-5},
	url = {http://dl.acm.org/citation.cfm?doid=3087801.3087834},
	doi = {10.1145/3087801.3087834},
	urldate = {2018-04-03},
	booktitle = {Proceedings of the {ACM} {Symposium} on {Principles} of {Distributed} {Computing}  - {PODC} '17},
	publisher = {ACM Press},
	author = {Brown, Trevor and {Trevor}},
	year = {2017},
	keywords = {concurrent, data structures, hardware transactional memory, lock-free, transactional memory, trees},
	pages = {293--302},
}

@article{meghan_garg_minimum_nodate,
	title = {Minimum {Consistent} {Subset} {Problem} in {Pattern} {Recognition}},
	author = {{Meghan Garg}},
}

@article{gao_minimum_2013,
	title = {The {Minimum} {Consistent} {Subset} {Cover} {Problem}: {A} {Minimization} {View} of {Data} {Mining}},
	volume = {25},
	issn = {1041-4347},
	url = {http://ieeexplore.ieee.org/document/6109255/},
	doi = {10.1109/TKDE.2011.260},
	number = {3},
	urldate = {2018-04-02},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Gao, Byron J. and Ester, Martin and Xiong, Hui and Cai, Jin-Yi and Schulte, Oliver},
	month = mar,
	year = {2013},
	pages = {690--703},
}

@inproceedings{wilfong_nearest_1991,
	address = {New York, New York, USA},
	title = {Nearest neighbor problems},
	isbn = {0-89791-426-0},
	url = {http://portal.acm.org/citation.cfm?doid=109648.109673},
	doi = {10.1145/109648.109673},
	urldate = {2018-04-02},
	booktitle = {Proceedings of the seventh annual symposium on {Computational} geometry  - {SCG} '91},
	publisher = {ACM Press},
	author = {Wilfong, Gordon and {Gordon}},
	year = {1991},
	pages = {224--233},
}

@article{garcia_bayes_2013,
	title = {Bayes filter for dynamic coordinate measurements - {Accuracy} improvment, data fusion and measurement uncertainty evaluation},
	issn = {02632241},
	doi = {10.1016/j.measurement.2013.04.001},
	abstract = {This paper presents a novel methodology to improve the measurement accuracy of dynamic measurements. This is achieved by deducing an online Bayes optimal estimate of the true measurand given uncertain, noisy or incomplete measurements within the framework of sequential Monte Carlo methods. The estimation problem is formulated as a general Bayesian inference problem for nonlinear dynamic systems. The optimal estimate is represented by probability density functions, which enable an online, probabilistic data fusion as well as a Bayesian measurement uncertainty evaluation corresponding to the "Guide to the expression of uncertainty in measurement". The efficiency and performance of the proposed methodology is verified and shown by dynamic coordinate measurements. © 2013 Elsevier Ltd. All rights reserved.},
	journal = {Measurement: Journal of the International Measurement Confederation},
	author = {Garcia, E. and Hausotte, T. and Amthor, A.},
	year = {2013},
	note = {ISBN: 0263-2241},
	keywords = {And data fusion, Bayesian filtering, Dynamic coordinate measurements, Online measurement, Particle filter, Sequential Monte Carlo methods, Uncertainty evaluation},
}

@misc{noauthor_groundbreaking_nodate,
	title = {Groundbreaking research results in artificial intelligence ({AI}) - {Universitetet} i {Agder}},
	url = {https://www.uia.no/en/news/groundbreaking-research-results-in-artificial-intelligence-ai},
	urldate = {2018-03-30},
}

@article{Krehbiel2004,
	title = {Correlation {Coefficient} {Rule} of {Thumb}},
	volume = {2},
	issn = {1540-4595},
	url = {http://doi.wiley.com/10.1111/j.0011-7315.2004.00025.x},
	doi = {10.1111/j.0011-7315.2004.00025.x},
	number = {1},
	urldate = {2018-03-29},
	journal = {Decision Sciences Journal of Innovative Education},
	author = {Krehbiel, Timothy C.},
	month = jan,
	year = {2004},
	note = {Publisher: Wiley/Blackwell (10.1111)},
	pages = {97--100},
}

@article{VanHeel1987,
	title = {Similarity measures between images},
	volume = {21},
	issn = {0304-3991},
	url = {https://www.sciencedirect.com/science/article/pii/0304399187900106},
	doi = {10.1016/0304-3991(87)90010-6},
	abstract = {A recurring problem in image analysis and three-dimensional reconstruction is how best to compare two independent images. Commonly used measures such as the cross-correlation coefficient are insufficient indicators of image similarity. In this paper two functional measures, the phase residual and the Fourier ring correlation, are discussed in that context.},
	number = {1},
	urldate = {2018-03-27},
	journal = {Ultramicroscopy},
	author = {Van Heel, Marin},
	month = jan,
	year = {1987},
	note = {Publisher: North-Holland},
	pages = {95--100},
}

@article{Nieuwenhuizen2013,
	title = {Measuring image resolution in optical nanoscopy},
	volume = {10},
	issn = {1548-7091},
	url = {http://www.nature.com/articles/nmeth.2448},
	doi = {10.1038/nmeth.2448},
	abstract = {A method for computing the intrinsic resolution of a super-resolution image that accounts for localization uncertainty, labeling density and image anisotropy is described. This work extends and builds on the Fourier ring correlation method used in cryoelectron microscopy.},
	number = {6},
	urldate = {2018-03-27},
	journal = {Nature Methods},
	author = {Nieuwenhuizen, Robert P J and Lidke, Keith A and Bates, Mark and Puig, Daniela Leyton and Grünwald, David and Stallinga, Sjoerd and Rieger, Bernd},
	month = jun,
	year = {2013},
	note = {Publisher: Nature Publishing Group},
	keywords = {Cellular imaging, Fluorescence imaging, Nanoscale biophysics, Super, resolution microscopy},
	pages = {557--562},
}

@article{Grashoff2010,
	title = {Measuring mechanical tension across vinculin reveals regulation of focal adhesion dynamics},
	volume = {466},
	issn = {0028-0836},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20613844},
	doi = {10.1038/nature09198},
	abstract = {Mechanical forces are central to developmental, physiological and pathological processes. However, limited understanding of force transmission within sub-cellular structures is a major obstacle to unravelling molecular mechanisms. Here we describe the development of a calibrated biosensor that measures forces across specific proteins in cells with piconewton (pN) sensitivity, as demonstrated by single molecule fluorescence force spectroscopy. The method is applied to vinculin, a protein that connects integrins to actin filaments and whose recruitment to focal adhesions (FAs) is force-dependent. We show that tension across vinculin in stable FAs is approximately 2.5 pN and that vinculin recruitment to FAs and force transmission across vinculin are regulated separately. Highest tension across vinculin is associated with adhesion assembly and enlargement. Conversely, vinculin is under low force in disassembling or sliding FAs at the trailing edge of migrating cells. Furthermore, vinculin is required for stabilizing adhesions under force. Together, these data reveal that FA stabilization under force requires both vinculin recruitment and force transmission, and that, surprisingly, these processes can be controlled independently.},
	number = {7303},
	urldate = {2018-03-27},
	journal = {Nature},
	author = {Grashoff, Carsten and Hoffman, Brenton D. and Brenner, Michael D. and Zhou, Ruobo and Parsons, Maddy and Yang, Michael T. and McLean, Mark A. and Sligar, Stephen G. and Chen, Christopher S. and Ha, Taekjip and Schwartz, Martin A.},
	month = jul,
	year = {2010},
	pmid = {20613844},
	pages = {263--266},
}

@article{Zamir1999,
	title = {Molecular diversity of cell-matrix adhesions.},
	volume = {112 ( Pt 1},
	issn = {0021-9533},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/10318759},
	abstract = {In this study we have examined for molecular heterogeneity of cell-matrix adhesions and the involvement of actomyosin contractility in the selective recruitment of different plaque proteins. For this purpose, we have developed a novel microscopic approach for molecular morphometry, based on automatic identification of matrix adhesions, followed by quantitative immunofluorescence and morphometric analysis. Particularly informative was fluorescence ratio imaging, comparing the local labeling intensities of different plaque molecules, including vinculin, paxillin, tensin and phosphotyrosine-containing proteins. Ratio imaging revealed considerable molecular heterogeneity between and within adhesion sites. Most striking were the differences between focal contacts, which are vinculin- and paxillin-rich and contain high levels of phosphotyrosine, and fibrillar adhesions, which are tensin-rich and contain little or no phosphotyrosine. Ratio imaging also revealed considerable variability in the molecular substructure of individual focal contacts, pointing to a non-uniform distribution of phosphotyrosine and the different plaque constituents. Studying the quantitative relationships between the various components of the submembrane plaque indicated that the levels of vinculin, paxillin and phosphotyrosine in adhesion sites are positively correlated with each other and negatively correlated with the levels of tensin. Tyrosine phosphorylation of focal contacts was highly sensitive to cellular contractility, and was diminished within 5 minutes after treatment with the kinase inhibitor H-7, an inhibitor of actomyosin contractility. This was followed by the loss of paxillin and vinculin from the focal adhesions. Tensin-rich fibrillar adhesions were relatively insensitive to H-7 treatment. These findings suggest a role for contractility in the generation of matrix adhesion diversity.},
	urldate = {2018-03-27},
	journal = {Journal of cell science},
	author = {Zamir, E and Katz, B Z and Aota, S and Yamada, K M and Geiger, B and Kam, Z},
	month = jun,
	year = {1999},
	pmid = {10318759},
	pages = {1655--69},
}

@article{katajainen_linear_1987,
	title = {A linear expected-time algorithm for computing planar relative neighbourhood graphs},
	volume = {25},
	issn = {00200190},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0020019087902250},
	doi = {10.1016/0020-0190(87)90225-0},
	number = {2},
	urldate = {2018-03-26},
	journal = {Information Processing Letters},
	author = {Katajainen, Jyrki and Nevalainen, Olli and Teuhola, Jukka},
	month = may,
	year = {1987},
	pages = {77--86},
}

@article{toussaint_relative_1980,
	title = {The relative neighbourhood graph of a finite planar set},
	volume = {12},
	issn = {00313203},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0031320380900667},
	doi = {10.1016/0031-3203(80)90066-7},
	number = {4},
	urldate = {2018-03-26},
	journal = {Pattern Recognition},
	author = {Toussaint, Godfried T.},
	month = jan,
	year = {1980},
	pages = {261--268},
}

@article{jaromczyk_relative_1992,
	title = {Relative neighborhood graphs and their relatives},
	volume = {80},
	issn = {00189219},
	url = {http://ieeexplore.ieee.org/document/163414/},
	doi = {10.1109/5.163414},
	number = {9},
	urldate = {2018-03-26},
	journal = {Proceedings of the IEEE},
	author = {Jaromczyk, J.W. and Toussaint, G.T.},
	year = {1992},
	pages = {1502--1517},
}

@inproceedings{jaromczyk_note_1987,
	address = {New York, New York, USA},
	title = {A note on relative neighborhood graphs},
	isbn = {0-89791-231-4},
	url = {http://portal.acm.org/citation.cfm?doid=41958.41983},
	doi = {10.1145/41958.41983},
	urldate = {2018-03-26},
	booktitle = {Proceedings of the third annual symposium on {Computational} geometry  - {SCG} '87},
	publisher = {ACM Press},
	author = {Jaromczyk, J. W. and Kowaluk, M.},
	year = {1987},
	pages = {233--241},
}

@article{orourke_computing_1982,
	title = {Computing the relative neighborhood graph in the {L1} and {L}∞ metrics},
	volume = {15},
	issn = {00313203},
	url = {http://linkinghub.elsevier.com/retrieve/pii/003132038290070X},
	doi = {10.1016/0031-3203(82)90070-X},
	number = {3},
	urldate = {2018-03-26},
	journal = {Pattern Recognition},
	author = {O'Rourke, Joseph},
	month = jan,
	year = {1982},
	pages = {189--192},
}

@article{jaromczyk_constructing_1991,
	title = {Constructing the relative neighborhood graph in 3-dimensional {Euclidean} space},
	volume = {31},
	issn = {0166218X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0166218X91900699},
	doi = {10.1016/0166-218X(91)90069-9},
	number = {2},
	urldate = {2018-03-26},
	journal = {Discrete Applied Mathematics},
	author = {Jaromczyk, Jerzy W. and Kowaluk, Mirosław},
	month = apr,
	year = {1991},
	pages = {181--191},
}

@article{lee_relative_1985,
	title = {Relative neighborhood graphs in the {Li}-metric},
	volume = {18},
	issn = {00313203},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0031320385900238},
	doi = {10.1016/0031-3203(85)90023-8},
	number = {5},
	urldate = {2018-03-26},
	journal = {Pattern Recognition},
	author = {Lee, D.T.},
	month = jan,
	year = {1985},
	pages = {327--332},
}

@article{toussaint_comment:_1980,
	title = {Comment: {Algorithms} for computing relative neighbourhood graph},
	volume = {16},
	issn = {00135194},
	url = {http://digital-library.theiet.org/content/journals/10.1049/el_19800611},
	doi = {10.1049/el:19800611},
	number = {22},
	urldate = {2018-03-26},
	journal = {Electronics Letters},
	author = {Toussaint, G.T.},
	year = {1980},
	pages = {860},
}

@article{Urquhart1980,
	title = {Reply: {Algorithms} for computing relative neighbourhood graph},
	volume = {16},
	issn = {00135194},
	url = {http://digital-library.theiet.org/content/journals/10.1049/el_19800612},
	doi = {10.1049/el:19800612},
	number = {22},
	urldate = {2018-03-26},
	journal = {Electronics Letters},
	author = {Urquhart, R.B.},
	year = {1980},
	pages = {860},
}

@book{andrade_proc._2001,
	title = {Proc. 13th {Canadian} {Conference} on {Computational} {Geometry}},
	urldate = {2018-03-26},
	author = {Andrade, Diogo Vieira and de Figueiredo, Luiz Henrique},
	year = {2001},
}

@article{urquhart_algorithms_1980,
	title = {Algorithms for computation of relative neighbourhood graph},
	volume = {16},
	issn = {00135194},
	url = {http://digital-library.theiet.org/content/journals/10.1049/el_19800386},
	doi = {10.1049/el:19800386},
	number = {14},
	urldate = {2018-03-26},
	journal = {Electronics Letters},
	author = {Urquhart, R.B.},
	year = {1980},
	pages = {556},
}

@book{agarwal_proc._1992,
	title = {Proc. 3rd {ACM}–{SIAM} {Symp}. {Discrete} {Algorithms}},
	url = {http://portal.acm.org/citation.cfm?id=139404.139416},
	urldate = {2018-03-26},
	author = {Agarwal, Pankaj K. and Mataušek, Jiří},
	year = {1992},
}

@article{lingas_linear-time_1994,
	title = {A linear-time construction of the relative neighborhood graph from the {Delaunay} triangulation},
	volume = {4},
	issn = {0925-7721},
	url = {https://www.sciencedirect.com/science/article/pii/0925772194900183?via%3Dihub},
	doi = {10.1016/0925-7721(94)90018-3},
	abstract = {A very simple linear-time algorithm for constructing the relative neighborhood graph RNG(V) for a finite set V of points in the plane from the Delaunay triangulation of V is presented. It is extended to include the construction of the so called β-skeletons (generalization of RNG(V)) in the spectrum 1 ⩽ β ⩽ 2 in linear time from the Delaunay triangulation under the metric Lp for 1 {\textless} p {\textless} ∞ if β = 2 or p = 2.},
	number = {4},
	urldate = {2018-03-26},
	journal = {Computational Geometry},
	author = {Lingas, Andrzej},
	month = aug,
	year = {1994},
	note = {Publisher: Elsevier},
	pages = {199--208},
}

@article{kawahara_brainnetcnn:_2017,
	title = {{BrainNetCNN}: {Convolutional} neural networks for brain networks; towards predicting neurodevelopment},
	volume = {146},
	issn = {10538119},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27693612},
	doi = {10.1016/j.neuroimage.2016.09.046},
	abstract = {We propose BrainNetCNN, a convolutional neural network (CNN) framework to predict clinical neurodevelopmental outcomes from brain networks. In contrast to the spatially local convolutions done in traditional image-based CNNs, our BrainNetCNN is composed of novel edge-to-edge, edge-to-node and node-to-graph convolutional filters that leverage the topological locality of structural brain networks. We apply the BrainNetCNN framework to predict cognitive and motor developmental outcome scores from structural brain networks of infants born preterm. Diffusion tensor images (DTI) of preterm infants, acquired between 27 and 46 weeks gestational age, were used to construct a dataset of structural brain connectivity networks. We first demonstrate the predictive capabilities of BrainNetCNN on synthetic phantom networks with simulated injury patterns and added noise. BrainNetCNN outperforms a fully connected neural-network with the same number of model parameters on both phantoms with focal and diffuse injury patterns. We then apply our method to the task of joint prediction of Bayley-III cognitive and motor scores, assessed at 18 months of age, adjusted for prematurity. We show that our BrainNetCNN framework outperforms a variety of other methods on the same data. Furthermore, BrainNetCNN is able to identify an infant's postmenstrual age to within about 2 weeks. Finally, we explore the high-level features learned by BrainNetCNN by visualizing the importance of each connection in the brain with respect to predicting the outcome scores. These findings are then discussed in the context of the anatomy and function of the developing preterm infant brain.},
	urldate = {2018-03-22},
	journal = {NeuroImage},
	author = {Kawahara, Jeremy and Brown, Colin J. and Miller, Steven P. and Booth, Brian G. and Chau, Vann and Grunau, Ruth E. and Zwicker, Jill G. and Hamarneh, Ghassan},
	month = feb,
	year = {2017},
	pmid = {27693612},
	keywords = {Brain networks, Connectome, Convolutional neural networks, Deep learning, Diffusion MRI, Neurodevelopment, Prediction, Preterm infants},
	pages = {1038--1049},
}

@article{duvenaud_convolutional_nodate,
	title = {Convolutional {Networks} on {Graphs} for {Learning} {Molecular} {Fingerprints}},
	abstract = {We introduce a convolutional neural network that operates directly on graphs. These networks allow end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape. The architecture we present generalizes standard molecular feature extraction methods based on circular fingerprints. We show that these data-driven features are more interpretable, and have better pre-dictive performance on a variety of tasks.},
	urldate = {2018-03-22},
	author = {Duvenaud, David and Maclaurin, Dougal and Aguilera-Iparraguirre, Jorge and Gómez-Bombarelli, Rafael and Hirzel, Timothy and Aspuru-Guzik, Alán and Adams, Ryan P},
}

@article{hammond_wavelets_2009,
	title = {Wavelets on {Graphs} via {Spectral} {Graph} {Theory}},
	abstract = {We propose a novel method for constructing wavelet transforms of functions defined on the vertices of an arbitrary finite weighted graph. Our approach is based on defining scaling using the the graph analogue of the Fourier domain, namely the spectral decomposition of the discrete graph Laplacian L. Given a wavelet generating kernel g and a scale pa-rameter t, we define the scaled wavelet operator T t g = g(tL). The spectral graph wavelets are then formed by localizing this operator by applying it to an indicator function. Subject to an admissibility condition on g, this procedure defines an invertible transform. We explore the localiza-tion properties of the wavelets in the limit of fine scales. Additionally, we present a fast Chebyshev polynomial approximation algorithm for com-puting the transform that avoids the need for diagonalizing L. We high-light potential applications of the transform through examples of wavelets on graphs corresponding to a variety of different problem domains.},
	urldate = {2018-03-22},
	author = {Hammond, David K and Vandergheynst, Pierre and Gribonval, Rémi},
	year = {2009},
}

@article{bruna_spectral_nodate,
	title = {Spectral {Networks} and {Deep} {Locally} {Connected} {Networks} on {Graphs}},
	abstract = {Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possi-ble generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.},
	urldate = {2018-03-22},
	author = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and Lecun, Yann},
}

@article{shuman_windowed_nodate,
	title = {A {WINDOWED} {GRAPH} {FOURIER} {TRANSFORM}},
	abstract = {The prevalence of signals on weighted graphs is increasing; how-ever, because of the irregular structure of weighted graphs, classical signal processing techniques cannot be directly applied to signals on graphs. In this paper, we define generalized translation and modula-tion operators for signals on graphs, and use these operators to adapt the classical windowed Fourier transform to the graph setting, en-abling vertex-frequency analysis. When we apply this transform to a signal with frequency components that vary along a path graph, the resulting spectrogram matches our intuition from classical discrete-time signal processing. Yet, our construction is fully generalized and can be applied to analyze signals on any undirected, connected, weighted graph.},
	urldate = {2018-03-22},
	author = {Shuman, David I and Ricaud, Benjamin and Vandergheynst, Pierre},
	keywords = {Index Terms— Signal processing on graphs, generalized translation and modulation, spectral graph the-ory, time-frequency analysis},
}

@misc{qi_pointnet++:_2017,
	title = {{PointNet}++: {Deep} {Hierarchical} {Feature} {Learning} on {Point} {Sets} in a {Metric} {Space}},
	url = {http://papers.nips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space},
	urldate = {2018-03-22},
	author = {Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J.},
	year = {2017},
	note = {Pages: 5099-5108},
}

@article{qi_pointnet:_2016,
	title = {{PointNet}: {Deep} {Learning} on {Point} {Sets} for {3D} {Classification} and {Segmentation}},
	url = {http://arxiv.org/abs/1612.00593},
	abstract = {Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds and well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.},
	urldate = {2018-03-22},
	author = {Qi, Charles R. and Su, Hao and Mo, Kaichun and Guibas, Leonidas J.},
	month = dec,
	year = {2016},
	note = {arXiv: 1612.00593},
}

@article{henaff_deep_2015,
	title = {Deep {Convolutional} {Networks} on {Graph}-{Structured} {Data}},
	url = {http://arxiv.org/abs/1506.05163},
	abstract = {Deep Learning's recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities. In this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data. In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate.},
	urldate = {2018-03-22},
	author = {Henaff, Mikael and Bruna, Joan and LeCun, Yann},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.05163},
}

@article{niepert_mathiasniepert_learning_nodate,
	title = {Learning {Convolutional} {Neural} {Networks} for {Graphs}},
	abstract = {Numerous important problems can be framed as learning from graph data. We propose a frame-work for learning convolutional neural networks for arbitrary graphs. These graphs may be undi-rected, directed, and with both discrete and con-tinuous node and edge attributes. Analogous to image-based convolutional networks that oper-ate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using estab-lished benchmark data sets, we demonstrate that the learned feature representations are competi-tive with state of the art graph kernels and that their computation is highly efficient.},
	urldate = {2018-03-22},
	author = {Niepert MATHIASNIEPERT, Mathias and Mohamed Ahmed MOHAMEDAHMED, Neclabeu and Konstantin Kutzkov KONSTANTINKUTZKOV, Neclabeu},
}

@inproceedings{colabrese_learning-based_2016,
	title = {Learning-based approach to boost detection rate and localisation accuracy in single molecule localisation microscopy},
	isbn = {978-1-4673-9961-6},
	url = {http://ieeexplore.ieee.org/document/7532947/},
	doi = {10.1109/ICIP.2016.7532947},
	urldate = {2018-03-21},
	booktitle = {2016 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	publisher = {IEEE},
	author = {Colabrese, Silvia and Castello, Marco and Vicidomini, Giuseppe and Del Bue, Alessio},
	month = sep,
	year = {2016},
	pages = {3184--3188},
}

@article{Banterle2013,
	title = {Fourier ring correlation as a resolution criterion for super-resolution microscopy},
	volume = {183},
	issn = {1047-8477},
	url = {https://www.sciencedirect.com/science/article/pii/S1047847713001184},
	doi = {10.1016/J.JSB.2013.05.004},
	abstract = {Optical nanoscopy techniques using localization based image reconstruction, also termed super-resolution microscopy (SRM), have become a standard tool to bypass the diffraction limit in fluorescence light microscopy. The localization precision measured for the detected fluorophores is commonly used to describe the maximal attainable resolution. However, this measure takes not all experimental factors, which impact onto the finally achieved resolution, into account. Several other methods to measure the resolution of super-resolved images were previously suggested, typically relying on intrinsic standards, such as molecular rulers, or on a priori knowledge about the specimen, e.g. its spatial frequency content. Here we show that Fourier ring correlation provides an easy-to-use, laboratory consistent standard for measuring the resolution of SRM images. We provide a freely available software tool that combines resolution measurement with image reconstruction.},
	number = {3},
	urldate = {2018-03-21},
	journal = {Journal of Structural Biology},
	author = {Banterle, Niccolò and Bui, Khanh Huy and Lemke, Edward A. and Beck, Martin},
	month = sep,
	year = {2013},
	note = {Publisher: Academic Press},
	pages = {363--367},
}

@misc{noauthor_search_nodate,
	title = {In search of the missing signals · giorgio patrini},
	url = {https://giorgiop.github.io/posts/2017/09/06/in-search-of-the-missing-signals/},
	urldate = {2018-03-21},
}

@article{athalye_obfuscated_nodate,
	title = {Obfuscated {Gradients} {Give} a {False} {Sense} of {Security}: {Circumventing} {Defenses} to {Adversarial} {Examples}},
	abstract = {We identify obfuscated gradients, a kind of gradi-ent masking, as a phenomenon that leads to a false sense of security in defenses against adversarial examples. While defenses that cause obfuscated gradients appear to defeat iterative optimization-based attacks, we find defenses relying on this effect can be circumvented. For each of the three types of obfuscated gradients we discover, we describe characteristic behaviors of defenses ex-hibiting this effect and develop attack techniques to overcome it. In a case study, examining non-certified white-box-secure defenses at ICLR 2018, we find obfuscated gradients are a common occur-rence, with 7 of 8 defenses relying on obfuscated gradients. Our new attacks successfully circum-vent 6 completely and 1 partially.},
	urldate = {2018-03-21},
	author = {Athalye, Anish and Carlini, Nicholas and Wagner, David},
}

@article{shi_graph_2017,
	title = {Graph {Processing} on {GPUs} : {A} {Survey}},
	issn = {03600300},
	doi = {10.1145/XXXXX},
	abstract = {See, stats, and : https : / / www . researchgate . net / publication / 318983530 Graph : A Article DOI : 10 . 1145 / XXXXX CITATIONS 3 READS 110 7 , including : Some : Fault - scale Fault - Tolerance Xuanhua Huazhong 115 SEE Yongluan University 65 SEE Hai Huazhong 789 , 165 SEE All . The . In the big data era , much real - world data can be naturally represented as graphs . Consequently , many application domains can be modeled as graph processing . Graph processing , especially the processing of the large scale graphs with the number of vertices and edges in the order of billions or even hundreds of billions , has attracted much attention in both industry and academia . It still remains a great challenge to process such large scale graphs . Researchers have been seeking for new possible solutions . Because of the massive degree of parallelism and the high memory access bandwidth in GPU , utilizing GPU to accelerate graph processing proves to be a promising solution . This paper surveys the key issues of graph processing on GPUs , including data layout , memory access pattern , workload mapping and specific GPU programming . In this paper , we summarize the state - of - the - art research on GPU - based graph processing , analyze the existing challenges in details , and explore the research opportunities in future .},
	journal = {ACM Comput . Surv},
	author = {Shi, Xuanhua and Zhou, Yongluan and Liu, Bo and Zheng, Zhigao and Jin, Hai and He, Ligang},
	year = {2017},
	keywords = {Additional Key Words and Phrases, BSP Model, CCS Concepts, GAS Model ACM Reference Format, GPU, Graph Datasets, Graph Processing, Parallelism, multiple data},
}

@article{guo_benchmarking_2014,
	title = {Benchmarking graph-processing platforms},
	doi = {10.1145/2568088.2576761},
	abstract = {Processing graphs, especially at large scale, is an increasingly useful activity in a variety of business, engineering, and scientific domains. Already, there are tens of graph-processing platforms, such as Hadoop, Giraph, GraphLab, etc., each with a different design and functionality. For graph-processing to continue to evolve, users have to find it easy to select a graph-processing platform, and developers and system integrators have to find it easy to quantify the performance and other non-functional aspects of interest. However, the state of performance analysis of graph-processing platforms is still immature: there are few studies and, for the few that exist, there are few similarities, and relatively little understanding of the impact of dataset and algorithm diversity on performance. Our vision is to develop, with the help of the performance-savvy community, a comprehensive benchmarking suite for graph-processing platforms. In this work, we take a step in this direction, by proposing a set of seven challenges, summarizing our previous work on performance evaluation of distributed graph-processing platforms, and introducing our on-going work within the SPEC Research Group's Cloud Working Group.},
	journal = {Proceedings of the 5th ACM/SPEC international conference on Performance engineering - ICPE '14},
	author = {Guo, Yong and Varbanescu, Ana Lucia and Iosup, Alexandru and Martella, Claudio and Willke, Theodore L.},
	year = {2014},
	note = {ISBN: 9781450327336},
	keywords = {benchmarking, experimentation, graph processing, performance},
}

@inproceedings{eisenman_parallel_2016,
	title = {Parallel {Graph} {Processing}: {Prejudice} and {State} of the {Art}},
	isbn = {978-1-4503-4080-9},
	doi = {10.1145/2851553.2851572},
	abstract = {Large graph processing has attracted much renewed attention due to its increased importance for a social network analysis. The efficient parallel graph processing faces a set of software and hardware issues, discussed in literature. The main cause of these challenges is the "irregularity" of graph computations and related difficulties in efficient parallelization of graph processing. Unbalanced computations, caused by uneven data partitioning, can affect application scalability. Moreover, the issue of poor data locality is another major concern, that makes the graph processing applications memory-bound. In this paper, we aim to profile how large, parallel graph applications (based on Galois framework) utilize modern systems, in particular, memory subsystem. We found that modern graph processing frameworks executed on the latest Intel multi-core systems (a single node server) exhibit a good data locality and achieve a good speedup with an increased number of cores, contrary to traditional past stereotypes. The application processing speedup is highly correlated with utilized memory bandwidth. At the same time, our measurements show that the memory bandwidth is not a bottleneck, and the analyzed graph applications are memory-latency bound. These new insights can help us in matching the resource demands of the graph processing applications to future system design parameters.},
	booktitle = {Proceedings of the 7th {ACM}/{SPEC} on {International} {Conference} on {Performance} {Engineering}},
	author = {Eisenman, Assaf and Cherkasova, Ludmila and Magalhaes, Guilherme and Cai, Qiong and Faraboschi, Paolo and Katti, Sachin},
	year = {2016},
}

@inproceedings{kumar_g-store:_2017,
	title = {G-{Store}: {High}-{Performance} {Graph} {Store} for {Trillion}-{Edge} {Processing}},
	isbn = {978-1-4673-8815-3},
	doi = {10.1109/SC.2016.70},
	abstract = {High-performance graph processing brings great benefits to a wide range of scientific applications, e.g., biology networks, recommendation systems, and social networks, where such graphs have grown to terabytes of data with billions of vertices and trillions of edges. Subsequently, storage performance plays a critical role in designing a high-performance computer system for graph analytics. In this paper, we present G-Store,a new graph store that incorporates three techniques to accelerate the I/O and computation of graph algorithms. First, G-Store develops a space-efficient tile format for graph data, which takes advantage of the symmetry present in graphs as well as a new smallest number of bits representation. Second, G-Store utilizes tile-based physical grouping on disks so that multi-core CPUs can achieve high cache and memory performance and fully utilize the throughput from an array of solid-state disks. Third, G-Store employs a novel slide-cache-rewind strategy to pipeline graph I/O and computing. With a modest amount of memory, G-Store utilizes a proactive caching strategy in the system so that all fetched graph data are fully utilized before evicted from memory. We evaluate G-Store on a number of graphs against two state- of-the-art graph engines and show that G-Store achieves 2 to 8× saving in storage and outperforms both by 2 to 32×. G-Store is able to run different algorithms on trillion-edge graphs within tens of minutes, setting a new milestone in semi-external graph processing system. I.},
	booktitle = {International {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}, {SC}},
	author = {Kumar, Pradeep and Huang, H. Howie},
	year = {2017},
	note = {ISSN: 21674337},
}

@inproceedings{Ahmed2016,
	title = {Efficient graphlet counting for large networks},
	isbn = {978-1-4673-9503-8},
	doi = {10.1109/ICDM.2015.141},
	abstract = {From social science to biology, numerous applications often rely on graphlets for intuitive and meaningful characterization of networks at both the global macro-level as well as the local micro-level. While graphlets have witnessed a tremendous success and impact in a variety of domains, there has yet to be a fast and efficient approach for computing the frequencies of these subgraph patterns. However, existing methods are not scalable to large networks with millions of nodes and edges, which impedes the application of graphlets to new problems that require large-scale network analysis. To address these problems, we propose a fast, efficient, and parallel algorithm for counting graphlets of size k=\{3,4\}-nodes that take only a fraction of the time to compute when compared with the current methods used. The proposed graphlet counting algorithms leverages a number of proven combinatorial arguments for different graphlets. For each edge, we count a few graphlets, and with these counts along with the combinatorial arguments, we obtain the exact counts of others in constant time. On a large collection of 300+ networks from a variety of domains, our graphlet counting strategies are on average 460x faster than current methods. This brings new opportunities to investigate the use of graphlets on much larger networks and newer applications as we show in the experiments. To the best of our knowledge, this paper provides the largest graphlet computations to date as well as the largest systematic investigation on over 300+ networks from a variety of domains.},
	booktitle = {Proceedings - {IEEE} {International} {Conference} on {Data} {Mining}, {ICDM}},
	author = {Ahmed, Nesreen K. and Neville, Jennifer and Rossi, Ryan A. and Duffield, Nick},
	year = {2016},
	note = {arXiv: 1506.0432
ISSN: 15504786},
	keywords = {Graph classification, Graph kernel, Graphlet, Motif counting, Parallel method, Visual analytics},
}

@article{Przulj2007,
	title = {Biological network comparison using graphlet degree distribution},
	volume = {23},
	issn = {1367-4803},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17237089},
	doi = {10.1093/bioinformatics/btl301},
	abstract = {MOTIVATION Analogous to biological sequence comparison, comparing cellular networks is an important problem that could provide insight into biological understanding and therapeutics. For technical reasons, comparing large networks is computationally infeasible, and thus heuristics, such as the degree distribution, clustering coefficient, diameter, and relative graphlet frequency distribution have been sought. It is easy to demonstrate that two networks are different by simply showing a short list of properties in which they differ. It is much harder to show that two networks are similar, as it requires demonstrating their similarity in all of their exponentially many properties. Clearly, it is computationally prohibitive to analyze all network properties, but the larger the number of constraints we impose in determining network similarity, the more likely it is that the networks will truly be similar. RESULTS We introduce a new systematic measure of a network's local structure that imposes a large number of similarity constraints on networks being compared. In particular, we generalize the degree distribution, which measures the number of nodes 'touching' k edges, into distributions measuring the number of nodes 'touching' k graphlets, where graphlets are small connected non-isomorphic subgraphs of a large network. Our new measure of network local structure consists of 73 graphlet degree distributions of graphlets with 2-5 nodes, but it is easily extendible to a greater number of constraints (i.e. graphlets), if necessary, and the extensions are limited only by the available CPU. Furthermore, we show a way to combine the 73 graphlet degree distributions into a network 'agreement' measure which is a number between 0 and 1, where 1 means that networks have identical distributions and 0 means that they are far apart. Based on this new network agreement measure, we show that almost all of the 14 eukaryotic PPI networks, including human, resulting from various high-throughput experimental techniques, as well as from curated databases, are better modeled by geometric random graphs than by Erdös-Rény, random scale-free, or Barabási-Albert scale-free networks. AVAILABILITY Software executables are available upon request.},
	number = {2},
	urldate = {2018-03-19},
	journal = {Bioinformatics},
	author = {Przulj, N.},
	month = jan,
	year = {2007},
	pmid = {17237089},
	pages = {e177--e183},
}

@inproceedings{jefferson_virtual_2017,
	title = {Virtual time {III}: {Unification} of conservative and optimistic synchronization in parallel discrete event simulation},
	isbn = {978-1-5386-3428-8},
	url = {http://ieeexplore.ieee.org/document/8247832/},
	doi = {10.1109/WSC.2017.8247832},
	urldate = {2018-03-19},
	booktitle = {2017 {Winter} {Simulation} {Conference} ({WSC})},
	publisher = {IEEE},
	author = {Jefferson, David R. and Barnes, Peter D.},
	month = dec,
	year = {2017},
	pages = {786--797},
}

@article{Brown2018,
	title = {Classifiers and their {Metrics} {Quantified}},
	volume = {37},
	issn = {18681743},
	url = {http://doi.wiley.com/10.1002/minf.201700127},
	doi = {10.1002/minf.201700127},
	number = {1-2},
	urldate = {2018-03-19},
	journal = {Molecular Informatics},
	author = {Brown, J. B.},
	month = jan,
	year = {2018},
	pages = {1700127},
}

@inproceedings{wei_speedup_2016,
	title = {Speedup {Graph} {Processing} by {Graph} {Ordering}},
	isbn = {978-1-4503-3531-7},
	doi = {10.1145/2882903.2915220},
	abstract = {The CPU cache performance is one of the key issues to efficiency in database systems. It is reported that cache miss latency takes a half of the execution time in database systems. To improve the CPU cache performance, there are studies to support searching includ-ing cache-oblivious, and cache-conscious trees. In this paper, we focus on CPU speedup for graph computing in general by reducing the CPU cache miss ratio for different graph algorithms. The ap-proaches dealing with trees are not applicable to graphs which are complex in nature. In this paper, we explore a general approach to speed up CPU computing, in order to further enhance the efficiency of the graph algorithms without changing the graph algorithms (im-plementations) and the data structures used. That is, we aim at de-signing a general solution that is not for a specific graph algorithm, neither for a specific data structure. The approach studied in this work is graph ordering, which is to find the optimal permutation among all nodes in a given graph by keeping nodes that will be fre-quently accessed together locally, to minimize the CPU cache miss ratio. We prove the graph ordering problem is NP-hard, and give a basic algorithm with a bounded approximation. To improve the time complexity of the basic algorithm, we further propose a new algorithm to reduce the time complexity and improve the efficiency with new optimization techniques based on a new data structure. We conducted extensive experiments to evaluate our approach in comparison with other 9 possible graph orderings (such as the one obtained by METIS) using 8 large real graphs and 9 representative graph algorithms. We confirm that our approach can achieve high performance by reducing the CPU cache miss ratios.},
	booktitle = {Proceedings of the 2016 {International} {Conference} on {Management} of {Data} - {SIGMOD} '16},
	author = {Wei, Hao and Yu, Jeffrey Xu and Lu, Can and Lin, Xuemin},
	year = {2016},
	note = {ISSN: 07308078},
}

@article{mccune_thinking_2015,
	title = {Thinking {Like} a {Vertex}: a {Survey} of {Vertex}-{Centric} {Frameworks} for {Distributed} {Graph} {Processing}},
	issn = {03600300},
	doi = {10.1145/2818185},
	abstract = {The vertex-centric programming model is an established computational paradigm recently incorporated into distributed processing frameworks to address challenges in large-scale graph processing. Billion-node graphs that exceed the memory capacity of standard machines are not well-supported by popular Big Data tools like MapReduce, which are notoriously poor-performing for iterative graph algorithms such as PageRank. In response, a new type of framework challenges one to Think Like A Vertex (TLAV) and implements user-defined programs from the perspective of a vertex rather than a graph. Such an approach improves locality, demonstrates linear scalability, and provides a natural way to express and compute many iterative graph algorithms. These frameworks are simple to program and widely applicable, but, like an operating system, are composed of several intricate, interdependent components, of which a thorough understanding is necessary in order to elicit top performance at scale. To this end, the first comprehensive survey of TLAV frameworks is presented. In this survey, the vertex-centric approach to graph processing is overviewed, TLAV frameworks are deconstructed into four main components and respectively analyzed, and TLAV implementations are reviewed and categorized.},
	author = {McCune, Robert Ryan and Weninger, Tim and Madey, Gregory},
	year = {2015},
	note = {arXiv: 1507.04405},
}

@article{teixeira_arabesque:_2015,
	title = {Arabesque: {A} {System} for {Distributed} {Graph} {Mining} - {Extended} version},
	url = {https://arxiv.org/abs/1510.04233},
	urldate = {2018-03-16},
	author = {Teixeira, Carlos H. C. and Fonseca, Alexandre J. and Serafini, Marco and Siganos, Georgos and Zaki, Mohammed J. and Aboulnaga, Ashraf},
	month = oct,
	year = {2015},
	note = {arXiv: 1510.04233},
}

@article{Otomo2012,
	title = {Dysregulation of the autophagy-endolysosomal system in amyotrophic lateral sclerosis and related motor neuron diseases.},
	volume = {2012},
	issn = {2090-1860},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22852081},
	doi = {10.1155/2012/498428},
	abstract = {Amyotrophic lateral sclerosis (ALS) is a heterogeneous group of incurable motor neuron diseases (MNDs) characterized by a selective loss of upper and lower motor neurons in the brain and spinal cord. Most cases of ALS are sporadic, while approximately 5-10\% cases are familial. More than 16 causative genes for ALS/MNDs have been identified and their underlying pathogenesis, including oxidative stress, endoplasmic reticulum stress, excitotoxicity, mitochondrial dysfunction, neural inflammation, protein misfolding and accumulation, dysfunctional intracellular trafficking, abnormal RNA processing, and noncell-autonomous damage, has begun to emerge. It is currently believed that a complex interplay of multiple toxicity pathways is implicated in disease onset and progression. Among such mechanisms, ones that are associated with disturbances of protein homeostasis, the ubiquitin-proteasome system and autophagy, have recently been highlighted. Although it remains to be determined whether disease-associated protein aggregates have a toxic or protective role in the pathogenesis, the formation of them results from the imbalance between generation and degradation of misfolded proteins within neuronal cells. In this paper, we focus on the autophagy-lysosomal and endocytic degradation systems and implication of their dysfunction to the pathogenesis of ALS/MNDs. The autophagy-endolysosomal pathway could be a major target for the development of therapeutic agents for ALS/MNDs.},
	urldate = {2018-03-14},
	journal = {Neurology research international},
	author = {Otomo, Asako and Pan, Lei and Hadano, Shinji},
	year = {2012},
	pmid = {22852081},
	note = {Publisher: Hindawi Limited},
	pages = {498428},
}

@article{beqollari_progressive_2016,
	title = {Progressive impairment of {CaV1}.1 function in the skeletal muscle of mice expressing a mutant type 1 {Cu}/{Zn} superoxide dismutase ({G93A}) linked to amyotrophic lateral sclerosis},
	volume = {6},
	issn = {2044-5040},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27340545},
	doi = {10.1186/s13395-016-0094-6},
	abstract = {BACKGROUND Amyotrophic lateral sclerosis (ALS) is an adult-onset neurodegenerative disorder that is typically fatal within 3-5 years of diagnosis. While motoneuron death is the defining characteristic of ALS, the events that underlie its pathology are not restricted to the nervous system. In this regard, ALS muscle atrophies and weakens significantly before presentation of neurological symptoms. Since the skeletal muscle L-type Ca(2+) channel (CaV1.1) is a key regulator of both mass and force, we investigated whether CaV1.1 function is impaired in the muscle of two distinct mouse models carrying an ALS-linked mutation. METHODS We recorded L-type currents, charge movements, and myoplasmic Ca(2+) transients from dissociated flexor digitorum brevis (FDB) fibers to assess CaV1.1 function in two mouse models expressing a type 1 Cu/Zn superoxide dismutase mutant (SOD1(G93A)). RESULTS In FDB fibers obtained from "symptomatic" global SOD1(G93A) mice, we observed a substantial reduction of SR Ca(2+) release in response to depolarization relative to fibers harvested from age-matched control mice. L-type current and charge movement were both reduced by {\textasciitilde}40 \% in symptomatic SOD1(G93A) fibers when compared to control fibers. Ca(2+) transients were not significantly reduced in similar experiments performed with FDB fibers obtained from "early-symptomatic" SOD1(G93A) mice, but L-type current and charge movement were decreased ({\textasciitilde}30 and {\textasciitilde}20 \%, respectively). Reductions in SR Ca(2+) release ({\textasciitilde}35 \%), L-type current ({\textasciitilde}20 \%), and charge movement ({\textasciitilde}15 \%) were also observed in fibers obtained from another model where SOD1(G93A) expression was restricted to skeletal muscle. CONCLUSIONS We report reductions in EC coupling, L-type current density, and charge movement in FDB fibers obtained from symptomatic global SOD1(G93A) mice. Experiments performed with FDB fibers obtained from early-symptomatic SOD1(G93A) and skeletal muscle autonomous MLC/SOD1(G93A) mice support the idea that events occurring locally in the skeletal muscle contribute to the impairment of CaV1.1 function in ALS muscle independently of innervation status.},
	number = {1},
	urldate = {2018-03-14},
	journal = {Skeletal Muscle},
	author = {Beqollari, Donald and Romberg, Christin F. and Dobrowolny, Gabriella and Martini, Martina and Voss, Andrew A. and Musarò, Antonio and Bannister, Roger A.},
	month = dec,
	year = {2016},
	pmid = {27340545},
	keywords = {ALS, Amyotrophic lateral sclerosis, CaV1.1, Excitation-contraction coupling, L-type, Neuromuscular disease, SOD1, Skeletal muscle},
	pages = {24},
}

@article{santos_pereira_predicting_2018,
	title = {Predicting the ripening of papaya fruit with digital imaging and random forests},
	volume = {145},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S016816991731030X#!},
	doi = {10.1016/J.COMPAG.2017.12.029},
	abstract = {Papaya grading is performed manually which may lead to misclassifications, resulting in fruit boxes with different maturity stages. The objective is to predict the ripening of the papaya fruit using digital imaging and random forests. A series of physical/chemical analyses are carried out and true maturity stage is derived from pulp firmness measurements. Imaging and image analysis provides hand-crafted color features computed from the peel and random decision forests are implemented to predict ripening stage. More specifically, a total of 114 samples from 57 fruits are used for the experiments, and classified into three stages of maturity. After image acquisition and analysis, twenty-one hand-crafted color features (comprising seven groups) that have low computational cost are extracted and evaluated. Random forests with two datasets (cross-validation and prediction set) are employed for the experiments. Concerning all image features, 94.3\% classification performance is obtained over the cross-validation set. The prediction set obtained 94.7\% misclassifying only a single sample. For the group comparisons, the normalized mean of the RGB (red, green, blue) color space achieved better performance (78.1\%). Essentially, the technique can mature into an industrial application with the right integration framework.},
	urldate = {2018-03-14},
	journal = {Computers and Electronics in Agriculture},
	author = {Santos Pereira, Luiz Fernando and Barbon, Sylvio and Valous, Nektarios A. and Barbin, Douglas Fernandes},
	month = feb,
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {76--82},
}

@article{sun_explanation_nodate,
	title = {Explanation of {Log}-{Normal} {Distributions} and {Power}-{Law} {Distributions} in {Biology} and {Social} {Science}},
	abstract = {In many biological and social systems, where the ideal of heritance and aberrance exist at the same time, normal distribution failed in describing the distributions of variables. In stead, many real data as well as simulations indicate that log-normal distribution and power-law distribution can characterize many properties of this kind of systems. In this paper, the failure of normal distribution is studied and a general phenomenological model including both heritance and aberrance is set up. Using Fokker-Plank equation, it turns out that, log-normal distribution will be favored if the system has an optimum value for the variable we are studying, but power-law distribution will be favored for discrete variables.},
	urldate = {2018-03-12},
	author = {Sun, Kai},
}

@inproceedings{khorasani_cusha_2014,
	address = {New York, New York, USA},
	title = {{CuSha}},
	isbn = {978-1-4503-2749-7},
	url = {http://dl.acm.org/citation.cfm?doid=2600212.2600227},
	doi = {10.1145/2600212.2600227},
	urldate = {2018-03-12},
	booktitle = {Proceedings of the 23rd international symposium on {High}-performance parallel and distributed computing - {HPDC} '14},
	publisher = {ACM Press},
	author = {Khorasani, Farzad and Vora, Keval and Gupta, Rajiv and Bhuyan, Laxmi N.},
	year = {2014},
	keywords = {coalesced memory accesses, concatenated windows, g-shards, gpu, graph representation},
	pages = {239--252},
}

@inproceedings{cheng_kineograph_2012,
	address = {New York, New York, USA},
	title = {Kineograph},
	isbn = {978-1-4503-1223-3},
	url = {http://dl.acm.org/citation.cfm?doid=2168836.2168846},
	doi = {10.1145/2168836.2168846},
	urldate = {2018-03-12},
	booktitle = {Proceedings of the 7th {ACM} european conference on {Computer} {Systems} - {EuroSys} '12},
	publisher = {ACM Press},
	author = {Cheng, Raymond and Chen, Enhong and Hong, Ji and Kyrola, Aapo and Miao, Youshan and Weng, Xuetian and Wu, Ming and Yang, Fan and Zhou, Lidong and Zhao, Feng},
	year = {2012},
	keywords = {distributed storage, graph processing},
	pages = {85},
}

@article{Zhou2017,
	title = {{VoxelNet}: {End}-to-{End} {Learning} for {Point} {Cloud} {Based} {3D} {Object} {Detection}},
	url = {http://arxiv.org/abs/1711.06396},
	abstract = {Accurate detection of objects in 3D point clouds is a central problem in many applications, such as autonomous navigation, housekeeping robots, and augmented/virtual reality. To interface a highly sparse LiDAR point cloud with a region proposal network (RPN), most existing efforts have focused on hand-crafted feature representations, for example, a bird's eye view projection. In this work, we remove the need of manual feature engineering for 3D point clouds and propose VoxelNet, a generic 3D detection network that unifies feature extraction and bounding box prediction into a single stage, end-to-end trainable deep network. Specifically, VoxelNet divides a point cloud into equally spaced 3D voxels and transforms a group of points within each voxel into a unified feature representation through the newly introduced voxel feature encoding (VFE) layer. In this way, the point cloud is encoded as a descriptive volumetric representation, which is then connected to a RPN to generate detections. Experiments on the KITTI car detection benchmark show that VoxelNet outperforms the state-of-the-art LiDAR based 3D detection methods by a large margin. Furthermore, our network learns an effective discriminative representation of objects with various geometries, leading to encouraging results in 3D detection of pedestrians and cyclists, based on only LiDAR.},
	urldate = {2018-03-09},
	author = {Zhou, Yin and Tuzel, Oncel},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.06396},
}

@inproceedings{vora_aspire_2014,
	address = {New York, New York, USA},
	title = {{ASPIRE}},
	volume = {49},
	isbn = {978-1-4503-2585-1},
	url = {http://dl.acm.org/citation.cfm?doid=2660193.2660227},
	doi = {10.1145/2660193.2660227},
	urldate = {2018-03-08},
	booktitle = {Proceedings of the 2014 {ACM} {International} {Conference} on {Object} {Oriented} {Programming} {Systems} {Languages} \& {Applications} - {OOPSLA} '14},
	publisher = {ACM Press},
	author = {Vora, Keval and Koduru, Sai Charan and Gupta, Rajiv and Vora, Keval and Koduru, Sai Charan and Gupta, Rajiv},
	year = {2014},
	note = {Issue: 10
ISSN: 0362-1340},
	keywords = {best effort refresh, bounded staleness, communication latency, distributed shared memory, graph analytics, graph mining, pde solvers},
	pages = {861--878},
}

@inproceedings{shi_tornado_2016,
	address = {New York, New York, USA},
	title = {Tornado},
	isbn = {978-1-4503-3531-7},
	url = {http://dl.acm.org/citation.cfm?doid=2882903.2882950},
	doi = {10.1145/2882903.2882950},
	urldate = {2018-03-08},
	booktitle = {Proceedings of the 2016 {International} {Conference} on {Management} of {Data} - {SIGMOD} '16},
	publisher = {ACM Press},
	author = {Shi, Xiaogang and Cui, Bin and Shao, Yingxia and Tong, Yunhai},
	year = {2016},
	keywords = {approximation method, concurrency control, iterative computation, stream processing},
	pages = {417--430},
}

@book{usenix_association._gridgraph_2004,
	title = {Gridgraph},
	isbn = {978-1-931971-22-5},
	url = {https://dl.acm.org/citation.cfm?id=2813795},
	urldate = {2018-03-05},
	publisher = {USENIX Association},
	author = {USENIX Association., Xiaowei and Han, Wentao and Chen, Wenguang},
	year = {2004},
	note = {Publication Title: Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference},
}

@article{noauthor_schlenker_nodate,
	title = {Schlenker {Self}-{Presentation} 492-518},
}

@article{Voraa,
	title = {{KickStarter}: {Fast} and {Accurate} {Computations} on {Streaming} {Graphs} via {Trimmed} {Approximations}},
	doi = {10.1145/3037697.3037748},
	abstract = {Continuous processing of a streaming graph maintains an approximate result of the iterative computation on a recent version of the graph. Upon a user query, the accurate result on the current graph can be quickly computed by feeding the approximate results to the iterative computation — a form of incremental computation that corrects the (small amount of) error in the approximate result. Despite the effectiveness of this approach in processing growing graphs, it is generally not applicable when edge deletions are present — existing ap-proximations can lead to either incorrect results (e.g., mono-tonic computations terminate at an incorrect minima/maxima) or poor performance (e.g., with approximations, convergence takes longer than performing the computation from scratch). This paper presents KickStarter, a runtime technique that can trim the approximate values for a subset of vertices impacted by the deleted edges. The trimmed approximation is both safe and profitable, enabling the computation to produce correct results and converge quickly. KickStarter works for a class of monotonic graph algorithms and can be readily incorporated in any existing streaming graph system. Our experiments with four streaming algorithms on five large graphs demonstrate that trimming not only produces correct results but also accelerates these algorithms by 8.5–23.7×.},
	urldate = {2018-03-01},
	author = {Vora, Keval and Gupta, Rajiv and Xu, Guoqing},
	keywords = {Graph Processing, Stream-ing Graphs, Value Dependence},
}

@article{de_transduction_2017,
	title = {Transduction on {Directed} {Graphs} via {Absorbing} {Random} {Walks}},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/8008851/},
	doi = {10.1109/TPAMI.2017.2730871},
	urldate = {2018-02-26},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {De, Jaydeep and Zhang, Xiaowei and Lin, Feng and Cheng, Li},
	year = {2017},
	pages = {1--1},
}

@article{miyauchi_fast_2018,
	title = {Fast modified {Self}-organizing {Deformable} {Model}: {Geometrical} feature-preserving mapping of organ models onto target surfaces with various shapes and topologies},
	volume = {157},
	issn = {0169-2607},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260717306235},
	doi = {10.1016/J.CMPB.2018.01.028},
	abstract = {BACKGROUND AND OBJECTIVE
This paper proposes a new method for mapping surface models of human organs onto target surfaces with the same genus as the organs. 

METHODS
In the proposed method, called modified Self-organizing Deformable Model (mSDM), the mapping problem is formulated as the minimization of an objective function which is defined as the weighted linear combination of four energy functions: model fitness, foldover-free, landmark mapping accuracy, and geometrical feature preservation. Further, we extend mSDM to speed up its processes, and call it Fast mSDM. 

RESULTS
From the mapping results of various organ models with different number of holes, it is observed that Fast mSDM can map the organ models onto their target surfaces efficiently and stably without foldovers while preserving geometrical features. 

CONCLUSIONS
Fast mSDM can map the organ model onto the target surface efficiently and stably, and is applicable to medical applications including Statistical Shape Model.},
	urldate = {2018-02-23},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Miyauchi, Shoko and Morooka, Ken’ichi and Tsuji, Tokuo and Miyagi, Yasushi and Fukuda, Takaichi and Kurazume, Ryo},
	month = apr,
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {237--250},
}

@article{Wang,
	title = {Probabilistic {Synchronous} {Parallel}},
	abstract = {Most machine learning and deep neural network algorithms rely on certain iterative algorithms to optimise their utility/cost functions, e.g. Stochastic Gradient Descent (SGD). In distributed learning, the networked nodes have to work collaboratively to update the model parameters, and the way how they proceed is referred to as synchronous parallel design (or barrier control). Synchronous parallel protocol is practically the building block of all distributed learning frameworks, and its design has direct impact on the performance and scalability of the system. In this paper, we propose a new barrier control technique -Probabilistic Synchronous Parallel (PSP). Com-paring to the previous Bulk Synchronous Parallel (BSP), Stale Synchronous Parallel (SSP), and (Asynchronous Parallel) ASP, the proposed solution effectively improves both the convergence speed and the scalability of the SGD algorithm by introducing a sampling primitive into the system. Moreover, we also show that the sampling primitive can be composed with the existing barrier control mechanisms to derive fully distributed PSP-based synchronous parallel. We not only provide a thorough theoretical analysis 1 on the convergence guarantee of PSP-based SGD algorithm, but also implement a full-featured distributed learning framework called Actor System and perform intensive evaluation atop of it. 1 INTRODUCTION Barrier synchronisation is critical in many distributed machine learning algorithms. In general, there are three major ways to coordinate how the nodes in a system should progress in iterative learning algorithms: Bulk synchronous parallel (BSP) [20], Stale synchronous parallel (SSP) [1, 8, 19], and Asynchronous parallel (ASP) [13]. Even though these synchronisation methods have attracted a lot of attentions lately in the distributed machine learning community, they have recurred several times in the distributed computing literature in the past decades. Among the aforementioned three methods, BSP is the most strict one and requires all the nodes making progress in a lockstepped way. BSP is the default option in many map-reduce-based applications. On the other hand, ASP removes such strict synchronisation requirement completely hence nodes can advance their computations without coordinating with other nodes. SSP is a solution in the middle of aforementioned two extremes wherein a bounded delay is specified between the fastest node and slowest one in the system. Regarding the pros and cons of each solution, BSP is deterministic and can lead to the same machine learning algorithm design. However, the network and system layer have to implement much more complicated logic to deal with network dynamics (nodes can fail and their progress may not be consistent). ASP eases the communication and synchronisation design among the nodes, but introduces errors (often non-negligible) when updating model parameters in the learning algorithms hence the convergence is not always guaranteed. SSP on the other hand tries to make a trade-off between the efficiency (from ASP) and the accuracy (from BSP) by specifying a bounded staleness.},
	urldate = {2018-02-21},
	author = {Wang, Liang},
}

@article{grigoryan_probabilistic_2002,
	title = {Probabilistic surfaces: point based primitives to show surface uncertainty},
	url = {https://dl.acm.org/citation.cfm?id=602121},
	urldate = {2018-02-21},
	journal = {Proceedings of the conference on Visualization '02},
	author = {Grigoryan, Gevorg and Rheingans, Penny},
	year = {2002},
	note = {Publisher: IEEE Computer Society
ISBN: 0-7803-7498-3},
	keywords = {points as display primitives, uncertainty, visualizing surface uncertainty},
	pages = {147--154},
}

@article{Kyrola,
	title = {{GraphChi}: {Large}-{Scale} {Graph} {Computation} on {Just} a {PC}},
	abstract = {Current systems for graph computation require a dis-tributed computing cluster to handle very large real-world problems, such as analysis on social networks or the web graph. While distributed computational resources have be-come more accessible, developing distributed graph algo-rithms still remains challenging, especially to non-experts. In this work, we present GraphChi, a disk-based system for computing efficiently on graphs with billions of edges. By using a well-known method to break large graphs into small parts, and a novel parallel sliding windows method, GraphChi is able to execute several advanced data mining, graph mining, and machine learning algorithms on very large graphs, using just a single consumer-level computer. We further extend GraphChi to support graphs that evolve over time, and demonstrate that, on a single computer, GraphChi can process over one hundred thousand graph updates per second, while simultaneously performing com-putation. We show, through experiments and theoretical analysis, that GraphChi performs well on both SSDs and rotational hard drives. By repeating experiments reported for existing dis-tributed systems, we show that, with only fraction of the resources, GraphChi can solve the same problems in very reasonable time. Our work makes large-scale graph com-putation available to anyone with a modern PC.},
	urldate = {2018-02-21},
	author = {Kyrola, Aapo and Blelloch, Guy and Guestrin, Carlos},
}

@article{VanOosterom2015,
	title = {Special {Section} on {Processing} {Large} {Geospatial} {Data} {Massive} point cloud data management: {Design}, implementation and execution of a point cloud benchmark},
	volume = {49},
	doi = {10.1016/j.cag.2015.01.007},
	abstract = {a b s t r a c t Point cloud data are important sources for 3D geo-information. An inventory of the point cloud data management user requirements has been compiled using structured interviews with users from different background: government, industry and academia. Based on these requirements a benchmark has been developed to compare various point cloud data management solutions with regard to functionality and performance. The main test dataset is the second national height map of the Netherlands, AHN2, with 6–10 samples for every square meter of the country, resulting in 640 billion points. At the database level, a data storage model based on grouping the points in blocks is available in Oracle and PostgreSQL. This model is compared with the 'flat table' model, where each point is stored in a table row, in Oracle, PostgreSQL and the column-store MonetDB. In addition, the commonly used file-based solution Rapidlasso LAStools is used for comparison with the database solutions. The results of executing the benchmark on different platforms are presented as obtained during the increasingly challenging stages with more functionality and more data: mini (20 million points), medium (20 billion points), and full benchmark (the complete AHN2). During the design, the implementation and the execution of the benchmarks, a number of point cloud data management improvements were proposed and partly tested: Morton/Hilbert code for ordering data (especially in flat model), two algorithms for parallel query execution, and a unique vario-scale LoD data organization avoiding the density jumps of the well-known discrete LoD data organizations.},
	urldate = {2018-02-21},
	journal = {Computers and Graphics},
	author = {Van Oosterom, Peter and Martinez-Rubi, Oscar and Ivanova, Milena and Horhammer, Mike and Geringer, Daniel and Ravada, Siva and Tijssen, Theo and Kodde, Martin and Gonçalves, Romulo},
	year = {2015},
	keywords = {Benchmark, DBMS, Parallel processing, Point cloud data, Space filling curve, Vario-scale},
	pages = {92--125},
}

@article{Zhengchun2016,
	title = {Point cloud uncertainty analysis for laser radar measurement system based on error ellipsoid model},
	issn = {01438166},
	doi = {10.1016/j.optlaseng.2015.11.010},
	abstract = {Three-dimensional laser scanning has become an increasingly popular measurement method in industrial fields as it provides a non-contact means of measuring large objects, whereas the conventional methods are contact-based. However, the data acquisition process is subject to many interference factors, which inevitably cause errors. Therefore, it is necessary to precisely evaluate the accuracy of the measurement results. In this study, an error-ellipsoid-based uncertainty model was applied to 3D laser radar measurement system (LRMS) data. First, a spatial point uncertainty distribution map was constructed according to the error ellipsoid attributes. The single-point uncertainty ellipsoid model was then extended to point–point, point–plane, and plane–plane situations, and the corresponding distance uncertainty models were derived. Finally, verification experiments were performed by using an LRMS to measure the height of a cubic object, and the measurement accuracies were evaluated. The results show that the plane–plane distance uncertainties determined based on the ellipsoid model are comparable to those obtained by actual distance measurements. Thus, this model offers solid theoretical support to enable further LRMS measurement accuracy improvement.},
	journal = {Optics and Lasers in Engineering},
	author = {Zhengchun, Du and Zhaoyong, Wu and Jianguo, Yang},
	year = {2016},
}

@inproceedings{Gadomski2015,
	title = {Calculating {LiDAR} {Point} {Cloud} {Uncertainty} and {Propagating} {Uncertainty} to {Snow}-{Water} {Equivalent} {Data} {Products}},
	abstract = {The use of high-resolution topographic data in the form of three-dimensional point clouds obtained from laser scanning systems (LiDAR) is becoming common across scientific disciplines. However little consideration has typically been given to the accuracy and the precision of LiDAR-derived measurements at the individual point scale. Numerous disparate sources contribute to the aggregate precision of each point measurement, including uncertainties in the range measurement, measurement of the attitude and position of the LiDAR collection platform, uncertainties associated with the interaction between the laser pulse and the target surface, and more. We have implemented open-source software tools to calculate per-point stochastic measurement errors for a point cloud using the general LiDAR georeferencing equation. We demonstrate the use of these propagated uncertainties by applying our methods to data collected by the Airborne Snow Observatory ALS, a NASA JPL project using a combination of airborne hyperspectral and LiDAR data to estimate snow-water equivalent distributions over full river basins. We present basin-scale snow depth maps with associated uncertainties, and demonstrate the propagation of those uncertainties to snow volume and snow-water equivalent calculations.},
	booktitle = {2015 {AGU} {Fall} {Meeting}},
	author = {Gadomski, Peter J. and Deems, Jeffrey S. and Glennie, Craig L. and Hartzell, Preston J. and Butler, Howard and Finnegan, David C.},
	year = {2015},
}

@article{Bae2005,
	title = {A {FRAMEWORK} {FOR} {POSITION} {UNCERTAINTY} {OF} {UNORGANISED} {THREE}-{DIMENSIONAL} {POINT} {CLOUDS} {FROM} {NEAR}-{MONOSTATIC} {LASER} {SCANNERS} {USING} {COVARIANCE} {ANALYSIS}},
	abstract = {Position uncertainty is one of the most important quantities of an unorganised three-dimensional point clouds since it provides the confidence level of any parametric estimation such as surface normal vector estimation and the registration of point clouds. We present an explicit form of position uncertainty based on the covariance analysis of a point. In addition, an explicit form of the variance of an estimated surface normal vector and an algorithm to evaluate an optimal size of the neighbourhood of a point which minimises the variance of the estimated normal vector are presented.},
	journal = {WG III/3-4 V/3 Proceedings of the ISPRS Workshop Laser scanning 2005},
	author = {Bae, Kwang-ho and Belton, David and Lichti, Derek D and Cloud, Point and Scanning, Laser},
	year = {2005},
	keywords = {laser scanning, point cloud, position uncertainty, three-dimensional},
}

@article{Pauly2004,
	title = {Uncertainty and variability in point cloud surface data},
	issn = {1811-7813},
	doi = {10.2312/SPBG/SPBG04/077-084},
	abstract = {We present a framework for analyzing shape uncertainty and variability in point-sampled geometry. Our repre- sentation is mainly targeted towards discrete surface data stemming from 3D acquisition devices, where a finite number of possibly noisy samples provides only incomplete information about the underlying surface.We capture this uncertainty by introducing a statistical representation that quantifies for each point in space the likelihood that a surface fitting the data passes through that point. This likelihood map is constructed by aggregating local linear extrapolators computed from weighted least squares fits. The quality of fit of these extrapolators is combined into a corresponding confidence map that measures the quality of local tangent estimates. We present an analysis of the effect of noise on these maps, show how to efficiently compute them, and extend the basic definition to a scale-space formulation. Various applications of our framework are discussed, including an adaptive re-sampling method, an algorithm for reconstructing surfaces in the presence of noise, and a technique for robustly merging a set of scans into a single point-based representation.},
	journal = {Symposium on point-based graphics},
	author = {Pauly, M and Mitra, NJ and Guibas, L},
	year = {2004},
	pmid = {84},
	note = {ISBN: 3-905673-09-6},
}

@article{Oudot,
	title = {Delaunay {Triangulation}},
	urldate = {2018-02-21},
	author = {Oudot, Steve},
}

@article{Slaney2012,
	title = {Optimal parameters for locality-sensitive hashing},
	issn = {00189219},
	doi = {10.1109/JPROC.2012.2193849},
	abstract = {Locality-sensitive hashing (LSH) is the basis of many algorithms that use a probabilistic approach to find nearest neighbors.We describe an algorithmfor optimizing the parameters and use of LSH. Prior work ignores these issues or suggests a search for the best parameters. We start with two histograms: one that characterizes the distributions of dis- tances to a point’s nearest neighbors and the second that characterizes the distance between a query and any point in the data set. Given a desired performance level (the chance of finding the true nearest neighbor) and a simple computational cost model, we return the LSH parameters that allow an LSH index to meet the performance goal and have the minimum computational cost. We can also use this analysis to connect LSH to deterministic nearest-neighbor algorithms such as k-d trees and thus start to unify the two approaches. KEYWORDS},
	journal = {Proceedings of the IEEE},
	author = {Slaney, Malcolm and Lifshits, Yury and He, Junfeng},
	year = {2012},
	keywords = {Database index, information retrieval, locality-sensitive hashing, multimedia databases, nearest-neighbor search},
}

@article{Gieseke2014,
	title = {Buffer k-d {Trees}: {Processing} {Massive} {Nearest} {Neighbor} {Queries} on {GPUs}},
	abstract = {We present a new approach for combining k-d trees and graphics processing units for near- est neighbor search. It is well known that a di- rect combination of these tools leads to a non- satisfying performance due to conditional com- putations and suboptimal memory accesses. To alleviate these problems, we propose a variant of the classical k-d tree data structure, called buffer k-d tree, which can be used to reorganize the search. Our experiments show that we can take advantage of both the hierarchical subdivi- sion induced by k-d trees and the huge computa- tional resources provided by today’s many-core devices. We demonstrate the potential of our ap- proach in astronomy, where hundreds of million nearest neighbor queries have to be processed. 1.},
	journal = {International Conference on Machine Learning},
	author = {Gieseke, F. and Heinermann, J. and Oancea, C. and Igel, C.},
	year = {2014},
	note = {ISBN: 9781634393973},
}

@article{Connor2010,
	title = {Fast construction of κ-nearest neighbor graphs for point clouds},
	issn = {10772626},
	doi = {10.1109/TVCG.2010.9},
	abstract = {We present a parallel algorithm for k-nearest neighbor graph construction that uses Morton ordering. Experiments show that our approach has the following advantages over existing methods: 1) faster construction of k-nearest neighbor graphs in practice on multicore machines, 2) less space usage, 3) better cache efficiency, 4) ability to handle large data sets, and 5) ease of parallelization and implementation. If the point set has a bounded expansion constant, our algorithm requires one-comparison-based parallel sort of points, according to Morton order plus near-linear additional steps to output the k-nearest neighbor graph.},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Connor, Michael and Kumar, Piyush},
	year = {2010},
	pmid = {20467058},
	note = {ISBN: 2009010019},
	keywords = {Morton ordering, Nearest neighbor searching, Parallel algorithms, Point-based graphics, κ-nearest neighbor graphics},
}

@inproceedings{Pingali2011,
	address = {New York, New York, USA},
	title = {The tao of parallelism in algorithms},
	volume = {46},
	isbn = {978-1-4503-0663-8},
	url = {http://portal.acm.org/citation.cfm?doid=1993498.1993501},
	doi = {10.1145/1993498.1993501},
	urldate = {2018-02-19},
	booktitle = {Proceedings of the 32nd {ACM} {SIGPLAN} conference on {Programming} language design and implementation - {PLDI} '11},
	publisher = {ACM Press},
	author = {Pingali, Keshav and Méndez-Lojo, Mario and Prountzos, Dimitrios and Sui, Xin and Nguyen, Donald and Kulkarni, Milind and Burtscher, Martin and Hassaan, M. Amber and Kaleem, Rashid and Lee, Tsung-Hsien and Lenharth, Andrew and Manevich, Roman and Pingali, Keshav and Nguyen, Donald and Kulkarni, Milind and Burtscher, Martin and Hassaan, M. Amber and Kaleem, Rashid and Lee, Tsung-Hsien and Lenharth, Andrew and Manevich, Roman and Méndez-Lojo, Mario and Prountzos, Dimitrios and Sui, Xin},
	year = {2011},
	note = {Issue: 6
ISSN: 0362-1340},
	keywords = {amorphous data-parallelism, galois system, irregular programs, operator formulation, tao-analysis},
	pages = {12},
}

@article{Wang2012,
	title = {A {Fast} {Exact} k-{Nearest} {Neighbors} {Algorithm} for {High} {Dimensional} {Search} {Using} k-{Means} {Clustering} and {Triangle} {Inequality}.},
	volume = {43},
	issn = {2161-4393},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22247818},
	doi = {10.1016/j.patcog.2010.01.003},
	abstract = {The k-nearest neighbors (k-NN) algorithm is a widely used machine learning method that finds nearest neighbors of a test object in a feature space. We present a new exact k-NN algorithm called kMkNN (k-Means for k-Nearest Neighbors) that uses the k-means clustering and the triangle inequality to accelerate the searching for nearest neighbors in a high dimensional space. The kMkNN algorithm has two stages. In the buildup stage, instead of using complex tree structures such as metric trees, kd-trees, or ball-tree, kMkNN uses a simple k-means clustering method to preprocess the training dataset. In the searching stage, given a query object, kMkNN finds nearest training objects starting from the nearest cluster to the query object and uses the triangle inequality to reduce the distance calculations. Experiments show that the performance of kMkNN is surprisingly good compared to the traditional k-NN algorithm and tree-based k-NN algorithms such as kd-trees and ball-trees. On a collection of 20 datasets with up to 10(6) records and 10(4) dimensions, kMkNN shows a 2-to 80-fold reduction of distance calculations and a 2- to 60-fold speedup over the traditional k-NN algorithm for 16 datasets. Furthermore, kMkNN performs significant better than a kd-tree based k-NN algorithm for all datasets and performs better than a ball-tree based k-NN algorithm for most datasets. The results show that kMkNN is effective for searching nearest neighbors in high dimensional spaces.},
	number = {6},
	urldate = {2018-02-19},
	journal = {Proceedings of ... International Joint Conference on Neural Networks. International Joint Conference on Neural Networks},
	author = {Wang, Xueyi},
	month = feb,
	year = {2012},
	pmid = {22247818},
	note = {Publisher: NIH Public Access},
	pages = {2351--2358},
}

@article{Omohundro1989,
	title = {Five {Balltree} {Construction} {Algorithms}},
	url = {http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.91.8209},
	urldate = {2018-02-19},
	author = {Omohundro, Stephen M. and Omohundro, Stephen M.},
	year = {1989},
}

@inproceedings{Li2014,
	title = {Similarity-aware patchwork assembly for depth image super-resolution},
	isbn = {978-1-4799-5117-8},
	doi = {10.1109/CVPR.2014.431},
	abstract = {This paper describes a patchwork assembly algorithm for depth image super-resolution. An input low resolution depth image is disassembled into parts by matching similar regions on a set of high resolution training images, and a super-resolution image is then assembled using these corresponding matched counterparts. We convert the super resolution problem into a Markov Random Field (MRF) labeling problem, and propose a unified formulation embedding (1) the consistency between the resolution enhanced image and the original input, (2) the similarity of disassembled parts with the corresponding regions on training images, (3) the depth smoothness in local neighborhoods, (4) the additional geometric constraints from self-similar structures in the scene, and (5) the boundary coincidence between the resolution enhanced depth image and an optional aligned high resolution intensity image. Experimental results on both synthetic and real-world data demonstrate that the proposed algorithm is capable of recovering high quality depth images with X4 resolution enhancement along each coordinate direction, and that it outperforms state-of-the-arts [14] in both qualitative and quantitative evaluations.},
	booktitle = {Proceedings of the {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Li, Jing and Lu, Zhichao and Zeng, Gang and Gan, Rui and Zha, Hongbin},
	year = {2014},
	note = {ISSN: 10636919},
	keywords = {Assembly, Disassemble, Dpeth map super resolution, Self-similarity},
}

@article{Yuan2016,
	title = {{PathGraph}: {A} {Path} {Centric} {Graph} {Processing} {System}},
	issn = {10459219},
	doi = {10.1109/TPDS.2016.2518664},
	abstract = {Abstract—Large scale iterative graph computation presents an inter- esting systems challenge due to two well known problems: (1) the lack of access locality and (2) the lack of storage efficiency. This paper presents PathGraph, a system for improving iterative graph computation on graphs with billions of edges. First, we improve the memory and disk access locality for iterative computation algorithms on large graphs by modeling a large graph using a collection of tree-based partitions. This enables us to use path-centric computation rather than vertex- centric or edge-centric computation. For each tree partition, we re-label vertices using DFS in order to preserve consistency between the order of vertex ids and vertex order in the paths. Second, a compact storage that is optimized for iterative graph parallel computation is developed in the PathGraph system. Concretely, we employ delta-compression and store tree-based partitions in a DFS order. By clustering highly correlated paths together as tree based partitions, we maximize se- quential access and minimize random access on storage media. Third but not the least, our path-centric computation model is implemented using a scatter/gather programming model. We parallel the iterative computation at partition tree level and perform sequential local updates for vertices in each tree partition to improve the convergence speed. To provide well balanced workloads among parallel threads at tree partition level, we introduce the concept of multiple stealing points based task queue to allow work stealings from multiple points in the task queue. We evaluate the effectiveness of PathGraph by comparing with recent representative graph processing systems such as GraphChi and X-Stream etc. Our experimental results show that our approach outperforms the two systems on a number of graph algorithms for both in-memory and out-of-core graphs. While our approach achieves better data balance and load balance, it also shows better speedup than the two systems with the growth of threads. Index},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Yuan, Pingpeng and Xie, Changfeng and Liu, Ling and Jin, Hai},
	year = {2016},
	note = {ISBN: 1045-9219},
	keywords = {Graphs and networks, concurrent programming, data storage representations, graph algorithms},
}

@article{Wolter2012,
	title = {{rapidSTORM}: accurate, fast open-source software for localization microscopy},
	volume = {9},
	issn = {1548-7091},
	url = {http://www.nature.com/articles/nmeth.2224},
	doi = {10.1038/nmeth.2224},
	abstract = {rapi\textit{d}STORM: accurate, fast open-source software for localization microscopy},
	number = {11},
	urldate = {2018-02-15},
	journal = {Nature Methods},
	author = {Wolter, Steve and Löschberger, Anna and Holm, Thorge and Aufmkolk, Sarah and Dabauvalle, Marie-Christine and van de Linde, Sebastian and Sauer, Markus},
	month = nov,
	year = {2012},
	note = {Publisher: Nature Publishing Group},
	keywords = {Bioinformatics, Microscopy, Software},
	pages = {1040--1041},
}

@article{Vonesch2006,
	title = {The colored revolution of bioimaging},
	volume = {23},
	issn = {1053-5888},
	url = {http://ieeexplore.ieee.org/document/1628875/},
	doi = {10.1109/MSP.2006.1628875},
	number = {3},
	urldate = {2018-02-15},
	journal = {IEEE Signal Processing Magazine},
	author = {Vonesch, C. and Aguet, F. and Vonesch, J.-L. and Unser, M.},
	month = may,
	year = {2006},
	pages = {20--31},
}

@article{Zhang2007,
	title = {Gaussian approximations of fluorescence microscope point-spread function models},
	volume = {46},
	issn = {0003-6935},
	url = {https://www.osapublishing.org/abstract.cfm?URI=ao-46-10-1819},
	doi = {10.1364/AO.46.001819},
	abstract = {We comprehensively study the least-squares Gaussian approximations of the diffraction-limited 2D-3D paraxial-nonparaxial point-spread functions (PSFs)
of the wide field fluorescence microscope (WFFM), the laser scanning confocal microscope
(LSCM), and the disk scanning confocal microscope (DSCM). The PSFs are expressed using the Debye integral. Under an
L∞ constraint imposing peak matching, optimal and near-optimal Gaussian parameters are derived for the PSFs. With an
L1 constraint imposing energy conservation, an optimal Gaussian parameter is derived for the 2D paraxial WFFM PSF. We found that (1) the 2D approximations are all very accurate; (2) no accurate Gaussian approximation exists for 3D WFFM PSFs; and (3) with typical pinhole sizes, the 3D approximations are accurate for the DSCM and nearly perfect for the LSCM. All the Gaussian parameters derived in this study are in explicit analytical form, allowing their direct use in practical applications.},
	number = {10},
	urldate = {2018-02-15},
	journal = {Applied Optics},
	author = {Zhang, Bo and Zerubia, Josiane and Olivo-Marin, Jean-Christophe},
	month = apr,
	year = {2007},
	note = {Publisher: Optical Society of America},
	keywords = {Confocal microscopy, Fluorescence microscopy, Microscopy, Numerical approximation and analysis, Three, dimensional microscopy},
	pages = {1819},
}

@article{Kechkar2013,
	title = {Real-{Time} {Analysis} and {Visualization} for {Single}-{Molecule} {Based} {Super}-{Resolution} {Microscopy}},
	issn = {19326203},
	doi = {10.1371/journal.pone.0062918},
	abstract = {Accurate multidimensional localization of isolated fluorescent emitters is a time consuming process in single-molecule based super-resolution microscopy. We demonstrate a functional method for real-time reconstruction with automatic feedback control, without compromising the localization accuracy. Compatible with high frame rates of EM-CCD cameras, it relies on a wavelet segmentation algorithm, together with a mix of CPU/GPU implementation. A combination with Gaussian fitting allows direct access to 3D localization. Automatic feedback control ensures optimal molecule density throughout the acquisition process. With this method, we significantly improve the efficiency and feasibility of localization-based super-resolution microscopy.},
	journal = {PLoS ONE},
	author = {Kechkar, Adel and Nair, Deepak and Heilemann, Mike and Choquet, Daniel and Sibarita, Jean Baptiste},
	year = {2013},
	pmid = {23646160},
	note = {ISBN: 1932-6203 (Electronic){\textbackslash}r1932-6203 (Linking)},
}

@article{Wolter2011,
	title = {Measuring localization performance of super-resolution algorithms on very active samples},
	volume = {19},
	issn = {1094-4087},
	doi = {10.1364/OE.19.007020},
	abstract = {Super-resolution fluorescence imaging based on single-molecule localization relies critically on the availability of efficient processing algorithms to distinguish, identify, and localize emissions of single fluorophores. In multiple current applications, such as three-dimensional, time-resolved or cluster imaging, high densities of fluorophore emissions are common. Here, we provide an analytic tool to test the performance and quality of localization microscopy algorithms and demonstrate that common algorithms encounter difficulties for samples with high fluorophore density. We demonstrate that, for typical single-molecule localization microscopy methods such as dSTORM and the commonly used rapidSTORM scheme, computational precision limits the acceptable density of concurrently active fluorophores to 0.6 per square micrometer and that the number of successfully localized fluorophores per frame is limited to 0.2 per square micrometer.},
	number = {8},
	journal = {Optics Express},
	author = {Wolter, Steve and Endesfelder, Ulrike and van de Linde, Sebastian and Heilemann, Mike and Sauer, Markus},
	year = {2011},
	pmid = {21503016},
	note = {ISBN: 1094-4087 (Electronic){\textbackslash}r1094-4087 (Linking)},
}

@article{Hohage2016,
	title = {Inverse problems with {Poisson} data: {Statistical} regularization theory, applications and algorithms},
	issn = {13616420},
	doi = {10.1088/0266-5611/32/9/093001},
	abstract = {Inverse problems with Poisson data: statistical regularization theory, applications and algorithms View the table of contents for this issue, or go to the journal homepage for more 2016 Inverse Problems 32 093001 Abstract Inverse problems with Poisson data arise in many photonic imaging modalities in medicine, engineering and astronomy. The design of regularization methods and estimators for such problems has been studied intensively over the last two decades. In this review we give an overview of statistical regularization theory for such problems, the most important applications, and the most widely used algorithms. The focus is on variational regularization methods in the form of penalized maximum likelihood estimators, which can be analyzed in a general setup. Complementing a number of recent convergence rate results we will establish consistency results. Moreover, we discuss estimators based on a wavelet-vaguelette decomposition of the (necessarily linear) forward operator. As most prominent applications we briefly introduce Positron emission tomography, inverse problems in fluorescence microscopy, and phase retrieval problems. The computation of a penalized maximum likelihood estimator involves the solution of a (typically convex) minimization problem. We also review several efficient algorithms which have been proposed for such pro-blems over the last five years.},
	journal = {Inverse Problems},
	author = {Hohage, Thorsten and Werner, Frank},
	year = {2016},
	keywords = {Poisson process, inverse problem, phase retrieval, positron emission tomography, regularization theory, splitting algorithms},
}

@article{Hoang2015,
	title = {The {Cauchy}-{Schwarz} divergence for poisson point processes},
	volume = {61},
	issn = {00189448},
	doi = {10.1109/TIT.2015.2441709},
	abstract = {In this paper, we extend the notion of Cauchy-Schwarz divergence to point processes and establish that the Cauchy-Schwarz divergence between the probability densities of two Poisson point processes is half the squared \${\textbackslash}mathbf\{L{\textasciicircum}\{2\}\}\$-distance between their intensity functions. Extension of this result to mixtures of Poisson point processes and, in the case where the intensity functions are Gaussian mixtures, closed form expressions for the Cauchy-Schwarz divergence are presented. Our result also implies that the Bhattachryaa distance between the probability distributions of two Poisson point processes is equal to the square of the Hellinger distance between their intensity measures. We illustrate the result via a sensor management application where the system states are modeled as point processes.},
	number = {8},
	journal = {IEEE Transactions on Information Theory},
	author = {Hoang, Hung Gia and Vo, Ba Ngu and Vo, Ba Tuong and Mahler, Ronald},
	year = {2015},
	note = {arXiv: 1312.6224
ISBN: 9781479949755},
}

@article{nino_molecular_2017,
	title = {Molecular {Counting} with {Localization} {Microscopy}: {A} {Bayesian} {Estimate} {Based} on {Fluorophore} {Statistics}.},
	volume = {112},
	issn = {1542-0086},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/28494949},
	doi = {10.1016/j.bpj.2017.03.020},
	abstract = {Superresolved localization microscopy has the potential to serve as an accurate, single-cell technique for counting the abundance of intracellular molecules. However, the stochastic blinking of single fluorophores can introduce large uncertainties into the final count. Here we provide a theoretical foundation for applying superresolved localization microscopy to the problem of molecular counting based on the distribution of blinking events from a single fluorophore. We also show that by redundantly tagging single molecules with multiple, blinking fluorophores, the accuracy of the technique can be enhanced by harnessing the central limit theorem. The coefficient of variation then, for the number of molecules M estimated from a given number of blinks B, scales like ∼1/Nl, where Nlis the mean number of labels on a target. As an example, we apply our theory to the challenging problem of quantifying the cell-to-cell variability of plasmid copy number in bacteria.},
	number = {9},
	urldate = {2018-02-14},
	journal = {Biophysical journal},
	author = {Nino, Daniel and Rafiei, Nafiseh and Wang, Yong and Zilman, Anton and Milstein, Joshua N},
	month = may,
	year = {2017},
	pmid = {28494949},
	note = {Publisher: Elsevier},
	pages = {1777--1785},
}

@incollection{Smal2016,
	title = {Poisson {Point} {Processes} for {Solving} {Stochastic} {Inverse} {Problems} in {Fluorescence} {Microscopy}},
	url = {http://link.springer.com/10.1007/978-3-319-46604-0_24},
	urldate = {2018-02-14},
	publisher = {Springer, Cham},
	author = {Smal, Ihor and Meijering, Erik},
	month = oct,
	year = {2016},
	doi = {10.1007/978-3-319-46604-0_24},
	pages = {326--338},
}

@article{Vora,
	title = {Load the {Edges} {You} {Need}: {A} {Generic} {I}/{O} {Optimization} for {Disk}-based {Graph} {Processing}},
	url = {https://www.usenix.org/conference/atc16/technical-sessions/presentation/vora},
	abstract = {Single-PC, disk-based processing of big graphs has re-cently gained much popularity. At the core of an efficient disk-based system is a well-designed partition structure that can minimize random disk accesses. All existing systems use static partitions that are created before pro-cessing starts. These partitions have static layouts and are loaded entirely into memory in every single iteration even though much of the edge data is not changed across many iterations, causing these unchanged edges to have zero new impact on the computation of vertex values. This work provides a general optimization that removes this I/O inefficiency by employing dynamic partitions whose layouts are dynamically adjustable. Our implemen-tation of this optimization in GraphChi — a representa-tive out-of-core vertex-centric graph system — yielded speedups of 1.5—2.8× on six large graphs. Our idea is generally applicable to other systems as well.},
	urldate = {2018-02-14},
	author = {Vora, Keval and Gupta, Rajiv and Xu, Guoqing},
}

@article{Zanacchi2017,
	title = {A {DNA} origami platform for quantifying protein copy number in super-resolution},
	volume = {14},
	issn = {1548-7091},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/28650478},
	doi = {10.1038/nmeth.4342},
	abstract = {Single-molecule-based super-resolution microscopy offers researchers a unique opportunity to quantify protein copy number with nanoscale resolution. However, while fluorescent proteins have been characterized for quantitative imaging using calibration standards, similar calibration tools for immunofluorescence with small organic fluorophores are lacking. Here we show that DNA origami, in combination with GFP antibodies, is a versatile platform for calibrating fluorophore and antibody labeling efficiency to quantify protein copy number in cellular contexts using super-resolution microscopy.},
	number = {8},
	urldate = {2018-01-23},
	journal = {Nature Methods},
	author = {Zanacchi, Francesca Cella and Manzo, Carlo and Alvarez, Angel S and Derr, Nathan D and Garcia-Parajo, Maria F and Lakadamyali, Melike},
	month = jun,
	year = {2017},
	pmid = {28650478},
	pages = {789--792},
}

@article{Leordeanu,
	title = {Unsupervised {Learning} for {Graph} {Matching}},
	abstract = {Graph matching is an important problem in computer vision. It is used in 2D and 3D object matching and recog-nition. Despite its importance, there is little literature on learning the parameters that control the graph matching problem, even though learning is important for improving the matching rate, as shown by this and other work. In this paper we show for the first time how to perform param-eter learning in an unsupervised fashion, that is when no correct correspondences between graphs are given during training. We show empirically that unsupervised learning is comparable in efficiency and quality with the supervised one, while avoiding the tedious manual labeling of ground truth correspondences. We also verify experimentally that this learning method can improve the performance of sev-eral state-of-the art graph matching algorithms.},
	urldate = {2018-02-13},
	author = {Leordeanu, Marius and Hebert, Martial},
}

@incollection{Kohlberger2012,
	title = {Evaluating {Segmentation} {Error} without {Ground} {Truth}},
	url = {http://link.springer.com/10.1007/978-3-642-33415-3_65},
	urldate = {2018-02-13},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Kohlberger, Timo and Singh, Vivek and Alvino, Chris and Bahlmann, Claus and Grady, Leo},
	year = {2012},
	doi = {10.1007/978-3-642-33415-3_65},
	pages = {528--536},
}

@article{Marin,
	title = {Bayesian {Modelling} and {Inference} on {Mixtures} of {Distributions}},
	urldate = {2018-02-13},
	author = {Marin, Jean-Michel and Mengersen, Kerrie and Robert, Christian P},
}

@article{Mirzaalian,
	title = {Skin {Lesion} {Tracking} using {Structured} {Graphical} {Models}},
	abstract = {An automatic pigmented skin lesions tracking system, which is important for early skin cancer detection, is proposed in this work. The input to the system is a pair of skin back images of the same subject captured at different times. The output is the correspondence (matching) between the detected lesions and the identi-fication of newly appearing and disappearing ones. First, a set of anatomical landmarks are detected using a pictorial structure algorithm. The lesions that are located within the polygon defined by the landmarks are identified and their anatomical spatial contexts are encoded by the landmarks. Then, these lesions are matched by labelling an association graph using a tensor based algorithm. A structured support vector ma-chine is employed to learn all free parameters in the aforementioned steps. An adaptive learning approach (on-the-fly vs offline learning) is applied to set the parameters of the matching objective function using the estimated error of the detected landmarks. The effectiveness of the different steps in our framework is validated on 194 skin back images (97 pairs).},
	urldate = {2018-02-13},
	author = {Mirzaalian, Hengameh and Lee, Tim K and Hamarneh, Ghassan},
	keywords = {Anatomical Landmark, Error Prediction, Feature (lesion and landmark) Detection, Graph Matching, Graphical Models, Hyperparameter Learning, Lesion Tracking, Melanoma, Pigmented Skin Lesion, Point Matching, Structured Support Vector Machines, Uncertainty Encoding},
}

@article{MirzaalianDastjerdi2014,
	title = {{COMPUTATIONAL} {TECHNIQUES} {FOR} {SKIN} {LESION} {TRACKING} {AND} {CLASSIFICATION}},
	url = {http://summit.sfu.ca/item/14898},
	urldate = {2018-02-13},
	author = {Mirzaalian Dastjerdi, Hengameh},
	month = nov,
	year = {2014},
}

@article{Novak2017,
	title = {{TestSTORM}: {Versatile} simulator software for multimodal super-resolution localization fluorescence microscopy},
	volume = {7},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-017-01122-7},
	doi = {10.1038/s41598-017-01122-7},
	abstract = {Optimization of sample, imaging and data processing parameters is an essential task in localization based super-resolution microscopy, where the final image quality strongly depends on the imaging of single isolated fluorescent molecules. A computational solution that uses a simulator software for the generation of test data stacks was proposed, developed and tested. The implemented advanced physical models such as scalar and vector based point spread functions, polarization sensitive detection, drift, spectral crosstalk, structured background etc., made the simulation results more realistic and helped us interpret the final super-resolved images and distinguish between real structures and imaging artefacts.},
	number = {1},
	urldate = {2018-02-13},
	journal = {Scientific Reports},
	author = {Novák, Tibor and Gajdos, Tamás and Sinkó, József and Szabó, Gábor and Erdélyi, Miklós},
	month = dec,
	year = {2017},
	note = {Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, Science, multidisciplinary},
	pages = {951},
}

@article{Chen2010,
	title = {A spectral characterization of the {Delaunay} triangulation},
	issn = {01678396},
	doi = {10.1016/j.cagd.2010.02.002},
	abstract = {The Delaunay triangulation of a planar point set is a fundamental construct in computational geometry. A simple algorithm to generate it is based on flips of diagonal edges in convex quads. We characterize the effect of a single edge flip in a triangulation on the geometric Laplacian of the triangulation, which leads to a simpler and shorter proof of a theorem of Rippa that the Dirichlet energy of any piecewise-linear scalar function on a triangulation obtains its minimum on the Delaunay triangulation. Using Rippa's theorem, we provide a spectral characterization of the Delaunay triangulation, namely that the spectrum of the geometric Laplacian is minimized on this triangulation. This spectral theorem then leads to a simpler proof of a theorem of Musin that the harmonic index also obtains its minimum on the Delaunay triangulation. © 2010 Elsevier B.V. All rights reserved.},
	journal = {Computer Aided Geometric Design},
	author = {Chen, Renjie and Xu, Yin and Gotsman, Craig and Liu, Ligang},
	year = {2010},
	keywords = {Delaunay triangulation, Dirichlet energy, Laplacian, Spectrum},
}

@article{Lenharth2016,
	title = {Parallel graph analytics},
	issn = {00010782},
	doi = {10.1145/2901919},
	abstract = {Data-centric abstractions and execution strategies are needed to exploit parallelism in large-scale graph analytics. © 2016 ACM.},
	journal = {Communications of the ACM},
	author = {Lenharth, A.a and Nguyen, D.b and Pingali, K.a},
	year = {2016},
}

@article{Karloff2013,
	title = {Maximum entropy summary trees},
	issn = {14678659},
	doi = {10.1111/cgf.12094},
	abstract = {Given a very large, node-weighted, rooted tree on, say, n nodes, if one has only enough space to display a k- node summary of the tree, what is the most informative way to draw the tree? We define a type of weighted tree that we call a summary tree of the original tree that results from aggregating nodes of the original tree subject to certain constraints. We suggest that the best choice of which summary tree to use (among those with a fixed number of nodes) is the one that maximizes the information-theoretic entropy of a natural probability distribution associated with the summary tree, and we provide a (pseudopolynomial-time) dynamic-programming algorithm to compute this maximum entropy summary tree, when the weights are integral. The result is an automated way to summarize large trees and retain as much information about them as possible, while using (and displaying) only a fraction of the original node set.We illustrate the computation and use of maximum entropy summary trees on five real data sets whose weighted tree representations vary widely in structure. We also provide an additive approximation algorithm and a greedy heuristic that are faster than the optimal algorithm, and generalize to trees with real-valued weights.},
	journal = {Computer Graphics Forum},
	author = {Karloff, Howard and Shirley, Kenneth E.},
	year = {2013},
	note = {ISBN: 01677055},
}

@inproceedings{Chen2013,
	title = {Localizing the delaunay triangulation and its parallel implementation},
	isbn = {978-3-642-41904-1},
	doi = {10.1007/978-3-642-41905-8-4},
	abstract = {We show how to localize the Delaunay triangulation of a given planar point set, namely, bound the set of points which are possible Delaunay neighbors of a given point. We then exploit this observation in an algorithm for constructing the Delaunay triangulation (and its dual Voronoi diagram) by computing the Delaunay neighbors (and Voronoi cell) of each point independently. While this does not lead to the fastest serial algorithm possible for Delaunay triangulation, it does lead to an efficient parallelization strategy which achieves almost perfect speedups on multicore machines. View full abstract},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Chen, Renjie and Gotsman, Craig},
	year = {2013},
	note = {ISSN: 03029743},
	keywords = {Delaunay triangulation, Voronoi diagram, parallel computation},
}

@article{Antonioni2013,
	title = {Degree {Correlations} in {Random} {Geometric} {Graphs}},
	abstract = {Spatially embedded networks are important in several disciplines. The prototypical spatial net-work we assume is the Random Geometric Graph of which many properties are known. Here we present new results for the two-point degree correlation function in terms of the clustering coefficient of the graphs for two-dimensional space in particular, with extensions to arbitrary finite dimension. PACS numbers: 02.10.Ox, 89.75.-k In the last decade, thanks to abundant data, new models, and adequate software tools, complex networks have been thoroughly investigated in many disciplines and as a substrate of many phenomena. A synthesis is now emerging, as can be seen e.g. in the recent comprehensive treatment by Newman [1] or in Boccaletti et al. [2]. Most of this work has dealt with " relational " networks, i.e. graphs in which distances do not have physical meaning and are just dimensionless quantities measured in terms of edge hops. Indeed, many networks are mainly of this kind such as big social networks. However, in many cases the physical space in which networks are embedded and the actual distances between nodes are important such as in rail and road networks, ad hoc communication device networks, and other geographical and transportation networks. The recent comprehensive review by Barthélemy [3] has at last put together a large amount of scattered material on spatial networks. The Random Geometric Graph (RGG) is a standard spatial network model that plays a role for spatial networks similar to the one played by the Erdös-Rényi random graph for relational ones. This model is well known [3–5] but some of its second-order features have not yet been uncovered. Among these, there is the question of the degree correlation functions. In this work we present some results on degree correlations on RGGs that we believe were previously unknown. The construction process of a RGG with N nodes and radius R can be summarized as follows [4, 5]: • the N nodes are placed on the unitary space Ω ∈ R d with uniform distribution.},
	author = {Antonioni, A and Tomassini, M},
	year = {2013},
	note = {arXiv: 1207.2573v2},
}

@article{Puchner2013,
	title = {Counting molecules in single organelles with superresolution microscopy allows tracking of the endosome maturation trajectory},
	volume = {110},
	issn = {0027-8424},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24043832},
	doi = {10.1073/pnas.1309676110},
	abstract = {Cells tightly regulate trafficking of intracellular organelles, but a deeper understanding of this process is technically limited by our inability to track the molecular composition of individual organelles below the diffraction limit in size. Here we develop a technique for intracellularly calibrated superresolution microscopy that can measure the size of individual organelles as well as accurately count absolute numbers of molecules, by correcting for undercounting owing to immature fluorescent proteins and overcounting owing to fluorophore blinking. Using this technique, we characterized the size of individual vesicles in the yeast endocytic pathway and the number of accessible phosphatidylinositol 3-phosphate binding sites they contain. This analysis reveals a characteristic vesicle maturation trajectory of composition and size with both stochastic and regulated components. The trajectory displays some cell-to-cell variability, with smaller variation between organelles within the same cell. This approach also reveals mechanistic information on the order of events in this trajectory: Colocalization analysis with known markers of different vesicle maturation stages shows that phosphatidylinositol 3-phosphate production precedes fusion into larger endosomes. This single-organelle analysis can potentially be applied to a range of small organelles to shed light on their precise composition/structure relationships, the dynamics of their regulation, and the noise in these processes.},
	number = {40},
	urldate = {2018-02-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Puchner, E. M. and Walter, J. M. and Kasper, R. and Huang, B. and Lim, W. A.},
	month = oct,
	year = {2013},
	pmid = {24043832},
	keywords = {GTPases, PALM, endocytosis, phosphoinositides, single-molecule},
	pages = {16015--16020},
}

@article{Wu2012,
	title = {Accounting for alignment uncertainty in phylogenomics},
	issn = {19326203},
	doi = {10.1371/journal.pone.0030288},
	abstract = {Uncertainty in multiple sequence alignments has a large impact on phylogenetic analyses. Little has been done to evaluate the quality of individual positions in protein sequence alignments, which directly impact the accuracy of phylogenetic trees. Here we describe ZORRO, a probabilistic masking program that accounts for alignment uncertainty by assigning confidence scores to each alignment position. Using the BALIBASE database and in simulation studies, we demonstrate that masking by ZORRO significantly reduces the alignment uncertainty and improves the tree accuracy.},
	journal = {PLoS ONE},
	author = {Wu, Martin and Chatterji, Sourav and Eisen, Jonathan A.},
	year = {2012},
	pmid = {22272325},
	note = {ISBN: 1932-6203},
}

@article{Robert2005,
	title = {Distinguishing {Biological} and {Non}-{Biological} {Networks} in {Single} {Molecule} {Localization} {Super} {Resolution} {Microscopy} {Objectives} {Conclusion} {Data}},
	volume = {145},
	author = {Robert, Ivan},
	year = {2005},
	keywords = {Distinguishing Biological and Non-Biological Netwo, Localization Super Resolution Microscopy},
	pages = {1--2},
}

@article{ferreon_interplay_2009,
	title = {Interplay of  -synuclein binding and conformational switching probed by single-molecule fluorescence},
	volume = {106},
	issn = {0027-8424},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19293380},
	doi = {10.1073/pnas.0809232106},
	abstract = {We studied the coupled binding and folding of alpha-synuclein, an intrinsically disordered protein linked with Parkinson's disease. Using single-molecule fluorescence resonance energy transfer and correlation methods, we directly probed protein membrane association, structural distributions, and dynamics. Results revealed an intricate energy landscape on which binding of alpha-synuclein to amphiphilic small molecules or membrane-like partners modulates conformational transitions between a natively unfolded state and multiple alpha-helical structures. Alpha-synuclein conformation is not continuously tunable, but instead partitions into 2 main classes of folding landscape structural minima. The switch between a broken and an extended helical structure can be triggered by changing the concentration of binding partners or by varying the curvature of the binding surfaces presented by micelles or bilayers composed of the lipid-mimetic SDS. Single-molecule experiments with lipid vesicles of various composition showed that a low fraction of negatively charged lipids, similar to that found in biological membranes, was sufficient to drive alpha-synuclein binding and folding, resulting here in the induction of an extended helical structure. Overall, our results imply that the 2 folded structures are preencoded by the alpha-synuclein amino acid sequence, and are tunable by small-molecule supramolecular states and differing membrane properties, suggesting novel control elements for biological and amyloid regulation of alpha-synuclein.},
	number = {14},
	urldate = {2018-02-07},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Ferreon, A. C. M. and Gambin, Y. and Lemke, E. A. and Deniz, A. A.},
	month = apr,
	year = {2009},
	pmid = {19293380},
	pages = {5645--5650},
}

@article{Vogel1998,
	title = {Expression of caveolin-1 and polarized formation of invaginated caveolae in {Caco}-2 and {MDCK} {II} cells.},
	volume = {111 ( Pt 6},
	issn = {0021-9533},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/9472010},
	abstract = {We have studied caveolin-1 expression and the frequency and distribution of typical invaginated caveolae as they are identified by electron microscopy in the polarized epithelial cell lines MDCK II and Caco-2. In wild-type MDCK II cells caveolin expression is high and more than 400 caveolae/mm filter were observed at the basolateral membrane. No caveolae were found at the apical surface. By contrast, wild-type Caco-2 cells do not express caveolin-1 and have extremely few, if any caveolae. Caco-2 cells were stably transfected with the gene for caveolin-1 in order to investigate if the formation of caveolae is polarized also in these cells. We have isolated Caco-2 clones expressing different levels of caveolin-1, where the level of expression varies from 10-100\% of the endogenous level in MDCK II cells. Caveolin-1 expression in Caco-2 cells gives rise to a marked immunofluorescense labeling mainly at the lateral plasma membrane. By electron microscopy an increase from less than 4 caveolae/mm filter in wild-type Caco-2 cells to 21-76 caveolae/mm filter in Caco-2 clones transfected with caveolin-1 was revealed and these caveolae were exclusively localized to the basolateral membrane. Thus expression of heterologous caveolin-1 in Caco-2 cells leads to polarized formation of caveolae, but there is a lack of correlation between the amount of caveolin expressed in the cells and the number of caveolae, suggesting that factors in addition to caveolin are required for generation of caveolae.},
	number = {6},
	urldate = {2018-02-07},
	journal = {Journal of cell science},
	author = {Vogel, U and Sandvig, K and van Deurs, B and Une, T.},
	month = mar,
	year = {1998},
	pmid = {9472010},
	note = {Publisher: The Company of Biologists Ltd},
	pages = {825--32},
}

@article{Kiskowski2009,
	title = {On the use of {Ripley}'s {K}-function and its derivatives to analyze domain size.},
	volume = {97},
	issn = {1542-0086},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19686657},
	doi = {10.1016/j.bpj.2009.05.039},
	abstract = {Ripley's K-, H-, and L-functions are used increasingly to identify clustering of proteins in membrane microdomains. In this approach, aggregation (or clustering) is identified if the average number of proteins within a distance r of another protein is statistically greater than that expected for a random distribution. However, it is not entirely clear how the function may be used to quantitatively determine the size of domains in which clustering occurs. Here, we evaluate the extent to which the domain radius can be determined by different interpretations of Ripley's K-statistic in a theoretical, idealized context. We also evaluate the measures for noisy experimental data and use Monte Carlo simulations to separate the effects of different types of experimental noise. We find that the radius of maximal aggregation approximates the domain radius, while identifying the domain boundary with the minimum of the derivative of H(r) is highly accurate in idealized conditions. The accuracy of both measures is impacted by the noise present in experimental data; for example, here, the presence of a large fraction of particles distributed as monomers and interdomain interactions. These findings help to delineate the limitations and potential of Ripley's K in real-life scenarios.},
	number = {4},
	urldate = {2018-02-07},
	journal = {Biophysical journal},
	author = {Kiskowski, Maria A and Hancock, John F and Kenworthy, Anne K},
	month = aug,
	year = {2009},
	pmid = {19686657},
	note = {Publisher: The Biophysical Society},
	pages = {1095--103},
}

@article{Tachikawa2017,
	title = {Measurement of caveolin-1 densities in the cell membrane for quantification of caveolar deformation after exposure to hypotonic membrane tension},
	volume = {7},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-017-08259-5},
	doi = {10.1038/s41598-017-08259-5},
	abstract = {Caveolae are abundant flask-shaped invaginations of plasma membranes that buffer membrane tension through their deformation. Few quantitative studies on the deformation of caveolae have been reported. Each caveola contains approximately 150 caveolin-1 proteins. In this study, we estimated the extent of caveolar deformation by measuring the density of caveolin-1 projected onto a two-dimensional (2D) plane. The caveolin-1 in a flattened caveola is assumed to have approximately one-quarter of the density of the caveolin-1 in a flask-shaped caveola. The proportion of one-quarter-density caveolin-1 increased after increasing the tension of the plasma membrane through hypo-osmotic treatment. The one-quarter-density caveolin-1 was soluble in detergent and formed a continuous population with the caveolin-1 in the caveolae of cells under isotonic culture. The distinct, dispersed lower-density caveolin-1 was soluble in detergent and increased after the application of tension, suggesting that the hypo-osmotic tension induced the dispersion of caveolin-1 from the caveolae, possibly through flattened caveolar intermediates.},
	number = {1},
	urldate = {2018-02-07},
	journal = {Scientific Reports},
	author = {Tachikawa, Masashi and Morone, Nobuhiro and Senju, Yosuke and Sugiura, Tadao and Hanawa-Suetsugu, Kyoko and Mochizuki, Atsushi and Suetsugu, Shiro},
	month = dec,
	year = {2017},
	note = {Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, Science, multidisciplinary},
	pages = {7794},
}

@inproceedings{Pundir2015,
	address = {New York, New York, USA},
	title = {Zorro},
	isbn = {978-1-4503-3651-2},
	url = {http://dl.acm.org/citation.cfm?doid=2806777.2806934},
	doi = {10.1145/2806777.2806934},
	urldate = {2018-02-07},
	booktitle = {Proceedings of the {Sixth} {ACM} {Symposium} on {Cloud} {Computing} - {SoCC} '15},
	publisher = {ACM Press},
	author = {Pundir, Mayank and Leslie, Luke M. and Gupta, Indranil and Campbell, Roy H.},
	year = {2015},
	pages = {195--208},
}

@article{Vora2017,
	title = {{CoRAL}},
	volume = {51},
	issn = {01635980},
	url = {http://dl.acm.org/citation.cfm?doid=3093315.3037747},
	doi = {10.1145/3093315.3037747},
	number = {2},
	urldate = {2018-02-07},
	journal = {ACM SIGOPS Operating Systems Review},
	author = {Vora, Keval and Tian, Chen and Gupta, Rajiv and Hu, Ziang and Vora, Keval and Tian, Chen and Gupta, Rajiv and Hu, Ziang and Vora, Keval and Tian, Chen and Gupta, Rajiv and Hu, Ziang and Vora, Keval and Tian, Chen and Gupta, Rajiv and Hu, Ziang},
	month = apr,
	year = {2017},
	note = {Publisher: ACM
ISBN: 978-1-4503-4465-4},
	keywords = {distributed processing, fault tolerance, graph processing},
	pages = {223--236},
}

@article{lechner_worm_nodate,
	title = {Worm level control through search based reinforcement learning},
	url = {https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnx3d25pcDIwMTd8Z3g6NDQ3YjZhZTZiYWJiNDI5NA},
	urldate = {2018-02-07},
	author = {Lechner, Mathias},
}

@article{kettani_distribution_nodate,
	title = {On the {Distribution} of the {Distance} {Between} {Two} {Multivariate} {Normally} {Distributed} {Points}},
	abstract = {Motivated by the problem of cluster identification, we consider two multivariate normally distributed points. We seek to find the distribution of the squared Euclidean distance between these two point. Con-sequently, we find the corresponding distribution in the general case. We then reduce this distribution for special cases based on the mean and covariance.},
	urldate = {2018-02-07},
	author = {Kettani, Houssain and Ostrouchov, George},
}

@article{CerruelaGarcia2011,
	title = {Analysis and study of molecule data sets using snowflake diagrams of weighted maximum common subgraph trees},
	issn = {15499596},
	doi = {10.1021/ci100484z},
	abstract = {Isomorphism measures based on the maximum common subgraph (MCS) calculation are widely used in computational chemistry for classifying, screening, and predicting properties and biological activity within chemical databases. The development of a weighted hierarchical structure based on the MCS is described in this paper. Furthermore, a 2D representation model is proposed as the proper tool for the study and preliminary analysis of molecule data sets. The development process of the weighted MCS tree is open to the use of different approaches. By taking into account different molecular descriptors, similarity and distance measures in the weighted MCS tree, the relationships between the molecular property or the activity, and the variables considered for the building and display of the weighted MCS tree can be observed. Besides that, the representation model based on snowflake diagrams allows to display of those relationships as well as shows any existing degeneration, in order to detect any possible outlier that could be obtained during the development of predictive models and to extract new variables that can be used in the building of quantitative structure-activity relationship models.},
	journal = {Journal of Chemical Information and Modeling},
	author = {Cerruela García, Gonzalo and Luque Ruiz, Irene and Gómez-Nieto, Miguel Ángel},
	year = {2011},
	pmid = {21513354},
	note = {ISBN: 1549-9596},
}

@article{Ehrlich2011,
	title = {Maximum common subgraph isomorphism algorithms and their applications in molecular science: {A} review},
	issn = {17590876},
	doi = {10.1002/wcms.5},
	abstract = {The intuitive description of small and large molecules using graphs has led to an increasing interest in the application of graph concepts for describing, analyzing, and comparing small molecules as well as proteins. Graph theory is a well-studied field and many applications are present in various scientific disciplines. Recent literature describes a number of successful applications to biological problems. One of the most applied concepts aims at finding a maximal common subgraph (MCS) isomorphism between two graphs. We review exact MCS algorithms, especially designed for graphs obtained from small and large molecules, and give an overview of their successful applications. © 2011 John Wiley \& Sons, Ltd. WIREs Comput Mol Sci 2011 1 68–79 DOI: 10.1002/wcms.5},
	journal = {Wiley Interdisciplinary Reviews: Computational Molecular Science},
	author = {Ehrlich, Hans Christian and Rarey, Matthias},
	year = {2011},
	note = {ISBN: 1759-0884},
}

@article{Kann1992,
	title = {On the approximability of the maximum common subgraph problem},
	issn = {16113349},
	abstract = {© Springer-Verlag Berlin Heidelberg 1992. Some versions of the maximum common subgraph problem are studied and approximation algorithms are given. The maximum bounded common induced subgraph problem is shown to be Max SNP-hard and the maximum unbounded common induced subgraph problem is shown to be as hard to approximate as the maximum independent set problem. The maximum common induced connected subgraph problem is still harder to approximate and is shown to be NPO PB-complete, i.e. complete in the class of optimization problems with optimal value bounded by a polynomial.},
	journal = {STACS 92},
	author = {Kann, Viggo},
	year = {1992},
	note = {ISBN: 9783540552109},
}

@article{Raymond2002,
	title = {Maximum common subgraph isomorphism algorithms for the matching of chemical structures},
	issn = {0920654X},
	doi = {10.1023/A:1021271615909},
	abstract = {The maximum common subgraph (MCS) problem has become increasingly important in those aspects of chemoinformatics that involve the matching of 2D or 3D chemical structures. This paper provides a classification and a review of the many MCS algorithms, both exact and approximate, that have been described in the literature, and makes recommendations regarding their applicability to typical chemoinformatics tasks.},
	journal = {Journal of Computer-Aided Molecular Design},
	author = {Raymond, John W. and Willett, Peter},
	year = {2002},
	pmid = {12510884},
	note = {ISBN: 0920-654X},
	keywords = {Algorithm, Graph matching, Graph simularity, Isomorphism algorithm, Maximum common subraph, Maximum common substructure},
}

@article{Duesbury2017,
	title = {Maximum {Common} {Subgraph} {Isomorphism} {Algorithms}: {A} {Review}},
	issn = {03406253},
	abstract = {Maximum common subgraph (MCS) isomorphism algorithms play an important role in chemoinformatics by providing an effective mechanism for the alignment of pairs of chemical structures. This article discusses the various types of MCS that can be identified when two graphs are compared and reviews some of the algorithms that are available for this purpose, focusing on those that are, or may be, applicable to the matching of chemical graphs.},
	journal = {MATCH Communications in Mathematical and in Computer Chemistry},
	author = {Duesbury, Edmund and Holliday, John D and Willett, Peter},
	year = {2017},
	note = {ISBN: 0000000345},
}

@article{Chen2015b,
	title = {Approximating the maximum common subgraph isomorphism problem with a weighted graph},
	volume = {85},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705115001987},
	doi = {10.1016/J.KNOSYS.2015.05.012},
	abstract = {The maximum common subgraph isomorphism problem is a difficult graph problem, and the problem of finding the maximum common subgraph isomorphism problem is NP-hard. This means there is likely no algorithm that will be able to find the maximal isomorphic common subgraph in polynomial time because as the size of the graphs grows the search space for the solution will grow exponentially. This research provides a method that will approximate the maximum common subgraph isomorphism problem by producing a weighted graph, where the weights will give an indication of the probability that the associated link will be in the maximum common subgraph of the two input graphs. The experimental results show that the method can effectively generate a weighted graph containing most of the expected links that would exist in the maximum common subgraph of some given graphs with similar structures.},
	urldate = {2018-02-05},
	journal = {Knowledge-Based Systems},
	author = {Chen, Alan Chia-Lung and Elhajj, Ahmed and Gao, Shang and Sarhan, Abdullah and Afra, Salim and Kassem, Ahmad and Alhajj, Reda},
	month = sep,
	year = {2015},
	note = {Publisher: Elsevier},
	pages = {265--276},
}

@inproceedings{Loffler2010,
	title = {Delaunay triangulation of imprecise points in linear time after preprocessing},
	isbn = {978-1-60558-071-5},
	doi = {10.1016/j.comgeo.2008.12.007},
	abstract = {An assumption of nearly all algorithms in computational geometry is that the input points are given precisely, so it is interesting to ask what is the value of imprecise information about points. We show how to preprocess a set of n disjoint unit disks in the plane in O(nlogn) time so that if one point per disk is specified with precise coordinates, the Delaunay triangulation can be computed in linear time. From the Delaunay, one can obtain the Gabriel graph and a Euclidean minimum spanning tree; it is interesting to note the roles that these two structures play in our algorithm to quickly compute the Delaunay. © 2009 Elsevier B.V.},
	booktitle = {Computational {Geometry}: {Theory} and {Applications}},
	author = {Löffler, Maarten and Snoeyink, Jack},
	year = {2010},
	note = {ISSN: 09257721},
	keywords = {Data imprecision, Delaunay triangulation, Minimum spanning tree},
}

@article{HwanJin,
	title = {Deep {Convolutional} {Neural} {Network} for {Inverse} {Problems} in {Imaging}},
	abstract = {In this paper, we propose a novel deep convolutional neural network (CNN)-based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard ap-proach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difficulty of hyper parameter selection. The starting point of our work is the observation that unrolled iterative methods have the form of a CNN (filtering followed by point-wise non-linearity) when the normal operator (H * H, the adjoint of H times H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill-posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a 512 × 512 image on the GPU.},
	urldate = {2018-02-05},
	author = {Hwan Jin, Kyong and McCann, Michael T and Froustey, Emmanuel and Unser, Michael},
}

@article{Loffler2012,
	title = {Triangulating the {Square} and {Squaring} the {Triangle}: {Quadtrees} and {Delaunay} {Triangulations} are {Equivalent}},
	issn = {0097-5397},
	doi = {10.1137/110825698},
	abstract = {We show that Delaunay triangulations and compressed quadtrees are equivalent structures. More precisely, we give two algorithms: the first computes a compressed quadtree for a planar point set, given the Delaunay triangulation; the second finds the Delaunay triangulation, given a compressed quadtree. Both algorithms run in deterministic linear time on a pointer machine. Our work builds on and extends previous results by Krznaric and Levcopolous and Buchin and Mulzer. Our main tool for the second algorithm is the well-separated pair decomposition(WSPD), a structure that has been used previously to find Euclidean minimum spanning trees in higher dimensions (Eppstein). We show that knowing the WSPD (and a quadtree) suffices to compute a planar Euclidean minimum spanning tree (EMST) in linear time. With the EMST at hand, we can find the Delaunay triangulation in linear time. As a corollary, we obtain deterministic versions of many previous algorithms related to Delaunay triangulations, such as splitting planar Delaunay triangulations, preprocessing imprecise points for faster Delaunay computation, and transdichotomous Delaunay triangulations.},
	journal = {SIAM Journal on Computing},
	author = {Löffler, Maarten and Mulzer, Wolfgang},
	year = {2012},
	note = {arXiv: 1205.4738
ISBN: 9780898719932},
}

@article{evans_learning_2018,
	title = {Learning {Explanatory} {Rules} from {Noisy} {Data}},
	volume = {61},
	abstract = {Artificial Neural Networks are powerful function approximators capable of modelling solutions to a wide variety of problems, both supervised and unsupervised. As their size and expressivity increases, so too does the variance of the model, yielding a nearly ubiquitous overfitting problem. Although mitigated by a variety of model regularisation methods, the common cure is to seek large amounts of training data—which is not necessarily easily obtained—that sufficiently approximates the data distribution of the domain we wish to test on. In contrast, logic programming methods such as Inductive Logic Programming offer an extremely data-efficient process by which models can be trained to reason on symbolic domains. However, these methods are unable to deal with the variety of domains neural networks can be applied to: they are not robust to noise in or mislabelling of inputs, and perhaps more importantly, cannot be applied to non-symbolic domains where the data is ambiguous, such as operating on raw pixels. In this paper, we propose a Differentiable Inductive Logic framework, which can not only solve tasks which traditional ILP systems are suited for, but shows a robustness to noise and error in the training data which ILP cannot cope with. Furthermore, as it is trained by backpropagation against a likelihood objective, it can be hybridised by connecting it with neural networks over ambiguous data in order to be applied to domains which ILP cannot address, while providing data efficiency and generalisation beyond what neural networks on their own can achieve.},
	urldate = {2018-02-05},
	journal = {Journal of Artificial Intelligence Research},
	author = {Evans, Richard and Grefenstette, Edward},
	year = {2018},
	pages = {1--64},
}

@incollection{simmhan_goffish:_2014,
	title = {{GoFFish}: {A} {Sub}-graph {Centric} {Framework} for {Large}-{Scale} {Graph} {Analytics}},
	url = {http://link.springer.com/10.1007/978-3-319-09873-9_38},
	urldate = {2018-02-05},
	publisher = {Springer, Cham},
	author = {Simmhan, Yogesh and Kumbhare, Alok and Wickramaarachchi, Charith and Nagarkar, Soonil and Ravi, Santosh and Raghavendra, Cauligi and Prasanna, Viktor},
	year = {2014},
	doi = {10.1007/978-3-319-09873-9_38},
	pages = {451--462},
}

@misc{noauthor_graph_nodate,
	title = {Graph 500 {\textbar} large-scale benchmarks},
	url = {https://graph500.org/},
	urldate = {2018-02-05},
}

@article{shrikumar_reverse-complement_2017,
	title = {Reverse-complement parameter sharing improves deep learning models for genomics},
	url = {https://www.biorxiv.org/content/early/2017/01/27/103663},
	doi = {10.1101/103663},
	abstract = {Deep learning approaches that have produced breakthrough predictive models in computer vision, speech recognition and machine translation are now being successfully applied to problems in regulatory genomics. However, deep learning architectures used thus far in genomics are often directly ported from computer vision and natural language processing applications with few, if any, domain-specific modifications. In double-stranded DNA, the same pattern may appear identically on one strand and its reverse complement due to complementary base pairing. Here, we show that conventional deep learning models that do not explicitly model this property can produce substantially different predictions on forward and reverse-complement versions of the same DNA sequence. We present four new convolutional neural network layers that leverage the reverse-complement property of genomic DNA sequence by sharing parameters between forward and reverse-complement representations in the model. These layers guarantee that forward and reverse-complement sequences produce identical predictions within numerical precision. Using experiments on simulated and in vivo transcription factor binding data, we show that our proposed architectures lead to improved performance, faster learning and cleaner internal representations compared to conventional architectures trained on the same data.},
	urldate = {2018-02-05},
	journal = {bioRxiv},
	author = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
	month = jan,
	year = {2017},
	note = {Publisher: Cold Spring Harbor Laboratory},
	pages = {103663},
}

@article{Blankstein,
	title = {Parallel {Subgraph} {Isomorphism}},
	abstract = {—The subgraph isomorphism problem deals with determining whether a given graph H is isomorphic to some subgraph of another graph G. In this paper we attempt to parallelize a fast serial subgraph isomorphism library, VFLib, which uses backtracking search to find a solution. Our parallel solution runs on Cilk++ for efficient execution on multicore machines. In our work we examine the benefits and drawbacks of several data structures when used during this backtracking search. We also examine several heuristics for spawning threads. Finally, we use conditional copying to achieve near-linear speedup with the number of CPU cores on random graphs and reasonable performance on parasitic inputs.},
	urldate = {2018-02-02},
	author = {Blankstein, Aaron and Goldstein, Matthew},
}

@article{Gambin2014,
	title = {Single-molecule analysis reveals self assembly and nanoscale segregation of two distinct cavin subcomplexes on caveolae},
	volume = {3},
	issn = {2050-084X},
	url = {https://elifesciences.org/articles/01434},
	doi = {10.7554/eLife.01434},
	abstract = {{\textless}p{\textgreater}In mammalian cells three closely related cavin proteins cooperate with the scaffolding protein caveolin to form membrane invaginations known as caveolae. Here we have developed a novel single-molecule fluorescence approach to directly observe interactions and stoichiometries in protein complexes from cell extracts and from in vitro synthesized components. We show that up to 50 cavins associate on a caveola. However, rather than forming a single coat complex containing the three cavin family members, single-molecule analysis reveals an exquisite specificity of interactions between cavin1, cavin2 and cavin3. Changes in membrane tension can flatten the caveolae, causing the release of the cavin coat and its disassembly into separate cavin1-cavin2 and cavin1-cavin3 subcomplexes. Each of these subcomplexes contain 9 ± 2 cavin molecules and appear to be the building blocks of the caveolar coat. High resolution immunoelectron microscopy suggests a remarkable nanoscale organization of these separate subcomplexes, forming individual striations on the surface of caveolae.{\textless}/p{\textgreater}},
	urldate = {2018-02-02},
	journal = {eLife},
	author = {Gambin, Yann and Ariotti, Nicholas and McMahon, Kerrie-Ann and Bastiani, Michele and Sierecki, Emma and Kovtun, Oleksiy and Polinkovsky, Mark E and Magenau, Astrid and Jung, WooRam and Okano, Satomi and Zhou, Yong and Leneva, Natalya and Mureev, Sergey and Johnston, Wayne and Gaus, Katharina and Hancock, John F and Collins, Brett M and Alexandrov, Kirill and Parton, Robert G},
	month = jan,
	year = {2014},
	note = {Publisher: eLife Sciences Publications Limited},
	keywords = {caveolae, cell-free protein expression, single-molecule},
	pages = {e01434},
}

@article{Prakash,
	title = {Delaunay {Triangulation} in {Parallel}},
	urldate = {2018-02-01},
	author = {Prakash, Adarsh},
}

@inproceedings{Lin2016,
	title = {Distributed and {Parallel} {Delaunay} {Triangulation} {Construction} with {Balanced} {Binary}-tree {Model} in {Cloud}},
	isbn = {978-1-5090-4152-7},
	url = {http://ieeexplore.ieee.org/document/7904277/},
	doi = {10.1109/ISPDC.2016.79},
	urldate = {2018-02-01},
	booktitle = {2016 15th {International} {Symposium} on {Parallel} and {Distributed} {Computing} ({ISPDC})},
	publisher = {IEEE},
	author = {Lin, Jiaxiang and Chen, Riqing and Yang, Changcai and Shu, Zhaogang and Wang, Changying and Lin, Yaohai and Wu, Liping},
	year = {2016},
	pages = {107--113},
}

@article{Gao,
	title = {A {GPU} accelerated algorithm for {3D} {Delaunay} triangulation},
	abstract = {We propose the first algorithm to compute the 3D Delaunay trian-gulation (DT) on the GPU. Our algorithm uses massively parallel point insertion followed by bilateral flipping, a powerful local op-eration in computational geometry. Although a flipping algorithm is very amenable to parallel processing and has been employed to construct the 2D DT and the 3D convex hull on the GPU, to our knowledge there is no such successful attempt for constructing the 3D DT. This is because in 3D when many points are inserted in par-allel, flipping gets stuck long before reaching the DT, and thus any further correction to obtain the DT is costly. In contrast, we show that by alternating between parallel point insertion and flipping, to-gether with picking an appropriate point insertion order, one can still obtain a triangulation very close to Delaunay. We further pro-pose an adaptive star splaying approach to subsequently transform this result into the 3D DT efficiently. In addition, we introduce sev-eral GPU speedup techniques for our implementation, which are also useful for general computational geometry algorithms. On the whole, our hybrid approach, with the GPU accelerating the main work of constructing a near-Delaunay structure and the CPU trans-forming that into the 3D DT, outperforms all existing sequential CPU algorithms by up to an order of magnitude, in both synthetic and real-world inputs. We also adapt our approach to the 2D DT problem and obtain similar speedup over the best sequential CPU algorithms, and up to 2 times over previous GPU algorithms.},
	urldate = {2018-02-01},
	author = {Gao, Mingcen},
	keywords = {Delaunay triangulation, GPGPU, bilateral flipping, incremental insertion, star splaying},
}

@article{blelloch_design_1999,
	title = {Design and {Implementation} of a {Practical} {Parallel} {Delaunay} {Algorithm}},
	volume = {24},
	issn = {0178-4617},
	url = {http://link.springer.com/10.1007/PL00008262},
	doi = {10.1007/PL00008262},
	number = {3-4},
	urldate = {2018-02-01},
	journal = {Algorithmica},
	author = {Blelloch, G. E. and Miller, G. L. and Hardwick, J. C. and Talmor, D.},
	month = jul,
	year = {1999},
	pages = {243--269},
}

@article{Lo2012,
	title = {Parallel {Delaunay} triangulation in three dimensions},
	volume = {237-240},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782512001570},
	doi = {10.1016/J.CMA.2012.05.009},
	abstract = {A generic parallel Delaunay triangulation scheme by means of zonal partition of points is proposed. For efficient Delaunay triangulation, points are first sorted into cells, each of which is allocated roughly equal number of points. The cells are naturally grouped into zones, in which Delaunay triangulation is constructed by simultaneous point insertion cell by cell within each zone. Tetrahedra at the boundary between zones are created in parallel by adding layers of cells at the boundary of each zone to ensure that circumspheres of boundary tetrahedra contain no points in their interior. Redundant tetrahedra at the boundary between zones can be easily eliminated by individual processors in a completely independent manner by means of the elegant minimum vertex allocation scheme, such that a simplex with k vertices from zones (z1,z2,…,zk) is allocated to zone z=min(z1,z2,…,zk). The parallel 3D Delaunay triangulation algorithm has been coded in Intel FORTRAN VS2010. The parallel zonal insertion on a PC can boost the speed of the single-processor insertion by 4.5 times for the insertion of 50 million randomly generated spatial points in 133s. The scalability of the parallel zonal insertion algorithm has also been tested on a proper multi-core machine with 12 processors running on OpenMP parallel directives with shared memory. Provided the number of zones is an integral multiple of the number of processors used, almost 100\% scalability at 90\% efficiency was observed for parallel insertion using 2, 4, 6, 8 and 12 processors, and a 10.8 time speed up was recorded in a parallel insertion of 20 million points in 2×2×3=12 zones by 12 processors.},
	urldate = {2018-02-01},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Lo, S.H.},
	month = sep,
	year = {2012},
	note = {Publisher: North-Holland},
	pages = {88--106},
}

@article{Lo2014,
	title = {{3D} {Delaunay} triangulation of non-uniform point distributions},
	volume = {90},
	issn = {0168874X},
	doi = {10.1016/j.finel.2014.07.002},
	abstract = {In view of the simplicity and the linearity of regular grid insertion, a multi-grid insertion scheme is proposed for the three-dimensional Delaunay triangulation of non-uniform point distributions by recursive application of the regular grid insertion to an arbitrary subset of the original point set. The fundamentals and difficulties of three-dimensional Delaunay triangulation of highly non-uniformly distributed points by the insertion method are reviewed. Current strategies and methods of point insertions for non-uniformly distributed spatial points are discussed. An enhanced kd-tree insertion algorithm with a specified number of points in a cell and its natural sequence derived from a sandwich insertion scheme is also presented. The regular grid insertion, the enhanced kd-tree insertion and the multi-grid insertion have been rigorously studied with benchmark non-uniform distributions of 0.4–20 million points. It is found that the kd-tree insertion is more efficient in locating the base tetrahedron, but it is also more sensitive to the triangulation of non-uniform point distributions with a large amount of conflicting elongated tetrahedra. Including the grid construction time, multi-grid insertion is the most stable and efficient for all the uniform and non-uniform point distributions tested.},
	urldate = {2018-02-01},
	journal = {Finite Elements in Analysis and Design},
	author = {Lo, S.H.},
	year = {2014},
	pages = {113--130},
}

@article{Wu2011,
	title = {{ParaStream}: {A} parallel streaming {Delaunay} triangulation algorithm for {LiDAR} points on multicore architectures},
	volume = {37},
	issn = {00983004},
	doi = {10.1016/j.cageo.2011.01.008},
	abstract = {This paper presents a robust parallel Delaunay triangulation algorithm called ParaStream for processing billions of points from nonoverlapped block LiDAR files. The algorithm targets ubiquitous multicore architectures. ParaStream integrates streaming computation with a traditional divide-and-conquer scheme, in which additional erase steps are implemented to reduce the runtime memory footprint. Furthermore, a kd-tree-based dynamic schedule strategy is also proposed to distribute triangulation and merging work onto the processor cores for improved load balance. ParaStream exploits most of the computing power of multicore platforms through parallel computing, demonstrating qualities of high data throughput as well as a low memory footprint. Experiments on a 2-Way-Quad-Core Intel Xeon platform show that ParaStream can triangulate approximately one billion LiDAR points (16.4GB) in about 16min with only 600MB physical memory. The total speedup (including I/O time) is about 6.62 with 8 concurrent threads.},
	number = {9},
	urldate = {2018-02-01},
	journal = {Computers \& Geosciences},
	author = {Wu, Huayi and Guan, Xuefeng and Gong, Jianya},
	year = {2011},
	pages = {1355--1363},
}

@article{Lo2015,
	title = {{3D} {Delaunay} triangulation of 1 billion points on a {PC}},
	volume = {102},
	issn = {0168874X},
	doi = {10.1016/j.finel.2015.05.003},
	abstract = {Of course, there is not enough memory on a PC with 16GB RAM, and tetrahedra constructed have to be output to leave rooms for the creation of new tetrahedra in the next round of point insertion. A segmental zonal insertion scheme is developed, in which large data sets of more than 100 million points are partitioned into zones, each of which is triangulated in turn by the parallel zonal insertion module. An overlapping zone between two steps of insertion has to be allowed to ensure Delaunay tetrahedra formed at the boundary between two insertion zones. Tetrahedra between zones can be easily eliminated by the minimum vertex allocation method. The collection of all the tetrahedra from each insertion zone/step will produce the required triangulation for the point set. As the work of each typical step for the insertion of an equal number of points is very much similar, the processing time bears roughly a linear relationship with the number of points in the set, at a construction rate of more than 5 million Delaunay tetrahedra per second for the triangulation of 1 billion randomly generated points.},
	urldate = {2018-02-01},
	journal = {Finite Elements in Analysis and Design},
	author = {Lo, S.H.},
	year = {2015},
	pages = {65--73},
}

@article{Kolingerova2002,
	title = {Optimistic parallel {Delaunay} triangulation},
	volume = {18},
	issn = {01782789},
	url = {http://link.springer.com/10.1007/s00371-002-0173-z},
	doi = {10.1007/s00371-002-0173-z},
	number = {8},
	urldate = {2018-02-01},
	journal = {The Visual Computer},
	author = {Kolingerová, Ivana and Kohout, Josef},
	month = dec,
	year = {2002},
	pages = {511--529},
}

@article{Chen2004,
	title = {Efficient parallel implementations of near {Delaunay} triangulation with {High} {Performance} {Fortran}},
	volume = {16},
	issn = {1532-0626},
	url = {http://doi.wiley.com/10.1002/cpe.802},
	doi = {10.1002/cpe.802},
	number = {12},
	urldate = {2018-02-01},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Chen, Min-Bin and Chuang, Tyng-Ruey and Wu, Jan-Jan},
	month = oct,
	year = {2004},
	pages = {1143--1159},
}

@article{liu_adaptive_2013,
	title = {Adaptive spatial clustering in the presence of obstacles and facilitators},
	volume = {56},
	issn = {0098-3004},
	url = {https://www.sciencedirect.com/science/article/pii/S0098300413000563},
	doi = {10.1016/J.CAGEO.2013.03.002},
	abstract = {An intersection-and-combination strategy for clustering spatial point data in the presence of obstacles (e.g. mountain) and facilitators (e.g. highway) is proposed in this paper, and an adaptive spatial clustering algorithm, called ASCDT+, is also developed. The ASCDT+ algorithm can take both obstacles and facilitators into account without additional preprocessing, and automatically detects spatial clusters adjacent to each other with arbitrary shapes and/or different densities. In addition, the ASCDT+ algorithm has the ability to find clustering patterns at both global and local levels so that users can make a more complete interpretation of the clustering results. Several simulated and real-world datasets are utilized to evaluate the effectiveness of the ASCDT+ algorithm. Comparison with two related algorithms, AUTOCLUST+ and DBRS+, demonstrates the advantages of the ASCDT+ algorithm.},
	urldate = {2018-02-01},
	journal = {Computers \& Geosciences},
	author = {Liu, Qiliang and Deng, Min and Shi, Yan},
	month = jul,
	year = {2013},
	note = {Publisher: Pergamon},
	pages = {104--118},
}

@article{Deng2011,
	title = {An adaptive spatial clustering algorithm based on delaunay triangulation},
	volume = {35},
	issn = {0198-9715},
	url = {https://www.sciencedirect.com/science/article/pii/S019897151100024X},
	doi = {10.1016/J.COMPENVURBSYS.2011.02.003},
	abstract = {In this paper, an adaptive spatial clustering algorithm based on Delaunay triangulation (ASCDT for short) is proposed. The ASCDT algorithm employs both statistical features of the edges of Delaunay triangulation and a novel spatial proximity definition based upon Delaunay triangulation to detect spatial clusters. Normally, this algorithm can automatically discover clusters of complicated shapes, and non-homogeneous densities in a spatial database, without the need to set parameters or prior knowledge. The user can also modify the parameter to fit with special applications. In addition, the algorithm is robust to noise. Experiments on both simulated and real-world spatial databases (i.e. an earthquake dataset in China) are utilized to demonstrate the effectiveness and advantages of the ASCDT algorithm.},
	number = {4},
	urldate = {2018-02-01},
	journal = {Computers, Environment and Urban Systems},
	author = {Deng, Min and Liu, Qiliang and Cheng, Tao and Shi, Yan},
	month = jul,
	year = {2011},
	note = {Publisher: Pergamon},
	pages = {320--332},
}

@article{Qiu,
	title = {Nonparametric {Nearest} {Neighbor} {Descent} {Clustering} based on {Delaunay} {Triangulation}},
	abstract = {In our physically inspired in-tree (IT) based clustering algorithm and the series after it, there is only one free parameter involved in computing the potential value of each point. In this work, based on the Delaunay Triangulation or its dual Voronoi tessellation, we propose a nonparametric process to compute potential values by the local information. This computation, though nonparametric, is relatively very rough, and consequently, many local extreme points will be generated. However, unlike those gradient-based methods, our IT-based methods are generally insensitive to those local extremes. This positively demonstrates the superiority of these parametric (previous) and nonparametric (in this work) IT-based methods. 1 Introduction In (1), we proposed a physically inspired clustering algorithm, in which an in-tree (IT) structure was first constructed. This IT structure organizes the data points into the clusters with several undesired connections (edges) between them requiring to be removed. In (1) and the series (2-4) after it, we proposed several methods to remove those redundant edges, either by using semi-supervised and interactive strategies or by combining with the Decision Graph recently proposed by Rodriguez and Laio (5) and some other popular methods as affinity propagation (AP) (6) and Isomap (7). All these efforts seem quite effective, showing the strong extensibility of this IT structure. For example, in (3), the proposed method (G-AP) lets AP do the post processing to the IT structure, which overcomes the weakness of AP in non-spherical cluster detection. In (4), the proposed method (IT-map) replaces the K-nearest-neighbor structure in Isomap by our IT structure and maps the IT structure into a low-dimensional space, while guaranteeing clusters to be distinguishable, which is generally hard for Isomap due to the so-called crowding problem (8).},
	urldate = {2018-02-01},
	author = {Qiu, Teng and Li, Yongjie},
}

@article{Marquez2014,
	title = {There are simple and robust refinements (almost) as good as {Delaunay}},
	volume = {106},
	issn = {0378-4754},
	url = {https://www.sciencedirect.com/science/article/pii/S0378475412001309},
	doi = {10.1016/J.MATCOM.2012.06.001},
	abstract = {A new edge-based partition for triangle meshes is presented, the Seven Triangle Quasi-Delaunay partition (7T-QD). The proposed partition joins together ideas of the Seven Triangle Longest-Edge partition (7T-LE), and the classical criteria for constructing Delaunay meshes. The new partition performs similarly compared to the Delaunay triangulation (7T-D) with the benefit of being more robust and with a cheaper cost in computation. It will be proved that in most of the cases the 7T-QD is equal to the 7T-D. In addition, numerical tests will show that the difference on the minimum angle obtained by the 7T-QD and by the 7T-D is negligible.},
	urldate = {2018-02-01},
	journal = {Mathematics and Computers in Simulation},
	author = {Márquez, Alberto and Moreno-González, Auxiliadora and Plaza, Ángel and Suárez, José P.},
	month = dec,
	year = {2014},
	note = {Publisher: North-Holland},
	pages = {84--94},
}

@article{joe_construction_1991,
	title = {Construction of three-dimensional {Delaunay} triangulations using local transformations},
	volume = {8},
	issn = {0167-8396},
	url = {https://www.sciencedirect.com/science/article/pii/016783969190038D},
	doi = {10.1016/0167-8396(91)90038-D},
	abstract = {In [Joe '89], we presented an algorithm which uses local transformations to construct a triangulation of a set of n three-dimensional points that is pseudo-locally-optimal with respect to the sphere criterion. We conjectured that this algorithm always constructs a Delaunay triangulation, and supported our conjecture with experimental results. The empirical time complexity of this algorithm is O(n43) or O(n(logn)2) for sets of random points, and O(n2) in the worst case (even for Delaunay triangulations containing O(n2) tetrahedrons). These time complexities are the same or better than those of other algorithms for constructing a three-dimensional Delaunay triangulation. In this paper, we prove that the conjecture is true, i.e., local transformations can be used to construct a Delaunay triangulation. From our proof, it follows that the algorithm can be improved by removing unnecessary tests. The empirical time complexities of the improved algorithm are the same as before. We also compare the improved algorithm with a related algorithm in which the local transformations are not explicitly performed. We show that both of these algorithms have a worst case time complexity of O(n2), which is worst case optimal.},
	number = {2},
	urldate = {2018-02-01},
	journal = {Computer Aided Geometric Design},
	author = {Joe, Barry},
	month = may,
	year = {1991},
	note = {Publisher: North-Holland},
	pages = {123--142},
}

@article{Su1996,
	title = {A {Comparison} of {Sequential} {Delaunay} {Triangulation} {Algorithms}},
	abstract = {This paper presents an experimental comparison of a number of different algorithms for computing the Deluanay triangulation. The algorithms examined are: Dwyer's divide and conquer algorithm, Fortune's sweepline algorithm, several versions of the incremental algorithm (including one by Ohya, Iri, and Murota, a new bucketing-based algorithm described in this paper, and Devillers's version of a Delaunay-tree based algorithm that appears in LEDA), an algorithm that incrementally adds a correct Delaunay triangle adjacent to a current triangle in a manner similar to gift wrapping algorithms for convex hulls, and Barber's convex hull based algorithm. Most of the algorithms examined are designed for good performance on uniformly distributed sites. However, we also test implementations of these algorithms on a number of non-uniform distibutions. The experiments go beyond measuring total running time, which tends to be machine-dependent. We also analyze the major high-level primitives that algorithms use and do an experimental analysis of how often implementations of these algorithms perform each operation.},
	urldate = {2018-02-01},
	author = {Su, Peter and Drysdale, Robert L Scot},
	year = {1996},
}

@article{Kannan2004,
	title = {On clusterings},
	volume = {51},
	issn = {00045411},
	url = {http://portal.acm.org/citation.cfm?doid=990308.990313},
	doi = {10.1145/990308.990313},
	number = {3},
	urldate = {2018-02-01},
	journal = {Journal of the ACM},
	author = {Kannan, Ravi and Vempala, Santosh and Vetta, Adrian},
	month = may,
	year = {2004},
	note = {Publisher: ACM},
	keywords = {Clustering, graph algorithms, spectral methods},
	pages = {497--515},
}

@misc{noauthor_ecosystem_nodate,
	title = {Ecosystem - {Plots}},
	url = {http://docs.juliaplots.org/latest/ecosystem/},
	urldate = {2018-02-01},
}

@misc{dongen_cluster_2000,
	title = {A cluster algorithm for graphs},
	url = {https://dl.acm.org/citation.cfm?id=868986},
	urldate = {2018-02-01},
	publisher = {CWI (Centre for Mathematics and Computer Science)},
	author = {{Dongen} and {Stijn}},
	year = {2000},
}

@article{enright_efficient_2002,
	title = {An efficient algorithm for large-scale detection of protein families.},
	volume = {30},
	issn = {1362-4962},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/11917018},
	abstract = {Detection of protein families in large databases is one of the principal research objectives in structural and functional genomics. Protein family classification can significantly contribute to the delineation of functional diversity of homologous proteins, the prediction of function based on domain architecture or the presence of sequence motifs as well as comparative genomics, providing valuable evolutionary insights. We present a novel approach called TRIBE-MCL for rapid and accurate clustering of protein sequences into families. The method relies on the Markov cluster (MCL) algorithm for the assignment of proteins into families based on precomputed sequence similarity information. This novel approach does not suffer from the problems that normally hinder other protein sequence clustering algorithms, such as the presence of multi-domain proteins, promiscuous domains and fragmented proteins. The method has been rigorously tested and validated on a number of very large databases, including SwissProt, InterPro, SCOP and the draft human genome. Our results indicate that the method is ideally suited to the rapid and accurate detection of protein families on a large scale. The method has been used to detect and categorise protein families within the draft human genome and the resulting families have been used to annotate a large proportion of human proteins.},
	number = {7},
	urldate = {2018-02-01},
	journal = {Nucleic acids research},
	author = {Enright, A J and Van Dongen, S and Ouzounis, C A},
	month = apr,
	year = {2002},
	pmid = {11917018},
	note = {Publisher: Oxford University Press},
	pages = {1575--84},
}

@incollection{VanDongen2012,
	title = {Using {MCL} to {Extract} {Clusters} from {Networks}},
	volume = {804},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22144159},
	abstract = {MCL is a general purpose cluster algorithm for both weighted and unweighted networks. The algorithm utilises network topology as well as edge weights, is highly scalable and has been applied in a wide variety of bioinformatic methods. In this chapter, we give protocols and case studies for clustering of networks derived from, respectively, protein sequence similarities and gene expression profile correlations.},
	urldate = {2018-02-01},
	booktitle = {Methods in molecular biology ({Clifton}, {N}.{J}.)},
	author = {van Dongen, Stijn and Abreu-Goodger, Cei},
	year = {2012},
	pmid = {22144159},
	doi = {10.1007/978-1-61779-361-5_15},
	note = {ISSN: 1940-6029},
	pages = {281--295},
}

@article{maier_how_2013,
	title = {How the {Result} of {Graph} {Clustering} {Methods} {Depends} on the {Construction} of the {Graph}},
	issn = {1262-3318},
	doi = {10.1051/ps/2012001},
	abstract = {We study the scenario of graph-based clustering algorithms such as spectral clustering. Given a set of data points, one first has to construct a graph on the data points and then apply a graph clustering algorithm to find a suitable partition of the graph. Our main question is if and how the construction of the graph (choice of the graph, choice of parameters, choice of weights) influences the outcome of the final clustering result. To this end we study the convergence of cluster quality measures such as the normalized cut or the Cheeger cut on various kinds of random geometric graphs as the sample size tends to infinity. It turns out that the limit values of the same objective function are systematically different on different types of graphs. This implies that clustering results systematically depend on the graph and can be very different for different types of graph. We provide examples to illustrate the implications on spectral clustering.},
	journal = {Esaim-Probability and Statistics},
	author = {Maier, M and Von Luxburg, U and Hein, M},
	year = {2013},
	note = {arXiv: 1102.2075v1
ISBN: 1292-8100},
	keywords = {INEQUALITIES, NEAREST-NEIGHBOR GRAPHS, Random geometric graph, Statistics \& Probability, clustering, graph cuts},
}

@article{Lin2012,
	title = {Scalable {Methods} for {Graph}-{Based} {Unsupervised} and {Semi}-{Supervised} {Learning}},
	urldate = {2018-01-31},
	author = {Lin, Frank and William Cohen Christos Faloutsos Tom Mitchell Xiaojin Zhu, Committee W},
	year = {2012},
}

@article{Chen,
	title = {Practical {Attacks} {Against} {Graph}-based {Clustering}},
	doi = {10.1145/3133956.3134083},
	abstract = {Graph modeling allows numerous security problems to be tackled in a general way, however, little work has been done to under-stand their ability to withstand adversarial attacks. We design and evaluate two novel graph attacks against a state-of-the-art network-level, graph-based detection system. Our work highlights areas in adversarial machine learning that have not yet been addressed, specifically: graph-based clustering techniques, and a global feature space where realistic attackers without perfect knowledge must be accounted for (by the defenders) in order to be practical. Even though less informed attackers can evade graph clustering with low cost, we show that some practical defenses are possible.},
	urldate = {2018-01-31},
	author = {Chen, Yizheng and Nadji, Yacin and Kountouras, Athanasios and Monrose, Fabian and Perdisci, Roberto and Antonakakis, Manos and Vasiloglou, Nikolaos},
	keywords = {Adversarial Machine Learning, DGA, Net-work Security, Unsupervised Learning},
}

@incollection{Vathy-Fogarassy2013,
	title = {Graph-{Based} {Clustering} {Algorithms}},
	url = {http://link.springer.com/10.1007/978-1-4471-5158-6_2},
	urldate = {2018-01-31},
	publisher = {Springer, London},
	author = {Vathy-Fogarassy, Ágnes and Abonyi, János},
	year = {2013},
	doi = {10.1007/978-1-4471-5158-6_2},
	pages = {17--41},
}

@article{Kittler1986,
	title = {Minimum error thresholding},
	volume = {19},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/0031320386900300},
	doi = {10.1016/0031-3203(86)90030-0},
	abstract = {A computationally efficient solution to the problem of minimum error thresholding is derived under the assumption of object and pixel grey level values being normally distributed. The method is applicable in multithreshold selection.},
	number = {1},
	urldate = {2018-01-31},
	journal = {Pattern Recognition},
	author = {Kittler, J. and Illingworth, J.},
	month = jan,
	year = {1986},
	note = {Publisher: Pergamon},
	pages = {41--47},
}

@article{moser_generalized_2006,
	title = {Generalized minimum-error thresholding for unsupervised change detection from {SAR} amplitude imagery},
	volume = {44},
	issn = {0196-2892},
	url = {http://ieeexplore.ieee.org/document/1704990/},
	doi = {10.1109/TGRS.2006.876288},
	number = {10},
	urldate = {2018-01-31},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Moser, G. and Serpico, S.B.},
	month = oct,
	year = {2006},
	pages = {2972--2982},
}

@inproceedings{nguyen_lightweight_2013,
	address = {New York, New York, USA},
	title = {A lightweight infrastructure for graph analytics},
	isbn = {978-1-4503-2388-8},
	url = {http://dl.acm.org/citation.cfm?doid=2517349.2522739},
	doi = {10.1145/2517349.2522739},
	urldate = {2018-01-31},
	booktitle = {Proceedings of the {Twenty}-{Fourth} {ACM} {Symposium} on {Operating} {Systems} {Principles} - {SOSP} '13},
	publisher = {ACM Press},
	author = {Nguyen, Donald and Lenharth, Andrew and Pingali, Keshav},
	year = {2013},
	pages = {456--471},
}

@inproceedings{shun_ligra_2013,
	address = {New York, New York, USA},
	title = {Ligra},
	volume = {48},
	isbn = {978-1-4503-1922-5},
	url = {http://dl.acm.org/citation.cfm?doid=2442516.2442530},
	doi = {10.1145/2442516.2442530},
	urldate = {2018-01-31},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN} symposium on {Principles} and practice of parallel programming - {PPoPP} '13},
	publisher = {ACM Press},
	author = {Shun, Julian and Blelloch, Guy E. and Shun, Julian and Blelloch, Guy E.},
	year = {2013},
	note = {Issue: 8
ISSN: 0362-1340},
	keywords = {graph algorithms, parallel programming, shared memory},
	pages = {135},
}

@article{Avilov2014,
	title = {In cellulo {Evaluation} of {Phototransformation} {Quantum} {Yields} in {Fluorescent} {Proteins} {Used} {As} {Markers} for {Single}-{Molecule} {Localization} {Microscopy}},
	volume = {9},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0098362},
	doi = {10.1371/journal.pone.0098362},
	number = {6},
	urldate = {2018-01-31},
	journal = {PLoS ONE},
	author = {Avilov, Sergiy and Berardozzi, Romain and Gunewardene, Mudalige S. and Adam, Virgile and Hess, Samuel T. and Bourgeois, Dominique},
	editor = {Anderson, Kurt I.},
	month = jun,
	year = {2014},
	note = {Publisher: Public Library of Science},
	pages = {e98362},
}

@article{Tang2016,
	title = {Automatic {Bayesian} single molecule identification for localization microscopy},
	volume = {6},
	issn = {20452322},
	doi = {10.1038/srep33521},
	abstract = {Single molecule localization microscopy (SMLM) is on its way to become a mainstream imaging technique in the life sciences. However, analysis of SMLM data is biased by user provided subjective parameters required by the analysis software. To remove this human bias we introduce here the Auto-Bayes method that executes the analysis of SMLM data automatically. We demonstrate the success of the method using the photoelectron count of an emitter as selection characteristic. Moreover, the principle can be used for any characteristic that is bimodally distributed with respect to false and true emitters. The method also allows generation of an emitter reliability map for estimating quality of SMLM-based structures. The potential of the Auto-Bayes method is shown by the fact that our first basic implementation was able to outperform all software packages that were compared in the ISBI online challenge in 2015, with respect to molecule detection (Jaccard index).},
	journal = {Scientific Reports},
	author = {Tang, Yunqing and Hendriks, Johnny and Gensch, Thomas and Dai, Luru and Li, Junbai},
	year = {2016},
	pmid = {27641933},
	keywords = {mixture},
}

@article{hamarneh_deformable_nodate,
	title = {Deformable {Organisms} for {Automatic} {Medical} {Image} {Analysis}},
	url = {www.cs.toronto.edu},
	abstract = {We introduce a new paradigm for automatic medical image analysis that adopts concepts from the field of Artificial Life. Our approach prescribes deformable organisms, autonomous agents whose objective is the segmentation and analysis of anatomical structures in medical images. A deformable organism is structured as a 'muscle'-actuated 'body' whose behavior is controlled by a 'brain' that is capable of making both reactive and deliberate decisions. This intelligent deformable model possesses an 'awareness' of the segmentation process, which emerges from a conflux of perceived sensory data, an internal mental state, memorized knowledge, and a cognitive plan. We develop a class of deformable organisms using a medial representation of body morphology that facilitates a variety of controlled local deformations at multiple spatial scales. Specifically, we demonstrate a deformable 'worm' organism that can overcome noise, incomplete edges, considerable anatomical variation, and occlusion in order to segment and label the corpus callosum in 2D mid-sagittal MR images of the brain.},
	urldate = {2018-01-30},
	author = {Hamarneh, Ghassan and Mcinerney, Tim and Terzopoulos, Demetri},
}

@misc{noauthor_single-molecule_nodate,
	title = {Single-{Molecule} {Localization} {Microscopy} • {Software} {Benchmarking}},
	url = {http://bigwww.epfl.ch/smlm/#&panel1-1},
	urldate = {2018-01-30},
}

@article{ghesu_multi-scale_2017,
	title = {Multi-{Scale} {Deep} {Reinforcement} {Learning} for {Real}-{Time} {3D}-{Landmark} {Detection} in {CT} {Scans}},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/8187667/},
	doi = {10.1109/TPAMI.2017.2782687},
	urldate = {2018-01-30},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Ghesu, Florin Cristian and Georgescu, Bogdan and Zheng, Yefeng and Grbic, Sasa and Maier, Andreas and Hornegger, Joachim and Comaniciu, Dorin},
	year = {2017},
	pages = {1--1},
}

@inproceedings{murray_naiad_2013,
	address = {New York, New York, USA},
	title = {Naiad},
	isbn = {978-1-4503-2388-8},
	url = {http://dl.acm.org/citation.cfm?doid=2517349.2522738},
	doi = {10.1145/2517349.2522738},
	urldate = {2018-01-29},
	booktitle = {Proceedings of the {Twenty}-{Fourth} {ACM} {Symposium} on {Operating} {Systems} {Principles} - {SOSP} '13},
	publisher = {ACM Press},
	author = {Murray, Derek G. and McSherry, Frank and Isaacs, Rebecca and Isard, Michael and Barham, Paul and Abadi, Martín},
	year = {2013},
	pages = {439--455},
}

@article{marcus_deep_nodate,
	title = {Deep {Learning}: {A} {Critical} {Appraisal}},
	abstract = {Although deep learning has historical roots going back decades, neither the term " deep learning " nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic 2012 (Krizhevsky, Sutskever, \& Hinton, 2012)deep net model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.},
	urldate = {2018-01-29},
	author = {Marcus, Gary},
}

@article{mnih_asynchronous_nodate,
	title = {Asynchronous {Methods} for {Deep} {Reinforcement} {Learning}},
	abstract = {We propose a conceptually simple and lightweight framework for deep reinforce-ment learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
	urldate = {2018-01-26},
	author = {Mnih, Volodymyr and Puigdomènech Badia, Adrià and Mirza, Mehdi and Graves, Alex and Harley, Tim and Lillicrap, Timothy P and Silver, David and Kavukcuoglu, Koray and Com, Korayk@google and Deepmind, Google},
}

@article{molchanov_variational_2017,
	title = {Variational {Dropout} {Sparsifies} {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1701.05369},
	abstract = {We explore a recently proposed Variational Dropout technique that provided an elegant Bayesian interpretation to Gaussian Dropout. We extend Variational Dropout to the case when dropout rates are unbounded, propose a way to reduce the variance of the gradient estimator and report first experimental results with individual dropout rates per weight. Interestingly, it leads to extremely sparse solutions both in fully-connected and convolutional layers. This effect is similar to automatic relevance determination effect in empirical Bayes but has a number of advantages. We reduce the number of parameters up to 280 times on LeNet architectures and up to 68 times on VGG-like networks with a negligible decrease of accuracy.},
	urldate = {2018-01-25},
	author = {Molchanov, Dmitry and Ashukha, Arsenii and Vetrov, Dmitry},
	month = jan,
	year = {2017},
	note = {arXiv: 1701.05369},
}

@article{zhang_pathological_2015,
	title = {Pathological brain detection based on wavelet entropy and {Hu} moment invariants},
	volume = {26},
	issn = {18783619},
	url = {http://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/BME-151426},
	doi = {10.3233/BME-151426},
	number = {s1},
	urldate = {2018-01-25},
	journal = {Bio-Medical Materials and Engineering},
	author = {Zhang, Yudong and Wang, Shuihua and Sun, Ping and Phillips, Preetha},
	editor = {Liu, Feng and Lee, Dong-Hoon and Lagoa, Ricardo and Kumar, Sandeep},
	month = aug,
	year = {2015},
	note = {Publisher: IOS Press},
	pages = {S1283--S1290},
}

@article{ashtiani_techniques_2018,
	title = {Some techniques in density estimation},
	url = {http://arxiv.org/abs/1801.04003},
	abstract = {Density estimation is an interdisciplinary topic at the intersection of statistics, theoretical computer science and machine learning. We review some old and new techniques for bounding sample complexity of estimating densities of continuous distributions, focusing on the class of mixtures of Gaussians and its subclasses.},
	urldate = {2018-01-25},
	author = {Ashtiani, Hassan and Mehrabian, Abbas},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.04003},
}

@inproceedings{Hant2014,
	address = {New York, New York, USA},
	title = {Chronos},
	isbn = {978-1-4503-2704-6},
	url = {http://dl.acm.org/citation.cfm?doid=2592798.2592799},
	doi = {10.1145/2592798.2592799},
	urldate = {2018-01-22},
	booktitle = {Proceedings of the {Ninth} {European} {Conference} on {Computer} {Systems} - {EuroSys} '14},
	publisher = {ACM Press},
	author = {Hant, Wentao and Miao, Youshan and Li, Kaiwei and Wu, Ming and Yang, Fan and Zhou, Lidong and Prabhakaran, Vijayan and Chen, Wenguang and Chen, Enhong},
	year = {2014},
	pages = {1--14},
}

@article{kang_hadi:_nodate,
	title = {{HADI}: {Mining} {Radii} of {Large} {Graphs}},
	abstract = {Given large, multi-million node graphs (e.g., Facebook, web-crawls, etc.), how do they evolve over time? How are they connected? What are the central nodes and the outliers? In this paper we define the Radius plot of a graph and show how it can answer these questions. However, computing the Radius plot is prohibitively expensive for graphs reaching the planetary scale. There are two major contributions in this paper: (a) We propose HADI (HAdoop DIameter and radii estimator), a carefully designed and fine-tuned algorithm to compute the radii and the diameter of massive graphs, that runs on the top of the Hadoop/MapReduce system, with excellent scale-up on the number of available machines (b) We run HADI on several real world datasets including YahooWeb (6B edges, 1/8 of a Terabyte), one of the largest public graphs ever analyzed. Thanks to HADI, we report fascinating patterns on large networks, like the surprisingly small effective diameter, the multi-modal/bi-modal shape of the Radius plot, and its palindrome motion over time.},
	urldate = {2018-01-22},
	author = {Kang, U},
	keywords = {Algorithms, Categories and Subject Descriptors, Database Applications – Data Mining General Terms, Experimentation Additional Key Words and Phrases, H28 [Database Management], HADI, graph mining, hadoop, radius plot, small web},
}

@article{Roditty,
	title = {Fast {Approximation} {Algorithms} for the {Diameter} and {Radius} of {Sparse} {Graphs}},
	abstract = {The diameter and the radius of a graph are fundamental topological parameters that have many important practi-cal applications in real world networks. The fastest com-binatorial algorithm for both parameters works by solving the all-pairs shortest paths problem (APSP) and has a run-ning time of O(mn) in m-edge, n-node graphs. In a seminal paper, Aingworth, Chekuri, Indyk and Motwani [SODA'96 and SICOMP'99] presented an algorithm that computes in O(m √ n + n 2) time an estimatê D for the diameter D, such that ⌊2/3D⌋ D ≤ D. Their paper spawned a long line of research on approximate APSP. For the specific problem of diameter approximation, however, no improvement has been achieved in over 15 years. Our paper presents the first improvement over the diame-ter approximation algorithm of Aingworth et al. , producing an algorithm with the same estimate but with an expected running time of O(m √ n). We thus show that for all sparse enough graphs, the diameter can be 3/2-approximated in o(n 2) time. Our algorithm is obtained using a surprisingly simple method of neighborhood depth estimation that is strong enough to also approximate, in the same running time, the radius and more generally, all of the eccentrici-ties, i.e. for every node the distance to its furthest node. We also provide strong evidence that our diameter approx-imation result may be hard to improve. We show that if for some constant ε {\textgreater} 0 there is an O(m 2−ε) time (3/2 − ε)-approximation algorithm for the diameter of undirected un-weighted graphs, then there is an O * ((2 − δ) n) time algo-rithm for CNF-SAT on n variables for constant δ {\textgreater} 0, and the strong exponential time hypothesis of [Impagliazzo, Pa-turi, Zane JCSS'01] is false. Motivated by this negative result, we give several im-proved diameter approximation algorithms for special cases. We show for instance that for unweighted graphs of constant diameter D not divisible by 3, there is an O(m 2−ε) time al-gorithm that gives a (3/2 − ε) approximation for constant ε {\textgreater} 0. This is interesting since the diameter approximation problem is hardest to solve for small D.},
	urldate = {2018-01-22},
	author = {Roditty, Liam and Williams, Virginia Vassilevska},
	keywords = {G22 [Graph Theory], Graph algorithms Keywords graph diameter, approximation algorithm, shortest paths},
}

@article{sibarita_high-density_2014,
	title = {High-density single-particle tracking: {Quantifying} molecule organization and dynamics at the nanoscale},
	issn = {1432119X},
	doi = {10.1007/s00418-014-1214-1},
	abstract = {The organization and dynamics of proteins are fundamental parameters for cellular function. Their study, at the single-molecule level, provides precise information on molecular interactions. Over the last 30 years, the single-particle tracking imaging technique has proven its capability to efficiently quantify such parameters in many biological systems, with nanometric accuracy and millisecond temporal resolutions. Nevertheless, the low concentration of labeling required for single-molecule imaging usually prevents the extraction of large statistics. The advent of high-density single-molecule-based super-resolution techniques has revolutionized the field, allowing monitoring of thousands of biomolecules in the minute timescale and providing unprecedented insight into the molecular organization and dynamics of cellular compounds. In this issue, I will review the main principles of single-particle tracking, a highly interdisciplinary technique at the interface between microscopy, image analysis and labeling strategies. I will point out the advantages brought by high-density single-particle tracking which will be illustrated with a few recent biological results.},
	journal = {Histochemistry and Cell Biology},
	author = {Sibarita, Jean Baptiste},
	year = {2014},
	pmid = {24671496},
	note = {ISBN: 1432-119X (Electronic){\textbackslash}r0948-6143 (Linking)},
	keywords = {Diffusion, Localization, Mean square displacement, Photoswitching, Single molecule, Tracking, Videomicroscopy},
}

@article{tangwongsan_parallel_2013,
	title = {Parallel {Triangle} {Counting} in {Massive} {Streaming} {Graphs}},
	doi = {10.1145/2505515.2505741},
	abstract = {The number of triangles in a graph is a fundamental metric, used in social network analysis, link classiﬁcation and recommendation, and more. Driven by these applications and the trend that modern graph datasets are both large and dynamic, we present the design and implementation of a fast and cache-ecient parallel algorithm for estimating the number of triangles in a massive undirected graph whose edges arrive as a stream. It brings together the beneﬁts of streaming algorithms and parallel algorithms. By building on the streaming algorithms framework, the algorithm has a small memory footprint. By leveraging the paralell cache-oblivious framework, it makes ecient use of the memory hierarchy of modern multicore machines without needing to know its speciﬁc parameters. We prove theoretical bounds on accuracy, memory access cost, and parallel runtime complexity, as well as showing empirically that the algorithm yields accurate results and substantial speedups compared to an optimized sequential implementation.},
	journal = {Proceedings of the 22nd ACM international conference on Conference on information \& knowledge management},
	author = {Tangwongsan, Kanat and Pavan, a. and Tirthapura, Srikanta},
	year = {2013},
	note = {arXiv: 1308.2166v1
ISBN: 9781450322638},
	keywords = {Put your keywords here, cache oblivious, massive graphs, parallel, parallel algorithm, pco, streaming algorithm, triangle counting},
}

@article{pavan_counting_nodate,
	title = {Counting and {Sampling} {Triangles} from a {Graph} {Stream}},
	abstract = {This paper presents a new space-efficient algorithm for count-ing and sampling triangles—and more generally, constant-sized cliques—in a massive graph whose edges arrive as a stream. When compared with prior work, our algorithm yields significant improve-ments in the space and time complexity for these fundamental prob-lems. Our algorithm is simple to implement and has very good practical performance on large graphs.},
	urldate = {2018-01-19},
	author = {Pavan, A and Tangwongsan, Kanat and Tirthapura, Srikanta and Wu, Kun-Lung},
}

@article{Ahmed2017a,
	title = {On {Sampling} from {Massive} {Graph} {Streams}},
	abstract = {We propose Graph Priority Sampling (GPS), a new paradigm for order–based reservoir sampling from massive streams of graph edges. GPS provides a general way to weight edge sampling according to auxiliary and/or size variables so as to accomplish various estima-tion goals of graph properties. In the context of subgraph count-ing, we show how edge sampling weights can be chosen so as to minimize the estimation variance of counts of specified sets of sub-graphs. In distinction with many prior graph sampling schemes, GPS separates the functions of edge sampling and subgraph esti-mation. We propose two estimation frameworks: (1) Post-Stream estimation, to allow GPS to construct a reference sample of edges to support retrospective graph queries, and (2) In-Stream estima-tion, to allow GPS to obtain lower variance estimates by incremen-tally updating the subgraph count estimates during stream process-ing. Unbiasedness of subgraph estimators is established through a new Martingale formulation of graph stream order sampling, which shows that subgraph estimators, written as a product of constituent edge estimators are unbiased, even when computed at different points in the stream. The separation of estimation and sampling enables significant resource savings relative to previous work. We illustrate our framework with applications to triangle and wedge counting. We perform a large-scale experimental study on real-world graphs from various domains and types. GPS achieves high accuracy with {\textless} 1\% error for triangle and wedge counting, while storing a small fraction of the graph with average update times of a few microseconds per edge. Notably, for a large Twitter graph with more than 260M edges, GPS accurately estimates triangle counts with {\textless} 1\% error, while storing only 40K edges.},
	urldate = {2018-01-19},
	author = {Ahmed, Nesreen K and Duffield, Nick and Willke, Theodore L and Rossi, Ryan A},
	year = {2017},
	note = {arXiv: 1703.02625v1},
	keywords = {()},
}

@article{Low2012,
	title = {Distributed {GraphLab}: a framework for machine learning and data mining in the cloud},
	volume = {5},
	issn = {2150-8097},
	url = {https://dl.acm.org/citation.cfm?id=2212354},
	doi = {10.14778/2212351.2212354},
	number = {8},
	urldate = {2018-01-17},
	journal = {Proceedings of the VLDB Endowment},
	author = {Low, Yucheng and Bickson, Danny and Gonzalez, Joseph and Guestrin, Carlos and Kyrola, Aapo and Hellerstein, Joseph M.},
	year = {2012},
	note = {Publisher: VLDB Endowment},
	pages = {716--727},
}

@article{low_graphlab:_nodate,
	title = {{GraphLab}: {A} {New} {Framework} {For} {Parallel} {Machine} {Learning}},
	abstract = {Designing and implementing efficient, provably correct parallel machine learning (ML) algo-rithms is challenging. Existing high-level par-allel abstractions like MapReduce are insuf-ficiently expressive while low-level tools like MPI and Pthreads leave ML experts repeatedly solving the same design challenges. By tar-geting common patterns in ML, we developed GraphLab, which improves upon abstractions like MapReduce by compactly expressing asyn-chronous iterative algorithms with sparse com-putational dependencies while ensuring data con-sistency and achieving a high degree of parallel performance. We demonstrate the expressiveness of the GraphLab framework by designing and implementing parallel versions of belief propaga-tion, Gibbs sampling, Co-EM, Lasso and Com-pressed Sensing. We show that using GraphLab we can achieve excellent parallel performance on large scale real-world problems.},
	urldate = {2018-01-17},
	author = {Low, Yucheng and Gonzalez, Joseph and Kyrola, Aapo and Bickson, Danny and Guestrin, Carlos and Hellerstein, Joseph M},
}

@article{condie_mapreduce_nodate,
	title = {{MapReduce} {Online}},
	abstract = {MapReduce is a popular framework for data-intensive distributed computing of batch jobs. To simplify fault tolerance, many implementations of MapReduce mate-rialize the entire output of each map and reduce task before it can be consumed. In this paper, we propose a modified MapReduce architecture that allows data to be pipelined between operators. This extends the MapRe-duce programming model beyond batch processing, and can reduce completion times and improve system utiliza-tion for batch jobs as well. We present a modified version of the Hadoop MapReduce framework that supports on-line aggregation, which allows users to see " early returns " from a job as it is being computed. Our Hadoop Online Prototype (HOP) also supports continuous queries, which enable MapReduce programs to be written for applica-tions such as event monitoring and stream processing. HOP retains the fault tolerance properties of Hadoop and can run unmodified user-defined MapReduce programs.},
	urldate = {2018-01-12},
	author = {Condie, Tyson and Conway, Neil and Alvaro, Peter and Hellerstein, Joseph M and Elmeleegy, Khaled and Sears, Russell and Research, Yahoo !},
}

@article{laptev_early_2012,
	title = {Early {Accurate} {Results} for {Advanced} {Analytics} on {MapReduce}},
	url = {http://arxiv.org/abs/1207.0142},
	abstract = {Approximate results based on samples often provide the only way in which advanced analytical applications on very massive data sets can satisfy their time and resource constraints. Unfortunately, methods and tools for the computation of accurate early results are currently not supported in MapReduce-oriented systems although these are intended for `big data'. Therefore, we proposed and implemented a non-parametric extension of Hadoop which allows the incremental computation of early results for arbitrary work-flows, along with reliable on-line estimates of the degree of accuracy achieved so far in the computation. These estimates are based on a technique called bootstrapping that has been widely employed in statistics and can be applied to arbitrary functions and data distributions. In this paper, we describe our Early Accurate Result Library (EARL) for Hadoop that was designed to minimize the changes required to the MapReduce framework. Various tests of EARL of Hadoop are presented to characterize the frequent situations where EARL can provide major speed-ups over the current version of Hadoop.},
	urldate = {2018-01-12},
	author = {Laptev, Nikolay and Zeng, Kai and Zaniolo, Carlo},
	month = jun,
	year = {2012},
	note = {arXiv: 1207.0142},
}

@article{Agarwal,
	title = {Knowing {When} {You}'re {Wrong}: {Building} {Fast} and {Reliable} {Approximate} {Query} {Processing} {Systems}},
	doi = {10.1145/2588555.2593667},
	abstract = {Modern data analytics applications typically process massive amounts of data on clusters of tens, hundreds, or thousands of ma-chines to support near-real-time decisions. The quantity of data and limitations of disk and memory bandwidth often make it infeasible to deliver answers at interactive speeds. However, it has been widely observed that many applications can tolerate some degree of inac-curacy. This is especially true for exploratory queries on data, where users are satisfied with " close-enough " answers if they can come quickly. A popular technique for speeding up queries at the cost of accuracy is to execute each query on a sample of data, rather than the whole dataset. To ensure that the returned result is not too inaccu-rate, past work on approximate query processing has used statistical techniques to estimate " error bars " on returned results. However, existing work in the sampling-based approximate query processing (S-AQP) community has not validated whether these techniques ac-tually generate accurate error bars for real query workloads. In fact, we find that error bar estimation often fails on real world produc-tion workloads. Fortunately, it is possible to quickly and accurately diagnose the failure of error estimation for a query. In this paper, we show that it is possible to implement a query approximation pipeline that produces approximate answers and reliable error bars at inter-active speeds.},
	urldate = {2018-01-12},
	author = {Agarwal, Sameer and Milner, Henry and Kleiner, Ariel and Talwalkar, Ameet and Jordan, Michael and Madden, Samuel and Mozafari, Barzan},
	keywords = {Categories and Subject Descriptors H24 [Systems], Diagnostics, Error Estimation},
}

@article{shang_auto-approximation_2014,
	title = {Auto-{Approximation} of {Graph} {Computing}},
	issn = {21508097},
	doi = {10.14778/2733085.2733090},
	abstract = {In the big data era, graph computing is one of the challenging issues because there are numerous large graph datasets emerging from real applications. A question is: do we need to know the final exact answer for a large graph? When it is impossible to know the exact answer in a limited time, is it possible to approximate the final answer in an automatic and systematic way without having to designing new approximate algorithms? The main idea behind the question is: it is more important to find out something meaningful quick from a large graph, and we should focus on finding a way of making use of large graphs instead of spending time on designing approximate algorithms. In this paper, we give an innovative approach which automatically and systematically synthesizes a program to approximate the original program. We show that we can give users some answers with reasonable accuracy and high efficiency for a wide spectrum of graph algorithms, without having to know the details of graph algorithms. We have conducted extensive experimental studies using many graph algorithms that are supported in the existing graph systems and large real graphs. Our extensive experimental results reveal that our automatically approximating approach is highly feasible.},
	journal = {Vldb},
	author = {Shang, Zechao and Yu, Jeffrey Xu},
	year = {2014},
}

@inproceedings{kim_context-guided_2015,
	title = {Context-guided diffusion for label propagation on graphs},
	isbn = {978-1-4673-8391-2},
	doi = {10.1109/ICCV.2015.318},
	abstract = {Existing approaches for diffusion on graphs, e.g., for label propagation, are mainly focused on isotropic diffusion, which is induced by the commonly-used graph Laplacian regularizer. Inspired by the success of diffusivity tensors for anisotropic diffusion in image processing, we presents anisotropic diffusion on graphs and the corresponding label propagation algorithm. We develop positive definite diffusivity operators on the vector bundles of Riemannian manifolds, and discretize them to diffusivity operators on graphs. This enables us to easily define new robust diffusivity operators which significantly improve semi-supervised learning performance over existing diffusion algorithms.},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {Kim, Kwang In and Tompkin, James and Pfister, Hanspeter and Theobalt, Christian},
	year = {2015},
	note = {arXiv: 1602.06439
ISSN: 15505499},
}

@article{zhang_relationship_2017,
	title = {On the {Relationship} {Between} the {OpenAI} {Evolution} {Strategy} and {Stochastic} {Gradient} {Descent}},
	url = {http://arxiv.org/abs/1712.06564},
	abstract = {Because stochastic gradient descent (SGD) has shown promise optimizing neural networks with millions of parameters and few if any alternatives are known to exist, it has moved to the heart of leading approaches to reinforcement learning (RL). For that reason, the recent result from OpenAI showing that a particular kind of evolution strategy (ES) can rival the performance of SGD-based deep RL methods with large neural networks provoked surprise. This result is difficult to interpret in part because of the lingering ambiguity on how ES actually relates to SGD. The aim of this paper is to significantly reduce this ambiguity through a series of MNIST-based experiments designed to uncover their relationship. As a simple supervised problem without domain noise (unlike in most RL), MNIST makes it possible (1) to measure the correlation between gradients computed by ES and SGD and (2) then to develop an SGD-based proxy that accurately predicts the performance of different ES population sizes. These innovations give a new level of insight into the real capabilities of ES, and lead also to some unconventional means for applying ES to supervised problems that shed further light on its differences from SGD. Incorporating these lessons, the paper concludes by demonstrating that ES can achieve 99\% accuracy on MNIST, a number higher than any previously published result for any evolutionary method. While not by any means suggesting that ES should substitute for SGD in supervised learning, the suite of experiments herein enables more informed decisions on the application of ES within RL and other paradigms.},
	urldate = {2018-01-12},
	author = {Zhang, Xingwen and Clune, Jeff and Stanley, Kenneth O.},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.06564},
}

@article{lehman_safe_2017,
	title = {Safe {Mutations} for {Deep} and {Recurrent} {Neural} {Networks} through {Output} {Gradients}},
	url = {http://arxiv.org/abs/1712.06563},
	abstract = {While neuroevolution (evolving neural networks) has a successful track record across a variety of domains from reinforcement learning to artificial life, it is rarely applied to large, deep neural networks. A central reason is that while random mutation generally works in low dimensions, a random perturbation of thousands or millions of weights is likely to break existing functionality, providing no learning signal even if some individual weight changes were beneficial. This paper proposes a solution by introducing a family of safe mutation (SM) operators that aim within the mutation operator itself to find a degree of change that does not alter network behavior too much, but still facilitates exploration. Importantly, these SM operators do not require any additional interactions with the environment. The most effective SM variant capitalizes on the intriguing opportunity to scale the degree of mutation of each individual weight according to the sensitivity of the network's outputs to that weight, which requires computing the gradient of outputs with respect to the weights (instead of the gradient of error, as in conventional deep learning). This safe mutation through gradients (SM-G) operator dramatically increases the ability of a simple genetic algorithm-based neuroevolution method to find solutions in high-dimensional domains that require deep and/or recurrent neural networks (which tend to be particularly brittle to mutation), including domains that require processing raw pixels. By improving our ability to evolve deep neural networks, this new safer approach to mutation expands the scope of domains amenable to neuroevolution.},
	urldate = {2018-01-12},
	author = {Lehman, Joel and Chen, Jay and Clune, Jeff and Stanley, Kenneth O.},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.06563},
}

@article{Such2017,
	title = {Deep {Neuroevolution}: {Genetic} {Algorithms} {Are} a {Competitive} {Alternative} for {Training} {Deep} {Neural} {Networks} for {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1712.06567},
	abstract = {Deep artificial neural networks (DNNs) are typically trained via gradient-based learning algorithms, namely backpropagation. Evolution strategies (ES) can rival backprop-based algorithms such as Q-learning and policy gradients on challenging deep reinforcement learning (RL) problems. However, ES can be considered a gradient-based algorithm because it performs stochastic gradient descent via an operation similar to a finite-difference approximation of the gradient. That raises the question of whether non-gradient-based evolutionary algorithms can work at DNN scales. Here we demonstrate they can: we evolve the weights of a DNN with a simple, gradient-free, population-based genetic algorithm (GA) and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm. These results (1) expand our sense of the scale at which GAs can operate, (2) suggest intriguingly that in some cases following the gradient is not the best choice for optimizing performance, and (3) make immediately available the multitude of techniques that have been developed in the neuroevolution community to improve performance on RL problems. To demonstrate the latter, we show that combining DNNs with novelty search, which was designed to encourage exploration on tasks with deceptive or sparse reward functions, can solve a high-dimensional problem on which reward-maximizing algorithms (e.g. DQN, A3C, ES, and the GA) fail. Additionally, the Deep GA parallelizes better than ES, A3C, and DQN, and enables a state-of-the-art compact encoding technique that can represent million-parameter DNNs in thousands of bytes.},
	urldate = {2018-01-12},
	author = {Such, Felipe Petroski and Madhavan, Vashisht and Conti, Edoardo and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.06567},
}

@article{Lakshminarayanan2014,
	title = {Mondrian {Forests}: {Efficient} {Online} {Random} {Forests}},
	issn = {10495258},
	abstract = {Ensembles of randomized decision trees, usually referred to as random forests, are widely used for classification and regression tasks in machine learning and statistics. Random forests achieve competitive predictive performance and are computationally efficient to train and test, making them excellent candidates for real-world prediction tasks. The most popular random forest variants (such as Breiman's random forest and extremely randomized trees) operate on batches of training data. Online methods are now in greater demand. Existing online random forests, however, require more training data than their batch counterpart to achieve comparable predictive performance. In this work, we use Mondrian processes (Roy and Teh, 2009) to construct ensembles of random decision trees we call Mondrian forests. Mondrian forests can be grown in an incremental/online fashion and remarkably, the distribution of online Mondrian forests is the same as that of batch Mondrian forests. Mondrian forests achieve competitive predictive performance comparable with existing online random forests and periodically re-trained batch random forests, while being more than an order of magnitude faster, thus representing a better computation vs accuracy tradeoff.},
	author = {Lakshminarayanan, Balaji and Roy, Daniel M. and Teh, Yee Whye},
	year = {2014},
	note = {arXiv: 1406.2673
ISBN: 1406.2673},
}

@book{Walter2007,
	address = {Basel},
	title = {La correspondance entre {Henri} {Poincaré} et les physiciens, chimistes et ingénieurs},
	isbn = {978-3-7643-7136-4},
	url = {http://link.springer.com/10.1007/978-3-7643-8303-9},
	urldate = {2018-01-10},
	publisher = {Birkhäuser Basel},
	editor = {Walter, Scott and Bolmont, Étienne and Coret, André},
	year = {2007},
	doi = {10.1007/978-3-7643-8303-9},
	note = {Series Title: Publications des Archives Henri-Poincaré / Publications of the Henri Poincaré Archives},
}

@article{aiello_random_nodate,
	title = {A {Random} {Graph} {Model} for {Power} {Law} {Graphs}},
	abstract = {We propose a random graph model which is a special case of sparse random graphs with given degree sequences which satisfy a power law. This model involves only a small number of parameters, called log-size and log-log growth rate. These parameters capture some universal characteristics of massive graphs. Furthermore, from these parame-ters, various properties of the graph can be derived. For example, for certain ranges of the parameters, we will compute the expected distri-bution of the sizes of the connected components which almost surely occur with high probability. We will illustrate the consistency of our model with the behavior of some massive graphs derived from data in telecommunications. We will also discuss the threshold function, the giant component, and the evolution of random graphs in this model.},
	urldate = {2018-01-10},
	author = {Aiello, William and Chung, Fan and Lu, Linyuan},
}

@inproceedings{Chen2015,
	address = {New York, New York, USA},
	title = {{PowerLyra}},
	isbn = {978-1-4503-3238-5},
	url = {http://dl.acm.org/citation.cfm?doid=2741948.2741970},
	doi = {10.1145/2741948.2741970},
	urldate = {2018-01-10},
	booktitle = {Proceedings of the {Tenth} {European} {Conference} on {Computer} {Systems} - {EuroSys} '15},
	publisher = {ACM Press},
	author = {Chen, Rong and Shi, Jiaxin and Chen, Yanzhe and Chen, Haibo},
	year = {2015},
	pages = {1--15},
}

@article{liu_k-nearest-neighbor_2015,
	title = {The k-{Nearest}-{Neighbor} {Voronoi} {Diagram} {Revisited}},
	issn = {14320541},
	doi = {10.1007/s00453-013-9809-9},
	abstract = {© 2013, Springer Science+Business Media New York.We revisit the k-nearest-neighbor (k-NN) Voronoi diagram and present a new paradigm for its construction. We introduce the k-NN Delaunay graph, which is the graph-theoretic dual of the k-NN Voronoi diagram, and use it as a base to directly compute this diagram in R2. We implemented our paradigm in the L1 and L∞ metrics, using segment-dragging queries, resulting in the first output-sensitive, O((n+m)logn)-time algorithm to compute the k-NN Voronoi diagram of n points in the plane, where m is the structural complexity (size) of this diagram. We also show that the structural complexity of the k-NN Voronoi diagram in the L∞ (equiv. L1) metric is O(min\{k(n−k),(n−k)2\}). Efficient implementation of our paradigm in the L2 (resp. Lp, 1{\textless}p{\textless}∞) metric remains an open problem.},
	journal = {Algorithmica},
	author = {Liu, Chih Hung and Papadopoulou, Evanthia and Lee, Der Tsai},
	year = {2015},
	keywords = {Higher-order Voronoi diagrams, Segment dragging queries, Voronoi diagrams, k Neareast neighbors},
}

@article{amir_approximation_2010,
	title = {Approximation algorithms for treewidth},
	issn = {01784617},
	doi = {10.1007/s00453-008-9180-4},
	abstract = {Abstract\&nbsp;\&nbsp;This paper presents algorithms whose input is an undirected graph, and whose output is a tree decomposition of width that{\textbackslash}n  approximates the optimal, the treewidth of that graph. The algorithms differ in their computation time and their approximation guarantees. The first algorithm works{\textbackslash}n  in polynomial-time and finds a factor-O(log OPT) approximation, where OPT is the treewidth of the graph. This is the first polynomial-time algorithm that approximates the optimal by a factor that{\textbackslash}n  does not depend on n, the number of nodes in the input graph. As a result, we get an algorithm for finding pathwidth within a factor of O(log OPT⋅log n) from the optimal. We also present algorithms that approximate the treewidth of a graph by constant factors of 3.66, 4, and{\textbackslash}n  4.5, respectively and take time that is exponential in the treewidth. These are more efficient than previously known algorithms{\textbackslash}n  by an exponential factor, and are of practical interest. Finding triangulations of minimum treewidth for graphs is central{\textbackslash}n  to many problems in computer science. Real-world problems in artificial intelligence, VLSI design and databases are efficiently{\textbackslash}n  solvable if we have an efficient approximation algorithm for them. Many of those applications rely on weighted graphs. We{\textbackslash}n  extend our results to weighted graphs and weighted treewidth, showing similar approximation results for this more general notion. We report on experimental results confirming the effectiveness{\textbackslash}n  of our algorithms for large graphs associated with real-world problems.},
	journal = {Algorithmica (New York)},
	author = {Amir, Eyal},
	year = {2010},
	note = {ISBN: 0045300891804},
	keywords = {Network flow, Tree decomposition, Treewidth, Triangulation},
}

@inproceedings{bodlaender_ockn_2013,
	title = {An {O}(ckn) 5-approximation algorithm for treewidth},
	isbn = {978-0-7695-5135-7},
	doi = {10.1109/FOCS.2013.60},
	abstract = {We give an algorithm that for an input n-vertex graph G and integer k{\textgreater}0, in time 2{\textasciicircum}[O(k)]n either outputs that the treewidth of G is larger than k, or gives a tree decomposition of G of width at most 5k+4. This is the first algorithm providing a constant factor approximation for treewidth which runs in time single-exponential in k and linear in n. Treewidth based computations are subroutines of numerous algorithms. Our algorithm can be used to speed up many such algorithms to work in time which is single-exponential in the treewidth and linear in the input size.},
	booktitle = {Proceedings - {Annual} {IEEE} {Symposium} on {Foundations} of {Computer} {Science}, {FOCS}},
	author = {Bodlaender, Hans L. and Drange, Pål Grønås and Dregi, Markus S. and Fomin, Fedor V. and Lokshtanov, Daniel and Pilipczuk, Michaø},
	year = {2013},
	note = {arXiv: 1304.6321
ISSN: 02725428},
	keywords = {Approximation, Fixed-parameter tractability, Treewidth},
}

@article{pound_deep_2017,
	title = {Deep machine learning provides state-of-the-art performance in image-based plant phenotyping},
	issn = {2047217X},
	doi = {10.1093/gigascience/gix083},
	abstract = {Deep learning is an emerging field that promises unparalleled results on many data analysis problems. We show the success offered by such techniques when applied to the challenging problem of image-based plant phenotyping, and demonstrate state-of-the-art results for root and shoot feature identification and localisation. We predict a paradigm shift in image-based phenotyping thanks to deep learning approaches.},
	journal = {GigaScience},
	author = {Pound, Michael P. and Atkinson, Jonathan A. and Townsend, Alexandra J. and Wilson, Michael H. and Griffiths, Marcus and Jackson, Aaron S. and Bulat, Adrian and Tzimiropoulos, Georgios and Wells, Darren M. and Murchie, Erik H. and Pridmore, Tony P. and French, Andrew P.},
	year = {2017},
	pmid = {29020747},
	note = {ISBN: 2047-217X},
	keywords = {Deep learning, Image analysis, Phenotyping, QTL, Root, Shoot},
}

@article{dhifli_protnn:_2016,
	title = {{ProtNN}: fast and accurate protein {3D}-structure classification in structural and topological space},
	volume = {9},
	issn = {1756-0381},
	url = {http://biodatamining.biomedcentral.com/articles/10.1186/s13040-016-0108-2},
	doi = {10.1186/s13040-016-0108-2},
	abstract = {Studying the functions and structures of proteins is important for understanding the molecular mechanisms of life. The number of publicly available protein structures has increasingly become extremely large. Still, the classification of a protein structure remains a difficult, costly, and time consuming task. The difficulties are often due to the essential role of spatial and topological structures in the classification of protein structures. We propose ProtNN, a novel classification approach for protein 3D-structures. Given an unannotated query protein structure and a set of annotated proteins, ProtNN assigns to the query protein the class with the highest number of votes across the k nearest neighbor reference proteins, where k is a user-defined parameter. The search of the nearest neighbor annotated structures is based on a protein-graph representation model and pairwise similarities between vector embedding of the query and the reference protein structures in structural and topological spaces. We demonstrate through an extensive experimental evaluation that ProtNN is able to accurately classify several datasets in an extremely fast runtime compared to state-of-the-art approaches. We further show that ProtNN is able to scale up to a whole PDB dataset in a single-process mode with no parallelization, with a gain of thousands order of magnitude in runtime compared to state-of-the-art approaches.},
	number = {1},
	urldate = {2018-01-08},
	journal = {BioData Mining},
	author = {Dhifli, Wajdi and Diallo, Abdoulaye Baniré},
	month = dec,
	year = {2016},
	note = {Publisher: BioMed Central},
	keywords = {Algorithms, Bioinformatics, Computational Biology/Bioinformatics, Computer Appl. in Life Sciences, Data Mining and Knowledge Discovery},
	pages = {30},
}

@article{kneis_practical_2009,
	title = {A {Practical} {Approach} to {Courcelle}'s {Theorem}},
	issn = {15710661},
	doi = {10.1016/j.entcs.2009.08.028},
	abstract = {In 1990, Courcelle showed that every problem definable in Monadic Second-Order Logic (MSO) can be solved in linear time on graphs with bounded treewidth. This powerful and important theorem is amongst others the foundation for several fixed parameter tractability results. The standard proof of Courcelle's Theorem is to construct a finite bottom-up tree automaton that recognizes a tree decomposition of the graph. However, the size of the automaton, which is usually hidden as a constant in the Landau-notation, can become extremely large and cannot be bounded by any elemental function unless P = NP (Frick and Grohe, 2004). This makes the problem hard to tackle in practice, because it is just impossible to construct the tree automata. Aiming for a practical implementation, we give a proof of Courcelle's Theorem restricted to Extended MSO formulas of the form opt U ⊆ V φ (U), where φ is a first-order formula with vocabulary (adj, U) and opt ∈ \{min, max\}. Note that many optimization problems such as Minimum Vertex Cover, Minimum Dominating Set, and Maximum Independent Set can be expressed by such formulas. The proof uses a new technique based on using Hintikka game properties in dynamic programming. To demonstrate the usability of this approach, we present an implementation that solves such formulas on graphs with small pathwidth. It turns out that the large constants can be circumvented on graphs that are not too complex. © 2009 Elsevier B.V. All rights reserved.},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Kneis, Joachim and Langer, Alexander},
	year = {2009},
	keywords = {Courcelle's Theorem, Exact Algorithms, Model-Checking, Monadic Second-Order Logic, Parameterized Algorithms, Treewidth},
}

@inproceedings{grumbach_distributed_2010,
	title = {Distributed tree decomposition of graphs and applications to verification},
	isbn = {978-1-4244-6534-7},
	doi = {10.1109/IPDPSW.2010.5470828},
	abstract = {The tree decomposition of graphs is a fundamental algorithmic tool. It has been shown that difficult problems, such as some NP-complete ones, can be solved efficiently over classes of graphs of bounded tree-width. We consider in this paper the distributed construction of the tree decompositions of network topology graphs. We propose algorithms to distributively construct the tree-decomposition of respectively (i) planar networks of bounded diameter and (ii) networks of bounded degree and bounded tree-length. Both algorithms are very efficient, requiring only a constant number of messages sent over each link. We then use these algorithms to distributively verify properties of graphs expressible in Monadic Second Order Logic, MSO.},
	booktitle = {Proceedings of the 2010 {IEEE} {International} {Symposium} on {Parallel} and {Distributed} {Processing}, {Workshops} and {Phd} {Forum}, {IPDPSW} 2010},
	author = {Grumbach, Stéphane and Wu, Zhilin},
	year = {2010},
}

@article{garcia-garcia_pointnet:_2016,
	title = {{PointNet}: {A} {3D} {Convolutional} {Neural} {Network} for real-time object class recognition},
	doi = {10.1109/IJCNN.2016.7727386},
	abstract = {During the last few years, Convolutional Neural Networks are slowly but surely becoming the default method solve many computer vision related problems. This is mainly due to the continuous success that they have achieved when applied to certain tasks such as image, speech, or object recognition. Despite all the efforts, object class recognition methods based on deep learning techniques still have room for improvement. Most of the current approaches do not fully exploit 3D information, which has been proven to effectively improve the performance of other traditional object recognition methods. In this work, we propose PointNet, a new approach inspired by VoxNet and 3D ShapeNets, as an improvement over the existing methods by using density occupancy grids representations for the input data, and integrating them into a supervised Convolutional Neural Network architecture. An extensive experimentation was carried out, using ModelNet - a large-scale 3D CAD models dataset - to train and test the system, to prove that our approach is on par with state-of-the-art methods in terms of accuracy while being able to perform recognition under real-time constraints.},
	journal = {2016 International Joint Conference on Neural Networks (IJCNN)},
	author = {Garcia-Garcia, A and Gomez-Donoso, F and Garcia-Rodriguez, J and Orts-Escolano, S and Cazorla, M and Azorin-Lopez, J},
	year = {2016},
	note = {ISBN: VO -},
	keywords = {3D ShapeNets, 3D convolutional neural network, CAD, Computer architecture, Machine learning, ModelNet, Neural networks, Object recognition, PointNet, Solid modeling, Three-dimensional displays, Two dimensional displays, VoxNet, computer vision, data structures, deep learning techniques, density occupancy grids representations, large-scale 3D CAD model dataset, learning (artificial intelligence), neural net architecture, object recognition, real-time object class recognition, supervised convolutional neural network architectu},
}

@article{Bohler2015,
	title = {On the complexity of higher order abstract {Voronoi} diagrams},
	issn = {09257721},
	doi = {10.1016/j.comgeo.2015.04.008},
	abstract = {Voronoi diagrams (AVDs) are based on bisecting curves enjoying simple combinatorial properties, rather than on the geometric notions of sites and circles. They serve as a unifying concept. Once the bisector system of any concrete type of Voronoi diagram is shown to fulfill the AVD properties, structural results and efficient algorithms become available without further effort. In a concrete order-k Voronoi diagram, all points are placed into the same region that have the same k nearest neighbors among the given sites. This paper is the first to study abstract Voronoi diagrams of arbitrary order k. We prove that their complexity in the plane is upper bounded by 2k(n - k). So far, an O(k(n - k)) bound has been shown only for point sites in the Euclidean and $^{\textrm{Lp}}$ planes, and, recently, for line segments, in the $^{\textrm{Lp}}$ metric. These proofs made extensive use of the geometry of the sites. Our result on AVDs implies a 2k(n - k) upper bound for a wide range of cases for which only trivial upper complexity bounds were previously known, and a slightly sharper bound for the known cases. Also, our proof shows that the reasons for this bound are combinatorial properties of certain permutation sequences.},
	journal = {Computational Geometry: Theory and Applications},
	author = {Bohler, Cecilia and Cheilaris, Panagiotis and Klein, Rolf and Liu, Chih Hung and Papadopoulou, Evanthia and Zavershynskyi, Maksym},
	year = {2015},
	note = {ISBN: 9783642392054},
	keywords = {Abstract Voronoi diagrams, Computational geometry, Distance problems, Higher order Voronoi diagrams, Voronoi diagrams},
}

@article{Klein2009,
	title = {Abstract {Voronoi} diagrams revisited},
	issn = {09257721},
	doi = {10.1016/j.comgeo.2009.03.002},
	abstract = {Abstract Voronoi diagrams [R. Klein, Concrete and Abstract Voronoi Diagrams, Lecture Notes in Computer Science, vol. 400, Springer-Verlag, 1987] were designed as a unifying concept that should include as many concrete types of diagrams as possible. To ensure that abstract Voronoi diagrams, built from given sets of bisecting curves, are finite graphs, it was required that any two bisecting curves intersect only finitely often; this axiom was a cornerstone of the theory. In [A.G. Corbalan, M. Mazon, T. Recio, Geometry of bisectors for strictly convex distance functions, International Journal of Computational Geometry and Applications 6 (1) (1996) 45-58], Corbalan et al. gave an example of a smooth convex distance function whose bisectors have infinitely many intersections, so that it was not covered by the existing AVD theory. In this paper we give a new axiomatic foundation of abstract Voronoi diagrams that works without the finite intersection property. © 2009 Elsevier B.V. All rights reserved.},
	journal = {Computational Geometry: Theory and Applications},
	author = {Klein, Rolf and Langetepe, Elmar and Nilforoushan, Zahra},
	year = {2009},
	note = {ISBN: 0925-7721},
	keywords = {Abstract Voronoi diagrams, Computational geometry, Distance problems, Voronoi diagrams},
}

@article{Zeng2009,
	title = {Comparing stars: {On} {Approximating} {Graph} {Edit} {Distance}},
	issn = {21508097},
	doi = {10.14778/1687627.1687631},
	abstract = {Graph data have become ubiquitous and manipulating them based on similarity is essential for many applications. Graph edit distance is one of the most widely accepted measures to determine similarities between graphs and has extensive applications in the fields of pattern recognition, computer vi- sion etc. Unfortunately, the problem of graph edit distance computation is NP-Hard in general. Accordingly, in this pa- per we introduce three novel methods to compute the upper and lower bounds for the edit distance between two graphs in polynomial time. Applying these methods, two algorithms AppFull and AppSub are introduced to perform different kinds of graph search on graph databases. Comprehensive experimental studies are conducted on both real and syn- thetic datasets to examine various aspects of the methods for bounding graph edit distance. Result shows that these methods achieve good scalability in terms of both the number of graphs and the size of graphs. The effectiveness of these algorithms also confirms the usefulness of using our bounds in filtering and searching of graphs.},
	journal = {Proceedings of the VLDB Endowment},
	author = {Zeng, Zhiping and Tung, Anthony K. H. and Wang, Jianyong and Feng, Jianhua and Zhou, Lizhu},
	year = {2009},
	note = {ISBN: 0000000000000},
}

@article{Cheilaris2016,
	title = {A {Randomized} {Incremental} {Algorithm} for the {Hausdorff} {Voronoi} {Diagram} of {Non}-crossing {Clusters}},
	issn = {14320541},
	doi = {10.1007/s00453-016-0118-y},
	abstract = {In the Hausdorff Voronoi diagram of a set of clusters of points in the plane, the distance between a point t and a cluster P is the maximum Euclidean distance between t and a point in P. This diagram has direct applications in VLSI design. We consider so-called "non-crossing" clusters. The complexity of the Hausdorff diagram of m such clusters is linear in the total number n of points in the convex hulls of all clusters. We present randomized incremental constructions for computing efficiently the diagram, improving considerably previous results. Our best complexity algorithm runs in expected time O((n + m(log log(n)){\textasciicircum}2)log{\textasciicircum}2(n)) and worst-case space O(n). We also provide a more practical algorithm whose expected running time is O((n + m log(n))log{\textasciicircum}2(n)) and expected space complexity is O(n). To achieve these bounds, we augment the randomized incremental paradigm for the construction of Voronoi diagrams with the ability to efficiently handle non-standard characteristics of generalized Voronoi diagrams, such as sites of non-constant complexity, sites that are not enclosed in their Voronoi regions, and empty Voronoi regions.},
	journal = {Algorithmica},
	author = {Cheilaris, Panagiotis and Khramtcova, Elena and Langerman, Stefan and Papadopoulou, Evanthia},
	year = {2016},
	note = {arXiv: 1306.5838
ISBN: 9783642544224},
	keywords = {Hausdorff distance, Hierarchical data structure, Point location, Randomized incremental construction, Voronoi diagram},
}

@article{Schuster,
	title = {The {Largest} {Empty} {Circle} {Problem}},
	abstract = {The largest empty circle (LEC) problem is defined on a set P and consists of finding the largest circle that contains no points in P and is also centered inside the convex hull of P . The LEC is always centered at either a vertex on the Voronoi diagram for P or on an intersection between a Voronoi edge and the convex hull of P . Thus, finding the LEC consists of constructing a Voronoi diagram and convex hull for P , then searching the Voronoi vertices and intersections between Voronoi edges and convex hull edges to see where the LEC lies. This paper presents a simple O(n[h+ log n]) solution to the largest empty circle problem. Though previous work on this problem has found O(n log n) solutions, we find that for data sets which are some-what normally distributed, h is small and our simple algorithm performs well.},
	urldate = {2018-01-02},
	author = {Schuster, Megan},
}

@inproceedings{toss_parallel_2014,
	title = {Parallel shortest path algorithm for voronoi diagrams with generalized distance functions},
	isbn = {978-1-4799-4260-2},
	doi = {10.1109/SIBGRAPI.2014.1},
	abstract = {© 2014 IEEE.Voronoi diagrams are fundamental data structures in computational geometry with applications on different areas. Recent soft object simulation algorithms for real time physics engines require the computation of Voronoi diagrams over 3D images with non-Euclidean distances. In this case, the computation must be performed over a graph, where the edges encode the required distance information. But excessive computation time of Voronoi diagrams prevent more sophisticated deformations that require interactive topological changes, such as cutting or stitching used in virtual surgery simulations. The major bottleneck in the Voronoi computation in this case is a shortest-path algorithm that must be computed multiple times during the deformation. In this paper, we tackle this problem by proposing a GPU algorithm of the shortest-path algorithm from multiple sources using generalized distance functions. Our algorithm was designed to leverage the grid-based nature of the underlying graph used in the simulation. Experimental results report speed-ups up to 65x over a current reference sequential method.},
	booktitle = {Brazilian {Symposium} of {Computer} {Graphic} and {Image} {Processing}},
	author = {Toss, Julio and Comba, João and Raffin, Bruno},
	year = {2014},
	note = {ISSN: 15301834},
}

@article{bodlaender_deterministic_2015,
	title = {Deterministic single exponential time algorithms for connectivity problems parameterized by treewidth},
	volume = {243},
	issn = {0890-5401},
	url = {http://www.sciencedirect.com/science/article/pii/S0890540114001606},
	doi = {10.1016/J.IC.2014.12.008},
	abstract = {It is well known that many local graph problems, like Vertex Cover and Dominating Set, can be solved in time 2O(tw){\textbar}V{\textbar}O(1) for graphs G=(V,E) with a given tree decomposition of width tw. However, for nonlocal problems, like the fundamental class of connectivity problems, for a long time we did not know how to do this faster than twO(tw){\textbar}V{\textbar}O(1). Recently, Cygan et al. (FOCS 2011) presented Monte Carlo algorithms for a wide range of connectivity problems running in time ctw{\textbar}V{\textbar}O(1) for a small constant c, e.g., for Hamiltonian Cycle and Steiner Tree. Naturally, this raises the question whether randomization is necessary to achieve this runtime; furthermore, it is desirable to also solve counting and weighted versions (the latter without incurring a pseudo-polynomial cost in the runtime in terms of the weights). We present two new approaches rooted in linear algebra, based on matrix rank and determinants, which provide deterministic ctw{\textbar}V{\textbar}O(1) time algorithms, also for weighted and counting versions. For example, in this time we can solve Traveling Salesman  or count the number of Hamiltonian cycles. The rank based ideas provide a rather general approach for speeding up even straightforward dynamic programming formulations by identifying “small” sets of representative partial solutions; we focus on the case of expressing connectivity via sets of partitions, but the essential ideas should have further applications. The determinant-based approach uses the Matrix Tree Theorem for deriving closed formulas for counting versions of connectivity problems; we show how to evaluate those formulas via dynamic programming.},
	urldate = {2017-12-19},
	journal = {Information and Computation},
	author = {Bodlaender, Hans L. and Cygan, Marek and Kratsch, Stefan and Nederlof, Jesper},
	month = aug,
	year = {2015},
	note = {Publisher: Academic Press},
	pages = {86--111},
}

@book{Berg2008,
	title = {Computational geometry : algorithms and applications},
	isbn = {978-3-540-77974-2},
	abstract = {3rd ed. This well-accepted introduction to computational geometry is a textbook for high-level undergraduate and low-level graduate courses. The focus is on algorithms and hence the book is well suited for students in computer science and engineering. Motivation is provided from the application areas: all solutions and techniques from computational geometry are related to particular applications in robotics, graphics, CAD/CAM, and geographic information systems. For students this motivation will be especially welcome. Modern insights in computational geometry are used to provide solutions that are both efficient and easy to understand and implement. All the basic techniques and topics from computational geometry, as well as several more advanced topics, are covered. The book is largely self-contained and can be used for self-study by anyone with a basic background in algorithms. In this third edition, besides revisions to the second edition, new sections discussing Voronoi diagrams of line segments, farthest-point Voronoi diagrams, and realistic input models have been added. Computational Geometry: Introduction -- Line Segment Intersection: Thematic Map Overlay -- Polygon Triangulation: Guarding an Art Gallery -- Linear Programming: Manufacturing with Molds -- Orthogonal Range Searching: Querying a Database -- Point Location: Knowing Where You Are -- Voronoi Diagrams: The Post Office Problem -- Arrangements and Duality: Supersampling in Ray Tracing -- Delaunay Triangulations: Height Interpolation -- More Geometric Data Structures: Windowing -- Convex Hulls: Mixing Things -- Binary Space Partitions: The Painter's Algorithm -- Robot Motion Planning: Getting Where You Want to Be -- Quadtrees: Non-Uniform Mesh Generation -- Visibility Graphs: Finding the Shortest Route -- Simplex Range Searching: Windowing Revisited -- Bibliography -- Index.},
	urldate = {2017-12-18},
	publisher = {Springer},
	author = {Berg, Mark de.},
	year = {2008},
}

@article{bodlaender_treewidth_2010,
	title = {Treewidth computations {I}. {Upper} bounds},
	issn = {08905401},
	doi = {10.1016/j.ic.2009.03.008},
	abstract = {For more and more applications, it is important to be able to compute the treewidth of a given graph and to find tree decompositions of small width reasonably fast. This paper gives an overview of several upper bound heuristics that have been proposed and tested for the problem of determining the treewidth of a graph and finding tree decompositions. Each of the heuristics produces tree decompositions whose width may be larger than the optimal width. However, experiments show that in many cases, the heuristics give tree decompositions whose width is close to the exact treewidth of the input graphs. © 2009 Elsevier Inc. All rights reserved.},
	journal = {Information and Computation},
	author = {Bodlaender, Hans L. and Koster, Arie M.C.A.},
	year = {2010},
	keywords = {Approximation algorithms, Graph algorithms, Heuristics, Treewidth, Upper bounds},
}

@inproceedings{greco_tree_2008,
	title = {Tree projections: {Hypergraph} games and minimality},
	isbn = {3-540-70574-0},
	doi = {10.1007/978-3-540-70575-8_60},
	abstract = {A hypergraph-game characterization is provided for hypergraph tree projections (TPs) and, hence, for the special cases of generalized and fractional hypertree decompositions, where such a characterization was missing and asked for. In this game, as for the Robber and Cops game characterizing tree decompositions, the existence of winning strategies implies the existence of monotone ones, which are yet somehow preferable, because they correspond to minimal tree projections. In fact, it is shown that minimal TPs enjoy a number of nice properties, such as the same kind of connection property as (minimal) tree decompositions of graphs. Finally, it is shown that this property is somehow tight, by giving a negative answer to an open question about a slightly stronger notion of connection property, defined to speed-up the computation of hypertree decompositions. © 2008 Springer-Verlag.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Greco, Gianluigi and Scarcello, Francesco},
	year = {2008},
	note = {ISSN: 03029743},
}

@article{wang_identification_2014,
	title = {Identification of human disease genes from interactome network using graphlet interaction},
	issn = {19326203},
	doi = {10.1371/journal.pone.0086142},
	abstract = {Identifying genes related to human diseases, such as cancer and cardiovascular disease, etc., is an important task in biomedical research because of its applications in disease diagnosis and treatment. Interactome networks, especially protein-protein interaction networks, had been used to disease genes identification based on the hypothesis that strong candidate genes tend to closely relate to each other in some kinds of measure on the network. We proposed a new measure to analyze the relationship between network nodes which was called graphlet interaction. The graphlet interaction contained 28 different isomers. The results showed that the numbers of the graphlet interaction isomers between disease genes in interactome networks were significantly larger than random picked genes, while graphlet signatures were not. Then, we designed a new type of score, based on the network properties, to identify disease genes using graphlet interaction. The genes with higher scores were more likely to be disease genes, and all candidate genes were ranked according to their scores. Then the approach was evaluated by leave-one-out cross-validation. The precision of the current approach achieved 90\% at about 10\% recall, which was apparently higher than the previous three predominant algorithms, random walk, Endeavour and neighborhood based method. Finally, the approach was applied to predict new disease genes related to 4 common diseases, most of which were identified by other independent experimental researches. In conclusion, we demonstrate that the graphlet interaction is an effective tool to analyze the network properties of disease genes, and the scores calculated by graphlet interaction is more precise in identifying disease genes.},
	journal = {PLoS ONE},
	author = {Wang, Xiao Dong and Huang, Jia Liang and Yang, Lun and Wei, Dong Qing and Qi, Ying Xin and Jiang, Zong Lai},
	year = {2014},
	pmid = {24465923},
	note = {ISBN: 1932-6203 (Electronic){\textbackslash}r1932-6203 (Linking)},
}

@inproceedings{kondor_graphlet_2009,
	title = {The graphlet spectrum},
	isbn = {978-1-60558-516-1},
	doi = {10.1145/1553374.1553443},
	abstract = {Current graph kernels suffer from two limita-tions: graph kernels based on counting par-ticular types of subgraphs ignore the relative position of these subgraphs to each other, while graph kernels based on algebraic meth-ods are limited to graphs without node la-bels. In this paper we present the graphlet spectrum, a system of graph invariants de-rived by means of group representation the-ory that capture information about the num-ber as well as the position of labeled sub-graphs in a given graph. In our experimen-tal evaluation the graphlet spectrum outper-forms state-of-the-art graph kernels.},
	booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning} - {ICML} '09},
	author = {Kondor, Risi and Shervashidze, Nino and Borgwardt, Karsten M.},
	year = {2009},
}

@article{soufiani_graphlet_2012,
	title = {Graphlet decomposition of a weighted network},
	issn = {15337928},
	abstract = {We introduce the graphlet decomposition of a weighted network, which encodes a notion of social information based on social structure. We develop a scalable inference algorithm, which combines EM with Bron-Kerbosch in a novel fashion, for estimating the parameters of the model underlying graphlets using one network sample. We explore some theoretical properties of the graphlet decomposition, including computational complexity, redundancy and expected accuracy. We demonstrate graphlets on synthetic and real data. We analyze messaging patterns on Facebook and criminal associations in the 19th century.},
	journal = {Aistats},
	author = {Soufiani, Hossein Azari and Airoldi, Em},
	year = {2012},
	note = {arXiv: 1203.2821v1},
	keywords = {2012, 22, address correspondence to em, airoldi, aistats, bron-kerbosch, conference proceedings, deconvolution, edu, expectation-maximization, fas, harvard, in journal of machine, learning research, massive data, parallel computation, social information, sparsity, statistical network analysis, this paper will appear, vol, workshop},
}

@article{Rossi2017,
	title = {Estimation of {Graphlet} {Statistics}},
	url = {https://arxiv.org/abs/1701.01772},
	urldate = {2017-12-17},
	author = {Rossi, Ryan A. and Zhou, Rong and Ahmed, Nesreen K.},
	month = jan,
	year = {2017},
	note = {arXiv: 1701.01772},
}

@article{ahmed_exact_2016,
	title = {Exact and {Estimation} of {Local} {Edge}-centric {Graphlet} {Counts}},
	issn = {1938-7228},
	url = {http://proceedings.mlr.press/v53/ahmed16.html},
	urldate = {2017-12-17},
	author = {Ahmed, Nesreen K. and Willke, Theodore L. and Rossi, Ryan A.},
	month = dec,
	year = {2016},
	pages = {1--17},
}

@article{Ahmed2015,
	title = {Graphlet {Decomposition}: {Framework}, {Algorithms}, and {Applications}},
	url = {https://arxiv.org/abs/1506.04322},
	urldate = {2017-12-17},
	author = {Ahmed, Nesreen K. and Neville, Jennifer and Rossi, Ryan A. and Duffield, Nick and Willke, Theodore L.},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.04322},
}

@article{graaff_dynamic_2015,
	title = {Dynamic programming on {Nice} {Tree} {Decompositions}},
	url = {https://dspace.library.uu.nl/handle/1874/309652},
	abstract = {Universiteit Utrecht},
	urldate = {2017-12-17},
	author = {Graaff, L.W. van der},
	month = mar,
	year = {2015},
	keywords = {Computing Science, Steiner tree problem, dynamic programming, treewidth},
}

@article{beer_vertex_2011,
	title = {On vertex, edge, and vertex-edge random graphs},
	issn = {10778926},
	abstract = {We consider three classes of random graphs: edge random graphs, vertex random graphs, and vertex-edge random graphs. Edge random graphs are Erdos-Renyi random graphs, vertex random graphs are generalizations of geometric random graphs, and vertex-edge random graphs generalize both. The names of these three types of random graphs describe where the randomness in the models lies: in the edges, in the vertices, or in both. We show that vertex-edge random graphs, ostensibly the most general of the three models, can be approximated arbitrarily closely by vertex random graphs, but that the two categories are distinct.},
	journal = {Electronic Journal of Combinatorics},
	author = {Beer, Elizabeth and Janson, Svante and Fill, James Allen and Scheinerman, Edward R.},
	year = {2011},
	note = {arXiv: 0812.1410
ISBN: 9781617823152},
}

@article{bodlaender_combinatorial_2008,
	title = {Combinatorial optimization on graphs of bounded treewidth},
	issn = {00104620},
	doi = {10.1093/comjnl/bxm037},
	abstract = {There are many graph problems that can be solved in linear or polynomial time with a dynamic programming algorithm when the input graph has bounded treewidth. For combinatorial optimization problems, this is a useful approach for obtaining fixed-parameter tractable algorithms. Starting from trees and series-parallel graphs, we introduce the concepts of treewidth and tree decompositions, and illustrate the technique with the Weighted Independent Set problem as an example. The paper surveys some of the latest developments, putting an emphasis on applicability, on algorithms that exploit tree decompositions, and on algorithms that determine or approximate treewidth and find tree decompositions with optimal or close to optimal treewidth. Directions for further research and suggestions for further reading are also given.},
	journal = {Computer Journal},
	author = {Bodlaender, Hans L. and Koster, Arie M.C.A.},
	year = {2008},
	keywords = {Bounded treewidth, Paramaterized algorithms},
}

@article{baumgardner_solving_2009,
	title = {Solving a {Hamiltonian} {Path} {Problem} with a bacterial computer},
	issn = {1754-1611},
	doi = {10.1186/1754-1611-3-11},
	abstract = {BACKGROUND: The Hamiltonian Path Problem asks whether there is a route in a directed graph from a beginning node to an ending node, visiting each node exactly once. The Hamiltonian Path Problem is NP complete, achieving surprising computational complexity with modest increases in size. This challenge has inspired researchers to broaden the definition of a computer. DNA computers have been developed that solve NP complete problems. Bacterial computers can be programmed by constructing genetic circuits to execute an algorithm that is responsive to the environment and whose result can be observed. Each bacterium can examine a solution to a mathematical problem and billions of them can explore billions of possible solutions. Bacterial computers can be automated, made responsive to selection, and reproduce themselves so that more processing capacity is applied to problems over time.{\textbackslash}n{\textbackslash}nRESULTS: We programmed bacteria with a genetic circuit that enables them to evaluate all possible paths in a directed graph in order to find a Hamiltonian path. We encoded a three node directed graph as DNA segments that were autonomously shuffled randomly inside bacteria by a Hin/hixC recombination system we previously adapted from Salmonella typhimurium for use in Escherichia coli. We represented nodes in the graph as linked halves of two different genes encoding red or green fluorescent proteins. Bacterial populations displayed phenotypes that reflected random ordering of edges in the graph. Individual bacterial clones that found a Hamiltonian path reported their success by fluorescing both red and green, resulting in yellow colonies. We used DNA sequencing to verify that the yellow phenotype resulted from genotypes that represented Hamiltonian path solutions, demonstrating that our bacterial computer functioned as expected.{\textbackslash}n{\textbackslash}nCONCLUSION: We successfully designed, constructed, and tested a bacterial computer capable of finding a Hamiltonian path in a three node directed graph. This proof-of-concept experiment demonstrates that bacterial computing is a new way to address NP-complete problems using the inherent advantages of genetic systems. The results of our experiments also validate synthetic biology as a valuable approach to biological engineering. We designed and constructed basic parts, devices, and systems using synthetic biology principles of standardization and abstraction.},
	journal = {Journal of Biological Engineering},
	author = {Baumgardner, Jordan and Acker, Karen and Adefuye, Oyinade and Crowley, Samuel and DeLoache, Will and Dickson, James O and Heard, Lane and Martens, Andrew T and Morton, Nickolaus and Ritter, Michelle and Shoecraft, Amber and Treece, Jessica and Unzicker, Matthew and Valencia, Amanda and Waters, Mike and Campbell, A Malcolm and Heyer, Laurie J and Poet, Jeffrey L and Eckdahl, Todd T},
	year = {2009},
	pmid = {19630940},
	note = {ISBN: 10.1186/1754-1611-3-11},
}

@article{Xing2016,
	title = {A {Self}-{Organizing} {Incremental} {Neural} {Network} based on local distribution learning},
	issn = {18792782},
	doi = {10.1016/j.neunet.2016.08.011},
	abstract = {In this paper, we propose an unsupervised incremental learning neural network based on local distribution learning, which is called Local Distribution Self-Organizing Incremental Neural Network (LD-SOINN). The LD-SOINN combines the advantages of incremental learning and matrix learning. It can automatically discover suitable nodes to fit the learning data in an incremental way without a priori knowledge such as the structure of the network. The nodes of the network store rich local information regarding the learning data. The adaptive vigilance parameter guarantees that LD-SOINN is able to add new nodes for new knowledge automatically and the number of nodes will not grow unlimitedly. While the learning process continues, nodes that are close to each other and have similar principal components are merged to obtain a concise local representation, which we call a relaxation data representation. A denoising process based on density is designed to reduce the influence of noise. Experiments show that the LD-SOINN performs well on both artificial and real-word data.},
	journal = {Neural Networks},
	author = {Xing, Youlu and Shi, Xiaofeng and Shen, Furao and Zhou, Ke and Zhao, Jinxi},
	year = {2016},
	keywords = {Incremental learning, Matrix learning, Relaxation data representation, Self-Organizing Incremental Neural Network (SOINN)},
}

@article{Trujillo2016,
	title = {Phase-shifting by means of an electronically tunable lens: quantitative phase imaging of biological specimens with digital holographic microscopy},
	issn = {0146-9592},
	doi = {10.1364/OL.41.001416},
	abstract = {The use of an electronically tunable lens (ETL) to produce controlled phase shifts in interferometric arrangements is shown. The performance of the ETL as a phase-shifting device is experimentally validated in phase-shifting digital holographic microscopy. Quantitative phase maps of a section of the thorax of a Drosophila melanogaster fly and of human red blood cells have been obtained using our proposal. The experimental results validate the possibility of using the ETL as a reliable phase-shifter device.},
	journal = {Optics Letters},
	author = {Trujillo, Carlos and Doblas, Ana and Saavedra, Genaro and Martínez-Corral, Manuel and García-Sucerquia, Jorge},
	year = {2016},
	keywords = {Digital holography, Phase retrieval, Phase shift, Wave propagation},
}

@article{Comaniciu2002,
	title = {Mean {Shift} : {A} {Robust} {Approach} toward {Feature} {Space} {Analysis}},
	volume = {24},
	issn = {01628828},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1000236%5Cnhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1000236},
	doi = {10.1109/34.1000236},
	abstract = {A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance},
	number = {5},
	journal = {Analysis and Machine Intelligence,},
	author = {Comaniciu, D and Meer, P},
	year = {2002},
	note = {ISBN: 9781424467129},
	keywords = {clustering, feature space, image segmentation, image smoothing, low-level, mean shift},
	pages = {1--37},
}

@article{Aljundi2017,
	title = {Memory {Aware} {Synapses}: {Learning} what (not) to forget},
	url = {http://arxiv.org/abs/1711.09601},
	abstract = {Humans can learn in a continuous manner. Old rarely utilized knowledge can be overwritten by new incoming information while important, frequently used knowledge is prevented from being erased. In artificial learning systems, lifelong learning so far has focused mainly on accumulating knowledge over tasks and overcoming catastrophic forgetting. In this paper, we argue that, given the limited model capacity and the unlimited new information to be learned, knowledge has to be preserved or erased selectively. Inspired by neuroplasticity, we propose an online method to compute the importance of the parameters of a neural network, based on the data that the network is actively applied to, in an unsupervised manner. After learning a task, whenever a sample is fed to the network, we accumulate an importance measure for each parameter of the network, based on how sensitive the predicted output is to a change in this parameter. When learning a new task, changes to important parameters are penalized. We show that a local version of our method is a direct application of Hebb's rule in identifying the important connections between neurons. We test our method on a sequence of object recognition tasks and on the challenging problem of learning an embedding in a continuous manner. We show state of the art performance and the ability to adapt the importance of the parameters towards what the network needs (not) to forget, which may be different for different test conditions.},
	urldate = {2017-12-13},
	author = {Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.09601},
}

@article{johnson_finding_1975,
	title = {Finding {All} the {Elementary} {Circuits} of a {Directed} {Graph}},
	volume = {4},
	issn = {0097-5397},
	url = {http://epubs.siam.org/doi/10.1137/0204007},
	doi = {10.1137/0204007},
	abstract = {An algorithm is presented which finds all the elementary circuits of a directed graph in time bounded by \$O((n + e)(c + 1))\$ and space bounded by \$O(n + e)\$, where there are n vertices, e edges and c elementary circuits in the graph. The algorithm resembles algorithms by Tiernan and Tarjan, but is faster because it considers each edge at most twice between any one circuit and the next in the output sequence.},
	number = {1},
	urldate = {2017-12-07},
	journal = {SIAM Journal on Computing},
	author = {Johnson, Donald B.},
	month = mar,
	year = {1975},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {algorithm, circuit, cycle, digraph, enumeration, graph},
	pages = {77--84},
}

@book{Diestel2017,
	title = {Graph {Theory}},
	volume = {173},
	isbn = {978-3-662-53621-6},
	url = {http://link.springer.com/10.1007/978-3-662-53622-3},
	abstract = {Almost two decades have passed since the appearance of those graph the- ory texts that still set the agenda for most introductory courses taught today. The canon created by those books has helped to identify some main fields of study and research, and will doubtless continue to influence the development of the discipline for some time to come.},
	author = {Diestel, Reinhard},
	year = {2017},
	doi = {10.1007/978-3-662-53622-3},
}

@article{bodlaender_linear-time_1996,
	title = {A {Linear}-{Time} {Algorithm} for {Finding} {Tree}-{Decompositions} of {Small} {Treewidth}},
	volume = {25},
	issn = {0097-5397},
	url = {http://epubs.siam.org/doi/10.1137/S0097539793251219},
	doi = {10.1137/S0097539793251219},
	abstract = {In this paper, we give for constant k a linear-time algorithm that, given a graph \$G = (V,E)\$, determines whether the treewidth of G is at most k and, if so, finds a tree-decomposition of G with treewidth at most k. A consequence is that every minor-closed class of graphs that does not contain all planar graphs has a linear-time recognition algorithm. Another consequence is that a similar result holds when we look instead for path-decompositions with pathwidth at most some constant k.},
	number = {6},
	urldate = {2017-12-07},
	journal = {SIAM Journal on Computing},
	author = {Bodlaender, Hans L.},
	month = dec,
	year = {1996},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {05C05, 05C85, 68R10, graph algorithms, graph minors, partial k-trees, pathwidth, treewidth},
	pages = {1305--1317},
}

@article{durrett_random_nodate,
	title = {Random {Graph} {Dynamics}},
	abstract = {Why. It would make a good story if I was inspired to write this book by an image of Paul Erdös magically appearing on a cheese quesadilla, which I later sold for thousands on dollars on eBay. However, that is not true. The three main events that led to this book were (i) the use of random graphs in the solution of a problem that was part of Nathanael Berestycki's thesis, (ii) a talk that I heard Steve Strogatz give on the CHKNS model, which inspired me to prove some rigorous results about their model, and (iii) a book review I wrote on the books by Watts and Barabási for the Notices of the American Math Society. The subject of this book was attractive for me, since many of the papers were outside the mathematics literature, so the rigorous proofs of the results were, in some cases, interesting mathematical problems. In addition, since I had worked for a number of years on the proper-ties of stochastic spatial models on regular lattices, there was the natural question of how did the behavior of these systems change when one introduced long range connections between individuals or considered power law degree distributions. Both of these modifications are reasonable if one considers the spread of influenza in a town where children bring the disease home from school, or the spread of sexually transmitted diseases through a population of individuals that have a widely varying number of contacts. How. The aim of this book is to introduce the reader to the subject in the same way that a walk through Museé d'Orsay exposes the visitor to the many styles of impressionism. We will choose results to highlight the major themes, but we will not examine in detail every variation of preferential attachment that has been studied. We will concentrate on the ideas, giving the interesting parts of proofs, and referring the reader to the literature for the missing details. As Tom Liggett said after he had written his book on Interacting Particle Systems, there is no point in having a book that is just a union of papers. Throughout we approach the subject with a probabilistic viewpoint. One pragmatic reason is that, in the absence of futuristic procedures like the one Tom Cruise's character had in The Minority Report, these are the only eyes through which I can view the world. For connections to computer algorithms and their analysis, you will have to ask someone who knows that story. In addition, we will emphasize topics not found in other mathematical books. We have nothing to add to the treatment of random regular graphs in Janson, Luczak, and Rucisky (2000), so we will not spend much time on this special case of random graphs with a fixed degree distribution. The classical theory of random graphs of Erdös and Rényi is covered nicely by Bollobás' (2001), so we keep our treatment to the minimum necessary to prepare for more complicated examples. Several reviewers lobbied for an introductory chapter devoted to some of the tools: branching processes, large deviations, martingales, convergence of Markov chains, almost exponentiality of waiting times, etc. Personally I do not think it is necessary (or even desir-able) to read the entire Kama Sutra before having sex the first time, so instead I approach the book as I do my Ph.D. students' research projects. We will start looking at the subject},
	urldate = {2017-12-07},
	author = {Durrett, Rick},
}

@book{solomon_numerical_nodate,
	title = {Numerical algorithms : methods for computer vision, machine learning, and graphics},
	isbn = {1-4822-5189-2},
	url = {https://sfu-primo.hosted.exlibrisgroup.com/primo-explore/fulldisplay?vid=SFUL&search_scope=default_scope&tab=default_tab&query=any,contains,numerical%20algorithms%20methods%20for%20computer%20vision%20machine%20learning%20and%20graphics&facet=rtype,exact,books&docid=01SFUL_ALMA51189135330003611&context=L&adaptor=Local%20Search%20Engine},
	abstract = {"An A K Peters Book"--Cover. Most existing textbooks on this subject were written either for mathematics or engineering students and do not address the unique situation of computer science students, who have some background in discrete mathematics but less familiarity with continuous methods of proof and algorithms. This book is written specifically for those students, filled throughout with practical examples using the algorithms being taught. The book also teaches theory in the context of application in parallel by delving into real-world problems in computer graphics and computer vision. Cover; Accessing the E-book edition; Dedication; Contents; Preface; Acknowledgments; Section I: Preliminaries; Chapter 1: Mathematics Review; Chapter 2: Numerics and Error Analysis; Section II: Linear Algebra; Chapter 3: Linear Systems and the LU Decomposition; Chapter 4: Designing and Analyzing Linear Systems; Chapter 5: Column Spaces and QR; Chapter 6: Eigenvectors; Chapter 7: Singular Value Decomposition; Section III: Nonlinear Techniques; Chapter 8: Nonlinear Systems; Chapter 9: Unconstrained Optimization; Chapter 10: Constrained Optimization; Chapter 11: Iterative Linear Solvers. Chapter 12: Specialized Optimization MethodsSection IV: Functions, Derivatives, and Integrals; Chapter 13: Interpolation; Chapter 14: Integration and Differentiation; Chapter 15: Ordinary Differential Equations; Chapter 16: Partial Differential Equations; Bibliography; Back Cover.},
	urldate = {2017-12-06},
	author = {Solomon, Justin},
}

@book{goshtasby_theory_nodate,
	title = {Theory and applications of image registration},
	isbn = {1-119-17171-7},
	abstract = {A hands-on guide to image registration theory and methods-with examples of a wide range of real-world applications Theory and Applications of Image Registration offers comprehensive coverage of feature-based image registration methods. It provides in-depth exploration of an array of fundamental issues, including image orientation detection, similarity measures, feature extraction methods, and elastic transformation functions. Also covered are robust parameter estimation, validation methods, multi-temporal and multi-modality image registration, methods for determining the orientation of an image, methods for identifying locally unique neighborhoods in an image, methods for detecting lines in an image, methods for finding corresponding points and corresponding lines in images, registration of video images to create panoramas, and much more. Theory and Applications of Image Registration provides readers with a practical guide to the theory and underpinning principles. Throughout the book numerous real-world examples are given, illustrating how image registration can be applied to problems in various fields, including biomedicine, remote sensing, and computer vision. Also provided are software routines to help readers develop their image registration skills. Many of the algorithms described in the book have been implemented, and the software packages are made available to the readers of the book on a companion website. In addition, the book: -Explores the fundamentals of image registration and provides a comprehensive look at its multi-disciplinary applications -Reviews real-world applications of image registration in the fields of biomedical imaging, remote sensing, computer vision, and more -Discusses methods in the registration of long videos in target tracking and 3-D reconstruction -Addresses key research topics and explores potential solutions to a number of open problems in image registration -Includes a companion website featuring fully implemented algorithms and image registration software for hands-on learning Theory and Applications of Image Registration is a valuable resource for researchers and professionals working in industry and government agencies where image registration techniques are routinely employed. It is also an excellent supplementary text for graduate students in computer science, electrical engineering, software engineering, and medical physics. Image orientation detection -- Feature point detection -- Feature line detection -- Finding homologous points -- Finding homologous lines -- Nonrigid image registration -- Volume image registration -- Validation methods -- Video image registration -- Multitemporal image registration -- Open problems and research topics.},
	urldate = {2017-12-06},
	author = {Goshtasby, Ardeshir},
}

@book{goshtasby_theory_nodate-1,
	title = {Theory and applications of image registration},
	isbn = {978-1-119-17171-3},
	abstract = {A hands-on guide to image registration theory and methods-with examples of a wide range of real-world applications Theory and Applications of Image Registration offers comprehensive coverage of feature-based image registration methods. It provides in-depth exploration of an array of fundamental issues, including image orientation detection, similarity measures, feature extraction methods, and elastic transformation functions. Also covered are robust parameter estimation, validation methods, multi-temporal and multi-modality image registration, methods for determining the orientation of an image, methods for identifying locally unique neighborhoods in an image, methods for detecting lines in an image, methods for finding corresponding points and corresponding lines in images, registration of video images to create panoramas, and much more. Theory and Applications of Image Registration provides readers with a practical guide to the theory and underpinning principles. Throughout the book numerous real-world examples are given, illustrating how image registration can be applied to problems in various fields, including biomedicine, remote sensing, and computer vision. Also provided are software routines to help readers develop their image registration skills. Many of the algorithms described in the book have been implemented, and the software packages are made available to the readers of the book on a companion website. In addition, the book: -Explores the fundamentals of image registration and provides a comprehensive look at its multi-disciplinary applications -Reviews real-world applications of image registration in the fields of biomedical imaging, remote sensing, computer vision, and more -Discusses methods in the registration of long videos in target tracking and 3-D reconstruction -Addresses key research topics and explores potential solutions to a number of open problems in image registration -Includes a companion website featuring fully implemented algorithms and image registration software for hands-on learning Theory and Applications of Image Registration is a valuable resource for researchers and professionals working in industry and government agencies where image registration techniques are routinely employed. It is also an excellent supplementary text for graduate students in computer science, electrical engineering, software engineering, and medical physics. Image orientation detection -- Feature point detection -- Feature line detection -- Finding homologous points -- Finding homologous lines -- Nonrigid image registration -- Volume image registration -- Validation methods -- Video image registration -- Multitemporal image registration -- Open problems and research topics.},
	urldate = {2017-12-06},
	author = {Goshtasby, Ardeshir},
}

@book{nixon_feature_2012,
	title = {Feature extraction \&amp; image processing for computer vision},
	isbn = {0-12-396549-7},
	abstract = {3rd ed. This book is an essential guide to the implementation of image processing and computer vision techniques, with tutorial introductions and sample code in Matlab. Algorithms are presented and fully explained to enable complete understanding of the methods and techniques demonstrated. As one reviewer noted, "The main strength of the proposed book is the exemplar code of the algorithms." Fully updated with the latest developments in feature extraction, including expanded tutorials and new techniques, this new edition contains extensive new material on Haar wavelets, Viola-Jones, bilateral filtering, SURF, PCA-SIFT, moving object detection and tracking, development of symmetry operators, LBP texture analysis, Adaboost, and a new appendix on color models. Coverage of distance measures, feature detectors, wavelets, level sets and texture tutorials has been extended.},
	urldate = {2017-12-06},
	publisher = {Academic Press},
	author = {Nixon, Mark S. and Aguado, Alberto S.},
	year = {2012},
}

@incollection{olague_honeybee_2016,
	title = {The {Honeybee} {Search} {Algorithm}: {A} {Cooperative} {Coevolutionary} {Framework} for {3D} {Reconstruction}},
	url = {http://link.springer.com/10.1007/978-3-662-43693-6_6},
	urldate = {2017-12-06},
	author = {Olague, Gustavo},
	year = {2016},
	doi = {10.1007/978-3-662-43693-6_6},
	pages = {241--272},
}

@incollection{olague_multiobjective_2016,
	title = {Multiobjective {Sensor} {Planning} for {Accurate} {Reconstruction}},
	url = {http://link.springer.com/10.1007/978-3-662-43693-6_7},
	urldate = {2017-12-06},
	author = {Olague, Gustavo},
	year = {2016},
	doi = {10.1007/978-3-662-43693-6_7},
	pages = {273--326},
}

@incollection{olague_evolutionary_2016,
	title = {Evolutionary {Synthesis} of {Feature} {Descriptor} {Operators} with {Genetic} {Programming}},
	url = {http://link.springer.com/10.1007/978-3-662-43693-6_9},
	urldate = {2017-12-06},
	author = {Olague, Gustavo},
	year = {2016},
	doi = {10.1007/978-3-662-43693-6_9},
	pages = {349--382},
}

@incollection{olague_evolutionary_2016-1,
	title = {Evolutionary {Visual} {Learning} with {Linear} {Genetic} {Programming}},
	url = {http://link.springer.com/10.1007/978-3-662-43693-6_8},
	urldate = {2017-12-06},
	author = {Olague, Gustavo},
	year = {2016},
	doi = {10.1007/978-3-662-43693-6_8},
	pages = {329--348},
}

@incollection{olague_summary_2016,
	title = {Summary and {Conclusions}},
	url = {http://link.springer.com/10.1007/978-3-662-43693-6_10},
	urldate = {2017-12-06},
	author = {Olague, Gustavo},
	year = {2016},
	doi = {10.1007/978-3-662-43693-6_10},
	pages = {385--401},
}

@book{tsutsui_massively_2013,
	title = {Massively {Parallel} {Evolutionary} {Computation} on {GPGPUs}.},
	abstract = {9783642379581. Evolutionary algorithms (EAs) are metaheuristics that learn from natural collective behavior and are applied to solve optimization problems in domains such as scheduling, engineering, bioinformatics, and finance. Such applications demand acceptable solutions with high-speed execution using finite computational resources. Therefore, there have been many attempts to develop platforms for running parallel EAs using multicore machines, massively parallel cluster machines, or grid computing environments. Recent advances in general-purpose computing on graphics processing units (GPGPU) have opened up this possibility for parallel EAs, and this is the first book dedicated to this exciting development. The three chapters of Part I are tutorials, representing a comprehensive introduction to the approach, explaining the characteristics of the hardware used, and presenting a representative project to develop a platform for automatic parallelization of evolutionary computing (EC) on GPGPUs. The ten chapters in Part II focus on how to consider key EC approaches in the light of this advanced computational technique, in particular addressing generic local search, tabu search, genetic algorithms, differential evolution, swarm optimization, ant colony optimization, systolic genetic search, genetic programming, and multiobjective optimization. The six chapters in Part III present successful results from real-world problems in data mining, bioinformatics, drug discovery, crystallography, artificial chemistries, and sudoku. Although the parallelism of EAs is suited to the single-instruction multiple-data (SIMD)-based GPU, there are many issues to be resolved in design and implementation, and a key feature of the contributions is the practical engineering advice offered. This book will be of value to researchers, practitioners, and graduate students in the areas of evolutionary computation and scientific computing. Tutorials. Why GPGPUs for Evolutionary Computation? / Pierre Collet -- Understanding NVIDIA GPGPU Hardware / Ogier Maitre -- Automatic Parallelization of EC on GPGPUs and Clusters of GPGPU Machines with EASEA and EASEA-CLOUD / Pierre Collet, Frédéric Krüger, Ogier Maitre -- Implementations of Various EAs. Generic Local Search (Memetic) Algorithm on a Single GPGPU Chip / Frédéric Krüger [and others] -- arGA: Adaptive Resolution Micro-genetic Algorithm with Tabu Search to Solve MINLP Problems Using GPU / Asim Munawar [and others] -- An Analytical Study of Parallel GA with Independent Runs on GPUs / Shigeyoshi Tsutsui, Noriyuki Fujimoto -- Many-Threaded Differential Evolution on the GPU / Pavel Krömer [and others] -- Scheduling Using Multiple Swarm Particle Optimization with Memetic Features on Graphics Processing Units / Steven Solomon, Parimala Thulasiraman, Ruppa K. Thulasiram -- ACO with Tabu Search on GPUs for Fast Solution of the QAP / Shigeyoshi Tsutsui, Noriyuki Fujimoto -- New Ideas in Parallel Metaheuristics on GPU: Systolic Genetic Search / Martín Pedemonte, Francisco Luna, Enrique Alba -- Genetic Programming on GPGPU Cards Using EASEA / Ogier Maitre -- Cartesian Genetic Programming on the GPU / Simon Harding, Julian F. Miller -- Implementation Techniques for Massively Parallel Multi-objective Optimization / Deepak Sharma, Pierre Collet -- Data Mining Using Parallel Multi-objective Evolutionary Algorithms on Graphics Processing Units / Man Leung Wong, Geng Cui -- Applications. Large-Scale Bioinformatics Data Mining with Parallel Genetic Programming on Graphics Processing Units / William B. Langdon -- GPU-Accelerated High-Accuracy Molecular Docking Using Guided Differential Evolution / Martin Simonsen [and others] -- Using Large-Scale Parallel Systems for Complex Crystallographic Problems in Materials Science / Laurent A. Baumes, Frédéric Krüger, Pierre Collet -- Artificial Chemistries on GPU / Lidia Yamamoto, Pierre Collet, Wolfgang Banzhaf -- Acceleration of Genetic Algorithms for Sudoku Solution on Many-Core Processors / Yuji Sato, Naohiro Hasegawa, Mikiko Sato.},
	urldate = {2017-12-06},
	publisher = {Springer Berlin Heidelberg},
	author = {Tsutsui, Shigeyoshi and Collet, Pierre.},
	year = {2013},
	note = {ISSN: 1619-7127},
}

@book{olague_evolutionary_2016-2,
	address = {Berlin, Heidelberg},
	title = {Evolutionary {Computer} {Vision}},
	isbn = {978-3-662-43692-9},
	url = {http://link.springer.com/10.1007/978-3-662-43693-6},
	urldate = {2017-12-06},
	publisher = {Springer Berlin Heidelberg},
	author = {Olague, Gustavo},
	year = {2016},
	doi = {10.1007/978-3-662-43693-6},
	note = {Series Title: Natural Computing Series},
}

@incollection{olague_vision_2016,
	title = {Vision and {Evolution}: {State} of the {Art}},
	url = {http://link.springer.com/10.1007/978-3-662-43693-6_2},
	urldate = {2017-12-06},
	author = {Olague, Gustavo},
	year = {2016},
	doi = {10.1007/978-3-662-43693-6_2},
	pages = {11--68},
}

@incollection{olague_introduction_2016,
	title = {Introduction},
	url = {http://link.springer.com/10.1007/978-3-662-43693-6_1},
	urldate = {2017-12-06},
	author = {Olague, Gustavo},
	year = {2016},
	doi = {10.1007/978-3-662-43693-6_1},
	pages = {3--8},
}

@incollection{olague_accurate_2016,
	title = {Accurate {Modeling} of {Image} {Features} {Using} {Evolutionary} {Computing}},
	url = {http://link.springer.com/10.1007/978-3-662-43693-6_4},
	urldate = {2017-12-06},
	author = {Olague, Gustavo},
	year = {2016},
	doi = {10.1007/978-3-662-43693-6_4},
	pages = {143--191},
}

@incollection{olague_evolutionary_2016-3,
	title = {Evolutionary {Synthesis} of {Interest} {Point} {Detectors} {Through} {Genetic} {Programming}},
	url = {http://link.springer.com/10.1007/978-3-662-43693-6_5},
	urldate = {2017-12-06},
	author = {Olague, Gustavo},
	year = {2016},
	doi = {10.1007/978-3-662-43693-6_5},
	pages = {193--238},
}

@incollection{olague_evolutionary_2016-4,
	title = {Evolutionary {Computing}},
	url = {http://link.springer.com/10.1007/978-3-662-43693-6_3},
	urldate = {2017-12-06},
	author = {Olague, Gustavo},
	year = {2016},
	doi = {10.1007/978-3-662-43693-6_3},
	pages = {69--140},
}

@article{unner_efficient_nodate,
	title = {Efficient {Use} of {Limited}-{Memory} {Accelerators} for {Linear} {Learning} on {Heterogeneous} {Systems}},
	abstract = {We propose a generic algorithmic building block to accelerate training of machine learning models on heterogeneous compute systems. Our scheme allows to effi-ciently employ compute accelerators such as GPUs and FPGAs for the training of large-scale machine learning models, when the training data exceeds their me-mory capacity. Also, it provides adaptivity to any system's memory hierarchy in terms of size and processing speed. Our technique is built upon novel theoretical insights regarding primal-dual coordinate methods, and uses duality gap informa-tion to dynamically decide which part of the data should be made available for fast processing. To illustrate the power of our approach we demonstrate its perfor-mance for training of generalized linear models on a large-scale dataset exceeding the memory size of a modern GPU, showing an order-of-magnitude speedup over existing approaches.},
	urldate = {2017-12-06},
	author = {Unner, Celestine and Parnell, Thomas and Jaggi, Martin},
}

@article{Desbordes2017,
	title = {Predictive value of initial {FDG}-{PET} features for treatment response and survival in esophageal cancer patients treated with chemo-radiation therapy using a random forest classifier},
	volume = {12},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0173208},
	doi = {10.1371/journal.pone.0173208},
	number = {3},
	urldate = {2017-12-02},
	journal = {PLOS ONE},
	author = {Desbordes, Paul and Ruan, Su and Modzelewski, Romain and Pineau, Pascal and Vauclin, Sébastien and Gouel, Pierrick and Michel, Pierre and Di Fiore, Frédéric and Vera, Pierre and Gardin, Isabelle},
	editor = {Ahmad, Aamir},
	month = mar,
	year = {2017},
	note = {Publisher: Public Library of Science},
	pages = {e0173208},
}

@article{liu_landmark-based_2018,
	title = {Landmark-based deep multi-instance learning for brain disease diagnosis},
	volume = {43},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841517301524?_rdoc=1&_fmt=high&_origin=gateway&_docanchor=&md5=b8429449ccfc9c30159a5f9aeaa92ffb&dgcid=raven_sd_via_email},
	doi = {10.1016/J.MEDIA.2017.10.005},
	abstract = {In conventional Magnetic Resonance (MR) image based methods, two stages are often involved to capture brain structural information for disease diagnosis, i.e., 1) manually partitioning each MR image into a number of regions-of-interest (ROIs), and 2) extracting pre-defined features from each ROI for diagnosis with a certain classifier. However, these pre-defined features often limit the performance of the diagnosis, due to challenges in 1) defining the ROIs and 2) extracting effective disease-related features. In this paper, we propose a landmark-based deep multi-instance learning (LDMIL) framework for brain disease diagnosis. Specifically, we first adopt a data-driven learning approach to discover disease-related anatomical landmarks in the brain MR images, along with their nearby image patches. Then, our LDMIL framework learns an end-to-end MR image classifier for capturing both the local structural information conveyed by image patches located by landmarks and the global structural information derived from all detected landmarks. We have evaluated our proposed framework on 1526 subjects from three public datasets (i.e., ADNI-1, ADNI-2, and MIRIAD), and the experimental results show that our framework can achieve superior performance over state-of-the-art approaches.},
	urldate = {2017-12-02},
	journal = {Medical Image Analysis},
	author = {Liu, Mingxia and Zhang, Jun and Adeli, Ehsan and Shen, Dinggang},
	month = jan,
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {157--168},
}

@article{zhao_deep_2018,
	title = {A deep learning model integrating {FCNNs} and {CRFs} for brain tumor segmentation},
	volume = {43},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S136184151730141X?_rdoc=1&_fmt=high&_origin=gateway&_docanchor=&md5=b8429449ccfc9c30159a5f9aeaa92ffb&dgcid=raven_sd_via_email},
	doi = {10.1016/J.MEDIA.2017.10.002},
	abstract = {Accurate and reliable brain tumor segmentation is a critical component in cancer diagnosis, treatment planning, and treatment outcome evaluation. Build upon successful deep learning techniques, a novel brain tumor segmentation method is developed by integrating fully convolutional neural networks (FCNNs) and Conditional Random Fields (CRFs) in a unified framework to obtain segmentation results with appearance and spatial consistency. We train a deep learning based segmentation model using 2D image patches and image slices in following steps: 1) training FCNNs using image patches; 2) training CRFs as Recurrent Neural Networks (CRF-RNN) using image slices with parameters of FCNNs fixed; and 3) fine-tuning the FCNNs and the CRF-RNN using image slices. Particularly, we train 3 segmentation models using 2D image patches and slices obtained in axial, coronal and sagittal views respectively, and combine them to segment brain tumors using a voting based fusion strategy. Our method could segment brain images slice-by-slice, much faster than those based on image patches. We have evaluated our method based on imaging data provided by the Multimodal Brain Tumor Image Segmentation Challenge (BRATS) 2013, BRATS 2015 and BRATS 2016. The experimental results have demonstrated that our method could build a segmentation model with Flair, T1c, and T2 scans and achieve competitive performance as those built with Flair, T1, T1c, and T2 scans.},
	urldate = {2017-12-02},
	journal = {Medical Image Analysis},
	author = {Zhao, Xiaomei and Wu, Yihong and Song, Guidong and Li, Zhenye and Zhang, Yazhuo and Fan, Yong},
	month = jan,
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {98--111},
}

@article{Ridgeway2007,
	title = {Generalized {Boosted} {Models}: {A} guide to the gbm package},
	abstract = {Boosting takes on various forms with different programs using different loss functions, different base models, and different optimization schemes. The gbm package takes the approach described in [2] and [3]. Some of the terminology differs, mostly due to an effort to cast boosting terms into more standard sta-tistical terminology (e.g. deviance). In addition, the gbm package implements boosting for models commonly used in statistics but not commonly associated with boosting. The Cox proportional hazard model, for example, is an incred-ibly useful model and the boosting framework applies quite readily with only slight modification [5]. Also some algorithms implemented in the gbm package differ from the standard implementation. The AdaBoost algorithm [1] has a particular loss function and a particular optimization algorithm associated with it. The gbm implementation of AdaBoost adopts AdaBoost's exponential loss function (its bound on misclassification rate) but uses Friedman's gradient de-scent algorithm rather than the original one proposed. So the main purposes of this document is to spell out in detail what the gbm package implements. 1 Gradient boosting This section essentially presents the derivation of boosting described in [2]. The gbm package also adopts the stochastic gradient boosting strategy, a small but important tweak on the basic algorithm, described in [3].},
	urldate = {2017-12-01},
	author = {Ridgeway, Greg},
	year = {2007},
}

@article{Feurer,
	title = {Efficient and {Robust} {Automated} {Machine} {Learning}},
	abstract = {The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efficient Bayesian optimization methods. Building on this, we introduce a robust new AutoML system based on scikit-learn (using 15 classifiers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub AUTO-SKLEARN, improves on existing AutoML methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won the first phase of the ongoing ChaLearn AutoML challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of AUTO-SKLEARN.},
	urldate = {2017-12-01},
	author = {Feurer, Matthias and Klein, Aaron and Eggensperger, Katharina and Springenberg, Jost Tobias and Blum, Manuel and Hutter, Frank},
}

@article{Golub1965,
	title = {Calculating the {Singular} {Values} and {Pseudo}-{Inverse} of a {Matrix}},
	volume = {2},
	issn = {0887-459X},
	url = {http://epubs.siam.org/doi/10.1137/0702016},
	doi = {10.1137/0702016},
	abstract = {A numerically stable and fairly fast scheme is described to compute the unitary matrices U and V which transform a given matrix A into a diagonal form \${\textbackslash}Sigma = U{\textasciicircum} * AV\$, thus exhibiting A’s singular values on \${\textbackslash}Sigma \$’s diagonal. The scheme first transforms A to a bidiagonal matrix J, then diagonalizes J. The scheme described here is complicated but does not suffer from the computational difficulties which occasionally afflict some previously known methods. Some applications are mentioned, in particular the use of the pseudo-inverse \$A{\textasciicircum}I = V{\textbackslash}Sigma {\textasciicircum}I U{\textasciicircum}* \$ to solve least squares problems in a way which dampens spurious oscillation and cancellation.},
	number = {2},
	urldate = {2017-12-01},
	journal = {Journal of the Society for Industrial and Applied Mathematics Series B Numerical Analysis},
	author = {Golub, G. and Kahan, W.},
	month = jan,
	year = {1965},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {205--224},
}

@article{Halko2009,
	title = {Finding structure with randomness: {Probabilistic} algorithms for constructing approximate matrix decompositions},
	url = {http://arxiv.org/abs/0909.4061},
	abstract = {Low-rank matrix approximations, such as the truncated singular value decomposition and the rank-revealing QR decomposition, play a central role in data analysis and scientific computing. This work surveys and extends recent research which demonstrates that randomization offers a powerful tool for performing low-rank matrix approximation. These techniques exploit modern computational architectures more fully than classical methods and open the possibility of dealing with truly massive data sets. This paper presents a modular framework for constructing randomized algorithms that compute partial matrix decompositions. These methods use random sampling to identify a subspace that captures most of the action of a matrix. The input matrix is then compressed---either explicitly or implicitly---to this subspace, and the reduced matrix is manipulated deterministically to obtain the desired low-rank factorization. In many cases, this approach beats its classical competitors in terms of accuracy, speed, and robustness. These claims are supported by extensive numerical experiments and a detailed error analysis.},
	urldate = {2017-12-01},
	author = {Halko, Nathan and Martinsson, Per-Gunnar and Tropp, Joel A.},
	month = sep,
	year = {2009},
	note = {arXiv: 0909.4061},
}

@article{golovin_google_2017,
	title = {Google {Vizier} : {A} {Service} for {Black}-{Box} {Optimization}},
	doi = {10.1145/3097983.3098043},
	abstract = {Any sufficiently complex system acts as a black box when it becomes easier to experiment with than to understand. Hence, black-box optimization has become increasingly im-portant as systems have become more complex. In this paper we describe Google Vizier, a Google-internal service for per-forming black-box optimization that has become the de facto parameter tuning engine at Google. Google Vizier is used to optimize many of our machine learning models and other systems, and also provides core capabilities to Google's Cloud Machine Learning HyperTune subsystem. We discuss our re-quirements, infrastructure design, underlying algorithms, and advanced features such as transfer learning and automated early stopping that the service provides.},
	journal = {Kdd '17},
	author = {Golovin, Daniel and Solnik, Benjamin and Moitra, Subhodeep and Kochanski, Greg and Karro, John and Sculley, D},
	year = {2017},
	note = {ISBN: 9781450348874},
}

@article{wang_bayesian_2016,
	title = {Bayesian optimization in a billion dimensions via random embeddings},
	volume = {55},
	issn = {10769757},
	doi = {10.1613/jair.4806},
	abstract = {Bayesian optimization techniques have been successfully applied to robotics, planning, sensor placement, recommendation, advertising, intelligent user interfaces and automatic algorithm configuration. Despite these successes, the approach is restricted to problems of moderate dimension, and several workshops on Bayesian optimization have identified its scaling to high-dimensions as one of the holy grails of the field. In this paper, we introduce a novel random embedding idea to attack this problem. The resulting Random EMbedding Bayesian Optimization (REMBO) algorithm is very simple, has important invariance properties, and applies to domains with both categorical and continuous variables. We present a thorough theoretical analysis of REMBO. Empirical results confirm that REMBO can effectively solve problems with billions of dimensions, provided the intrinsic dimensionality is low. They also show that REMBO achieves state-of-the-art performance in optimizing the 47 discrete parameters of a popular mixed integer linear programming solver.},
	journal = {Journal of Artificial Intelligence Research},
	author = {Wang, Ziyu and Hutter, Frank and Zoghi, Masrour and Matheson, David and De Freitas, Nando},
	year = {2016},
	note = {arXiv: 1301.1942
ISBN: 978-1-57735-633-2},
}

@article{Shahriari2016,
	title = {Taking the human out of the loop: {A} review of {Bayesian} optimization},
	volume = {104},
	issn = {00189219},
	doi = {10.1109/JPROC.2015.2494218},
	abstract = {—Big data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., rec-ommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involves many tunable config-uration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
	number = {1},
	journal = {Proceedings of the IEEE},
	author = {Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and De Freitas, Nando},
	year = {2016},
	pmid = {25246403},
	note = {arXiv: 1011.1669v3
ISBN: 0018-9219},
}

@article{feurer_initializing_2015,
	title = {Initializing {Bayesian} {Hyperparameter} {Optimization} via {Meta}-{Learning}},
	abstract = {Model selection and hyperparameter optimization is crucial in applying machine learning to a novel dataset. Recently, a sub-community of machine learning has focused on solving this problem with Sequential Model-based Bayesian Optimization (SMBO), demonstrating substantial successes in many appli-cations. However, for computationally expensive algorithms the overhead of hyperparameter optimization can still be pro-hibitive. In this paper we mimic a strategy human domain experts use: speed up optimization by starting from promising configurations that performed well on similar datasets. The resulting initialization technique integrates naturally into the generic SMBO framework and can be trivially applied to any SMBO method. To validate our approach, we perform exten-sive experiments with two established SMBO frameworks (Spearmint and SMAC) with complementary strengths; opti-mizing two machine learning frameworks on 57 datasets. Our initialization procedure yields mild improvements for low-dimensional hyperparameter optimization and substantially improves the state of the art for the more complex combined algorithm selection and hyperparameter optimization problem.},
	journal = {AAAI},
	author = {Feurer, Matthias and Springenberg, Jost Tobias and Hutter, Frank},
	year = {2015},
	note = {ISBN: 9781577357001},
}

@article{zegklitz_learning_2017,
	title = {Learning {Linear} {Feature} {Space} {Transformations} in {Symbolic} {Regression}},
	url = {http://arxiv.org/abs/1704.05134},
	abstract = {We propose a new type of leaf node for use in Symbolic Regression (SR) that performs linear combinations of feature variables (LCF). These nodes can be handled in three different modes -- an unsynchronized mode, where all LCFs are free to change on their own, a synchronized mode, where LCFs are sorted into groups in which they are forced to be identical throughout the whole individual, and a globally synchronized mode, which is similar to the previous mode but the grouping is done across the whole population. We also present two methods of evolving the weights of the LCFs -- a purely stochastic way via mutation and a gradient-based way based on the backpropagation algorithm known from neural networks -- and also a combination of both. We experimentally evaluate all configurations of LCFs in Multi-Gene Genetic Programming (MGGP), which was chosen as baseline, on a number of benchmarks. According to the results, we identified two configurations which increase the performance of the algorithm.},
	urldate = {2017-11-24},
	author = {Žegklitz, Jan and Pošík, Petr},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.05134},
}

@article{arumugam_andreas_brandstadt_takao_nishizeki_thulasiraman_krishnaiyan_nodate,
	title = {Krishnaiyan \&quot; {KT} \&quot; {Thulasiraman} {Handbook} of {Graph} {Theory}, {Combinatorial} {Optimization}, and {Algorithms}},
	abstract = {The fusion between graph theory and combinatorial optimization has led to theoretically profound and practically useful algorithms, yet there is no book that currently covers both areas together. Handbook of Graph Theory, Combinatorial Optimization, and Algorithms is the first to present a unified, comprehensive treatment of both graph theory and combinatorial optimization. Divided into 11 cohesive sections, the handbook's 44 chapters focus on graph theory, combinatorial optimization, and algorithmic issues. The book provides readers with the algorithmic and theoretical foundations to • Understand phenomena as shaped by their graph structures • Develop needed algorithmic and optimization tools for the study of graph structures • Design and plan graph structures that lead to certain desirable behavior With contributions from more than 40 worldwide experts, this handbook equips readers with the necessary techniques and tools to solve problems in a variety of applications. Readers gain expo-sure to the theoretical and algorithmic foundations of a wide range of topics in graph theory and combinatorial optimization, enabling them to identify (and hence solve) problems encountered in diverse disciplines, such as electrical, communication, computer, social, transportation, biological, and other networks. Features • Gives a broad, integrated account of graph theory, combinatorial optimization, and related algorithmic issues • Describes well-tested algorithms, techniques, and tools for solving computationally intractable problems • Covers numerous topics of interest in applications in computer science, electrical and com-puter engineering, very large-scale integrated (VLSI) circuit design, industrial and systems engineering, telecommunication networks, network science and engineering, transportation networks, machine intelligence, and data mining • Provides the theoretical foundation for further advances • Includes a survey section at the end of each chapter that offers pointers for exploring related advances and issues},
	urldate = {2017-11-19},
	author = {Arumugam Andreas Brandstädt Takao Nishizeki Thulasiraman, Subramanian},
}

@article{noauthor_isbi_2018,
	title = {{ISBI} 2018 {Author} {Questionnaire} – limit to one page},
	volume = {34},
	number = {2015},
	year = {2018},
	pages = {2018},
}

@article{Quantif2018,
	title = {{CONFIDENTIAL} . {Limited} circulation . {For} review only . {RADIOMICS}-{NET} : {PREDICTING} {RESPONSE} {TO} {RADIOCHEMOTHERAPY} {USING} {3D} {CONVOLUTIONAL} {NEURAL} {NETWORK}},
	author = {Quantif, Litis E A and Ea, Litis and Rouen, Insa De},
	year = {2018},
	pages = {3--6},
}

@article{ypsilantis_predicting_2015,
	title = {Predicting {Response} to {Neoadjuvant} {Chemotherapy} with {PET} {Imaging} {Using} {Convolutional} {Neural} {Networks}},
	volume = {10},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0137036},
	doi = {10.1371/journal.pone.0137036},
	number = {9},
	urldate = {2017-11-18},
	journal = {PLOS ONE},
	author = {Ypsilantis, Petros-Pavlos and Siddique, Musib and Sohn, Hyon-Mok and Davies, Andrew and Cook, Gary and Goh, Vicky and Montana, Giovanni},
	editor = {Anto, Ruby John},
	month = sep,
	year = {2015},
	note = {Publisher: Public Library of Science},
	pages = {e0137036},
}

@article{xue_application_2017,
	title = {Application of {Deep} {Learning} in {Automated} {Analysis} of {Molecular} {Images} in {Cancer}: {A} {Survey}},
	volume = {2017},
	issn = {1555-4309},
	url = {https://www.hindawi.com/journals/cmmi/2017/9512370/},
	doi = {10.1155/2017/9512370},
	abstract = {{\textless}p{\textgreater}Molecular imaging enables the visualization and quantitative analysis of the alterations of biological procedures at molecular and/or cellular level, which is of great significance for early detection of cancer. In recent years, deep leaning has been widely used in medical imaging analysis, as it overcomes the limitations of visual assessment and traditional machine learning techniques by extracting hierarchical features with powerful representation capability. Research on cancer molecular images using deep learning techniques is also increasing dynamically. Hence, in this paper, we review the applications of deep learning in molecular imaging in terms of tumor lesion segmentation, tumor classification, and survival prediction. We also outline some future directions in which researchers may develop more powerful deep learning models for better performance in the applications in cancer molecular imaging.{\textless}/p{\textgreater}},
	urldate = {2017-11-18},
	journal = {Contrast Media \& Molecular Imaging},
	author = {Xue, Yong and Chen, Shihui and Qin, Jing and Liu, Yong and Huang, Bingsheng and Chen, Hanwei},
	month = oct,
	year = {2017},
	note = {Publisher: Hindawi},
	pages = {1--10},
}

@article{Polya1945,
	title = {How to {Solve} {It}},
	volume = {30},
	issn = {00255572},
	url = {http://www.jstor.org/stable/3609122?origin=crossref},
	doi = {10.2307/3609122},
	abstract = {Perennial bestseller by eminent mathematician G. Polya, How to Solve It will show anyone in any field how to think straight. In lucid and appealing prose, Polya reveals how the mathematical method of demonstrating a proof or finding an unknown can be of help in attacking any problem that can be "reasoned" out-from building a bridge to winning a game of anagrams. Generations of readers have relished Polya's deft-indeed, brilliant-instructions on stripping away irrelevancies and going straight to the heart of the problem. In this best-selling classic, George Pólya revealed how the mathematical method of demonstrating a proof or finding an unknown can be of help in attacking any problem that can be "reasoned" out-from building a bridge to winning a game of anagrams. Generations of readers have relished Pólya's deft instructions on stripping away irrelevancies and going straight to the heart of a problem. How to Solve It popularized heuristics, the art and science of discovery and invention. It has been in print continuously since 1945 and has been translated into twenty-three different languages. Pólya was one of the most influential mathematicians of the twentieth century. He made important contributions to a great variety of mathematical research: from complex analysis to mathematical physics, number theory, probability, geometry, astronomy, and combinatorics. He was also an extraordinary teacher-he taught until he was ninety-and maintained a strong interest in pedagogical matters throughout his long career. In addition to How to Solve It, he published a two-volume work on the topic of problem solving, Mathematics of Plausible Reasoning, also with Princeton. Pólya is one of the most frequently quoted mathematicians, and the following statements from How to Solve It make clear why: "My method to overcome a difficulty is to go around it." "Geometry is the science of correct reasoning on incorrect figures." "In order to solve this differential equation you look at it till a solution occurs to you."},
	journal = {The Mathematical Gazette},
	author = {Polya, G.},
	year = {1945},
	pmid = {11410596},
	note = {ISBN: 0-691-08097-6},
	pages = {181},
}

@book{Velleman2006,
	title = {How to {Prove} {It}},
	isbn = {978-0-511-80823-4},
	url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:No+Title#0%5Cnhttp://ebooks.cambridge.org/ref/id/CBO9780511808234},
	author = {Velleman, Daniel J.},
	year = {2006},
	doi = {10.1017/CBO9780511808234},
	note = {Publication Title: Zhurnal Eksperimental'noi i Teoreticheskoi Fiziki},
}

@article{Rajpurkar,
	title = {{CheXNet}: {Radiologist}-{Level} {Pneumonia} {Detection} on {Chest} {X}-{Rays} with {Deep} {Learning}},
	abstract = {We develop an algorithm that can detect pneumonia from chest X-rays at a level ex-ceeding practicing radiologists. Our algo-rithm, CheXNet, is a 121-layer convolutional neural network trained on ChestX-ray14, cur-rently the largest publicly available chest X-ray dataset, containing over 100,000 frontal-view X-ray images with 14 diseases. Four practicing academic radiologists annotate a test set, on which we compare the perfor-mance of CheXNet to that of radiologists. We find that CheXNet exceeds average radi-ologist performance on pneumonia detection on both sensitivity and specificity. We extend CheXNet to detect all 14 diseases in ChestX-ray14 and achieve state of the art results on all 14 diseases.},
	urldate = {2017-11-17},
	author = {Rajpurkar, Pranav and Irvin, Jeremy and Zhu, Kaylie and Yang, Brandon and Mehta, Hershel and Duan, Tony and Ding, Daisy and Bagul, Aarti and Langlotz, Curtis and Shpanskaya, Katie and Lungren, Matthew P and Ng, Andrew Y},
}

@article{bach_breaking_2017,
	title = {Breaking the {Curse} of {Dimensionality} with {Convex} {Neural} {Networks}},
	volume = {18},
	abstract = {We consider neural networks with a single hidden layer and non-decreasing positively ho-mogeneous activation functions like the rectified linear units. By letting the number of hidden units grow unbounded and using classical non-Euclidean regularization tools on the output weights, they lead to a convex optimization problem and we provide a de-tailed theoretical analysis of their generalization performance, with a study of both the approximation and the estimation errors. We show in particular that they are adaptive to unknown underlying linear structures, such as the dependence on the projection of the input variables onto a low-dimensional subspace. Moreover, when using sparsity-inducing norms on the input weights, we show that high-dimensional non-linear variable selection may be achieved, without any strong assumption regarding the data and with a total num-ber of variables potentially exponential in the number of observations. However, solving this convex optimization problem in infinite dimensions is only possible if the non-convex subproblem of addition of a new unit can be solved efficiently. We provide a simple geo-metric interpretation for our choice of activation functions and describe simple conditions for convex relaxations of the finite-dimensional non-convex subproblem to achieve the same generalization error bounds, even when constant-factor approximations cannot be found. We were not able to find strong enough convex relaxations to obtain provably polynomial-time algorithms and leave open the existence or non-existence of such tractable algorithms with non-exponential sample complexities.},
	urldate = {2017-11-16},
	journal = {Journal of Machine Learning Research},
	author = {Bach, Francis},
	year = {2017},
	keywords = {Neural networks, convex optimization, convex relaxation, non-parametric estimation},
	pages = {1--53},
}

@article{noauthor_multi-objective_2017,
	title = {Multi-{Objective} {Differential} {Evolution} for feature selection in {Facial} {Expression} {Recognition} systems},
	volume = {89},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417417305134},
	doi = {10.1016/J.ESWA.2017.07.037},
	urldate = {2017-11-16},
	journal = {Expert Systems with Applications},
	month = dec,
	year = {2017},
	note = {Publisher: Pergamon},
	pages = {129--137},
}

@incollection{krause_survey_2013,
	title = {A {Survey} of {Swarm} {Algorithms} {Applied} to {Discrete} {Optimization} {Problems}},
	isbn = {978-0-12-405163-8},
	abstract = {Most swarm intelligence algorithms were devised for continuous optimization problems. However, they have been adapted for discrete optimization as well with applications in different domains. This survey aims at providing an updated review of research of swarm intelligence algorithms for discrete optimization problems, comprising combinatorial or binary. The biological inspiration that motivated the creation of each swarm algorithm is introduced, and later, the discretization and encoding methods are used to adapt each algorithm for discrete problems. Methods are compared for different classes of problems and a critical analysis is provided, pointing to future trends. © 2013 Copyright © 2013 Elsevier Inc. All rights reserved.},
	booktitle = {Swarm {Intelligence} and {Bio}-{Inspired} {Computation}},
	author = {Krause, Jonas and Cordeiro, Jelson and Parpinelli, Rafael Stubs and Lopes, Heitor Silvério A.},
	year = {2013},
	doi = {10.1016/B978-0-12-405163-8.00007-7},
	keywords = {Binary problems, Bioinspired algorithms, Combinatorial problems, Discrete domain, Swarm Intelligence},
}

@article{suzuki_overview_2017,
	title = {Overview of deep learning in medical imaging},
	volume = {10},
	issn = {1865-0333},
	url = {http://link.springer.com/10.1007/s12194-017-0406-5},
	doi = {10.1007/s12194-017-0406-5},
	number = {3},
	urldate = {2017-11-16},
	journal = {Radiological Physics and Technology},
	author = {Suzuki, Kenji},
	month = sep,
	year = {2017},
	note = {Publisher: Springer Singapore},
	pages = {257--273},
}

@book{zhou_deep_nodate,
	title = {Deep learning for medical image analysis},
	isbn = {978-0-12-810408-8},
	url = {http://www.sciencedirect.com/science/book/9780128104088},
	abstract = {"Deep learning is providing exciting solutions for medical image analysis problems and is seen as a key method for future applications. This book gives a clear understanding of the principles and methods of neural network and deep learning concepts, showing how the algorithms that integrate deep learning as a core component have been applied to medical image detection, segmentation and registration, and computer-aided analysis, using a wide variety of application areas. Deep Learning for Medical Image Analysis is a great learning resource for academic and industry researchers in medical imaging analysis, and for graduate students taking courses on machine learning and deep learning for computer vision and medical image computing and analysis"-- Front Cover; Deep Learning for Medical Image Analysis; Copyright; Contents; Contributors; About the Editors; Foreword; Part 1 Introduction; 1 An Introduction to Neural Networks and Deep Learning; 1.1 Introduction; 1.2 Feed-Forward Neural Networks; 1.2.1 Perceptron; 1.2.2 Multi-Layer Neural Network; 1.2.3 Learning in Feed-Forward Neural Networks; 1.3 Convolutional Neural Networks; 1.3.1 Convolution and Pooling Layer; 1.3.2 Computing Gradients; 1.4 Deep Models; 1.4.1 Vanishing Gradient Problem; 1.4.2 Deep Neural Networks; 1.4.3 Deep Generative Models; 1.5 Tricks for Better Learning. 1.5.1 Rectified Linear Unit (ReLU)1.5.2 Dropout; 1.5.3 Batch Normalization; 1.6 Open-Source Tools for Deep Learning; References; Notes; 2 An Introduction to Deep Convolutional Neural Nets for Computer Vision; 2.1 Introduction; 2.2 Convolutional Neural Networks; 2.2.1 Building Blocks of CNNs; 2.2.2 Depth; 2.2.3 Learning Algorithm; 2.2.4 Tricks to Increase Performance; 2.2.5 Putting It All Together: AlexNet; 2.2.6 Using Pre-Trained CNNs; 2.2.7 Improving AlexNet; 2.3 CNN Flavors; 2.3.1 Region-Based CNNs; 2.3.2 Fully Convolutional Networks; 2.3.3 Multi-Modal Networks; 2.3.4 CNNs with RNNs. 2.3.5 Hybrid Learning Methods2.4 Software for Deep Learning; References; Part 2 Medical Image Detection and Recognition; 3 Efficient Medical Image Parsing; 3.1 Introduction; 3.2 Background and Motivation; 3.2.1 Object Localization and Segmentation: Challenges; 3.3 Methodology; 3.3.1 Problem Formulation; 3.3.2 Sparse Adaptive Deep Neural Networks; 3.3.3 Marginal Space Deep Learning; 3.3.4 An Artificial Agent for Image Parsing; 3.4 Experiments; 3.4.1 Anatomy Detection and Segmentation in 3D; 3.4.2 Landmark Detection in 2D and 3D; 3.5 Conclusion; Disclaimer; References. 4 Multi-Instance Multi-Stage Deep Learning for Medical Image Recognition4.1 Introduction; 4.2 Related Work; 4.3 Methodology; 4.3.1 Problem Statement and Framework Overview; 4.3.2 Learning Stage I: Multi-Instance CNN Pre-Train; 4.3.3 Learning Stage II: CNN Boosting; 4.3.4 Run-Time Classification; 4.4 Results; 4.4.1 Image Classification on Synthetic Data; 4.4.2 Body-Part Recognition on CT Slices; 4.5 Discussion and Future Work; References; 5 Automatic Interpretation of Carotid Intima-Media Thickness Videos Using Convolutional Neural Networks; 5.1 Introduction; 5.2 Related Work. 5.3 CIMT Protocol5.4 Method; 5.4.1 Convolutional Neural Networks (CNNs); 5.4.2 Frame Selection; 5.4.3 ROI Localization; 5.4.4 Intima-Media Thickness Measurement; 5.5 Experiments; 5.5.1 Pre- and Post-Processing for Frame Selection; 5.5.2 Constrained ROI Localization; 5.5.3 Intima-Media Thickness Measurement; 5.5.4 End-to-End CIMT Measurement; 5.6 Discussion; 5.7 Conclusion; Acknowledgement; References; Notes; 6 Deep Cascaded Networks for Sparsely Distributed Object Detection from Medical Images; 6.1 Introduction; 6.2 Method; 6.2.1 Coarse Retrieval Model; 6.2.2 Fine Discrimination Model.},
	urldate = {2017-11-16},
	author = {Zhou, S. Kevin and Greenspan, Hayit and Shen, Dinggang},
}

@incollection{chen_chapter_2017,
	title = {Chapter 6 – {Deep} {Cascaded} {Networks} for {Sparsely} {Distributed} {Object} {Detection} from {Medical} {Images}},
	isbn = {978-0-12-810408-8},
	abstract = {With the development of deep learning techniques, the performance of object detection has been significantly advanced. Although various methods have been designed to detect landmarks for computer-aided diagnosis, how to efficiently and effectively leverage deep learning approaches to detect sparsely distributed objects, such as mitosis and cerebral microbleeds, from large scale medical images hasn't been fully explored. In this chapter, we introduce a two-stage cascaded deep learning framework, referred as deep cascaded networks, to detect sparsely distributed objects that provide clinical significance with both high efficiency and accuracy. Specifically, the first screening stage with coarse retrieval model rapidly retrieves potential candidates, and subsequently the second discrimination stage with the fine discrimination model focuses on those candidates to further accurately single out the true targets from challenging mimics. Furthermore, we corroborate the importance of volumetric feature representations for volumetric imaging modalities by exploiting 3D convolutional neural networks. Extensive experimental results on the challenging problems, including mitosis detection from 2D histopathological images and cerebral microbleed detection from 3D magnetic resonance images, demonstrated superior performance of our framework in terms of both speed and accuracy.},
	urldate = {2017-11-16},
	booktitle = {Deep {Learning} for {Medical} {Image} {Analysis}},
	author = {Chen, Hao and Dou, Qi and Yu, Lequan and Qin, Jing and Zhao, Lei and Mok, Vincent C.T. and Wang, Defeng and Shi, Lin and Heng, Pheng-Ann},
	year = {2017},
	doi = {10.1016/B978-0-12-810408-8.00008-0},
	pages = {133--154},
}

@article{kammer_approximate_2016,
	title = {Approximate tree decompositions of planar graphs in linear time},
	volume = {645},
	issn = {03043975},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397516302961},
	doi = {10.1016/j.tcs.2016.06.040},
	urldate = {2017-11-16},
	journal = {Theoretical Computer Science},
	author = {Kammer, Frank and Tholey, Torsten},
	month = sep,
	year = {2016},
	note = {Publisher: Elsevier B.V.
ISBN: 9781611972108},
	pages = {60--90},
}

@incollection{wang_scalable_2017,
	title = {Scalable {High} {Performance} {Image} {Registration} {Framework} by {Unsupervised} {Deep} {Feature} {Representations} {Learning}},
	isbn = {978-0-12-810409-5},
	url = {http://linkinghub.elsevier.com/retrieve/pii/B9780128104088000158},
	urldate = {2017-11-16},
	booktitle = {Deep {Learning} for {Medical} {Image} {Analysis}},
	publisher = {Elsevier},
	author = {Wang, Shaoyu and Kim, Minjeong and Wu, Guorong and Shen, Dinggang},
	year = {2017},
	doi = {10.1016/B978-0-12-810408-8.00015-8},
	note = {ISSN: 15582531},
	pages = {245--269},
}

@incollection{chen_deep_2017,
	title = {Deep {Cascaded} {Networks} for {Sparsely} {Distributed} {Object} {Detection} from {Medical} {Images}},
	isbn = {978-0-12-810409-5},
	url = {http://linkinghub.elsevier.com/retrieve/pii/B9780128104088000080},
	urldate = {2017-11-16},
	booktitle = {Deep {Learning} for {Medical} {Image} {Analysis}},
	publisher = {Elsevier},
	author = {Chen, Hao and Dou, Qi and Yu, Lequan and Qin, Jing and Zhao, Lei and Mok, Vincent C.T. and Wang, Defeng and Shi, Lin and Heng, Pheng-Ann},
	year = {2017},
	doi = {10.1016/B978-0-12-810408-8.00008-0},
	pages = {133--154},
}

@article{li_hyperband:_2016,
	title = {Hyperband: {A} {Novel} {Bandit}-{Based} {Approach} to {Hyperparameter} {Optimization}},
	url = {https://arxiv.org/abs/1603.06560},
	urldate = {2017-11-15},
	author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.06560},
}

@article{brock_smash:_2017,
	title = {{SMASH}: {One}-{Shot} {Model} {Architecture} {Search} through {HyperNetworks}},
	url = {http://arxiv.org/abs/1708.05344},
	abstract = {Designing architectures for deep neural networks requires expert knowledge and substantial computation time. We propose a technique to accelerate architecture selection by learning an auxiliary HyperNet that generates the weights of a main model conditioned on that model's architecture. By comparing the relative validation performance of networks with HyperNet-generated weights, we can effectively search over a wide range of architectures at the cost of a single training run. To facilitate this search, we develop a flexible mechanism based on memory read-writes that allows us to define a wide range of network connectivity patterns, with ResNet, DenseNet, and FractalNet blocks as special cases. We validate our method (SMASH) on CIFAR-10 and CIFAR-100, STL-10, ModelNet10, and Imagenet32x32, achieving competitive performance with similarly-sized hand-designed networks. Our code is available at https://github.com/ajbrock/SMASH},
	urldate = {2017-11-13},
	author = {Brock, Andrew and Lim, Theodore and Ritchie, J. M. and Weston, Nick},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.05344},
}

@article{bousquet_toward_2017,
	title = {Toward {Optimal} {Run} {Racing}: {Application} to {Deep} {Learning} {Calibration}},
	abstract = {This paper aims at one-shot learning of deep neural nets, where a highly parallel setting is considered to address the algorithm calibration problem − selecting the best neural architecture and learning hyper-parameter values depending on the dataset at hand. The notoriously expensive calibration problem is optimally reduced by detecting and early stopping non-optimal runs. The theoretical contribution regards the optimality guarantees within the multiple hypothesis testing framework. Experimentations on the Cifar10, PTB and Wiki benchmarks demonstrate the relevance of the approach with a principled and consistent improvement on the state of the art [7] with no extra hyper-parameter.},
	urldate = {2017-11-13},
	author = {Bousquet, Olivier and Gelly, Sylvain and Kurach, Karol and Schoenauer, Marc and Sebag, Michèle and Teytaud, Olivier and Vincent, Damien},
	year = {2017},
}

@article{mendoza_towards_2016,
	title = {Towards {Automatically}-{Tuned} {Neural} {Networks}},
	volume = {64},
	abstract = {Recent advances in AutoML have led to automated tools that can compete with machine learning experts on supervised learning tasks. However, current AutoML tools do not yet support modern neural networks effectively. In this work, we present a first version of Auto-Net, which provides automatically-tuned feed-forward neural networks without any human intervention. We report results on datasets from the recent AutoML challenge showing that ensembling Auto-Net with Auto-sklearn can perform better than either approach alone and report the first results on winning competition datasets against human experts with automatically-tuned neural networks.},
	urldate = {2017-11-13},
	author = {Mendoza, Hector and Klein, Aaron and Feurer, Matthias and Springenberg, Jost Tobias and Hutter, Frank},
	year = {2016},
	keywords = {Automated Machine Learning, Bayesian Optimization, Neural Networks},
	pages = {58--65},
}

@article{hazan_hyperparameter_2017,
	title = {Hyperparameter {Optimization}: {A} {Spectral} {Approach}},
	url = {http://arxiv.org/abs/1706.00764},
	abstract = {We give a simple, fast algorithm for hyperparameter optimization inspired by techniques from the analysis of Boolean functions. We focus on the high-dimensional regime where the canonical example is training a neural network with a large number of hyperparameters. The algorithm --- an iterative application of compressed sensing techniques for orthogonal polynomials --- requires only uniform sampling of the hyperparameters and is thus easily parallelizable. Experiments for training deep neural networks on Cifar-10 show that compared to state-of-the-art tools (e.g., Hyperband and Spearmint), our algorithm finds significantly improved solutions, in some cases better than what is attainable by hand-tuning. In terms of overall running time (i.e., time required to sample various settings of hyperparameters plus additional computation time), we are at least an order of magnitude faster than Hyperband and Bayesian Optimization. We also outperform Random Search 8x. Additionally, our method comes with provable guarantees and yields the first improvements on the sample complexity of learning decision trees in over two decades. In particular, we obtain the first quasi-polynomial time algorithm for learning noisy decision trees with polynomial sample complexity.},
	urldate = {2017-11-13},
	author = {Hazan, Elad and Klivans, Adam and Yuan, Yang},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.00764},
}

@article{ilievski_efficient_2016,
	title = {Efficient {Hyperparameter} {Optimization} of {Deep} {Learning} {Algorithms} {Using} {Deterministic} {RBF} {Surrogates}},
	url = {http://arxiv.org/abs/1607.08316},
	abstract = {Automatically searching for optimal hyperparameter configurations is of crucial importance for applying deep learning algorithms in practice. Recently, Bayesian optimization has been proposed for optimizing hyperparameters of various machine learning algorithms. Those methods adopt probabilistic surrogate models like Gaussian processes to approximate and minimize the validation error function of hyperparameter values. However, probabilistic surrogates require accurate estimates of sufficient statistics (e.g., covariance) of the error distribution and thus need many function evaluations with a sizeable number of hyperparameters. This makes them inefficient for optimizing hyperparameters of deep learning algorithms, which are highly expensive to evaluate. In this work, we propose a new deterministic and efficient hyperparameter optimization method that employs radial basis functions as error surrogates. The proposed mixed integer algorithm, called HORD, searches the surrogate for the most promising hyperparameter values through dynamic coordinate search and requires many fewer function evaluations. HORD does well in low dimensions but it is exceptionally better in higher dimensions. Extensive evaluations on MNIST and CIFAR-10 for four deep neural networks demonstrate HORD significantly outperforms the well-established Bayesian optimization methods such as GP, SMAC, and TPE. For instance, on average, HORD is more than 6 times faster than GP-EI in obtaining the best configuration of 19 hyperparameters.},
	urldate = {2017-11-13},
	author = {Ilievski, Ilija and Akhtar, Taimoor and Feng, Jiashi and Shoemaker, Christine Annette},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.08316},
}

@article{klein_fast_nodate,
	title = {Fast {Bayesian} {Optimization} of {Machine} {Learning} {Hyperparameters} on {Large} {Datasets}},
	abstract = {Bayesian optimization has become a successful tool for hyperparameter optimization of machine learning algorithms, such as support vector ma-chines or deep neural networks. Despite its suc-cess, for large datasets, training and validating a single configuration often takes hours, days, or even weeks, which limits the achievable perfor-mance. To accelerate hyperparameter optimiza-tion, we propose a generative model for the valida-tion error as a function of training set size, which is learned during the optimization process and al-lows exploration of preliminary configurations on small subsets, by extrapolating to the full dataset. We construct a Bayesian optimization procedure, dubbed FABOLAS, which models loss and train-ing time as a function of dataset size and auto-matically trades off high information gain about the global optimum against computational cost. Experiments optimizing support vector machines and deep neural networks show that FABOLAS often finds high-quality solutions 10 to 100 times faster than other state-of-the-art Bayesian opti-mization methods or the recently proposed bandit strategy Hyperband.},
	urldate = {2017-11-13},
	author = {Klein, Aaron and Falkner, Stefan and Bartels, Simon and Hennig, Philipp and Hutter, Frank},
}

@incollection{jia_qim:_2016,
	title = {{QIM}: {Quantifying} {Hyperparameter} {Importance} for {Deep} {Learning}},
	url = {http://link.springer.com/10.1007/978-3-319-47099-3_15},
	urldate = {2017-11-13},
	publisher = {Springer, Cham},
	author = {Jia, Dan and Wang, Rui and Xu, Chengzhong and Yu, Zhibin},
	month = oct,
	year = {2016},
	doi = {10.1007/978-3-319-47099-3_15},
	pages = {180--188},
}

@article{takadama_special_2017,
	title = {Special {Issue} on {Cutting} {Edge} of {Reinforcement} {Learning} and its {Hybrid} {Methods}},
	volume = {21},
	issn = {1883-8014},
	url = {https://www.fujipress.jp/jaciii/jc/jacii002100050833},
	doi = {10.20965/jaciii.2017.p0833},
	abstract = {{\textless}p{\textgreater}Machine learning has been attracting significant attention again since the potential of deep learning was recognized. Not only has machine learning been improved, but it has also been integrated with “reinforcement learning,” revealing other potential applications, e.g., deep Q-networks (DQN) and AlphaGO proposed by Google DeepMind. It is against this background that this special issue, “Cutting Edge of Reinforcement Learning and its Hybrid Methods,” focuses on both reinforcement learning and its hybrid methods, including reinforcement learning with deep learning or evolutionary computation, to explore new potentials of reinforcement learning.{\textless}/p{\textgreater}},
	number = {5},
	urldate = {2017-11-12},
	journal = {Journal of Advanced Computational Intelligence and Intelligent Informatics},
	author = {Takadama, Keiki and Miyazaki, Kazuteru},
	month = sep,
	year = {2017},
	pages = {833--833},
}

@article{Hutter,
	title = {Sequential {Model}-{Based} {Optimization} for {General} {Algorithm} {Configuration}},
	abstract = {State-of-the-art algorithms for hard computational problems often ex-pose many parameters that can be modified to improve empirical performance. However, manually exploring the resulting combinatorial space of parameter set-tings is tedious and tends to lead to unsatisfactory outcomes. Recently, automated approaches for solving this algorithm configuration problem have led to substantial improvements in the state of the art for solving various problems. One promising approach constructs explicit regression models to describe the dependence of target algorithm performance on parameter settings; however, this approach has so far been limited to the optimization of few numerical algorithm parameters on single instances. In this paper, we extend this paradigm for the first time to gen-eral algorithm configuration problems, allowing many categorical parameters and optimization for sets of instances. We experimentally validate our new algorithm configuration procedure by optimizing a local search and a tree search solver for the propositional satisfiability problem (SAT), as well as the commercial mixed integer programming (MIP) solver CPLEX. In these experiments, our procedure yielded state-of-the-art performance, and in many cases outperformed the previous best configuration approach.},
	urldate = {2017-11-11},
	author = {Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
}

@article{Li2017a,
	title = {{DEEP} {REINFORCEMENT} {LEARNING}: {AN} {OVERVIEW}},
	abstract = {We give an overview of recent exciting achievements of deep reinforcement learn-ing (RL). We discuss six core elements, six important mechanisms, and twelve applications. We start with background of machine learning, deep learning and reinforcement learning. Next we discuss core RL elements, including value func-tion, in particular, Deep Q-Network (DQN), policy, reward, model, planning, and exploration. After that, we discuss important mechanisms for RL, including at-tention and memory, unsupervised learning, transfer learning, multi-agent RL, hi-erarchical RL, and learning to learn. Then we discuss various applications of RL, including games, in particular, AlphaGo, robotics, natural language processing, including dialogue systems, machine translation, and text generation, computer vision, neural architecture design, business management, finance, healthcare, In-dustry 4.0, smart grid, intelligent transportation systems, and computer systems. We mention topics not reviewed yet, and list a collection of RL resources. After presenting a brief summary, we close with discussions. This is the first overview about deep reinforcement learning publicly available online. It is comprehensive. Comments and criticisms are welcome.},
	urldate = {2017-11-11},
	author = {Li, Yuxi},
	year = {2017},
	note = {arXiv: 1701.07274v5},
}

@article{Diaz2017,
	title = {An effective algorithm for hyperparameter optimization of neural networks},
	url = {http://arxiv.org/abs/1705.08520},
	abstract = {A major challenge in designing neural network (NN) systems is to determine the best structure and parameters for the network given the data for the machine learning problem at hand. Examples of parameters are the number of layers and nodes, the learning rates, and the dropout rates. Typically, these parameters are chosen based on heuristic rules and manually fine-tuned, which may be very time-consuming, because evaluating the performance of a single parametrization of the NN may require several hours. This paper addresses the problem of choosing appropriate parameters for the NN by formulating it as a box-constrained mathematical optimization problem, and applying a derivative-free optimization tool that automatically and effectively searches the parameter space. The optimization tool employs a radial basis function model of the objective function (the prediction accuracy of the NN) to accelerate the discovery of configurations yielding high accuracy. Candidate configurations explored by the algorithm are trained to a small number of epochs, and only the most promising candidates receive full training. The performance of the proposed methodology is assessed on benchmark sets and in the context of predicting drug-drug interactions, showing promising results. The optimization tool used in this paper is open-source.},
	urldate = {2017-11-11},
	author = {Diaz, Gonzalo and Fokoue, Achille and Nannicini, Giacomo and Samulowitz, Horst},
	month = may,
	year = {2017},
	note = {arXiv: 1705.08520},
}

@inproceedings{bergstra_algorithms_2011,
	title = {Algorithms for {Hyper}-{Parameter} {Optimization}},
	isbn = {978-1-61839-599-3},
	doi = {2012arXiv1206.2944S},
	abstract = {Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel ap-proaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it pos-sible to run more trials and we show that algorithmic approaches can find better results. We present hyper-parameter optimization results on tasks of training neu-ral networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the ex-pected improvement criterion. Random search has been shown to be sufficiently efficient for learning neural networks for several datasets, but we show it is unreli-able for training DBNs. The sequential algorithms are applied to the most difficult DBN learning problems from [1] and find significantly better results than the best previously reported. This work contributes novel techniques for making response surface models P (y{\textbar}x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} ({NIPS})},
	author = {Bergstra, James and Bardenet, Rémi and Bengio, Yoshua and Kégl, Balázs},
	year = {2011},
	pmid = {9377276},
	note = {arXiv: 1206.2944
ISSN: 10495258},
}

@article{kawaguchi_global_2016,
	title = {Global continuous optimization with error bound and fast convergence},
	issn = {10769757},
	doi = {10.1613/jair.4742},
	abstract = {This paper considers global optimization with a black-box unknown objective function that can be non-convex and non-differentiable. Such a difficult optimization problem arises in many real-world applications, such as parameter tuning in machine learning, engineering design problem, and planning with a complex physics simulator. This paper proposes a new global optimization algorithm, called Locally Oriented Global Optimization (LOGO), to aim for both fast convergence in practice and finite-time error bound in theory. The advantage and usage of the new algorithm are illustrated via theoretical analysis and an experiment conducted with 11 benchmark test functions. Further, we modify the LOGO algorithm to specifically solve a planning problem via policy search with continuous state/action space and long time horizon while maintaining its finite-time error bound. We apply the proposed planning method to accident management of a nuclear power plant. The result of the application study demonstrates the practical utility of our method.},
	journal = {Journal of Artificial Intelligence Research},
	author = {Kawaguchi, Kenji and Maruyama, Yu and Zheng, Xiaoyu},
	year = {2016},
	note = {arXiv: 1607.04817},
}

@article{russo_learning_2014,
	title = {Learning to {Optimize} via {Posterior} {Sampling}},
	issn = {0364-765X},
	doi = {10.1287/moor.2014.0650},
	abstract = {This paper considers the use of a simple posterior sampling algorithm to balance between exploration and exploitation when learning to optimize actions such as in multiarmed bandit problems. The algorithm, also known as Thompson Sampling and as probability matching, offers significant advantages over the popular upper confidence bound (UCB) approach, and can be applied to problems with finite or infinite action spaces and complicated relationships among action rewards. We make two theoretical contributions. The first establishes a connection between posterior sampling and UCB algorithms. This result lets us convert regret bounds developed for UCB algorithms into Bayesian regret bounds for posterior sampling. Our second theoretical contribution is a Bayesian regret bound for posterior sampling that applies broadly and can be specialized to many model classes. This bound depends on a new notion we refer to as the eluder dimension, which measures the degree of dependence among action rewards. Compared to UCB algorithm Bayesian regret bounds for specific model classes, our general bound matches the best available for linear models and is stronger than the best available for generalized linear models. Further, our analysis provides insight into performance advantages of posterior sampling, which are highlighted through simulation results that demonstrate performance surpassing recently proposed UCB algorithms.},
	journal = {Mathematics of Operations Research},
	author = {Russo, Daniel and Van Roy, Benjamin},
	year = {2014},
	pmid = {28028460},
	note = {arXiv: 1301.2609v5
ISBN: 0364-765X},
}

@inproceedings{burnett_gender_2010,
	address = {New York, New York, USA},
	title = {Gender {HCI}},
	isbn = {978-1-4503-0403-0},
	url = {http://portal.acm.org/citation.cfm?doid=1878450.1878493},
	doi = {10.1145/1878450.1878493},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 28th {ACM} {International} {Conference} on {Design} of {Communication} - {SIGDOC} '10},
	publisher = {ACM Press},
	author = {Burnett, Margaret M. and M., Margaret},
	year = {2010},
	keywords = {HCI, gender HCI, user demographics},
	pages = {251},
}

@article{srinivas_gaussian_2009,
	title = {Gaussian {Process} {Optimization} in the {Bandit} {Setting}: {No} {Regret} and {Experimental} {Design}},
	url = {http://arxiv.org/abs/0912.3995},
	doi = {10.1109/TIT.2011.2182033},
	abstract = {Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multi-armed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches.},
	urldate = {2017-11-10},
	author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M. and Seeger, Matthias},
	month = dec,
	year = {2009},
	note = {arXiv: 0912.3995},
}

@book{Weise2011,
	title = {Global {Optimization} - {Theory} {And} {Application}},
	author = {Weise, T.},
	year = {2011},
}

@article{bodlaender_tourist_1993,
	title = {A tourist guide through treewidth},
	volume = {11},
	abstract = {A short overview is given of many recent results in algorithmic graph theory that deal with the notions treewidth, and pathwidth. We discuss algorithms that find tree-decompositions, algorithms that use tree-decompositions to solve hard problems efficiently, graph minor theory, and some applications. The paper contains an extensive bibliography.},
	number = {1-2},
	urldate = {2017-11-08},
	journal = {Acta Cybernetica},
	author = {Bodlaender, H. L.},
	year = {1993},
	keywords = {graph, np complete, tree decompostion, treewidth},
}

@article{Shcherbina2007,
	title = {Tree decomposition and discrete optimization problems: {A} survey},
	volume = {43},
	issn = {1060-0396},
	url = {http://link.springer.com/10.1007/s10559-007-0080-4},
	doi = {10.1007/s10559-007-0080-4},
	number = {4},
	urldate = {2017-11-08},
	journal = {Cybernetics and Systems Analysis},
	author = {Shcherbina, O. A.},
	month = jul,
	year = {2007},
	note = {Publisher: Springer US},
	pages = {549--562},
}

@misc{noauthor_final_nodate,
	title = {Final {CMPT705}},
	url = {https://canvas.sfu.ca/courses/35408/files?preview=6874978},
	urldate = {2017-11-05},
}

@article{aspvall_linear-time_nodate,
	title = {A {LINEAR}-{TIME} {ALGORITHM} {FOR} {TESTING} {THE} {TRUTH} {OF} {CERTAIN} {QUANTIFIED} {BOOLEAN} {FORMULAS} *},
	urldate = {2017-11-05},
	author = {Aspvall, Bengt and Plass, Michael F and Tarjan, Robert Endre},
}

@article{Edmonds1965,
	title = {Paths, trees, and flowers},
	volume = {17},
	issn = {1496-4279},
	url = {https://cms.math.ca/10.4153/CJM-1965-045-4},
	doi = {10.4153/CJM-1965-045-4},
	number = {0},
	urldate = {2017-11-05},
	journal = {Canadian Journal of Mathematics},
	author = {Edmonds, Jack},
	month = jan,
	year = {1965},
	pages = {449--467},
}

@article{Yang,
	title = {A {Graph} {Regularized} {Deep} {Neural} {Network} for {Unsupervised} {Image} {Representation} {Learning}},
	abstract = {Deep Auto-Encoder (DAE) has shown its promising pow-er in high-level representation learning. From the per-spective of manifold learning, we propose a graph reg-ularized deep neural network (GR-DNN) to endue tradi-tional DAEs with the ability of retaining local geometric structure. A deep-structured regularizer is formulated upon multi-layer perceptions to capture this structure. The robust and discriminative embedding space is learned to simulta-neously preserve the high-level semantics and the geomet-ric structure within local manifold tangent space. Theo-retical analysis presents the close relationship between the proposed graph regularizer and the graph Laplacian regu-larizer in terms of the optimization objective. We also al-leviate the growth of the network complexity by introduc-ing the anchor-based bipartite graph, which guarantees the good scalability for large scale data. The experiments on four datasets show the comparable results of the proposed GR-DNN with the state-of-the-art methods.},
	urldate = {2017-11-05},
	author = {Yang, Shijie and Li, Liang and Wang, Shuhui and Zhang, Weigang and Huang, Qingming},
}

@article{noauthor_mindmap_nodate,
	title = {Mindmap},
}

@misc{noauthor_c1uncertainty_nodate,
	title = {c1uncertainty},
}

@article{Sun2017,
	title = {Quantifying {Variable} {Interactions} in {Continuous} {Optimization} {Problems}},
	volume = {21},
	issn = {1089-778X},
	url = {http://ieeexplore.ieee.org/document/7539575/},
	doi = {10.1109/TEVC.2016.2599164},
	number = {2},
	urldate = {2017-10-27},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Sun, Yuan and Kirley, Michael and Halgamuge, Saman K.},
	month = apr,
	year = {2017},
	pages = {249--264},
}

@book{Saparbaev,
	title = {{CLRS}},
	author = {Saparbaev, M K and Mazin, a V and Ovchinnikova, L P and Dianov, G L and Salganik, R I},
}

@article{noauthor_algorithm_1989,
	title = {An algorithm for transitive reduction of an acyclic graph},
	volume = {12},
	issn = {0167-6423},
	url = {http://www.sciencedirect.com/science/article/pii/0167642389900397},
	doi = {10.1016/0167-6423(89)90039-7},
	number = {2},
	urldate = {2017-10-17},
	journal = {Science of Computer Programming},
	month = jul,
	year = {1989},
	note = {Publisher: Elsevier},
	pages = {151--155},
}

@article{loubiere_sensitivity_2017,
	title = {A sensitivity analysis method aimed at enhancing the metaheuristics for continuous optimization},
	issn = {0269-2821},
	url = {http://link.springer.com/10.1007/s10462-017-9553-7},
	doi = {10.1007/s10462-017-9553-7},
	urldate = {2017-10-16},
	journal = {Artificial Intelligence Review},
	author = {Loubière, Peio and Jourdan, Astrid and Siarry, Patrick and Chelouah, Rachid},
	month = apr,
	year = {2017},
	note = {Publisher: Springer Netherlands},
	pages = {1--23},
}

@article{box_evolutionary_1957,
	title = {Evolutionary {Operation}: {A} {Method} for {Increasing} {Industrial} {Productivity}},
	volume = {6},
	issn = {00359254},
	url = {http://www.jstor.org/stable/10.2307/2985505?origin=crossref},
	doi = {10.2307/2985505},
	number = {2},
	urldate = {2017-10-13},
	journal = {Applied Statistics},
	author = {Box, George E. P.},
	month = jun,
	year = {1957},
	pages = {81},
}

@incollection{vuchkov_quality_2001,
	title = {Quality {Improvement} through {Mechanistic} {Models}},
	url = {http://link.springer.com/10.1007/978-94-009-0009-7_8},
	urldate = {2017-10-13},
	author = {Vuchkov, Ivan N. and Boyadjieva, Lidia N.},
	year = {2001},
	doi = {10.1007/978-94-009-0009-7_8},
	pages = {388--421},
}

@incollection{vuchkov_quality_2001-1,
	title = {Quality {Improvement} of {Products} {Depending} on {Both} {Qualitative} and {Quantitative} {Factors}},
	url = {http://link.springer.com/10.1007/978-94-009-0009-7_9},
	urldate = {2017-10-13},
	author = {Vuchkov, Ivan N. and Boyadjieva, Lidia N.},
	year = {2001},
	doi = {10.1007/978-94-009-0009-7_9},
	pages = {422--452},
}

@incollection{vuchkov_design_2001,
	title = {Design of {Regression} {Experiments}},
	url = {http://link.springer.com/10.1007/978-94-009-0009-7_3},
	urldate = {2017-10-13},
	author = {Vuchkov, Ivan N. and Boyadjieva, Lidia N.},
	year = {2001},
	doi = {10.1007/978-94-009-0009-7_3},
	pages = {96--189},
}

@incollection{vuchkov_quality_2001-2,
	title = {Quality {Improvement} through {Reduction} of the {Errors} {Transmitted} from the {Factors} to the {Response}},
	url = {http://link.springer.com/10.1007/978-94-009-0009-7_5},
	urldate = {2017-10-13},
	author = {Vuchkov, Ivan N. and Boyadjieva, Lidia N.},
	year = {2001},
	doi = {10.1007/978-94-009-0009-7_5},
	pages = {237--286},
}

@incollection{vuchkov_optimization_2001,
	title = {Optimization {Procedures} for {Robust} {Design} of {Products} and {Processes} with {Errors} in the {Factors}},
	url = {http://link.springer.com/10.1007/978-94-009-0009-7_6},
	urldate = {2017-10-13},
	author = {Vuchkov, Ivan N. and Boyadjieva, Lidia N.},
	year = {2001},
	doi = {10.1007/978-94-009-0009-7_6},
	pages = {287--343},
}

@incollection{vuchkov_robustness_2001,
	title = {Robustness against {Both} {Errors} in {Product} {Parameters} and {External} {Noise} {Factors}},
	url = {http://link.springer.com/10.1007/978-94-009-0009-7_7},
	urldate = {2017-10-13},
	author = {Vuchkov, Ivan N. and Boyadjieva, Lidia N.},
	year = {2001},
	doi = {10.1007/978-94-009-0009-7_7},
	pages = {344--387},
}

@incollection{vuchkov_other_2001,
	title = {Other {Methods} for {Model} {Based} {Quality} {Improvement}},
	url = {http://link.springer.com/10.1007/978-94-009-0009-7_10},
	urldate = {2017-10-13},
	author = {Vuchkov, Ivan N. and Boyadjieva, Lidia N.},
	year = {2001},
	doi = {10.1007/978-94-009-0009-7_10},
	pages = {453--481},
}

@book{vuchkov_quality_2001-3,
	title = {Quality improvement with design of experiments : a response surface approach},
	isbn = {978-0-7923-6827-4},
	abstract = {1. Introduction to Quality Improvement -- 2. Statistical Methods for Data Analysis -- 3. Design of Regression Experiments -- 4. Taguchi's Approach to Quality Improvement -- 5. Quality Improvement through Reduction of the Errors Transmitted from the Factors to the Response -- 6. Optimization Procedures for Robust Design of Products and Processes with Errors in the Factors -- 7. Robustness Against Both Errors in Product Parameters and External Noise Factors -- 8. Quality Improvement through Mechanistic Models -- 9. Quality Improvement of Products Depending on Both Quality and Quantitive Factors -- 10. Other Methods for Model Based Quality Improvement.},
	urldate = {2017-10-13},
	publisher = {Kluwer Academic Publishers},
	author = {Vuchkov, Ivan Nikolov. and Boyadjieva, Lidia N.},
	year = {2001},
}

@book{faber_statistics_2012,
	title = {Statistics and probability theory : in pursuit of engineering decision support},
	abstract = {This book provides the reader with the basic skills and tools of statistics and probability in the context of engineering modeling and analysis. The emphasis is on the application and the reasoning behind the application of these skills and tools for the purpose of enhancing decision making in engineering. The purpose of the book is to ensure that the reader will acquire the required theoretical basis and technical skills such as to feel comfortable with the theory of basic statistics and probability. Moreover, in this book, as opposed to many standard books on the same subject, the perspective is to focus on the use of the theory for the purpose of engineering model building and decision making. This work is suitable for readers with little or no prior knowledge on the subject of statistics and probability. Engineering Decisions Under Uncertainty -- Basic Probability Theory -- Descriptive Statistics -- Uncertainty Modeling -- Estimation and Model Building -- Methods of Structural Reliability -- Bayesian Decision Analysis.},
	urldate = {2017-10-13},
	publisher = {Springer},
	author = {Faber, M. H. (Michael Havbro)},
	year = {2012},
	note = {ISSN: 1566-0443},
}

@incollection{vuchkov_taguchis_2001,
	title = {Taguchi’s {Approach} to {Quality} {Improvement}},
	url = {http://link.springer.com/10.1007/978-94-009-0009-7_4},
	urldate = {2017-10-13},
	author = {Vuchkov, Ivan N. and Boyadjieva, Lidia N.},
	year = {2001},
	doi = {10.1007/978-94-009-0009-7_4},
	pages = {190--236},
}

@incollection{vuchkov_introduction_2001,
	title = {Introduction to {Quality} {Improvement}},
	url = {http://link.springer.com/10.1007/978-94-009-0009-7_1},
	urldate = {2017-10-13},
	author = {Vuchkov, Ivan N. and Boyadjieva, Lidia N.},
	year = {2001},
	doi = {10.1007/978-94-009-0009-7_1},
	pages = {1--13},
}

@incollection{vuchkov_statistical_2001,
	title = {Statistical {Methods} for {Data} {Analysis}},
	url = {http://link.springer.com/10.1007/978-94-009-0009-7_2},
	urldate = {2017-10-13},
	author = {Vuchkov, Ivan N. and Boyadjieva, Lidia N.},
	year = {2001},
	doi = {10.1007/978-94-009-0009-7_2},
	pages = {14--95},
}

@article{viana_0_nodate,
	title = {0 th {World} {Congress} on {Structural} and {Multidisciplinary} {Optimization} {Things} you wanted to know about the {Latin} hypercube design and were afraid to ask},
	abstract = {1. Abstract The growing power of computers enabled techniques coined for design and analysis of simulations to be applied to a large spectrum of problems and to reach high level of acceptance among practitioners. Generally, when simulations are time consuming, a surrogate model replaces the computer code in further studies. The very first step for successful surrogate modeling and statistical analysis is the planning of the input configuration that will be used to exercise the simulation code. Among strategies coined for computer experiments, Latin hypercube designs have become particularly popular. This paper provides a short overview of the research in Latin hypercube design of experiments, highlighting potential reasons of its widespread use. The discussion starts with the early developments in optimization of the point selection and goes all the way to the pitfalls of always using Latin hypercube designs for selecting experimental designs. Then, final thoughts are given on how the Latin hypercube design fits in the state of the art as well as opportunities for future research. 2. Keywords: Design and analysis of computer experiments, Latin hypercube sampling, space-filling designs, sequential sampling.},
	urldate = {2017-10-13},
	author = {Viana, Felipe A C},
}

@book{conference_on_advances_in_neural_information_processing_systems._2006_vancouver_advances_2007,
	title = {Advances in neural information processing systems 19 : proceedings of the 2006 conference},
	url = {https://dash.harvard.edu/handle/1/11708816},
	abstract = {The annual Neural Information Processing Systems (NIPS) conference is the flagship meeting on neural computation and machine learning. This volume contains the papers presented at the December 2006 meeting, held in Vancouver.},
	urldate = {2017-10-13},
	publisher = {MIT Press},
	author = {Conference on Advances in Neural Information Processing Systems. 2006 Vancouver, B.C.) and Schölkopf, Bernhard. and Platt, John C. and Hofmann, Thomas.},
	year = {2007},
	note = {ISSN: 1049-5258},
	keywords = {Conference Paper},
}

@article{bergstra_jamesbergstra_random_2012,
	title = {Random {Search} for {Hyper}-{Parameter} {Optimization}},
	volume = {13},
	abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimiza-tion. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a compar-ison with a large previous study that used grid search and manual search to configure neural net-works and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising con-figuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent " High Throughput " methods achieve surprising success—they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural base-line against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
	urldate = {2017-10-13},
	journal = {Journal of Machine Learning Research},
	author = {Bergstra JAMESBERGSTRA, James and Yoshua Bengio YOSHUABENGIO, Umontrealca},
	year = {2012},
	keywords = {deep learning, global optimization, model selection, neural networks, response surface modeling},
	pages = {281--305},
}

@misc{noauthor_most_nodate,
	title = {The most efficient techniques to fine tune hyperparameters in deep learning - {Quora}},
	url = {https://www.quora.com/What-are-the-most-efficient-techniques-to-fine-tune-hyperparameters-in-deep-learning},
	urldate = {2017-10-13},
}

@article{heinrich_efficient_1996,
	title = {{EFFICIENT} {ALGORITHMS} {FOR} {COMPUTING} {THE} {L} 2 -{DISCREPANCY}},
	volume = {65},
	abstract = {The L 2 -discrepancy is a quantitative measure of precision for mul-tivariate quadrature rules. It can be computed explicitly. Previously known algorithms needed O(m 2) operations, where m is the number of nodes. In this paper we present algorithms which require O(m(log m) d) operations.},
	urldate = {2017-10-13},
	journal = {MATHEMATICS OF COMPUTATION},
	author = {Heinrich, S},
	year = {1996},
	pages = {1621--1633},
}

@article{aerts_decoding_2014,
	title = {Decoding tumour phenotype by noninvasive imaging using a quantitative radiomics approach},
	volume = {5},
	issn = {2041-1723},
	url = {http://www.nature.com/doifinder/10.1038/ncomms5006},
	doi = {10.1038/ncomms5006},
	abstract = {{\textless}p{\textgreater}
An individual tumour is often heterogeneous and its various features can be visualised noninvasively using medical imaging. Here, the authors analyse large computed tomography data sets using radiomic algorithms to identify heterogeneity, and find that some of these tumo\&hellip;{\textless}/p{\textgreater}},
	urldate = {2017-10-12},
	journal = {Nature Communications},
	author = {Aerts, Hugo J. W. L. and Velazquez, Emmanuel Rios and Leijenaar, Ralph T. H. and Parmar, Chintan and Grossmann, Patrick and Cavalho, Sara and Bussink, Johan and Monshouwer, René and Haibe-Kains, Benjamin and Rietveld, Derek and Hoebers, Frank and Rietbergen, Michelle M. and Leemans, C. René and Dekker, Andre and Quackenbush, John and Gillies, Robert J. and Lambin, Philippe},
	month = jun,
	year = {2014},
	note = {Publisher: Nature Publishing Group},
	keywords = {Cancer imaging, Medical research},
	pages = {ncomms5006},
}

@book{By,
	title = {Artificial {Intelligence} a {Modern} {Approach}},
	isbn = {978-0-13-604259-4},
	author = {By, Uploaded},
}

@article{noauthor_formulation_2003,
	title = {Formulation of the {Audze}–{Eglais} {Uniform} {Latin} {Hypercube} design of experiments},
	volume = {34},
	issn = {0965-9978},
	url = {http://www.sciencedirect.com/science/article/pii/S0965997803000425},
	doi = {10.1016/S0965-9978(03)00042-5},
	number = {8},
	urldate = {2017-10-06},
	journal = {Advances in Engineering Software},
	month = aug,
	year = {2003},
	note = {Publisher: Elsevier},
	pages = {493--506},
}

@article{noauthor_modification_2016,
	title = {Modification of the {Audze}–{Eglājs} criterion to achieve a uniform distribution of sampling points},
	volume = {100},
	issn = {0965-9978},
	url = {http://www.sciencedirect.com/science/article/pii/S0965997816301776},
	doi = {10.1016/J.ADVENGSOFT.2016.07.004},
	urldate = {2017-10-06},
	journal = {Advances in Engineering Software},
	month = oct,
	year = {2016},
	note = {Publisher: Elsevier},
	pages = {82--96},
}

@article{janouchova_competitive_nodate,
	title = {Competitive {Comparison} of {Optimal} {Designs} of {Experiments} for {Sampling}-based {Sensitivity} {Analysis}},
	abstract = {Nowadays, the numerical models of real-world structures are more precise, more complex and, of course, more time-consuming. Despite the growth of a computational performance, the exploration of model behaviour remains a complex task. The sensitivity analysis is a basic tool for investigating the sensitivity of the model to its inputs. One widely used strategy to assess the sensitivity is based on a finite set of simulations for a given sets of input parameters, i.e. points in the design space. An estimate of the sensitivity can be then obtained by computing correlations between the input parameters and the chosen response of the model. The accuracy of the sensitivity prediction depends on the choice of design points called the design of experiments. The aim of the presented paper is to review and compare available criteria for the assessment of design of experiments suitable for sampling-based sensitivity analysis.},
	urldate = {2017-10-06},
	author = {Janouchová, Eliška and Kučerová, Anna},
	keywords = {Design of experiments, Latin Hypercube Sampling, Orthogonality, Sampling-based sensitivity analysis, Space-filling},
}

@article{Fuerle2011,
	title = {Formulation of the {Audze}–{Eglais} uniform {Latin} hypercube design of experiments for constrained design spaces},
	volume = {42},
	issn = {09659978},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0965997811001116},
	doi = {10.1016/j.advengsoft.2011.05.004},
	number = {9},
	urldate = {2017-10-06},
	journal = {Advances in Engineering Software},
	author = {Fuerle, Fabian and Sienz, Johann},
	month = sep,
	year = {2011},
	note = {Publisher: Elsevier Science Ltd.},
	keywords = {Audze-Eglais, Constrained design space, Design of experiments, Optimal Latin Hypercubes, Permutation genetic algorithm, Surrogate based optimization},
	pages = {680--689},
}

@article{arnborg_linear_1989,
	title = {Linear time algorithms for {NP}-hard problems restricted to partial k-trees},
	volume = {23},
	issn = {0166218X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0166218X89900310},
	doi = {10.1016/0166-218X(89)90031-0},
	number = {1},
	urldate = {2017-10-06},
	journal = {Discrete Applied Mathematics},
	author = {Arnborg, Stefan and Proskurowski, Andrzej},
	month = apr,
	year = {1989},
	pages = {11--24},
}

@article{halin_s-functions_1976,
	title = {S-functions for graphs},
	volume = {8},
	issn = {0047-2468},
	url = {http://link.springer.com/10.1007/BF01917434},
	doi = {10.1007/BF01917434},
	number = {1-2},
	urldate = {2017-10-06},
	journal = {Journal of Geometry},
	author = {Halin, Rudolf},
	month = mar,
	year = {1976},
	pages = {171--186},
}

@article{robertson_graph_1984,
	title = {Graph minors. {III}. {Planar} tree-width},
	volume = {36},
	issn = {00958956},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0095895684900133},
	doi = {10.1016/0095-8956(84)90013-3},
	number = {1},
	urldate = {2017-10-06},
	journal = {Journal of Combinatorial Theory, Series B},
	author = {Robertson, Neil and Seymour, P.D},
	month = feb,
	year = {1984},
	pages = {49--64},
}

@book{Bertele1972,
	title = {Nonserial dynamic programming},
	isbn = {0-12-093450-7},
	urldate = {2017-10-06},
	publisher = {Academic Press},
	author = {Bertelè, Umberto. and Brioschi, Francesco},
	year = {1972},
}

@book{Diestel2005,
	edition = {3rd},
	title = {Graph theory},
	isbn = {3-540-26182-6},
	url = {http://www.math.uni-hamburg.de/home/diestel/books/graph.theory/},
	abstract = {3rd ed. The basics -- Matching, covering and packing -- Connectivity -- Planar graphs -- Colouring -- Flows -- Extremal graph theory -- Infinite graphs -- Ramsey theory for graphs -- Hamilton cycles -- Random graphs -- Minors, trees, and WQO.},
	urldate = {2017-10-06},
	publisher = {Springer},
	author = {Diestel, Reinhard.},
	year = {2005},
}

@article{arnborg_complexity_1987,
	title = {Complexity of {Finding} {Embeddings} in a \textit{k} -{Tree}},
	volume = {8},
	issn = {0196-5212},
	url = {http://epubs.siam.org/doi/10.1137/0608024},
	doi = {10.1137/0608024},
	number = {2},
	urldate = {2017-10-06},
	journal = {SIAM Journal on Algebraic Discrete Methods},
	author = {Arnborg, Stefan and Corneil, Derek G. and Proskurowski, Andrzej},
	month = apr,
	year = {1987},
	pages = {277--284},
}

@article{bern_linear-time_1987,
	title = {Linear-time computation of optimal subgraphs of decomposable graphs},
	volume = {8},
	issn = {01966774},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0196677487900393},
	doi = {10.1016/0196-6774(87)90039-3},
	number = {2},
	urldate = {2017-10-06},
	journal = {Journal of Algorithms},
	author = {Bern, M.W and Lawler, E.L and Wong, A.L},
	month = jun,
	year = {1987},
	pages = {216--235},
}

@article{noauthor_tree_nodate,
	title = {Tree decomposition},
	urldate = {2017-10-06},
}

@article{noauthor_tourist_nodate,
	title = {A tourist guide through treewidth},
	urldate = {2017-10-06},
}

@misc{noauthor_graphs_nodate,
	title = {graphs - {Tree} decomposition - {Fastest} algorithm in practise - {Computer} {Science} {Stack} {Exchange}},
	url = {https://cs.stackexchange.com/questions/41651/tree-decomposition-fastest-algorithm-in-practise},
	urldate = {2017-10-06},
}

@incollection{csurka_fisher_2011,
	title = {Fisher {Vectors}: {Beyond} {Bag}-of-{Visual}-{Words} {Image} {Representations}},
	url = {http://link.springer.com/10.1007/978-3-642-25382-9_2},
	urldate = {2017-10-05},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Csurka, Gabriela and Perronnin, Florent},
	year = {2011},
	doi = {10.1007/978-3-642-25382-9_2},
	pages = {28--42},
}

@article{Russo2017,
	title = {A {Tutorial} on {Thompson} {Sampling}},
	url = {http://arxiv.org/abs/1707.02038},
	abstract = {Thompson sampling is an algorithm for online decision problems where actions are taken sequentially in a manner that must balance between exploiting what is known to maximize immediate performance and investing to accumulate new information that may improve future performance. The algorithm addresses a broad range of problems in a computationally efficient manner and is therefore enjoying wide use. This tutorial covers the algorithm and its application, illustrating concepts through a range of examples, including Bernoulli bandit problems, shortest path problems, dynamic pricing, recommendation, active learning with neural networks, and reinforcement learning in Markov decision processes. Most of these problems involve complex information structures, where information revealed by taking an action informs beliefs about other actions. We will also discuss when and why Thompson sampling is or is not effective and relations to alternative algorithms.},
	urldate = {2017-10-05},
	author = {Russo, Daniel and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.02038},
}

@article{ali_multi-resolution_2015,
	title = {Multi-resolution {MRI} {Brain} {Image} {Segmentation} {Based} on {Morphological} {Pyramid} and {Fuzzy} {C}-mean {Clustering}},
	volume = {40},
	issn = {1319-8025},
	url = {http://link.springer.com/10.1007/s13369-015-1791-x},
	doi = {10.1007/s13369-015-1791-x},
	number = {11},
	urldate = {2017-09-30},
	journal = {Arabian Journal for Science and Engineering},
	author = {Ali, Hala and Elmogy, Mohammed and El-Daydamony, Eman and Atwan, Ahmed},
	month = nov,
	year = {2015},
	note = {Publisher: Springer Berlin Heidelberg},
	pages = {3173--3185},
}

@article{quinn_parallel_1984,
	title = {Parallel graph algorithms},
	volume = {16},
	issn = {03600300},
	url = {http://portal.acm.org/citation.cfm?doid=2514.2515},
	doi = {10.1145/2514.2515},
	number = {3},
	urldate = {2017-09-29},
	journal = {ACM Computing Surveys},
	author = {Quinn, Michael J. and Deo, Narsingh},
	month = sep,
	year = {1984},
	note = {Publisher: ACM},
	pages = {319--348},
}

@article{Malyshkin2001,
	title = {Parallel {Computing} {Technologies}},
	volume = {17},
	doi = {10.1007/978-3-319-62932-2},
	number = {6},
	journal = {Elsevier Future Generation Computer Systems},
	author = {Malyshkin, Victor E},
	year = {2001},
	note = {ISBN: 978-3-319-62931-5},
	pages = {667--668},
}

@article{ediger_ieee_nodate,
	title = {{IEEE} {TRANSACTIONS} {ON} {PARALLEL} {AND} {DISTRIBUTED} {SYSTEMS} {GraphCT}: {Multithreaded} {Algorithms} for {Massive} {Graph} {Analysis}},
	doi = {10.1109/TPDS.2012.323},
	abstract = {—The digital world has given rise to massive quantities of data that include rich semantic and complex networks. A social graph, for example, containing hundreds of millions of actors and tens of billions of relationships is not uncommon. Analyzing these large datasets, even to answer simple analytic queries, often pushes the limits of algorithms and machine architectures. We present GraphCT, a scalable framework for graph analysis using parallel and multithreaded algorithms on shared memory platforms. Utilizing the unique characteristics of the Cray XMT, GraphCT enables fast network analysis at unprecedented scales on a variety of input datasets. On a synthetic power law graph with 2 billion vertices and 17 billion edges, we can find the connected components in under 2 minutes. We can estimate the betweenness centrality of a similar graph with 537 million vertices and over 8 billion edges in under one hour. GraphCT is built for portability and performance.},
	urldate = {2017-09-28},
	author = {Ediger, David and Jiang, Karl and Riedy, E Jason and Bader, David A},
	keywords = {Cray XMT, Index Terms—Graph algorithms, high-performance computing, multithreaded architectures, network analysis},
}

@misc{noauthor_parallel_nodate,
	title = {Parallel {Programming} for {Graph} {Analysis}},
	url = {https://www.cc.gatech.edu/~bader/papers/GraphAnalysisTutorial-PPoPP2012.html},
	urldate = {2017-09-28},
}

@incollection{Pardalos1998,
	title = {An {Exact} {Parallel} {Algorithm} for the {Maximum} {Clique} {Problem}},
	url = {http://link.springer.com/10.1007/978-1-4613-3279-4_18},
	urldate = {2017-09-28},
	publisher = {Springer, Boston, MA},
	author = {Pardalos, Panos M. and Rappe, Jonas and Resende, Mauricio G. C.},
	year = {1998},
	doi = {10.1007/978-1-4613-3279-4_18},
	pages = {279--300},
}

@article{ktena_distance_2017,
	title = {Distance {Metric} {Learning} using {Graph} {Convolutional} {Networks}: {Application} to {Functional} {Brain} {Networks}},
	url = {http://arxiv.org/abs/1703.02161},
	abstract = {Evaluating similarity between graphs is of major importance in several computer vision and pattern recognition problems, where graph representations are often used to model objects or interactions between elements. The choice of a distance or similarity metric is, however, not trivial and can be highly dependent on the application at hand. In this work, we propose a novel metric learning method to evaluate distance between graphs that leverages the power of convolutional neural networks, while exploiting concepts from spectral graph theory to allow these operations on irregular graphs. We demonstrate the potential of our method in the field of connectomics, where neuronal pathways or functional connections between brain regions are commonly modelled as graphs. In this problem, the definition of an appropriate graph similarity function is critical to unveil patterns of disruptions associated with certain brain disorders. Experimental results on the ABIDE dataset show that our method can learn a graph similarity metric tailored for a clinical application, improving the performance of a simple k-nn classifier by 11.9\% compared to a traditional distance metric.},
	urldate = {2017-09-27},
	author = {Ktena, Sofia Ira and Parisot, Sarah and Ferrante, Enzo and Rajchl, Martin and Lee, Matthew and Glocker, Ben and Rueckert, Daniel},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.02161},
}

@incollection{wong_building_2017,
	title = {Building {Disease} {Detection} {Algorithms} with {Very} {Small} {Numbers} of {Positive} {Samples}},
	url = {http://link.springer.com/10.1007/978-3-319-66179-7_54},
	urldate = {2017-09-27},
	publisher = {Springer, Cham},
	author = {Wong, Ken C. L. and Karargyris, Alexandros and Syeda-Mahmood, Tanveer and Moradi, Mehdi},
	month = sep,
	year = {2017},
	doi = {10.1007/978-3-319-66179-7_54},
	pages = {471--479},
}

@misc{noauthor_ieee_nodate,
	title = {{IEEE} {Xplore}: {Computer} - ( {Volume} 16 {Issue} 1 )},
	url = {http://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=34674},
	urldate = {2017-09-27},
}

@article{chen_neuron_2017,
	title = {Neuron {Segmentation} {Using} {Deep} {Complete} {Bipartite} {Networks}},
	url = {http://arxiv.org/abs/1705.11053},
	abstract = {In this paper, we consider the problem of automatically segmenting neuronal cells in dual-color confocal microscopy images. This problem is a key task in various quantitative analysis applications in neuroscience, such as tracing cell genesis in Danio rerio (zebrafish) brains. Deep learning, especially using fully convolutional networks (FCN), has profoundly changed segmentation research in biomedical imaging. We face two major challenges in this problem. First, neuronal cells may form dense clusters, making it difficult to correctly identify all individual cells (even to human experts). Consequently, segmentation results of the known FCN-type models are not accurate enough. Second, pixel-wise ground truth is difficult to obtain. Only a limited amount of approximate instance-wise annotation can be collected, which makes the training of FCN models quite cumbersome. We propose a new FCN-type deep learning model, called deep complete bipartite networks (CB-Net), and a new scheme for leveraging approximate instance-wise annotation to train our pixel-wise prediction model. Evaluated using seven real datasets, our proposed new CB-Net model outperforms the state-of-the-art FCN models and produces neuron segmentation results of remarkable quality},
	urldate = {2017-09-25},
	author = {Chen, Jianxu and Banerjee, Sreya and Grama, Abhinav and Scheirer, Walter J. and Chen, Danny Z.},
	month = may,
	year = {2017},
	note = {arXiv: 1705.11053},
}

@article{hauser_correlative_2017,
	title = {Correlative {Super}-{Resolution} {Microscopy}: {New} {Dimensions} and {New} {Opportunities}},
	volume = {117},
	issn = {0009-2665},
	url = {http://pubs.acs.org/doi/abs/10.1021/acs.chemrev.6b00604},
	doi = {10.1021/acs.chemrev.6b00604},
	abstract = {Correlative microscopy, the integration of two or more microscopy techniques performed on the same sample, produces results that emphasize the strengths of each technique while offsetting their individual weaknesses. Light microscopy has historically been a central method in correlative microscopy due to its widespread availability, compatibility with hydrated and live biological samples, and excellent molecular specificity through fluorescence labeling. However, conventional light microscopy can only achieve a resolution of ∼300 nm, undercutting its advantages in correlations with higher-resolution methods. The rise of super-resolution microscopy (SRM) over the past decade has drastically improved the resolution of light microscopy to ∼10 nm, thus creating exciting new opportunities and challenges for correlative microscopy. Here we review how these challenges are addressed to effectively correlate SRM with other microscopy techniques, including light microscopy, electron microscopy, cryomicroscopy, atom...},
	number = {11},
	urldate = {2017-09-20},
	journal = {Chemical Reviews},
	author = {Hauser, Meghan and Wojcik, Michal and Kim, Doory and Mahmoudi, Morteza and Li, Wan and Xu, Ke},
	month = jun,
	year = {2017},
	note = {Publisher: American Chemical Society},
	pages = {7428--7456},
}

@article{huang_three-dimensional_2008,
	title = {Three-dimensional super-resolution imaging by stochastic optical reconstruction microscopy.},
	volume = {319},
	issn = {1095-9203},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18174397},
	doi = {10.1126/science.1153529},
	abstract = {Recent advances in far-field fluorescence microscopy have led to substantial improvements in image resolution, achieving a near-molecular resolution of 20 to 30 nanometers in the two lateral dimensions. Three-dimensional (3D) nanoscale-resolution imaging, however, remains a challenge. We demonstrated 3D stochastic optical reconstruction microscopy (STORM) by using optical astigmatism to determine both axial and lateral positions of individual fluorophores with nanometer accuracy. Iterative, stochastic activation of photoswitchable probes enables high-precision 3D localization of each probe, and thus the construction of a 3D image, without scanning the sample. Using this approach, we achieved an image resolution of 20 to 30 nanometers in the lateral dimensions and 50 to 60 nanometers in the axial dimension. This development allowed us to resolve the 3D morphology of nanoscopic cellular structures.},
	number = {5864},
	urldate = {2017-09-19},
	journal = {Science (New York, N.Y.)},
	author = {Huang, Bo and Wang, Wenqin and Bates, Mark and Zhuang, Xiaowei},
	month = feb,
	year = {2008},
	pmid = {18174397},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {810--3},
}

@article{havaei_deep_2016,
	title = {Deep learning trends for focal brain pathology segmentation in {MRI}},
	url = {http://arxiv.org/abs/1607.05258},
	doi = {10.1007/978-3-319-50478-0_6},
	abstract = {Segmentation of focal (localized) brain pathologies such as brain tumors and brain lesions caused by multiple sclerosis and ischemic strokes are necessary for medical diagnosis, surgical planning and disease development as well as other applications such as tractography. Over the years, attempts have been made to automate this process for both clinical and research reasons. In this regard, machine learning methods have long been a focus of attention. Over the past two years, the medical imaging field has seen a rise in the use of a particular branch of machine learning commonly known as deep learning. In the non-medical computer vision world, deep learning based methods have obtained state-of-the-art results on many datasets. Recent studies in computer aided diagnostics have shown deep learning methods (and especially convolutional neural networks - CNN) to yield promising results. In this chapter, we provide a survey of CNN methods applied to medical imaging with a focus on brain pathology segmentation. In particular, we discuss their characteristic peculiarities and their specific configuration and adjustments that are best suited to segment medical images. We also underline the intrinsic differences deep learning methods have with other machine learning methods.},
	urldate = {2017-09-18},
	author = {Havaei, Mohammad and Guizard, Nicolas and Larochelle, Hugo and Jodoin, Pierre-Marc},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.05258},
}

@incollection{pai_characterization_2017,
	title = {Characterization of {Errors} in {Deep} {Learning}-{Based} {Brain} {MRI} {Segmentation}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/B9780128104088000134},
	urldate = {2017-09-18},
	booktitle = {Deep {Learning} for {Medical} {Image} {Analysis}},
	publisher = {Elsevier},
	author = {Pai, Akshay and Teng, Yuan-Ching and Blair, Joseph and Kallenberg, Michiel and Dam, Erik B. and Sommer, Stefan and Igel, Christian and Nielsen, Mads},
	year = {2017},
	doi = {10.1016/B978-0-12-810408-8.00013-4},
	pages = {223--242},
}

@article{Akkus2017,
	title = {Deep {Learning} for {Brain} {MRI} {Segmentation}: {State} of the {Art} and {Future} {Directions}},
	volume = {30},
	issn = {0897-1889},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/28577131},
	doi = {10.1007/s10278-017-9983-4},
	abstract = {Quantitative analysis of brain MRI is routine for many neurological diseases and conditions and relies on accurate segmentation of structures of interest. Deep learning-based segmentation approaches for brain MRI are gaining interest due to their self-learning and generalization ability over large amounts of data. As the deep learning architectures are becoming more mature, they gradually outperform previous state-of-the-art classical machine learning algorithms. This review aims to provide an overview of current deep learning-based segmentation approaches for quantitative brain MRI. First we review the current deep learning architectures used for segmentation of anatomical brain structures and brain lesions. Next, the performance, speed, and properties of deep learning approaches are summarized and discussed. Finally, we provide a critical assessment of the current state and identify likely future developments and trends.},
	number = {4},
	urldate = {2017-09-18},
	journal = {Journal of Digital Imaging},
	author = {Akkus, Zeynettin and Galimzianova, Alfiia and Hoogi, Assaf and Rubin, Daniel L. and Erickson, Bradley J.},
	month = aug,
	year = {2017},
	pmid = {28577131},
	keywords = {Brain lesion segmentation, Convolutional neural network, Deep learning, Quantitative brain MRI},
	pages = {449--459},
}

@article{Rueckert1999,
	title = {Nonrigid registration using free-form deformations: application to breast {MR} images},
	volume = {18},
	issn = {02780062},
	url = {http://ieeexplore.ieee.org/document/796284/},
	doi = {10.1109/42.796284},
	number = {8},
	urldate = {2017-09-18},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Rueckert, D. and Sonoda, L.I. and Hayes, C. and Hill, D.L.G. and Leach, M.O. and Hawkes, D.J.},
	year = {1999},
	pages = {712--721},
}

@article{Mooney2012,
	title = {Developing {X}-ray {Computed} {Tomography} to non-invasively image 3-{D} root systems architecture in soil},
	volume = {352},
	issn = {0032-079X},
	url = {http://link.springer.com/10.1007/s11104-011-1039-9},
	doi = {10.1007/s11104-011-1039-9},
	number = {1-2},
	urldate = {2017-09-18},
	journal = {Plant and Soil},
	author = {Mooney, S. J. and Pridmore, T. P. and Helliwell, J. and Bennett, M. J.},
	month = mar,
	year = {2012},
	note = {Publisher: Springer Netherlands},
	pages = {1--22},
}

@inproceedings{Ekin2011,
	title = {Pathology-robustmr intensity normalizationwith global and local constraints},
	isbn = {978-1-4244-4127-3},
	url = {http://ieeexplore.ieee.org/document/5872417/},
	doi = {10.1109/ISBI.2011.5872417},
	urldate = {2017-09-17},
	booktitle = {2011 {IEEE} {International} {Symposium} on {Biomedical} {Imaging}: {From} {Nano} to {Macro}},
	publisher = {IEEE},
	author = {Ekin, Ahmet},
	month = mar,
	year = {2011},
	pages = {333--336},
}

@article{Speier2011,
	title = {Robust skull stripping of clinical glioblastoma multiforme data.},
	volume = {14},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22003756},
	abstract = {Skull stripping is the first step in many neuroimaging analyses and its success is critical to all subsequent processing. Methods exist to skull strip brain images without gross deformities, such as those affected by Alzheimer's and Huntington's disease. However, there are no techniques for extracting brains affected by diseases that significantly disturb normal anatomy. Glioblastoma multiforme (GBM) is such a disease, as afflicted individuals develop large tumors that often require surgical resection. In this paper, we extend the ROBEX skull stripping method to extract brains from GBM images. The proposed method uses a shape model trained on healthy brains to be relatively insensitive to lesions inside the brain. The brain boundary is then searched for potential resection cavities using adaptive thresholding and the Random Walker algorithm corrects for leakage into the ventricles. The results show significant improvement over three popular skull stripping algorithms (BET, BSE and HWA) in a dataset of 48 GBM cases.},
	number = {Pt 3},
	urldate = {2017-09-17},
	journal = {Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
	author = {Speier, William and Iglesias, Juan E and El-Kara, Leila and Tu, Zhuowen and Arnold, Corey},
	year = {2011},
	pmid = {22003756},
	pages = {659--66},
}

@inproceedings{Diaz2011,
	title = {A critical review of the effects of de-noising algorithms on {MRI} brain tumor segmentation},
	isbn = {978-1-4577-1589-1},
	url = {http://ieeexplore.ieee.org/document/6090977/},
	doi = {10.1109/IEMBS.2011.6090977},
	urldate = {2017-09-17},
	booktitle = {2011 {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	publisher = {IEEE},
	author = {Diaz, I. and Boulanger, P. and Greiner, R. and Murtha, A.},
	month = aug,
	year = {2011},
	pages = {3934--3937},
}

@article{hu_skin_2009,
	title = {Skin segmentation based on graph cuts},
	volume = {14},
	issn = {1007-0214},
	url = {http://ieeexplore.ieee.org/document/6076238/},
	doi = {10.1016/S1007-0214(09)70106-3},
	number = {4},
	urldate = {2017-09-17},
	journal = {Tsinghua Science and Technology},
	author = {Hu, Zhilan and Wang, Guijin and Lin, Xinggang and Yan, Hong},
	month = aug,
	year = {2009},
	pages = {478--486},
}

@article{Valverde2015,
	title = {Comparison of 10 brain tissue segmentation methods using revisited {IBSR} annotations},
	volume = {41},
	issn = {10531807},
	url = {http://doi.wiley.com/10.1002/jmri.24517},
	doi = {10.1002/jmri.24517},
	number = {1},
	urldate = {2017-09-17},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Valverde, Sergi and Oliver, Arnau and Cabezas, Mariano and Roura, Eloy and Lladó, Xavier},
	month = jan,
	year = {2015},
	pages = {93--101},
}

@article{Slavl&,
	title = {A {Tight} {Analysis} of the {Greedy} {Algorithm} for {Set} {Cover}},
	abstract = {We establish significantly improved bounds on the perfor-mance of the greedy algorithm for approximating set cover. In particular, we provide the first substantial improvement of the 20 year old classical harmonic upper bound, H(m), of Johnson, Lovssz, and ChvAt al, by showing that the per-formance ratio of the greedy algorithm is, in fact, exactly in m – in ht m + Q(l), where m is the size of the ground set. The difference between the upper and lower bounds turns out to be less than 1.1. This provides the first tight ansJysis of the greedy algorithm, as well as the first upper bound that lies below H(m) by a function going to infinity with m. We also show that the approximation guarantee for the greedy algorithm is better than the guarantee recently estab-lished by Srinivasan for the randomized rounding technique, thus improving the bounds on the integralit{\textasciitilde} gap. Our improvements result from a new approach which might be generally useful for attacking other similar prob-lems.},
	urldate = {2017-09-15},
	author = {Slavl\&, Petr},
	keywords = {Approximation Algorithms, Fractional Set Cover, Greedy Algorithm, Partial Set Cover, Set Cover},
}

@article{Arulkumaran2017,
	title = {A {Brief} {Survey} of {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1708.05866},
	abstract = {Deep reinforcement learning is poised to revolutionise the field of AI and represents a step towards building autonomous systems with a higher level understanding of the visual world. Currently, deep learning is enabling reinforcement learning to scale to problems that were previously intractable, such as learning to play video games directly from pixels. Deep reinforcement learning algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of reinforcement learning, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep reinforcement learning, including the deep \$Q\$-network, trust region policy optimisation, and asynchronous advantage actor-critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via reinforcement learning. To conclude, we describe several current areas of research within the field.},
	urldate = {2017-09-13},
	author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.05866},
}

@article{grefenstette_fred_2013,
	title = {{FRED} ({A} {Framework} for {Reconstructing} {Epidemic} {Dynamics}): an open-source software system for modeling infectious diseases and control strategies using census-based populations},
	volume = {13},
	issn = {1471-2458},
	url = {http://bmcpublichealth.biomedcentral.com/articles/10.1186/1471-2458-13-940},
	doi = {10.1186/1471-2458-13-940},
	number = {1},
	urldate = {2017-06-12},
	journal = {BMC Public Health},
	author = {Grefenstette, John J and Brown, Shawn T and Rosenfeld, Roni and DePasse, Jay and Stone, Nathan TB and Cooley, Phillip C and Wheaton, William D and Fyshe, Alona and Galloway, David D and Sriram, Anuroop and Guclu, Hasan and Abraham, Thomas and Burke, Donald S},
	month = dec,
	year = {2013},
	pages = {940},
}

@article{nsoesie_sensitivity_2012,
	title = {Sensitivity {Analysis} of an {Individual}-{Based} {Model} for {Simulation} of {Influenza} {Epidemics}},
	volume = {7},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0045414},
	doi = {10.1371/journal.pone.0045414},
	abstract = {Mathematical and computational models provide valuable tools that help public health planners to evaluate competing health interventions, especially for novel circumstances that cannot be examined through observational or controlled studies, such as pandemic influenza. The spread of diseases like influenza depends on the mixing patterns within the population, and these mixing patterns depend in part on local factors including the spatial distribution and age structure of the population, the distribution of size and composition of households, employment status and commuting patterns of adults, and the size and age structure of schools. Finally, public health planners must take into account the health behavior patterns of the population, patterns that often vary according to socioeconomic factors such as race, household income, and education levels. FRED (a Framework for Reconstructing Epidemic Dynamics) is a freely available open-source agent-based modeling system based closely on models used in previously published studies of pandemic influenza. This version of FRED uses open-access census-based synthetic populations that capture the demographic and geographic heterogeneities of the population, including realistic household, school, and workplace social networks. FRED epidemic models are currently available for every state and county in the United States, and for selected international locations. State and county public health planners can use FRED to explore the effects of possible influenza epidemics in specific geographic regions of interest and to help evaluate the effect of interventions such as vaccination programs and school closure policies. FRED is available under a free open source license in order to contribute to the development of better modeling tools and to encourage open discussion of modeling tools being used to evaluate public health policies. We also welcome participation by other researchers in the further development of FRED.},
	number = {10},
	urldate = {2017-06-12},
	journal = {PLoS ONE},
	author = {Nsoesie, Elaine O. and Beckman, Richard J. and Marathe, Madhav V. and DePasse, Jay and Stone, Nathan TB and Cooley, Phillip C and Wheaton, William D and Fyshe, Alona and Galloway, David D and Sriram, Anuroop and Guclu, Hasan and Abraham, Thomas and Burke, Donald S and Burke, DS and Macken, CA and Burke, DS and Cooley, P},
	editor = {Vespignani, Alessandro},
	month = oct,
	year = {2012},
	note = {Publisher: BioMed Central},
	keywords = {Biostatistics, Environmental Health, Epidemiology, Medicine/Public Health, Public Health, Vaccine, general},
	pages = {e45414},
}

@inproceedings{taht_value_2014,
	address = {New York, New York, USA},
	title = {The value of repeatable experiments and negative results},
	isbn = {978-1-4503-2991-0},
	url = {http://dl.acm.org/citation.cfm?doid=2630088.2652480},
	doi = {10.1145/2630088.2652480},
	urldate = {2017-06-08},
	booktitle = {Proceedings of the 2014 {ACM} {SIGCOMM} workshop on {Capacity} sharing workshop - {CSWS} '14},
	publisher = {ACM Press},
	author = {Täht, Dave and {Dave}},
	year = {2014},
	keywords = {ARM, MIPS, OpenWrt, WiFi, active queue management, bufferbloat, codel, fq\_codel, linux, stochastic fair queuing},
	pages = {1--2},
}

@article{wu-chang_feng_blue_2002,
	title = {The {BLUE} active queue management algorithms},
	volume = {10},
	issn = {1063-6692},
	url = {http://ieeexplore.ieee.org/document/1026008/},
	doi = {10.1109/TNET.2002.801399},
	number = {4},
	urldate = {2017-06-07},
	journal = {IEEE/ACM Transactions on Networking},
	author = {Wu-chang Feng, Wu-chang and Shin, K.G. and Kandlur, D.D. and Saha, D.},
	month = aug,
	year = {2002},
	note = {Publisher: IEEE Press},
	keywords = {congestion control, fair queue, networks, queue management},
	pages = {513--528},
}

@article{Gettys2012,
	title = {Bufferbloat},
	volume = {55},
	issn = {00010782},
	url = {http://dl.acm.org/citation.cfm?doid=2063176.2063196},
	doi = {10.1145/2063176.2063196},
	number = {1},
	urldate = {2017-06-06},
	journal = {Communications of the ACM},
	author = {Gettys, Jim and Nichols, Kathleen},
	month = jan,
	year = {2012},
	note = {Publisher: ACM},
	pages = {57},
}

@inproceedings{pan_pie:_2013,
	title = {{PIE}: {A} lightweight control scheme to address the bufferbloat problem},
	isbn = {978-1-4673-4620-7},
	url = {http://ieeexplore.ieee.org/document/6602305/},
	doi = {10.1109/HPSR.2013.6602305},
	urldate = {2017-06-06},
	booktitle = {2013 {IEEE} 14th {International} {Conference} on {High} {Performance} {Switching} and {Routing} ({HPSR})},
	publisher = {IEEE},
	author = {Pan, Rong and Natarajan, Preethi and Piglione, Chiara and Prabhu, Mythili Suryanarayana and Subramanian, Vijay and Baker, Fred and VerSteeg, Bill},
	month = jul,
	year = {2013},
	pages = {148--155},
}

@article{Floyd1991,
	title = {Traffic phase effects in packet-switched gateways},
	volume = {21},
	issn = {01464833},
	url = {http://portal.acm.org/citation.cfm?doid=122419.122421},
	doi = {10.1145/122419.122421},
	abstract = {Much of the traffic in existing packet networks is highly periodic, either because of periodic sources (e.g., real time speech or video, rate control) or because window flow control protocols have a periodic cycle equal to the connection roundtrip time (e.g., a network-bandwidth limited TCP bulk data transfer). Control theory suggests that this periodicity can resonate (i.e., have a strong, non-linear interaction) with deterministic control algorithms in network gateways. In this paper we define the notion of traffic phase in a packet-switched network and describe how phase differences between competing traffic streams can be the dominant factor in relative throughput. Drop Tail gateways in a TCP/IP network with strongly periodic traffic can result in systematic discrimination against some connections. We demonstrate this behavior with both simulations and theoretical analysis. This discrimination can be eliminated with the addition of appropriate randomization to the network. In particular, analysis suggests that simply coding a gateway to drop a random packet from its queue on overflow, rather than dropping the tail, is often sufficient. We do not claim that Random Drop gateways solve all of the problems of Drop Tail gateways. Biases against bursty traffic and long roundtrip time connections are shared by both DropTail and Random Drop gateways. Correcting the bursty traffic bias has led us to investigate a different kind of randomized gateway algorithm that operates on the traffic stream, rather than on the queue. Preliminary results show that the Random Early Detection gateway, a newly developed gateway congestion avoidance algorithm, corrects this bias against bursty traffic. The roundtrip time bias in TCP/IP networks results from the TCP window increase algorithm, not from the gateway dropping policy, and we briefly discuss changes to the window increase algorithm that could eliminate this bias.},
	number = {2},
	urldate = {2017-06-06},
	journal = {ACM SIGCOMM Computer Communication Review},
	author = {Floyd, Sally and Jacobson, Van},
	month = apr,
	year = {1991},
	note = {Publisher: ACM
ISBN: 0146-4833},
	pages = {26--42},
}

@article{Hollot2002,
	title = {Analysis and design of controllers for {AQM} routers supporting {TCP} flows},
	volume = {47},
	issn = {00189286},
	url = {http://ieeexplore.ieee.org/document/1008360/},
	doi = {10.1109/TAC.2002.1008360},
	abstract = {In active queue management (AQM), core routers signal transmission control protocol (TCP) sources with the objective of managing queue utilization and delay. It is essentially a feedback control problem. Based on a recently developed dynamic model of TCP congestion-avoidance mode, this paper does three things: 1) it relates key network parameters such as the number of TCP sessions, link capacity and round-trip time to the underlying feedback control problem; 2) it analyzes the present de facto AQM standard: random early detection (RED) and determines that REDs queue-averaging is not beneficial; and 3) it recommends alternative AQM schemes which amount to classical proportional and proportional-integral control. We illustrate our results using ns simulations and demonstrate the practical impact of proportional-integral control on managing queue utilization and delay},
	number = {6},
	urldate = {2017-06-06},
	journal = {IEEE Transactions on Automatic Control},
	author = {Hollot, C. V. and Misra, Vishal and Towsley, Donald and Gong, Weibo},
	month = jun,
	year = {2002},
	note = {ISBN: 0-7803-7016-3},
	keywords = {Computer networks, Feedback control, Parametric robustness, Stability, Time delay},
	pages = {945--959},
}

@article{Athuraliya2001,
	title = {{REM}: {Active} queue management},
	volume = {15},
	issn = {08908044},
	url = {http://ieeexplore.ieee.org/document/923940/},
	doi = {10.1109/65.923940},
	abstract = {We describe a new active queue management scheme, random exponential marking (REM), that aims to achieve both high utilization and negligible loss and delay in a simple and scalable manner. The key idea is to decouple the congestion measure from the performance measure such as loss, queue length, or delay. While the congestion measure indicates excess demand for bandwidth and must track the number of users, the performance measure should be stabilized around their targets independent of the number of users. We explain the design rationale behind REM and present simulation results of its performance in wireline and wireless networks},
	number = {3},
	urldate = {2017-06-03},
	journal = {IEEE Network},
	author = {Athuraliya, Sanjeewa and Low, Steven H. and Li, Victor H. and Yin, Qinghe},
	year = {2001},
	note = {Publisher: IEEE Press},
	pages = {48--53},
}

@article{Floyd1993,
	title = {Random {Early} {Detection} {Gateways} for {Congestion} {Avoidance}},
	volume = {1},
	issn = {15582566},
	url = {http://dl.acm.org/citation.cfm?id=169935},
	doi = {10.1109/90.251892},
	abstract = {The authors present random early detection (RED) gateways for{\textbackslash}ncongestion avoidance in packet-switched networks. The gateway detects{\textbackslash}nincipient congestion by computing the average queue size. The gateway{\textbackslash}ncould notify connections of congestion either by dropping packets{\textbackslash}narriving at the gateway or by setting a bit in packet headers. When the{\textbackslash}naverage queue size exceeds a present threshold, the gateway drops or{\textbackslash}nmarks each arriving packet with a certain probability, where the exact{\textbackslash}nprobability is a function of the average queue size. RED gateways keep{\textbackslash}nthe average queue size low while allowing occasional bursts of packets{\textbackslash}nin the queue. During congestion, the probability that the gateway{\textbackslash}nnotifies a particular connection to reduce its window is roughly{\textbackslash}nproportional to that connection's share of the bandwidth through the{\textbackslash}ngateway. RED gateways are designed to accompany a transport-layer{\textbackslash}ncongestion control protocol such as TCP. The RED gateway has no bias{\textbackslash}nagainst bursty traffic and avoids the global synchronization of many{\textbackslash}nconnections decreasing their window at the same time. Simulations of a{\textbackslash}nTCP/IP network are used to illustrate the performance of RED gateways{\textbackslash}n},
	number = {4},
	urldate = {2017-06-03},
	journal = {IEEE/ACM Transactions on Networking},
	author = {Floyd, Sally and Jacobson, Van},
	year = {1993},
	note = {ISBN: 1063-6692},
	pages = {397--413},
}

@article{May1999,
	title = {Reasons not to deploy {RED}},
	url = {http://ieeexplore.ieee.org/document/766502/},
	doi = {10.1109/IWQOS.1999.766502},
	abstract = {In this paper we examine the benefits of random early detection{\textbackslash}n(RED) by using a testbed made of two commercially available routers and{\textbackslash}nup to 16 PCs to observe RED performance under a traffic load made of FTP{\textbackslash}ntransfers, together with HTTP traffic and non-responsive UDP flows. The{\textbackslash}nmain results we found were, first, that RED with small buffers does not{\textbackslash}nimprove significantly the performance of the network, in particular the{\textbackslash}noverall throughput is smaller than with tail drop and the difference in{\textbackslash}ndelay is not significant. Second, parameter tuning in RED remains an{\textbackslash}ninexact science, but has no big impact on the end-to-end performance. We{\textbackslash}nargue that RED deployment is not straightforward, and we strongly{\textbackslash}nrecommend more research with realistic network settings to develop a{\textbackslash}nfull quantitative understanding of RED. Nevertheless, RED allows us to{\textbackslash}ncontrol the queue size with large buffers},
	urldate = {2017-06-03},
	journal = {1999 Seventh International Workshop on Quality of Service. IWQoS'99. (Cat. No.98EX354)},
	author = {May, M. and Bolot, J. and Diot, C. and Lyles, B.},
	year = {1999},
	note = {Publisher: IEEE
ISBN: 0-7803-5671-3},
	pages = {0--2},
}

@article{vishwanath_perspectives_2009,
	title = {Perspectives on router buffer sizing},
	volume = {39},
	issn = {01464833},
	url = {http://portal.acm.org/citation.cfm?doid=1517480.1517487},
	doi = {10.1145/1517480.1517487},
	abstract = {The past few years have witnessed a lot of debate on how large Internet router buffers should be. The widely believed rule-of- thumb used by router manufacturers today mandates a buffer size equal to the delay-bandwidth product. This rule was first challenged by researchers in 2004 who argued that if there are a large number of long-lived TCP connections flowing through a router, then the buffer size needed is equal to the delay- bandwidth product divided by the square root of the number of long-lived TCP flows. The publication of this result has since reinvigorated interest in the buffer sizing problem with numerous other papers exploring this topic in further detail - ranging from papers questioning the applicability of this result to proposing alternate schemes to developing new congestion control algorithms, etc. This paper provides a synopsis of the recently proposed buffer sizing strategies and broadly classifies them according to their desired objective: link utilisation, and per-flow per- formance. We discuss the pros and cons of these different approaches. These prior works study buffer sizing purely in the context of TCP. Subsequently, we present arguments that take into account both real-time and TCP traffic. We also report on the performance studies of various high-speed TCP variants and experimental results for networks with limited buffers. We conclude this paper by outlining some interesting avenues for further research.},
	number = {2},
	urldate = {2017-06-03},
	journal = {ACM SIGCOMM Computer Communication Review},
	author = {Vishwanath, Arun and Sivaraman, Vijay and Thottan, Marina},
	month = mar,
	year = {2009},
	note = {Publisher: ACM},
	keywords = {buffer size, mixed real-time and tcp, optical, survey, traffic},
	pages = {34},
}

@inproceedings{Han2016,
	title = {Optimal active queue management for internet with reduced-order state-observer},
	isbn = {978-1-4673-9714-8},
	url = {http://ieeexplore.ieee.org/document/7531178/},
	doi = {10.1109/CCDC.2016.7531178},
	urldate = {2017-06-03},
	booktitle = {2016 {Chinese} {Control} and {Decision} {Conference} ({CCDC})},
	publisher = {IEEE},
	author = {Han, Cunwu and Diao, Qi and Chang, Shurui and Bi, Song and Liu, Lei and Pang, Zhonghua},
	month = may,
	year = {2016},
	pages = {1260--1263},
}

@article{Marami2009,
	title = {Implementation of {MPC} as an {AQM} controller},
	volume = {33},
	doi = {10.1016/j.comcom.2009.09.001},
	abstract = {a b s t r a c t Utilizing model predictive controllers (MPC) as an active queue management scheme is investigated in this paper. Model based prediction of future output and determining optimized value of the control signal have made MPC as an advanced control strategy in various modern control systems. In this paper a new approach is proposed to alleviate the computational complexity of MPC in order to implement in fast dynamics systems like computer networks. Neural network approximation of MPC as an active queue management (AQM) method implemented here not only has less computational burden with respect to the common MPC approaches, but also results in better performance compare to the well-known AQM methods such as random early detection (RED) and proportional-integral (PI) control. The proposed AQM approach is implemented in a field-programmable gate array (FPGA) system and its feasibility is investigated by timing analysis.},
	urldate = {2017-06-03},
	journal = {Computer Communications},
	author = {Marami, Bahram and Haeri, Mohammad},
	year = {2009},
	keywords = {Active queue management, FPGA timing analysis, Model predictive control, Neural network approximator},
	pages = {227--239},
}

@article{Janouchov??2013,
	title = {Competitive comparison of optimal designs of experiments for sampling-based sensitivity analysis},
	issn = {00457949},
	doi = {10.1016/j.compstruc.2013.04.009},
	abstract = {A widely used strategy to explore the sensitivity of the model to its inputs is based on a finite set of simulations. These are usually performed for a chosen set of points in a parameter space. An estimate of the sensitivity can be then obtained by computing correlations between the model inputs and outputs. The accuracy of the sensitivity prediction depends on a quality of the points distribution in the parameter space, so-called the design of experiments. The aim of the presented paper is to review and compare available criteria determining an optimal design of experiments for sampling-based sensitivity analysis. ?? 2013 Elsevier Ltd.},
	journal = {Computers and Structures},
	author = {Janouchov??, Eli??ka and Ku??erov??, Anna},
	year = {2013},
	note = {arXiv: 1201.0942
ISBN: 0045-7949},
	keywords = {Design of experiments, Latin hypercube sampling, Orthogonality, Sampling-based sensitivity analysis, Space-filling},
}

@article{Adams2013,
	title = {Active {Queue} {Management}: {A} {Survey}},
	volume = {15},
	issn = {1553-877X},
	url = {http://ieeexplore.ieee.org/document/6329367/},
	doi = {10.1109/SURV.2012.082212.00018},
	abstract = {Since its formal introduction to IP networks in 1993 as a viable complementary approach for congestion control, there has been a steady stream of research output with respect to Active Queue Management (AQM). This survey attempts to travel the trajectory of AQM research from 1993 with the first algorithm, Random Early Detection (RED), to current work in 2011. In this survey we discuss the general attributes of AQM schemes, and the design approaches taken such as heuristic, control-theoretic and deterministic optimization. Of interest is the role of AQM in QoS provisioning particularly in the DiffServ context, as well as the role of AQM in the wireless domain. For each section, example algorithms from the research literature are presented.},
	number = {3},
	urldate = {2017-05-25},
	journal = {IEEE Communications Surveys \& Tutorials},
	author = {Adams, Richelle},
	year = {2013},
	pages = {1425--1476},
}

@article{Floyd2001,
	title = {Adaptive {RED}: {An} algorithm for increasing the robustness of {RED}'s active queue management},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.2841},
	urldate = {2017-05-25},
	journal = {Icsi},
	author = {Floyd, Sally and Gummadi, Ramakrishna and Shenker, Scott},
	year = {2001},
	pages = {1--12},
}

@misc{noauthor_paper_nodate,
	title = {Paper - {QoE}: {As} {Easy} {As} {PIE} - {NCTA} {Technical} {Papers}},
	url = {http://www.nctatechnicalpapers.com/Paper/2013/2013-qoe-as-easy-as-pie},
	urldate = {2017-05-25},
}

@article{nichols_controlling_2012,
	title = {Controlling queue delay},
	volume = {55},
	issn = {00010782},
	url = {http://dl.acm.org/citation.cfm?doid=2208917.2209336},
	doi = {10.1145/2209249.2209264},
	abstract = {A modern AQM is just one piece of the solution to bufferbloat.},
	number = {7},
	urldate = {2017-05-25},
	journal = {Communications of the ACM},
	author = {Nichols, Kathleen and Jacobson, Van},
	month = may,
	year = {2012},
	note = {Publisher: ACM
ISBN: 1542-7730},
	pages = {42},
}

@book{koza_genetic_1996,
	title = {Genetic programming : proceedings of the first annual conference, 1996},
	isbn = {0-262-61127-9},
	url = {https://dl.acm.org/citation.cfm?id=1595583},
	abstract = {"July 28-31, 1996, Stanford University." "A Bradford Book." Discovery by genetic programming of a cellular automata rule that is better than any known rule for the majority classification problem / David Andre, Forrest H. Bennett, John R. Koza -- A study in program response and the negative effects of introns in genetic programming / David Andre, Astro Teller -- An investigation into the sensitivity of genetic programming to the frequency of leaf selection during subtree crossover / Peter J. Angeline -- Automatic creation of an efficient multi-agent architecture using genetic programming with architecture-altering operations / Forrest H. Bennett -- Evolving deterministic finite automata using cellular encoding / Scott Brave -- Genetic programming and the efficient market hypothesis / Shu-Heng Chen, Chia-Hsuan Yeh -- Bargaining by artificial agents in two coalition games / Garett Dworman, Steven O. Kimbrough, James D. Laing -- Waveform recognition using genetic programming / Jaime J. Fernandez, Kristin A. Farry, John B. Cheatham -- Benchmarking the ceneralization capabilities of a compiling genetic programming system using sparse data sets / Frank D. Francone, Peter Nordin, Wolfgang Banzhaf -- A comparison between cellular encoding and direct encoding for genetic neural networks / Frederic Gruau, Darrell Whitley, Larry Pyeatt -- Entailment for specification refinement / Thomas Haynes [and others] -- Genetic programming of near-minimum-time spacecraft attitude maneuvers / Brian Howley -- Evolving evolution programs / Christian Jacob -- Genetic programming using genotype-phenotype mapping from linear genomes into linear phenotypes / Robert E. Keller, Wolfgang Banzhaf -- Automated WYWIWYG design of both the topology and component values of electrical circuits using genetic programming / John R. Koza [and others] -- Use of automatically defined functions and architecture-altering operations in automated circuit synthesis with genetic programming / John R. Koza [and others] -- Using data structures within genetic programming / W.B. Langdon -- Evolving teamwork and coordination with genetic programming / Sean Luke, Lee Spector -- Using genetic programming to develop Inferential Estimation Algorithms / Ben McKay [and others] -- Dynamics of genetic programming and chaotic time series prediction / Brian S. Mulloy, Rick L. Riolo, Robert S. Savit -- Genetic programming, the reflection of chaos, and the bootstrap / E. Howard N. Oakley -- Solving facility layout problems using genetic programming / Jaime Garces-Perez, Dale A. Schoenefeld, Roger L. Wainwright -- Variations in evolution of subsumption architectures using genetic programming / Steven J. Ross [and others] -- MASSON / Tae-Wan Ryu, Christoph F. Eick -- Cultural transmission of information in genetic programming / Lee Spector, Sean Luke -- Code growth in genetic programming / Terence Soule, James A. Foster, John Dickinson -- High-performance, parallel, stack-based genetic programming / Kilian Stoffel, Lee Spector -- Search bias, language bias, and genetic programming / P.A. Whigham -- Learning recursive functions from noisy examples using generic genetic programming / Man Leung Wong, Kwong Sak Leung -- Classification using cultural co-evolution and genetic programming / Myriam Z. Abramson, Lawrence Hunter -- Type-constrained genetic programming for rule-base definition in fuzzy logic controllers / Enrique Alba, Carlos Cotta, Jose M. Troya -- The evolution of memory and mental models using genetic programming / Scott Brave -- Automatic generation of object-oriented programs using genetic programming / Wilker Shane Bruce -- Evolving event-driven programs / Mark Crosbie, Eugene H. Spafford -- Computer-assisted design of image classification algorithms / Jason M. Daida [and others] -- Improved direct acyclic graph evaluation and the combine operator in genetic programming / Herman Ehrenberg -- An adverse interaction between crossover and restricted tree depth in genetic programming / Chris Gathercole, Peter Ross -- The prediction of the degree of exposure to solvent of amino acid residues via genetic programming / Simon Handley -- A new class of function sets for solving sequence problems / Simon Handley -- Evolving edge detectors with genetic programming / Christopher Harris, Bernard Buxton -- Toward simulated evolution of machine language iteration / Lorenz Huelsbergen -- Robustness of robot programs generated by genetic programming / Takuya Ito, Hitoshi Iba, Masayuki Kimura -- Signal path oriented approach for generation of dynamic process models / Peter Marenbach, Kurt D. Bettenhausen, Stephan Freyer -- Evolving control laws for a network of traffic signals / David J. Montana, Steven Czerwinski -- Distributed genetic programming / Tatsuya Niwa, Hitoshi Iba -- Programmatic compression of images and sound / Peter Nordin, Wolfgang Banzhaf -- Investigating the generality of automatically defined functions / Una-May O'Reilly -- Parallel genetic programming / Mouloud Oussaidene [and others] -- Genetic programming for image analysis / Riccardo Poli -- Evolving agents / Adil Qureshi -- Genetic programming for improved data mining / M.L. Raymer [and others] -- Generality versus size in genetic programming / Justinian P. Rosca -- Genetic programming in database query optimization / Michael Stillger, Myra Spiliopoulou -- Ontogenetic programming / Lee Spector, Kilian Stoffel -- Using genetic programming to approximate maximum clique / Terence Soule, James A. Foster, John Dickinson -- Paragen / Paul Walsh, Conor Ryan -- The benefits of computing with introns / Mark Wineberg, Franz Oppacher -- Co-evolving hierarchical programs using genetic programming / Manu Ahluwalia, Terence C. Fogarty -- Genetic programming tools available on the web / Anthony G. Deakin, Derek F. Yates -- Speeding up genetic programming / Dimitris C. Dracopoulos, Simon Kent -- Easy inverse kinematics using genetic programming / Jonathan Gibbs -- Noisy wall following and maze navigation through genetic programming / Andrew Goldish -- Genetic programming classification of magnetic resonance data / H.F. Gray [and others] -- GP-COM / Christopher Harris, Bernard Buxton -- Clique detection via genetic programming / Thomas Haynes, Dale Schoenefeld -- Functional languages on linear chromosomes / Paul Holmes, Peter J. Barclay -- Improving the accuracy and robustness of genetic programming through expression simplification / Dale C. Hooper, Nicholas S. Flann -- COAST / Naohiro Hondo, Hitoshi Iba, Yukinori Kakazu -- Recurrences with fixed base cases in genetic programming / Stefan J. Johansson -- Evolutionary and incremental methods to solve hard learning problems / Ibrahim Kuscu -- Detection of patterns in radiographs using ANN designed and trained with the genetic algorithm / Alejandro Pazos, Julian Dorado, Antonino Santos -- The logic-grammars-based genetic programming system / Man Leung Wong, Kwong Sak Leung -- Genetic algorithms with analytical solution / Erol Gelenbe -- Silicon evolution / Adrian Thompson -- On sensor evolution in robotics / Karthik Balakrishnan, Vasant Honavar -- Testing software using order-based genetic algorithms / Edward B. Boden, Gilford F. Martino -- Optimizing local area networks using genetic algorithms / Andy Choi -- A genetic algorithm for the construction of small and highly testable OKFDD circuits / Rolf Drechsler, Bernd Becker, Nicole Gockel -- Motion planning and design of CAM mechanisms by means of a genetic algorithm / Rodolfo Faglia, David Vetturi -- Evolving strategies based on the nearest-neighbor rule and a genetic algorithm / Matthias Fuchs -- Recognition and reconstruction of visibility graphs using a genetic algorithm / Marshall S. Veach -- The use of genetic algorithms in the optimization of competitive neural networks which resolve the stuck vectors problem / Tin Ilakovac, Zeljka Perkovic, Strahil Ristov -- An extraction method of a car license plate using a distributed genetic algorithm / Dae Wook Kim, Sang Kyoon Kim, Hang Joon Kim -- Evolving fractal movies / Peter J. Angeline -- Preliminary experiments on discriminating between chaotic signals and noise using evolutionary programming / David B. Fogel, Lawrence J. Fogel -- Discovering patterns in spatial data using evolutionary programming / Adam Ghozeil, David B. Fogel -- Evolving reduced parameter bilinear models for time series prediction using fast evolutionary programming / Sathyanarayan S. Rao, Kumar Chellapilla -- Three-dimensional shape optimization utilizing a learning classifier system / Robert A. Richards, Sheri D. Sheppard -- Classifier system renaissance / H. Brown Cribbs, Robert E. Smith -- Natural niching for evolving cooperative classifiers / Jeffrey Horn, David E. Goldberg.},
	urldate = {2017-05-23},
	publisher = {MIT Press},
	author = {Koza, John R. and Iba, Hitoshi},
	year = {1996},
	note = {Publication Title: Proceedings of the 1st annual conference on genetic programming},
}

@article{salhi_parallel_1998,
	title = {Parallel implementation of a genetic-programming based tool for symbolic regression},
	volume = {66},
	issn = {00200190},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0020019098000568},
	doi = {10.1016/S0020-0190(98)00056-8},
	number = {6},
	urldate = {2017-05-22},
	journal = {Information Processing Letters},
	author = {Salhi, A. and Glaser, H. and De Roure, D.},
	month = jun,
	year = {1998},
	pages = {299--307},
}

@book{fortin_deap_2001,
	title = {{DEAP} {Python} framework {Evolutionary} algorithms},
	volume = {13},
	url = {https://dl.acm.org/citation.cfm?id=2503311},
	abstract = {Vol. 5 onward called also Print-archive edition and represents articles already published online. Issues for 2005- published by Microtome publishing.},
	urldate = {2017-05-22},
	publisher = {MIT Press},
	author = {Fortin, Félix-Antoine and De Rainville, François-Michel and Gardner, Marc-André Gardner and Parizeau, Marc and Gagné, Christian},
	year = {2001},
	note = {Publication Title: The Journal of Machine Learning Research
Issue: 1
ISSN: 1532-4435},
	keywords = {distributed evolutionary algorithms, software tools},
}

@incollection{dostal_modularity_2013,
	title = {Modularity in {Genetic} {Programming}},
	url = {http://link.springer.com/10.1007/978-3-642-30504-7_15},
	urldate = {2017-05-22},
	publisher = {Springer Berlin Heidelberg},
	author = {Dostál, Martin},
	year = {2013},
	doi = {10.1007/978-3-642-30504-7_15},
	pages = {365--393},
}

@incollection{veenhuis_structure-based_2013,
	title = {Structure-{Based} {Constants} in {Genetic} {Programming}},
	url = {http://link.springer.com/10.1007/978-3-642-40669-0_12},
	urldate = {2017-05-22},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Veenhuis, Christian B.},
	year = {2013},
	doi = {10.1007/978-3-642-40669-0_12},
	pages = {126--137},
}

@inproceedings{mcdermott_genetic_2012,
	address = {New York, New York, USA},
	title = {Genetic programming needs better benchmarks},
	isbn = {978-1-4503-1177-9},
	url = {http://dl.acm.org/citation.cfm?doid=2330163.2330273},
	doi = {10.1145/2330163.2330273},
	urldate = {2017-05-22},
	booktitle = {Proceedings of the fourteenth international conference on {Genetic} and evolutionary computation conference - {GECCO} '12},
	publisher = {ACM Press},
	author = {McDermott, James and De Jong, Kenneth and O'Reilly, Una-May and White, David R. and Luke, Sean and Manzoni, Luca and Castelli, Mauro and Vanneschi, Leonardo and Jaskowski, Wojciech and Krawiec, Krzysztof and Harper, Robin},
	year = {2012},
	keywords = {benchmarks, genetic programming},
	pages = {791},
}

@incollection{korns_abstract_2011,
	title = {Abstract {Expression} {Grammar} {Symbolic} {Regression}},
	url = {http://link.springer.com/10.1007/978-1-4419-7747-2_7},
	urldate = {2017-05-22},
	publisher = {Springer New York},
	author = {Korns, Michael F.},
	year = {2011},
	doi = {10.1007/978-1-4419-7747-2_7},
	pages = {109--128},
}

@article{pillay_genetic_2007,
	title = {A {Genetic} {Programming} {Approach} to the {Generation} of {Hyper}-{Heuristics} for the {Uncapacitated} {Examination} {Timetabling} {Problem}},
	issn = {03029743},
	doi = {doi:10.1007/978-3-540-77002-2_19},
	abstract = {Research in the field of examination timetabling has developed in two directions. The first looks at applying various methodologies to induce examination timetables. The second takes an indirect approach to the problem and examines the generation of heuristics or combinations of heuristics, i.e. hyper-heuristics, to be used in the construction of examination timetables. The study presented in this paper focuses on the latter area. This paper presents a first attempt at using genetic programming for the evolution of hyper-heuristics for the uncapacitated examination timetabling problem. The system has been tested on 9 benchmark examination timetabling problems. Clash-free timetables were found for all 9 nine problems. Furthermore, the performance of the genetic programming system is comparable to, and in a number of cases has produced better quality timetables, than other search algorithms used to evolve hyper-heuristics for this set of problems.},
	journal = {LNAI},
	author = {Pillay, Nelishia and Banzhaf, Wolfgang},
	year = {2007},
	note = {ISBN: 9783540770008},
	keywords = {examination timetabling, genetic programming, hyper-heuristics},
}

@article{jafer_synchronization_2013,
	title = {Synchronization methods in parallel and distributed discrete-event simulation},
	issn = {1569190X},
	doi = {10.1016/j.simpat.2012.08.003},
	abstract = {This work attempts to provide insight into the problem of executing discrete event simulation in a distributed fashion. The article serves as the state of the art in Parallel Discrete- Event Simulation (PDES) by surveying existing algorithms and analyzing the merits and drawbacks of various techniques. We discuss the main characteristics of existing synchronization methods for parallel and distributed discrete event simulation. The two major categories of synchronization protocols, namely conservative and optimistic, are introduced and various approaches within each category are presented. We also present the latest efforts towards PDES on emerging platforms such as heterogeneous multicore processors, Web services, as well as Grid and Cloud environment. ?? 2012 Elsevier B.V. All rights reserved.},
	journal = {Simulation Modelling Practice and Theory},
	author = {Jafer, Shafagh and Liu, Qi and Wainer, Gabriel},
	year = {2013},
	note = {ISBN: 1569-190X},
	keywords = {Conservative approach, Discrete-event simulation, Optimistic mechanism},
}

@article{poli_free_2009,
	title = {Free lunches for function and program induction},
	doi = {10.1145/1527125.1527148},
	abstract = {In this paper we prove that for a variety of practical{\textbackslash}nproblems and representations, there is a free lunch for{\textbackslash}nsearch algorithms that specialise in the task of{\textbackslash}nfinding functions or programs that solve problems, such{\textbackslash}nas genetic programming. In other words, not all such{\textbackslash}nalgorithms are equally good under all possible{\textbackslash}nperformance measures. We focus in particular on the{\textbackslash}ncase where the objective is to discover functions that{\textbackslash}nfit sets of data-points a task that we will call{\textbackslash}nsymbolic regression. We show under what conditions{\textbackslash}nthere is a free lunch for symbolic regression,{\textbackslash}nhighlighting that these are extremely restrictive.},
	journal = {Proceedings of the tenth ACM SIGEVO …},
	author = {Poli, Riccardo and Graff, Mario and McPhee, NF},
	year = {2009},
	note = {ISBN: 9781605584140},
	keywords = {a prob-, a sample search space, an assignment of fitness, e, figure 1, genetic programming, i, lem, no-free lunch, theory, to the elements of, top left},
}

@incollection{poli_there_2009,
	title = {There {Is} a {Free} {Lunch} for {Hyper}-{Heuristics}, {Genetic} {Programming} and {Computer} {Scientists}},
	isbn = {978-3-642-01180-1},
	url = {http://link.springer.com/10.1007/978-3-642-01181-8_17},
	urldate = {2017-05-13},
	booktitle = {Proceedings of the 12th {European} {Conference} on {Genetic} {Programming}},
	publisher = {Springer-Verlag},
	author = {Poli, Riccardo and Graff, Mario},
	year = {2009},
	doi = {10.1007/978-3-642-01181-8_17},
	pages = {195--207},
}

@article{cardoen_pdevs_2017,
	title = {A {PDEVS} {Simulator} {Supporting} {Multiple} {Synchronization} {Protocols} : {Implementation} and {Performance} {Analysis}},
	doi = {10.1177/0037549717690826},
	abstract = {See, stats, and : https : / / www . researchgate . net / publication / 313874064 A synchronization : implementation performance Article : Transactions DOI : 10 . 1177 / 0037549717690826 CITATIONS 0 READS 37 4 , including : Ben University 2 SEE Stijn University 2 SEE Jan University 201 , 443 SEE All . The . All - text and , letting . Abstract With the ever increasing complexity of simulation mod - els , parallel simulation becomes necessary to perform simulation within reasonable time bounds . The built - in parallelism of Parallel DEVS is often insufficient to tackle this problem on its own . Several synchronization pro - tocols have been proposed , each with their distinct ad - vantages and disadvantages . Due to the significantly dif - ferent implementation of these protocols , most Parallel DEVS simulation tools are limited to only one such pro - tocol . In this paper , we present a Parallel DEVS simula - tor , grafted on C++11 and based on PythonPDEVS , sup - porting both conservative and optimistic synchronization protocols . The simulator not only supports both proto - cols but also has the capability to switch between them at runtime . The simulator can combine each synchroniza - tion protocols with either a threaded or sequential imple - mentation of the PDEVS protocol . We evaluate the per - formance gain obtained by choosing the most appropriate synchronization protocol . A comparison is made to adevs in terms of CPU time and memory usage , to show that our modularity does not hinder performance . We com - pare the speedup obtained by synchronization with that of the inherent parallelism of PDEVS in isolation and com - bination , and contrast the results with the theoretical lim - its . We further allow for an external component to gather simulation statistics , on which runtime switching between the different synchronization protocols can be based . The effects of allocation on our synchronization protocols is also studied .},
	author = {Cardoen, Ben and Manhaeve, Stijn and Tendeloo, Yentl Van and Broeckhove, Jan},
	year = {2017},
}

@inproceedings{cardoen_performance_2016,
	title = {Performance analysis of a {PDEVS} simulator supporting multiple synchronization protocols},
	abstract = {©2016 Society for Modeling \& Simulation International (SCS).With the ever increasing complexity of simulation models, parallel simulation becomes necessary to perform the simulation within reasonable time bounds. The built-in parallelism of Parallel DEVS is often insufficient to tackle this problem on its own. Several synchronization protocols have been proposed, each with their distinct advantages and disadvantages. Due to the significantly different implementation of these protocols, most Parallel DEVS simulation tools are limited to only one such protocol. In this paper, we present a Parallel DEVS simulator, grafted on C++11, but based on PythonPDEVS, which supports both conservative and optimistic synchronization. We evaluate the performance gain obtained by choosing the most appropriate synchronization protocol. Performance results are compared to adevs, in terms of CPU time and memory usage.},
	booktitle = {Proceedings of the 2016 {Spring} {Simulation} {Multiconference} - {TMS}/{DEVS} {Symposium} on {Theory} of {Modeling} and {Simulation}, {TMS}/{DEVS} 2016},
	author = {Cardoen, B. and Manhaeve, S. and Tuijn, T. and Van Tendeloo, Y. and Vanmechelen, K. and Vangheluwe, H. and Broeckhove, J.},
	year = {2016},
	keywords = {Conservative synchronization, Optimistic synchronization, Parallel DEVS, Performance, Simulation},
}
